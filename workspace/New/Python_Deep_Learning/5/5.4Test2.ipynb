{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T01:58:44.387417Z",
     "start_time": "2019-07-29T01:58:44.355816Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras import layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:00:48.618378Z",
     "start_time": "2019-07-29T02:00:46.863679Z"
    }
   },
   "outputs": [],
   "source": [
    "model=load_model('F:\\\\study\\\\ml\\\\DataSet\\\\dogs_vs_cats\\\\cats_and_dogs_small\\\\models\\\\cats_and_dogs_small_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:00:55.706925Z",
     "start_time": "2019-07-29T02:00:55.675725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:05:11.091502Z",
     "start_time": "2019-07-29T02:05:11.075902Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path='F:\\\\study\\\\ml\\\\DataSet\\\\dogs_vs_cats\\\\cats_and_dogs_small\\\\test\\\\cats\\\\cat.1700.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:05:11.680729Z",
     "start_time": "2019-07-29T02:05:11.665129Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:10:56.645946Z",
     "start_time": "2019-07-29T02:10:56.618346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(img_path,target_size=(150,150))\n",
    "img_tensor=image.img_to_array(img)\n",
    "img_tensor=np.expand_dims(img_tensor,axis=0)\n",
    "img_tensor /=255.\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:11:39.991450Z",
     "start_time": "2019-07-29T02:11:39.931847Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:12:06.530563Z",
     "start_time": "2019-07-29T02:12:06.514963Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(img_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T06:13:53.726332Z",
     "start_time": "2019-07-29T06:13:53.714332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_9/Relu:0' shape=(?, 148, 148, 32) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T06:16:00.329574Z",
     "start_time": "2019-07-29T06:16:00.145563Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_output=[layer.output for layer in model.layers[:8]]\n",
    "activation_model=models.Model(inputs=model.input,outputs=layer_output)\n",
    "activations=activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T06:45:56.671319Z",
     "start_time": "2019-07-29T06:45:56.659318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 148, 148, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer_activation=activations[0]\n",
    "first_layer_activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T06:47:47.394652Z",
     "start_time": "2019-07-29T06:47:47.387651Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.matshow(first_layer_activation[0,:,:,3],cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T09:36:51.895884Z",
     "start_time": "2019-07-29T09:36:51.756876Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_names=[]\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer)\n",
    "    \n",
    "images_per_row=16\n",
    "\n",
    "for layer_name,layer_activation in zip(layer_names,activations):\n",
    "    n_feature=layer_activation.shape[-1]\n",
    "    size=layer_activation.shape[1]\n",
    "    n_cols=n_feature // images_per_row\n",
    "    display_grid=np.zeros((n_cols*size,images_per_row*size))\n",
    "    \n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image=layer_activation[0,:,:,col*images_per_row+row]\n",
    "            \n",
    "            channel_image-=channel_image.mean()\n",
    "            channel_image/=channel_image.std()\n",
    "            channel_image*=64\n",
    "            channel_image+=128\n",
    "            channel_image=np.clip(channel_image,0,255).astype('uint8')\n",
    "            display_grid[col*size:(col+1)*size,row*size:(row+1)*size]=channel_image\n",
    "    \n",
    "    scale=1./size\n",
    "#     plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "#                        scale * display_grid.shape[0]))\n",
    "    \n",
    "#     plt.imshow(display_grid,aspect='auto',cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
