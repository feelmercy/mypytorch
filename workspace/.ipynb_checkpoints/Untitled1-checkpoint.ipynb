{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "[0]\ttrain-merror:0.086293\tval-merror:0.125238\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.062891\tval-merror:0.098333\n",
      "[2]\ttrain-merror:0.054898\tval-merror:0.087302\n",
      "[3]\ttrain-merror:0.050238\tval-merror:0.080397\n",
      "[4]\ttrain-merror:0.047245\tval-merror:0.078333\n",
      "[5]\ttrain-merror:0.046497\tval-merror:0.07619\n",
      "[6]\ttrain-merror:0.044014\tval-merror:0.074444\n",
      "[7]\ttrain-merror:0.043673\tval-merror:0.072143\n",
      "[8]\ttrain-merror:0.042959\tval-merror:0.072063\n",
      "[9]\ttrain-merror:0.042279\tval-merror:0.071508\n",
      "[10]\ttrain-merror:0.041395\tval-merror:0.070159\n",
      "[11]\ttrain-merror:0.040952\tval-merror:0.070159\n",
      "[12]\ttrain-merror:0.040442\tval-merror:0.070794\n",
      "[13]\ttrain-merror:0.039864\tval-merror:0.068968\n",
      "[14]\ttrain-merror:0.039728\tval-merror:0.068413\n",
      "[15]\ttrain-merror:0.039558\tval-merror:0.067857\n",
      "[16]\ttrain-merror:0.038912\tval-merror:0.067619\n",
      "[17]\ttrain-merror:0.038776\tval-merror:0.06746\n",
      "[18]\ttrain-merror:0.038333\tval-merror:0.066667\n",
      "[19]\ttrain-merror:0.038197\tval-merror:0.066587\n",
      "[20]\ttrain-merror:0.037687\tval-merror:0.065635\n",
      "[21]\ttrain-merror:0.037075\tval-merror:0.065\n",
      "[22]\ttrain-merror:0.036531\tval-merror:0.064603\n",
      "[23]\ttrain-merror:0.036497\tval-merror:0.064524\n",
      "[24]\ttrain-merror:0.03602\tval-merror:0.064683\n",
      "[25]\ttrain-merror:0.035714\tval-merror:0.064048\n",
      "[26]\ttrain-merror:0.035102\tval-merror:0.063492\n",
      "[27]\ttrain-merror:0.034694\tval-merror:0.063651\n",
      "[28]\ttrain-merror:0.034626\tval-merror:0.062937\n",
      "[29]\ttrain-merror:0.034354\tval-merror:0.063175\n",
      "[30]\ttrain-merror:0.034354\tval-merror:0.06254\n",
      "[31]\ttrain-merror:0.034558\tval-merror:0.062778\n",
      "[32]\ttrain-merror:0.034456\tval-merror:0.06254\n",
      "[33]\ttrain-merror:0.033946\tval-merror:0.062381\n",
      "[34]\ttrain-merror:0.033299\tval-merror:0.061905\n",
      "[35]\ttrain-merror:0.033265\tval-merror:0.061984\n",
      "[36]\ttrain-merror:0.033197\tval-merror:0.061984\n",
      "[37]\ttrain-merror:0.033027\tval-merror:0.062222\n",
      "[38]\ttrain-merror:0.032789\tval-merror:0.061429\n",
      "[39]\ttrain-merror:0.032279\tval-merror:0.061349\n",
      "[40]\ttrain-merror:0.032211\tval-merror:0.060952\n",
      "[41]\ttrain-merror:0.031939\tval-merror:0.060556\n",
      "[42]\ttrain-merror:0.031565\tval-merror:0.060079\n",
      "[43]\ttrain-merror:0.031565\tval-merror:0.060159\n",
      "[44]\ttrain-merror:0.031259\tval-merror:0.059683\n",
      "[45]\ttrain-merror:0.031122\tval-merror:0.059524\n",
      "[46]\ttrain-merror:0.030782\tval-merror:0.060079\n",
      "[47]\ttrain-merror:0.030714\tval-merror:0.060317\n",
      "[48]\ttrain-merror:0.030748\tval-merror:0.059762\n",
      "[49]\ttrain-merror:0.030646\tval-merror:0.059603\n",
      "[50]\ttrain-merror:0.030544\tval-merror:0.059365\n",
      "[51]\ttrain-merror:0.030408\tval-merror:0.058889\n",
      "[52]\ttrain-merror:0.030034\tval-merror:0.05873\n",
      "[53]\ttrain-merror:0.03\tval-merror:0.05881\n",
      "[54]\ttrain-merror:0.029796\tval-merror:0.058571\n",
      "[55]\ttrain-merror:0.029592\tval-merror:0.05873\n",
      "[56]\ttrain-merror:0.029422\tval-merror:0.058571\n",
      "[57]\ttrain-merror:0.029286\tval-merror:0.058254\n",
      "[58]\ttrain-merror:0.029252\tval-merror:0.057937\n",
      "[59]\ttrain-merror:0.02915\tval-merror:0.058413\n",
      "[60]\ttrain-merror:0.028946\tval-merror:0.058095\n",
      "[61]\ttrain-merror:0.028537\tval-merror:0.057698\n",
      "[62]\ttrain-merror:0.028537\tval-merror:0.057778\n",
      "[63]\ttrain-merror:0.028503\tval-merror:0.05754\n",
      "[64]\ttrain-merror:0.028401\tval-merror:0.057381\n",
      "[65]\ttrain-merror:0.028061\tval-merror:0.057302\n",
      "[66]\ttrain-merror:0.028129\tval-merror:0.056905\n",
      "[67]\ttrain-merror:0.027993\tval-merror:0.056587\n",
      "[68]\ttrain-merror:0.027755\tval-merror:0.056746\n",
      "[69]\ttrain-merror:0.027415\tval-merror:0.056667\n",
      "[70]\ttrain-merror:0.027483\tval-merror:0.056984\n",
      "[71]\ttrain-merror:0.027347\tval-merror:0.056349\n",
      "[72]\ttrain-merror:0.027177\tval-merror:0.055476\n",
      "[73]\ttrain-merror:0.027041\tval-merror:0.055317\n",
      "[74]\ttrain-merror:0.027007\tval-merror:0.055714\n",
      "[75]\ttrain-merror:0.026735\tval-merror:0.055476\n",
      "[76]\ttrain-merror:0.026803\tval-merror:0.055397\n",
      "[77]\ttrain-merror:0.026667\tval-merror:0.055476\n",
      "[78]\ttrain-merror:0.026531\tval-merror:0.055238\n",
      "[79]\ttrain-merror:0.026531\tval-merror:0.055159\n",
      "[80]\ttrain-merror:0.026361\tval-merror:0.055476\n",
      "[81]\ttrain-merror:0.026259\tval-merror:0.055238\n",
      "[82]\ttrain-merror:0.025952\tval-merror:0.055317\n",
      "[83]\ttrain-merror:0.025986\tval-merror:0.055159\n",
      "[84]\ttrain-merror:0.025884\tval-merror:0.055\n",
      "[85]\ttrain-merror:0.025646\tval-merror:0.055159\n",
      "[86]\ttrain-merror:0.025442\tval-merror:0.055079\n",
      "[87]\ttrain-merror:0.025476\tval-merror:0.054841\n",
      "[88]\ttrain-merror:0.02534\tval-merror:0.055159\n",
      "[89]\ttrain-merror:0.025374\tval-merror:0.055317\n",
      "[90]\ttrain-merror:0.025238\tval-merror:0.054921\n",
      "[91]\ttrain-merror:0.025204\tval-merror:0.054762\n",
      "[92]\ttrain-merror:0.025136\tval-merror:0.054524\n",
      "[93]\ttrain-merror:0.025034\tval-merror:0.054524\n",
      "[94]\ttrain-merror:0.02483\tval-merror:0.054683\n",
      "[95]\ttrain-merror:0.024762\tval-merror:0.054841\n",
      "[96]\ttrain-merror:0.024694\tval-merror:0.054524\n",
      "[97]\ttrain-merror:0.024592\tval-merror:0.054444\n",
      "[98]\ttrain-merror:0.024524\tval-merror:0.054683\n",
      "[99]\ttrain-merror:0.024456\tval-merror:0.054841\n",
      "best best_ntree_limit 98\n",
      "xgboost success! \n",
      " cost time: 510.9642255306244 (s)......\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "train = pd.read_csv(\"F:\\\\study\\\\ml\\DataSet\\DigitRecognizer/train.csv\")\n",
    "test = pd.read_csv(\"F:\\study\\ml\\DataSet\\DigitRecognizer/test.csv\") \n",
    "print(train.shape)\n",
    "\n",
    "train_xy,val = train_test_split(train,test_size=0.3,random_state=1)\n",
    "y= train_xy.label\n",
    "x=train_xy.drop(['label'],axis=1)\n",
    "val_y=val.label\n",
    "val_x=val.drop(['label'],axis=1)\n",
    "\n",
    "xgb_val=xgb.DMatrix(val_x,label=val_y)\n",
    "xgb_train=xgb.DMatrix(x,label=y)\n",
    "xgb_test=xgb.DMatrix(test)\n",
    "\n",
    "params={\n",
    "'booster':'gbtree',\n",
    "'objective': 'multi:softmax', #多分类的问题\n",
    "'num_class':10, # 类别数，与 multisoftmax 并用\n",
    "'gamma':0.1,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "'max_depth':12, # 构建树的深度，越大越容易过拟合\n",
    "'lambda':2,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "'subsample':0.7, # 随机采样训练样本\n",
    "'colsample_bytree':0.7, # 生成树时进行的列采样\n",
    "'min_child_weight':3, \n",
    "# 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "'eta': 0.007, # 如同学习率\n",
    "'seed':1000,\n",
    "'nthread':4,# cpu 线程数\n",
    "#'eval_metric': 'auc'\n",
    "}\n",
    "plst = list(params.items())\n",
    "num_rounds = 100 # 迭代次数\n",
    "watchlist = [(xgb_train, 'train'),(xgb_val, 'val')]\n",
    "\n",
    "model = xgb.train(plst, xgb_train, num_rounds, watchlist,early_stopping_rounds=100)\n",
    "model.save_model('D:\\\\tmp\\\\jupyter\\\\tmp\\\\xgb.model')\n",
    "print (\"best best_ntree_limit\",model.best_ntree_limit )\n",
    "\n",
    "preds = model.predict(xgb_test,ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "np.savetxt('xgb_submission.csv',np.c_[range(1,len(tests)+1),preds],delimiter=',',header='ImageId,Label',comments='',fmt='%d')\n",
    "cost_time = time.time()-start_time\n",
    "print (\"xgboost success!\",'\\n',\"cost time:\",cost_time,\"(s)......\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
