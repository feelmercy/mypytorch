{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:34:42.822455Z",
     "start_time": "2023-08-11T02:34:42.818550Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:34:46.267017Z",
     "start_time": "2023-08-11T02:34:46.263123Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def forward(self,X,*args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:34:55.563345Z",
     "start_time": "2023-08-11T02:34:55.558464Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        raise NotImplementedError\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:35:05.524836Z",
     "start_time": "2023-08-11T02:35:05.518964Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size,num_hiddens,num_layers,dropout=dropout)\n",
    "    \n",
    "    def forward(self,X,*args):\n",
    "#         (batch,step,embed)\n",
    "        X=self.embedding(X)\n",
    "#         (step,batch,embed)    \n",
    "        X=X.permute(1,0,2)\n",
    "#         output:(step,batch,hidden)\n",
    "#         state :(layers,batch,hidden)\n",
    "        output,state=self.rnn(X)\n",
    "        return output,state        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:35:14.029637Z",
     "start_time": "2023-08-11T02:35:14.022787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqEncoder(\n",
       "  (embedding): Embedding(10, 8)\n",
       "  (rnn): GRU(8, 16, num_layers=2)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=Seq2SeqEncoder(vocab_size=10,embed_size=8,num_hiddens=16,num_layers=2)\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:35:15.463231Z",
     "start_time": "2023-08-11T02:35:15.455818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.zeros((4,7,),dtype=torch.long)\n",
    "output,state=encoder(X)\n",
    "output.shape,state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:37:10.829022Z",
     "start_time": "2023-08-11T02:37:10.823178Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(Decoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size+num_hiddens,num_hiddens,num_layers,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "    \n",
    "    def init_state(self,enc_outputs,*args):\n",
    "        return enc_outputs[1]\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        X=self.embedding(X).permute(1,0,2)\n",
    "#         上下文和上一步状态相关\n",
    "        context=state[-1].repeat(X.shape[0],1,1)\n",
    "#         输入需要X,上下文\n",
    "        X_and_context=torch.cat((X,context),2)\n",
    "        output,statee=self.rnn(X_and_context,state)\n",
    "#         output经过两次permute,shape和X最开始一样了\n",
    "        output=self.dense(output).permute(1,0,2)\n",
    "        return output,state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:37:46.412954Z",
     "start_time": "2023-08-11T02:37:46.406103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqDecoder(\n",
       "  (embedding): Embedding(10, 8)\n",
       "  (rnn): GRU(24, 16, num_layers=2)\n",
       "  (dense): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder=Seq2SeqDecoder(vocab_size=10,embed_size=8,num_hiddens=16,num_layers=2)\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:37:47.634891Z",
     "start_time": "2023-08-11T02:37:47.629995Z"
    }
   },
   "outputs": [],
   "source": [
    "state=decoder.init_state(encoder(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:37:48.981945Z",
     "start_time": "2023-08-11T02:37:48.974302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output,state=decoder(X,state)\n",
    "output.shape,state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:37:50.898369Z",
     "start_time": "2023-08-11T02:37:50.894462Z"
    }
   },
   "outputs": [],
   "source": [
    "def sequence_mask(X,valid_len,value=0):\n",
    "    maxlen=X.size(1)\n",
    "    mask=torch.arange((maxlen),dtype=torch.float32,device=X.device)[None,:]<valid_len[:,None]\n",
    "    X[~mask]=value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:38:34.113848Z",
     "start_time": "2023-08-11T02:38:34.109956Z"
    }
   },
   "outputs": [],
   "source": [
    "X=torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:38:35.293998Z",
     "start_time": "2023-08-11T02:38:35.269589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:38:37.700383Z",
     "start_time": "2023-08-11T02:38:37.637588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_mask(X,torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:39:26.185603Z",
     "start_time": "2023-08-11T02:39:26.181682Z"
    }
   },
   "outputs": [],
   "source": [
    "a=torch.arange(3)\n",
    "b=torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:39:28.138909Z",
     "start_time": "2023-08-11T02:39:28.134022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:39:34.322262Z",
     "start_time": "2023-08-11T02:39:34.317380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:39:34.762587Z",
     "start_time": "2023-08-11T02:39:34.757705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:39:35.330245Z",
     "start_time": "2023-08-11T02:39:35.325351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:39:35.803222Z",
     "start_time": "2023-08-11T02:39:35.797350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None,:]<b[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T06:31:09.330944Z",
     "start_time": "2023-08-08T06:31:09.326076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(0)<b.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:43:21.825786Z",
     "start_time": "2023-08-11T02:43:21.820918Z"
    }
   },
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def forward(self,pred,label,valid_len):\n",
    "        weights=torch.ones_like(label)\n",
    "        weights=sequence_mask(weights,valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss=super().forward(pred.permute(0,2,1),label)\n",
    "        weighted_loss=(unweighted_loss*weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:43:22.631054Z",
     "start_time": "2023-08-11T02:43:22.556853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3,4,10),torch.ones((3,4),dtype=torch.long),torch.tensor([4,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T02:43:24.394125Z",
     "start_time": "2023-08-11T02:43:24.389265Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params=[p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params=net.params\n",
    "    norm=torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta/norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T03:02:44.801302Z",
     "start_time": "2023-08-11T03:02:44.776894Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_seq2seq(net,data_iter,lr,num_epochs,tgt_vocab,device):\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) ==nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m)==nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    \n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    loss=MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    train_l,train_num=0,0\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X,X_valid_len,Y,Y_valid_len=[x.to(device) for x in batch]\n",
    "            bos=torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],device=device).reshape(-1,1)\n",
    "            dec_input=torch.cat([bos,Y[:,:-1]],1)\n",
    "            Y_hat,_=net(X,dec_input,X_valid_len)\n",
    "            l=loss(Y_hat,Y,Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(net,1)\n",
    "            num_tokens=Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                train_l+=l.sum()\n",
    "                train_num+=num_tokens\n",
    "        if(epoch+1)%10==0:\n",
    "            print(\"epoch : \",epoch+1,\" train loss : \",(train_l.item()/train_num.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T07:44:55.117081Z",
     "start_time": "2023-08-11T07:44:55.099220Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter=count_corpus(tokens)\n",
    "        self._token_freqs=sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        self.idx_to_token=['<unk>']+reserved_tokens\n",
    "        self.token_to_idx={token:idx for idx,token in enumerate(self.idx_to_token)}\n",
    "        self.idx_to_token,self.token_to_idx=[],dict()\n",
    "        for token,freq in self._token_freqs:\n",
    "            if freq<min_freq:\n",
    "                break;\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0;\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:11:54.949200Z",
     "start_time": "2023-08-11T08:11:54.945286Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_corpus(tokens):\n",
    "    if len(tokens)==0 or isinstance(tokens[0],list):\n",
    "        tokens=[token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:11:55.791614Z",
     "start_time": "2023-08-11T08:11:55.785754Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_nmt(text):\n",
    "    def no_space(char,prev_char):\n",
    "        return char in set(',.!?') and prev_char !=' '\n",
    "    \n",
    "    text=text.replace('\\u202f', ' ').replace('\\xa0',' ').lower()\n",
    "    out=[' '+char if i>0 and no_space(char,text[i-1]) else char for i,char in enumerate(text) ]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:11:56.741818Z",
     "start_time": "2023-08-11T08:11:56.736936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abd', 'aaa', 'bbb']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"abd,aaa,bbb\"\n",
    "b=a.split(',')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:11:57.477639Z",
     "start_time": "2023-08-11T08:11:57.473532Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_nmt(text,num_examples=None):\n",
    "    source,target=[],[]\n",
    "    for i ,line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts=line.split('\\t')\n",
    "        if len(parts)==2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source,target \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:11:58.222536Z",
     "start_time": "2023-08-11T08:11:58.217667Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "#     \"\"\"将机器翻译的⽂本序列转换成⼩批量\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "#     print(\"lines : \",lines)\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:00.271817Z",
     "start_time": "2023-08-11T08:12:00.265958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([0])\n",
    "(a!=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:02.966673Z",
     "start_time": "2023-08-11T08:12:02.961668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a!=b).type(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:03.646574Z",
     "start_time": "2023-08-11T08:12:03.641692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a!=b).type(torch.int32).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:04.244224Z",
     "start_time": "2023-08-11T08:12:04.233470Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-4d063fc83a15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "(a!=b).type(torch.int32).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:04.766548Z",
     "start_time": "2023-08-11T08:12:04.761680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a!=b).type(torch.int32).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:05.782674Z",
     "start_time": "2023-08-11T08:12:05.776809Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "#     \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "#     print(\"source : \",source)\n",
    "#     print(\"target : \",target)\n",
    "    src_vocab = Vocab(source, min_freq=2,reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocab(target, min_freq=2,reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:09.156283Z",
     "start_time": "2023-08-11T08:12:09.153353Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:10.677846Z",
     "start_time": "2023-08-11T08:12:10.674019Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data_nmt():\n",
    "    data_dir=r'F:\\study\\ml\\DataSet\\fra-eng'\n",
    "    with open(os.path.join(data_dir,'fra.txt'),'r',encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:11.334131Z",
     "start_time": "2023-08-11T08:12:11.329249Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_nmt(text,num_examples=None):\n",
    "    source,target=[],[]\n",
    "    for i ,line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts=line.split('\\t')\n",
    "        if len(parts)==2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source,target \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:12.268741Z",
     "start_time": "2023-08-11T08:12:12.264836Z"
    }
   },
   "outputs": [],
   "source": [
    "def truncate_pad(line,num_steps,padding_token):\n",
    "    if len(line)>num_steps:\n",
    "        return line[:num_steps]\n",
    "    return line + [padding_token]*(num_steps-len(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:17.069184Z",
     "start_time": "2023-08-11T08:12:17.065278Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:17.863445Z",
     "start_time": "2023-08-11T08:12:17.858563Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:19.925254Z",
     "start_time": "2023-08-11T08:12:19.921244Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size,num_hiddens,num_layers,dropout=32,32,2,0.1\n",
    "batch_size,num_steps=64,10\n",
    "lr,num_epochs,device=0.005,300,'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:27.785703Z",
     "start_time": "2023-08-11T08:12:20.833556Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, src_vocab, tgt_vocab =load_data_nmt(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:38.111849Z",
     "start_time": "2023-08-11T08:12:38.105991Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:39.172829Z",
     "start_time": "2023-08-11T08:12:39.168924Z"
    }
   },
   "outputs": [],
   "source": [
    "net = EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:13:46.522772Z",
     "start_time": "2023-08-11T08:12:42.313419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  10  train loss :  0.3717254590913537\n",
      "epoch :  20  train loss :  0.3053531175114926\n",
      "epoch :  30  train loss :  0.2551770802767997\n",
      "epoch :  40  train loss :  0.21818605043891823\n",
      "epoch :  50  train loss :  0.19044174552523474\n",
      "epoch :  60  train loss :  0.169087441314554\n",
      "epoch :  70  train loss :  0.15245553180192264\n",
      "epoch :  80  train loss :  0.13915062368569053\n",
      "epoch :  90  train loss :  0.12829703190206052\n",
      "epoch :  100  train loss :  0.11937162253032081\n",
      "epoch :  110  train loss :  0.1118645674949317\n",
      "epoch :  120  train loss :  0.10549232351574726\n",
      "epoch :  130  train loss :  0.10000449075328037\n",
      "epoch :  140  train loss :  0.09522963518960988\n",
      "epoch :  150  train loss :  0.09106233902256129\n",
      "epoch :  160  train loss :  0.08736981077000196\n",
      "epoch :  170  train loss :  0.08406418648738838\n",
      "epoch :  180  train loss :  0.08111838226504087\n",
      "epoch :  190  train loss :  0.0784633421876287\n",
      "epoch :  200  train loss :  0.07607555598347027\n",
      "epoch :  210  train loss :  0.07389829427956629\n",
      "epoch :  220  train loss :  0.07190612801652084\n",
      "epoch :  230  train loss :  0.07008214367728108\n",
      "epoch :  240  train loss :  0.06840137686652321\n",
      "epoch :  250  train loss :  0.0668646138986698\n",
      "epoch :  260  train loss :  0.06544376518862104\n",
      "epoch :  270  train loss :  0.06414490188300585\n",
      "epoch :  280  train loss :  0.06292455798156997\n",
      "epoch :  290  train loss :  0.06177059513450434\n",
      "epoch :  300  train loss :  0.06068580464267084\n"
     ]
    }
   ],
   "source": [
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net,src_sentence,src_sentence,tgt_vocab,num_steps,device,\n",
    "                    save_attention_weights=False):\n",
    "    net.eval()\n",
    "    src_tokens=src_vocab[src_sentence.lower().split(' ')]+[src_vocab['<eos>']]\n",
    "    enc_valid_len\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
