{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823d8d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:53:42.197630Z",
     "start_time": "2023-05-24T07:53:42.187847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c143ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:53:48.608368Z",
     "start_time": "2023-05-24T07:53:48.603487Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path=r'F:\\study\\ml\\LM\\8\\timemachine.txt'\n",
    "def read_time_machine():\n",
    "    with open(file_path) as f:\n",
    "        lines=f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+',' ',line).strip().lower() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402d66d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:53:52.482371Z",
     "start_time": "2023-05-24T07:53:52.477489Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(lines,token='word'):\n",
    "    if token=='word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token=='char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print(\"error : unknown token type : \",token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7de671",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:53:57.660092Z",
     "start_time": "2023-05-24T07:53:57.651304Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter=count_corpus(tokens)\n",
    "        self._token_freqs=sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        self.idx_to_token=['<unk>']+reserved_tokens\n",
    "        self.token_to_idx={token:idx for idx,token in enumerate(self.idx_to_token)}\n",
    "        self.idx_to_token,self.token_to_idx=[],dict()\n",
    "        for token,freq in self._token_freqs:\n",
    "            if freq<min_freq:\n",
    "                break;\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0;\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158276c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:03.153709Z",
     "start_time": "2023-05-24T07:54:03.149803Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_corpus(tokens):\n",
    "    if len(tokens)==0 or isinstance(tokens[0],list):\n",
    "        tokens=[token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a193067b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:07.216938Z",
     "start_time": "2023-05-24T07:54:07.179858Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens=tokenize(read_time_machine())\n",
    "corpus=[token for line in tokens for token in line]\n",
    "vocab=Vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e9519d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:14.007953Z",
     "start_time": "2023-05-24T07:54:14.003134Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_corpus_time_machine(max_tokens=-1):\n",
    "    lines=read_time_machine()\n",
    "    tokens=tokenize(lines,'char')\n",
    "    vocab=Vocab(tokens)\n",
    "    corpus=[vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens>0:\n",
    "        corpus=corpus[:max_tokens]\n",
    "    return corpus,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f35943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:19.093471Z",
     "start_time": "2023-05-24T07:54:18.956087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170580, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus,vocab=load_corpus_time_machine()\n",
    "len(corpus),len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fed8792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:24.010067Z",
     "start_time": "2023-05-24T07:54:24.004040Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    corpus=corpus[random.randint(0,num_step-1):]\n",
    "    num_subseqs=(len(corpus)-1)//num_steps\n",
    "    initial_indices=list(range(0,num_subseqs*num_steps,num_steps))\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "    \n",
    "    num_batches=num_subseqs // batch_size\n",
    "    for i in range(0,batch_size*num_batches,batch_size):\n",
    "        initial_indices_per_batch=initial_indices[i:i+batch_size]\n",
    "        X=[data(j) for j in initial_indices_per_batch]\n",
    "        Y=[data(j+1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X),torch.tensor(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c79351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:29.875986Z",
     "start_time": "2023-05-24T07:54:29.869214Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "    offset=random.randint(0,num_steps)\n",
    "    num_tokens=((len(corpus)-offset -1) //batch_size)*batch_size\n",
    "    Xs=torch.tensor(corpus[offset:offset+num_tokens])\n",
    "    Ys=torch.tensor(corpus[offset+1:offset+1+num_tokens])\n",
    "    Xs,Ys=Xs.reshape(batch_size,-1),Ys.reshape(batch_size,-1)\n",
    "    num_batches=Xs.shape[1]//num_steps\n",
    "    for i in range(0,num_steps*num_batches,num_steps):\n",
    "        X=Xs[:,i:i+num_steps]\n",
    "        Y=Ys[:,i:i+num_steps]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aac706a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:36.969042Z",
     "start_time": "2023-05-24T07:54:36.963091Z"
    }
   },
   "outputs": [],
   "source": [
    "class SeqDataLoader:\n",
    "    def __init__(self,batch_size,num_steps,use_random_iter,max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn=seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn=seq_data_iter_sequential\n",
    "        self.corpus,self.vocab=load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size,self.num_steps=batch_size,num_steps\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus,self.batch_size,self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a24cc6e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:54:41.314043Z",
     "start_time": "2023-05-24T07:54:41.309161Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_time_machine(batch_size,num_steps,use_random_iter=False,max_tokens=10000):\n",
    "    data_iter=SeqDataLoader(batch_size,num_steps,use_random_iter,max_tokens)\n",
    "    return data_iter,data_iter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1830502a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:55:30.741595Z",
     "start_time": "2023-05-24T07:55:30.605108Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size,num_steps=32,35\n",
    "train_iter,vocab=load_data_time_machine(batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698f84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens=256\n",
    "rnn_layer=nn.RNN(len(vocab),num_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f07888ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=torch.zeros((1,batch_size,num_hiddens))\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32792c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([35, 32, 256]), torch.Size([1, 32, 256]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.rand(size=(num_steps,batch_size,len(vocab)))\n",
    "Y,state_new=rnn_layer(X,state)\n",
    "Y.shape,state_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50ff695e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf8fa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer.num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c7d6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self,rnn_layer,vocab_size,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.rnn=rnn_layer\n",
    "        self.vocab_size=vocab_size\n",
    "        self.num_hiddens=self.rnn.hidden_size\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions=1\n",
    "            self.linear=nn.Linear(self.num_hiddens,self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions=2\n",
    "            self.linear=nn.Linear(self.num_hiddens*2,self.vocab_size)\n",
    "    \n",
    "    def forward(self,inputs,state):\n",
    "        X=F.one_hot(inputs.T.long(),self.vocab_size)\n",
    "        X=X.to(torch.float32)\n",
    "        Y,state=self.rnn(X,state)\n",
    "        output=self.linear(Y.reshape((-1,Y.shape[-1])))\n",
    "        return output,state\n",
    "    \n",
    "    def begin_state(self,device,batch_size=1):\n",
    "        if not isinstance(self.rnn,nn.LSTM):\n",
    "            return torch.zeros((self.num_directions*self.rnn.num_layers,batch_size,self.num_hiddens),device=device)\n",
    "        else:\n",
    "            return (torch.zeros((self.num_directions*self.rnn.num_layers,batch_size,self.num_hiddens),device=device),\n",
    "                    torch.zeros((self.num_directions*self.rnn.num_layers,batch_size,self.num_hiddens),device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76c8a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'\n",
    "net=RNNModule(rnn_layer,vocab_size=len(vocab))\n",
    "net=net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "042fc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix,num_preds,net,vocab,device):\n",
    "    state=net.begin_state(batch_size=1,device=device)\n",
    "    outputs=[vocab[prefix[0]]]\n",
    "    get_input=lambda : torch.tensor([outputs[-1]],device=device).reshape((1,1))\n",
    "    for y in prefix[1:]:\n",
    "        _,state=net(get_input(),state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):\n",
    "        y,state=net(get_input(),state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a119fbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time travelleroooooooooo'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('time traveller', 10, net, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d15f9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params=[p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params=net.params\n",
    "    norm=torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm>theta:\n",
    "        for param in params:\n",
    "            param.grad[:]*=theta /norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1188082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ch8(net,train_iter,loss,updater,device,use_random_iter):\n",
    "    state=None\n",
    "    tr_l,tr_num=[],[]\n",
    "    for X,Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            state=net.begin_state(batch_size=X.shape[0],device=device)\n",
    "        else:\n",
    "            if isinstance(net,nn.Module) and not isinstance(state,tuple):\n",
    "                state.detach_()\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y=Y.T.reshape(-1)\n",
    "        X,y=X.to(device),y.to(device)\n",
    "        y_hat,state=net(X,state)\n",
    "        l=loss(y_hat,y.long()).mean()\n",
    "        if isinstance(updater,torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net,l)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net,l)\n",
    "            updater(batch_size=1)\n",
    "        tr_l.append(l*y.numel())\n",
    "        tr_num.append(y.numel())\n",
    "    return math.exp(sum(tr_l)/sum(tr_num))\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8167d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for p in params:\n",
    "            p.data -=lr*p.grad.data/batch_size\n",
    "            p.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e197e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch8(net,train_iter,vocab,lr,num_epochs,device,use_random_iter=False):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    if isinstance(net,nn.Module):\n",
    "        updater=torch.optim.SGD(net.parameters(),lr)\n",
    "    else:\n",
    "        updater=lambda batch_size:sgd(net.params,lr,batch_size)\n",
    "    predict=lambda prefix:predict_ch8(prefix,50,net,vocab,device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        ppl=train_epoch_ch8(net,train_iter,loss,updater,device,use_random_iter)\n",
    "        \n",
    "        if(epoch+1) %10==0:\n",
    "            print(predict(\"time traveller\"))\n",
    "    print(f'困惑度 {ppl:.1f}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fedfbade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time travellere the the the the the the the the the the the the \n",
      "time traveller and he the the the the the the the the the the th\n",
      "time traveller the that the this the that the that the this the \n",
      "time traveller the thing the the the the the the the the the the\n",
      "time traveller anding sion and have and the the the thas ans and\n",
      "time traveller simension sion the ghit the the three dimension s\n",
      "time traveller the fice travely thave and have a dine simett the\n",
      "time traveller the ond he but se to he wis he thate d male ande \n",
      "time traveller the e dimensions ard he the ghe the e we the ong \n",
      "time traveller the gea lo ghe thaven th yon in a mone the time t\n",
      "time traveller bot some anoul thave at ond have able this be and\n",
      "time travellerit fiughis to teeputhe ald he sumale ingther attee\n",
      "time travellerit s alaig the firedid now yor ank the this bect a\n",
      "time travellericentalive the ind in filby becall hand the mime s\n",
      "time travellerit s ala lle ge at a coul one somot ichthef a dor \n",
      "time traveller hat no heal they toun chis tount movent ou monica\n",
      "time traveller hat sathed his will ix sugat iouradit ef ly ingen\n",
      "time traveller hal shallitheee trmed ancablincedinstse waller or\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller hat sad la that is ale pars ar aid anots it ficbe\n",
      "time travellerit s ala hed gange tothendor an sovellbee of the r\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller fftle ws cha rige sat op that oo st acamout ubeee\n",
      "time traveller proceeded anyreal body must have extension in fou\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "困惑度 1.1\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "traveller with a slight accession ofcheerfulness really thi\n"
     ]
    }
   ],
   "source": [
    "num_epochs,lr=500,1\n",
    "train_ch8(net,train_iter,vocab,lr,num_epochs,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ab90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModuelScatch:\n",
    "    def __init__(self,vocab_size,num_hiddens,device,get_params,init_state,forward_fn):\n",
    "        self.vocab_size,self.num_hiddens=vocab_size,num_hiddens\n",
    "        self.params=get_params(vocab_size,num_hiddens,device)\n",
    "        self.init_state,self.forward_fn=init_state,forward_fn\n",
    "    \n",
    "    def __call__(self,X,state):\n",
    "        X=F.one_hot(X.T,self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X,state,self.params)\n",
    "    \n",
    "    def begin_state(self,batch_size,device):\n",
    "        return self.init_state(batch_size,self.num_hiddens,device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85f4dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size,num_hiddens,device):\n",
    "    num_inputs=num_outputs=vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape,device=device)*0.01\n",
    "    \n",
    "    def three():\n",
    "        return (normal((num_inputs,num_hiddens)),\n",
    "                normal((num_hiddens,num_hiddens)),\n",
    "                torch.zeros(num_hiddens,device=device))\n",
    "    \n",
    "    W_xz,W_hz,b_z=three()\n",
    "    W_xr,W_hr,b_r=three()\n",
    "    W_xh,W_hh,b_h=three()\n",
    "\n",
    "    W_hq=normal((num_hiddens,num_outputs))\n",
    "    b_q=torch.zeros(num_outputs,device=device)\n",
    "\n",
    "    params=[W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for p in params:\n",
    "        p.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7366d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d128265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(inputs,state,params):\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q=params\n",
    "    H,=state\n",
    "    outputs=[]\n",
    "    for X in inputs:\n",
    "        Z=torch.sigmoid((X@W_xz)+(H@W_hz)+b_z)\n",
    "        R=torch.sigmoid(((X@W_xr)+(H@W_hr)+b_r))\n",
    "        H_tilda=torch.tanh((X@W_xh)+((R*H)@W_hh)+b_h)\n",
    "        H=Z*H+(1-Z)*H_tilda\n",
    "        Y=H@W_hq+b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs,dim=0),(H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bf6f33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time traveller                                                  \n",
      "time traveller te te te te te te te te te te te te te te te te t\n",
      "time traveller the the the the the the the the the the the the t\n",
      "time traveller the the the the the the the the the the the the t\n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellerererererererererererererererererererererererererer\n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller the the the the the the the the the the the the t\n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller the the the the the the the the the the the the t\n",
      "time traveller the there there there there there there there the\n",
      "time traveller the the the the the the the the the the the the t\n",
      "time traveller the there the the the the the the the the the the\n",
      "time traveller the thing the thing the thing the thing the thing\n",
      "time traveller the thing the thing the thing the thing the thing\n",
      "time traveller the this the the the the the the the the the the \n",
      "time traveller thing so man and the thing so man and the thing s\n",
      "time traveller this the thing the thime traveller this the thing\n",
      "time traveller that the madimensions and the time than as manthe\n",
      "time traveller this that seep and the time traveller this that s\n",
      "time traveller this thatthe time timetsime the perspersthe fithe\n",
      "time traveller thing the time dimensions of space have and and t\n",
      "time traveller three dimensions of space betyou bugned travel th\n",
      "time traveller that is a somiented the time traveller three dime\n",
      "time traveller the grimknes or a sict as in and de have exponitn\n",
      "time traveller three dimensions they coun indifferentely smicel \n",
      "time traveller three dimensions dinges of the surfll that all al\n",
      "time traveller for so it will of romeronat i but is al mantan en\n",
      "time traveller for so it will of romatere tere at will be canden\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller freey disensions we can rop t agary unitting they\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n"
     ]
    }
   ],
   "source": [
    "vocab_size, num_hiddens, device = len(vocab), 256, 'cpu'\n",
    "num_epochs, lr = 500, 1\n",
    "model = RNNModuelScatch(len(vocab), num_hiddens, device, get_params,init_gru_state, gru)\n",
    "train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d2a63",
   "metadata": {},
   "source": [
    "#### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "464b6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bc437de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_params(vocab_size,num_hiddens,device):\n",
    "    num_inputs=num_outputs=vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape,device=device)*0.01\n",
    "    \n",
    "    def three():\n",
    "        return (normal((num_inputs,num_hiddens)),\n",
    "                normal((num_hiddens,num_hiddens)),\n",
    "                torch.zeros(num_hiddens,device=device))\n",
    "    \n",
    "    W_xi,W_hi,b_i=three()\n",
    "    W_xf,W_hf,b_f=three()\n",
    "    W_xo,W_ho,b_o=three()\n",
    "    W_xc,W_hc,b_c=three()\n",
    "\n",
    "    W_hq=normal((num_hiddens,num_outputs))\n",
    "    b_q=torch.zeros(num_outputs,device=device)\n",
    "\n",
    "    params=[W_xi,W_hi,b_i,W_xf,W_hf,b_f,W_xo,W_ho,b_o,W_xc,W_hc,b_c,W_hq,b_q]\n",
    "\n",
    "    for p in params:\n",
    "        p.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8b1814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lstm_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),\n",
    "            torch.zeros((batch_size,num_hiddens),device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3de6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(inputs,state,params):\n",
    "    [W_xi,W_hi,b_i,W_xf,W_hf,b_f,W_xo,W_ho,b_o,W_xc,W_hc,b_c,W_hq,b_q]=params\n",
    "    (H,C)=state\n",
    "    outputs=[]\n",
    "    for X in inputs:\n",
    "        I=torch.sigmoid((X@W_xi)+(H@W_hi)+b_i)\n",
    "        F=torch.sigmoid((X@W_xf)+(H@W_hf)+b_f)\n",
    "        O=torch.sigmoid((X@W_xo)+(H@W_ho)+b_o)\n",
    "        C_tilda=torch.tanh((X@W_xc)+(H@W_hc)+b_c)\n",
    "        C=F*C+I*C_tilda\n",
    "        H=O*torch.tanh(C)\n",
    "        Y=(H@W_hq)+b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs,dim=0),(H,C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5af72589",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, device = len(vocab), 256, 'cpu'\n",
    "num_epochs, lr = 500, 1\n",
    "model = RNNModuelScatch(len(vocab), num_hiddens, device, get_lstm_params,init_lstm_state, lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eff21e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time traveller                                                  \n",
      "time traveller                                                  \n",
      "time traveller  t t a t t t a t t t a t t t a t t t a t t t a t \n",
      "time traveller at at at at at at at at at at at at at at at at a\n",
      "time traveller at at at at at at at at at at at at at at at at a\n",
      "time traveller at an the the the the the the the the the the the\n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller the the the the the the the the the the the the t\n",
      "time traveller an the the the the the the the the the the the th\n",
      "time traveller an the the the the the the the the the the the th\n",
      "time travellerererererererererererererererererererererererererer\n",
      "time traveller the the the the the the the the the the the the t\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller an a the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time travellererentions and the the there and the the there and \n",
      "time traveller the the the the the the the the the the the the t\n",
      "time traveller the timensions of the timensions of the timension\n",
      "time traveller the time time time time time time time time time \n",
      "time traveller the and the time time and and the time time and a\n",
      "time traveller the time traveller the time traveller the time tr\n",
      "time traveller the perich and the time traveller the peppered th\n",
      "time traveller the time travel there and the time travel there a\n",
      "time travellered the perichtere and the time travellered the per\n",
      "time traveller the time traveller the time traveller the time tr\n",
      "time traveller the time travellerical and hind the time travelle\n",
      "time traveller the time traveller the time traveller the time tr\n",
      "time traveller the time traveller the time traveller the time tr\n",
      "time travellericht and his in the pasthe this is and have an thi\n",
      "time traveller and thesticalle th scechought a gead thist alomit\n",
      "time travellerice that is in the time traveller the rewar dimens\n",
      "time traveller the reard the tracelatly i the batthe that the bu\n",
      "time travellericente beth and they four dimensions of space the \n",
      "time travellerit to s ach a said the medical man there about mov\n",
      "time travellericht and shith youghthe rave then sour dimension o\n",
      "time traveller for mateeniter as have exsenting the pstare furm \n",
      "time travellericht and hive travellerit s age have extent and on\n",
      "time travelleriche mas haid to y at a overtly it folly has attee\n",
      "time traveller for said the medical man and for space why a supp\n",
      "time travellerit s age spontime soolione simention alo a said th\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for said the medical man there are lalonionsconsc\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "困惑度 1.2\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "travelleryou can show black is white by argument said filby\n"
     ]
    }
   ],
   "source": [
    "train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49863e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
