{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c780cc1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:22:39.714392Z",
     "start_time": "2023-09-28T02:22:23.678170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b30a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:22:50.577693Z",
     "start_time": "2023-09-28T02:22:50.572795Z"
    }
   },
   "outputs": [],
   "source": [
    "def sequence_mask(X,valid_len,value=0):\n",
    "    maxlen=X.size(1)\n",
    "    mask=torch.arange((maxlen),dtype=torch.float32,device=X.device)[None,:]<valid_len[:,None]\n",
    "    X[~mask]=value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbc82e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:22:51.681476Z",
     "start_time": "2023-09-28T02:22:51.676607Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_softmax(X,valid_lens):\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X,dim=-1)\n",
    "    else:\n",
    "        shape=X.shape\n",
    "        if valid_lens.dim()==1:\n",
    "            valid_lens=torch.repeat_interleave(valid_lens,shape[1])\n",
    "        else:\n",
    "            valid_lens=valid_lens.reshape(-1)\n",
    "        X=sequence_mask(X.reshape(-1,shape[-1]),valid_lens,value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68934ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:22:52.661209Z",
     "start_time": "2023-09-28T02:22:52.516630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4361, 0.5639, 0.0000, 0.0000],\n",
       "         [0.6351, 0.3649, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.1783, 0.3847, 0.4370, 0.0000],\n",
       "         [0.2127, 0.4698, 0.3175, 0.0000]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061396b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2893ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:22:54.296082Z",
     "start_time": "2023-09-28T02:22:54.292173Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def init_state(self,enc_all_outputs,*args):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3c87a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:22:54.951635Z",
     "start_time": "2023-09-28T02:22:54.947729Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(Decoder):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168db6c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:04.554190Z",
     "start_time": "2023-09-28T02:23:04.548347Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self,key_size,query_size,num_hiddens,dropout,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.W_k=nn.Linear(key_size,num_hiddens,bias=False)\n",
    "        self.W_q=nn.Linear(query_size,num_hiddens,bias=False)\n",
    "        self.W_v=nn.Linear(num_hiddens,1,bias=False)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,queries,keys,values,valid_lens):\n",
    "        queries,keys=self.W_q(queries),self.W_k(keys)\n",
    "        features=queries.unsqueeze(2)+keys.unsqueeze(1)\n",
    "        features=torch.tanh(features)\n",
    "        scores=self.W_v(features).squeeze(-1)\n",
    "        self.attention_weights=masked_softmax(scores,valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights),values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c50e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:05.623000Z",
     "start_time": "2023-09-28T02:23:05.613224Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention=AdditiveAttention(num_hiddens,num_hiddens,num_hiddens,dropout)\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size+num_hiddens,num_hiddens,num_layers,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "        \n",
    "    def init_state(self,enc_outputs,enc_valid_lens,*args):\n",
    "        outputs,hidden_state=enc_outputs\n",
    "        return (outputs.permute(1,0,2),hidden_state,enc_valid_lens)\n",
    "    \n",
    "    def forward(self,X,state):\n",
    "        enc_outputs,hidden_state,enc_valid_lens=state\n",
    "        X=self.embedding(X).permute(1,0,2)\n",
    "        outputs,self._attention_weights=[],[]\n",
    "        for x in X:\n",
    "            query=torch.unsqueeze(hidden_state[-1],dim=1)\n",
    "            context=self.attention(query,enc_outputs,enc_outputs,enc_valid_lens)\n",
    "            x=torch.cat((context,torch.unsqueeze(x,dim=1)),dim=-1)\n",
    "            out,hidden_state=self.rnn(x.permute(1,0,2),hidden_state)\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        outputs=self.dense(torch.cat(outputs,dim=0))\n",
    "        return outputs.permute(1,0,2),[enc_outputs,hidden_state,enc_valid_lens]\n",
    "    \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef576e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:06.904561Z",
     "start_time": "2023-09-28T02:23:06.900660Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30977a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:08.921861Z",
     "start_time": "2023-09-28T02:23:08.916003Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size,num_hiddens,num_layers,dropout=dropout)\n",
    "#         8,16,2,0\n",
    "\n",
    "    def forward(self,X ,*args):\n",
    "        X=self.embedding(X) #4,7,8\n",
    "        X=X.permute(1,0,2) #7,4,8\n",
    "        output,state=self.rnn(X) \n",
    "        #output:step,batch,num_hiddens=7,4,16\n",
    "        #state :layers,batch,num_hiddnes=2,4,16\n",
    "        return output,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a05e1763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:11.290771Z",
     "start_time": "2023-09-28T02:23:11.260504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqEncoder(\n",
       "  (embedding): Embedding(10, 8)\n",
       "  (rnn): GRU(8, 16, num_layers=2)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,num_layers=2)\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6073ee1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:12.082701Z",
     "start_time": "2023-09-28T02:23:12.075866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqAttentionDecoder(\n",
       "  (attention): AdditiveAttention(\n",
       "    (W_k): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (W_q): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (W_v): Linear(in_features=16, out_features=1, bias=False)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (embedding): Embedding(10, 8)\n",
       "  (rnn): GRU(24, 16, num_layers=2)\n",
       "  (dense): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder=Seq2SeqAttentionDecoder(vocab_size=10,embed_size=8,num_hiddens=16,num_layers=2)\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d487594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3703503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:13.730016Z",
     "start_time": "2023-09-28T02:23:13.725134Z"
    }
   },
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def forward(self,pred,label,valid_len):\n",
    "        weights=torch.ones_like(label)\n",
    "        weights=sequence_mask(weights,valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss=super().forward(pred.permute(0,2,1),label)\n",
    "        weighted_loss=(unweighted_loss*weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a545fcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:14.489719Z",
     "start_time": "2023-09-28T02:23:14.453594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3,4,10),torch.ones((3,4),dtype=torch.long),torch.tensor([4,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0ffb18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:15.377159Z",
     "start_time": "2023-09-28T02:23:15.372291Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params=[p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params=net.params\n",
    "    norm=torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1bcd7c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:16.356628Z",
     "start_time": "2023-09-28T02:23:16.347840Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_seq2seq(net,data_iter,lr,num_epochs,tgt_vocab,device):\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m)==nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m)==nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "        \n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    loss=MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    train_l,train_num=0,0\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X,X_valid_len,Y,Y_valid_len=[x.to(device) for x in batch]\n",
    "            bos=torch.tensor([tgt_vocab['<bos>']]*Y.shape[0],device=device).reshape(-1,1)\n",
    "            dec_input=torch.cat([bos,Y[:,:-1]],1)\n",
    "            Y_hat,_=net(X,dec_input,X_valid_len)\n",
    "            l=loss(Y_hat,Y,Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(net,1)\n",
    "            num_tokens=Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                train_l+=l.sum()\n",
    "                train_num+=num_tokens\n",
    "        if(epoch+1)%10==0:\n",
    "            print(\"epoch : \",epoch+1,\" train loss : \",(train_l.item()/train_num.item()))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d229055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c98bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce534e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:19.095220Z",
     "start_time": "2023-09-28T02:23:18.884229Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.zeros((4,7),dtype=torch.long)\n",
    "state=decoder.init_state(encoder(X),None)\n",
    "output,state=decoder(X,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9ed584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:23.956198Z",
     "start_time": "2023-09-28T02:23:23.940577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([4, 16]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8e373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45a166d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:25.439466Z",
     "start_time": "2023-09-28T02:23:25.436537Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cb60985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:26.300831Z",
     "start_time": "2023-09-28T02:23:26.292046Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter=count_corpus(tokens)\n",
    "        self._token_freqs=sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        self.idx_to_token=['<unk>']+reserved_tokens\n",
    "        self.token_to_idx={token:idx for idx,token in enumerate(self.idx_to_token)}\n",
    "        self.idx_to_token,self.token_to_idx=[],dict()\n",
    "        for token,freq in self._token_freqs:\n",
    "            if freq<min_freq:\n",
    "                break;\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0;\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ce7c051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:27.152798Z",
     "start_time": "2023-09-28T02:23:27.148893Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_corpus(tokens):\n",
    "    if len(tokens)==0 or isinstance(tokens[0],list):\n",
    "        tokens=[token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73fb23d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:27.776242Z",
     "start_time": "2023-09-28T02:23:27.772323Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_nmt(text):\n",
    "    def no_space(char,prev_char):\n",
    "        return char in set(',.!?') and prev_char !=' '\n",
    "    \n",
    "    text=text.replace('\\u202f', ' ').replace('\\xa0',' ').lower()\n",
    "    out=[' '+char if i>0 and no_space(char,text[i-1]) else char for i,char in enumerate(text) ]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42762d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:28.537484Z",
     "start_time": "2023-09-28T02:23:28.532602Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_nmt(text,num_examples=None):\n",
    "    source,target=[],[]\n",
    "    for i ,line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts=line.split('\\t')\n",
    "        if len(parts)==2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source,target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "145b6164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:29.568717Z",
     "start_time": "2023-09-28T02:23:29.564825Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "#     \"\"\"将机器翻译的⽂本序列转换成⼩批量\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "#     print(\"lines : \",lines)\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fd87de5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:30.441661Z",
     "start_time": "2023-09-28T02:23:30.436778Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "#     \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "#     print(\"source : \",source)\n",
    "#     print(\"target : \",target)\n",
    "    src_vocab = Vocab(source, min_freq=2,reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocab(target, min_freq=2,reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55d8b95a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:31.263421Z",
     "start_time": "2023-09-28T02:23:31.260492Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5191da7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:31.984089Z",
     "start_time": "2023-09-28T02:23:31.980183Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data_nmt():\n",
    "    data_dir=r'F:\\study\\ml\\DataSet\\fra-eng'\n",
    "    with open(os.path.join(data_dir,'fra.txt'),'r',encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bae4704b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:32.703888Z",
     "start_time": "2023-09-28T02:23:32.699968Z"
    }
   },
   "outputs": [],
   "source": [
    "def truncate_pad(line,num_steps,padding_token):\n",
    "    if len(line)>num_steps:\n",
    "        return line[:num_steps]\n",
    "    return line + [padding_token]*(num_steps-len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab0df802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:33.528478Z",
     "start_time": "2023-09-28T02:23:33.524571Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7096eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:23:34.241429Z",
     "start_time": "2023-09-28T02:23:34.236533Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453da232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90833192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ae54d9",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7cdbc65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:24:38.967447Z",
     "start_time": "2023-09-28T02:24:38.963530Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size,num_hiddens,num_layers,dropout=32,32,2,0.1\n",
    "batch_size,num_steps=64,10\n",
    "lr,num_epochs,device=0.005,250,'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6280f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3da2b2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:24:49.958787Z",
     "start_time": "2023-09-28T02:24:43.195355Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter,src_vocab,tgt_vocab=load_data_nmt(batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2553e839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:25:19.257842Z",
     "start_time": "2023-09-28T02:25:19.251971Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder=Seq2SeqEncoder(len(src_vocab),embed_size,num_hiddens,num_layers,dropout)\n",
    "decoder=Seq2SeqAttentionDecoder(len(tgt_vocab),embed_size,num_hiddens,num_layers,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7c855eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:25:27.863193Z",
     "start_time": "2023-09-28T02:25:27.859274Z"
    }
   },
   "outputs": [],
   "source": [
    "net=EncoderDecoder(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2cdc7bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:27:04.068312Z",
     "start_time": "2023-09-28T02:25:31.739859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  10  train loss :  0.36707769402875584\n",
      "epoch :  20  train loss :  0.3036410383961757\n",
      "epoch :  30  train loss :  0.25744711687369587\n",
      "epoch :  40  train loss :  0.22361015594434663\n",
      "epoch :  50  train loss :  0.19862289404831768\n",
      "epoch :  60  train loss :  0.17908439496935316\n",
      "epoch :  70  train loss :  0.16351200737410573\n",
      "epoch :  80  train loss :  0.15064960891651996\n",
      "epoch :  90  train loss :  0.13996249633215962\n",
      "epoch :  100  train loss :  0.13089516700899845\n",
      "epoch :  110  train loss :  0.12312196847435623\n",
      "epoch :  120  train loss :  0.11641426066526474\n",
      "epoch :  130  train loss :  0.11057046908856988\n",
      "epoch :  140  train loss :  0.10540969340347642\n",
      "epoch :  150  train loss :  0.10082947191249347\n",
      "epoch :  160  train loss :  0.09678022835362872\n",
      "epoch :  170  train loss :  0.0931576797385621\n",
      "epoch :  180  train loss :  0.08987865391616676\n",
      "epoch :  190  train loss :  0.08693181452567746\n",
      "epoch :  200  train loss :  0.0842547712490219\n",
      "epoch :  210  train loss :  0.08180369834749236\n",
      "epoch :  220  train loss :  0.07957601988191777\n",
      "epoch :  230  train loss :  0.07752029804126692\n",
      "epoch :  240  train loss :  0.07564554627388172\n",
      "epoch :  250  train loss :  0.07389304577464789\n"
     ]
    }
   ],
   "source": [
    "train_seq2seq(net,train_iter,lr,num_epochs,tgt_vocab,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef20e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net,src_sentence,src_vocab,tgt_vocab,num_steps,device,save_attention_weights=True):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8ebb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfba20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
