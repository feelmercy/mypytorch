{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10dc60c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T05:57:28.880819Z",
     "start_time": "2023-05-24T05:57:14.032906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2c8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:06:56.958390Z",
     "start_time": "2023-05-24T06:06:56.952533Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path=r'F:\\study\\ml\\LM\\8\\timemachine.txt'\n",
    "def read_time_machine():\n",
    "    with open(file_path) as f:\n",
    "        lines=f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+',' ',line).strip().lower() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538d4292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:07:08.002856Z",
     "start_time": "2023-05-24T06:07:07.996341Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(lines,token='word'):\n",
    "    if token=='word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token=='char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print(\"error : unknown token type : \",token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e7a485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:07:17.061860Z",
     "start_time": "2023-05-24T06:07:17.038432Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter=count_corpus(tokens)\n",
    "        self._token_freqs=sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        self.idx_to_token=['<unk>']+reserved_tokens\n",
    "        self.token_to_idx={token:idx for idx,token in enumerate(self.idx_to_token)}\n",
    "        self.idx_to_token,self.token_to_idx=[],dict()\n",
    "        for token,freq in self._token_freqs:\n",
    "            if freq<min_freq:\n",
    "                break;\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0;\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2f4602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:07:17.793045Z",
     "start_time": "2023-05-24T06:07:17.788163Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_corpus(tokens):\n",
    "    if len(tokens)==0 or isinstance(tokens[0],list):\n",
    "        tokens=[token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f3f28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:07:18.479886Z",
     "start_time": "2023-05-24T06:07:18.413179Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens=tokenize(read_time_machine())\n",
    "corpus=[token for line in tokens for token in line]\n",
    "vocab=Vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4d21d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:07:19.027566Z",
     "start_time": "2023-05-24T06:07:19.021690Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_corpus_time_machine(max_tokens=-1):\n",
    "    lines=read_time_machine()\n",
    "    tokens=tokenize(lines,'char')\n",
    "    vocab=Vocab(tokens)\n",
    "    corpus=[vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens>0:\n",
    "        corpus=corpus[:max_tokens]\n",
    "    return corpus,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78d3c26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:07:19.789247Z",
     "start_time": "2023-05-24T06:07:19.662955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170580, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus,vocab=load_corpus_time_machine()\n",
    "len(corpus),len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507814eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:11:37.292148Z",
     "start_time": "2023-05-24T06:11:37.285313Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    corpus=corpus[random.randint(0,num_step-1):]\n",
    "    num_subseqs=(len(corpus)-1)//num_steps\n",
    "    initial_indices=list(range(0,num_subseqs*num_steps,num_steps))\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "    \n",
    "    num_batches=num_subseqs // batch_size\n",
    "    for i in range(0,batch_size*num_batches,batch_size):\n",
    "        initial_indices_per_batch=initial_indices[i:i+batch_size]\n",
    "        X=[data(j) for j in initial_indices_per_batch]\n",
    "        Y=[data(j+1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X),torch.tensor(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8739de94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:11:50.682623Z",
     "start_time": "2023-05-24T06:11:50.675788Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "    offset=random.randint(0,num_steps)\n",
    "    num_tokens=((len(corpus)-offset -1) //batch_size)*batch_size\n",
    "    Xs=torch.tensor(corpus[offset:offset+num_tokens])\n",
    "    Ys=torch.tensor(corpus[offset+1:offset+1+num_tokens])\n",
    "    Xs,Ys=Xs.reshape(batch_size,-1),Ys.reshape(batch_size,-1)\n",
    "    num_batches=Xs.shape[1]//num_steps\n",
    "    for i in range(0,num_steps*num_batches,num_steps):\n",
    "        X=Xs[:,i:i+num_steps]\n",
    "        Y=Ys[:,i:i+num_steps]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5a55de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:11:51.606092Z",
     "start_time": "2023-05-24T06:11:51.508459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[ 3,  4,  5,  6,  7],\n",
      "        [18, 19, 20, 21, 22]]) \n",
      "Y: tensor([[ 4,  5,  6,  7,  8],\n",
      "        [19, 20, 21, 22, 23]])\n",
      "X:  tensor([[ 8,  9, 10, 11, 12],\n",
      "        [23, 24, 25, 26, 27]]) \n",
      "Y: tensor([[ 9, 10, 11, 12, 13],\n",
      "        [24, 25, 26, 27, 28]])\n",
      "X:  tensor([[13, 14, 15, 16, 17],\n",
      "        [28, 29, 30, 31, 32]]) \n",
      "Y: tensor([[14, 15, 16, 17, 18],\n",
      "        [29, 30, 31, 32, 33]])\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
    "    print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37b4c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:11:52.561130Z",
     "start_time": "2023-05-24T06:11:52.556248Z"
    }
   },
   "outputs": [],
   "source": [
    "class SeqDataLoader:\n",
    "    def __init__(self,batch_size,num_steps,use_random_iter,max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn=seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn=seq_data_iter_sequential\n",
    "        self.corpus,self.vocab=load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size,self.num_steps=batch_size,num_steps\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus,self.batch_size,self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9b2b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:22.568396Z",
     "start_time": "2023-05-24T06:12:22.563496Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_time_machine(batch_size,num_steps,use_random_iter=False,max_tokens=10000):\n",
    "    data_iter=SeqDataLoader(batch_size,num_steps,use_random_iter,max_tokens)\n",
    "    return data_iter,data_iter.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf7cb8",
   "metadata": {},
   "source": [
    "### 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3286bc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:25.449623Z",
     "start_time": "2023-05-24T06:12:25.324182Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size,num_steps=32,35\n",
    "train_iter,vocab=load_data_time_machine(batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475eddfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:26.172883Z",
     "start_time": "2023-05-24T06:12:26.075430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(10).reshape((2,5))\n",
    "F.one_hot(X.T,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e2d10d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:26.820166Z",
     "start_time": "2023-05-24T06:12:26.813355Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_params(vocab_size,num_hiddens,device):\n",
    "    num_inputs=num_outputs=vocab_size\n",
    "    \n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape,device=device)*0.01\n",
    "#     hidden layer\n",
    "    W_xh=normal((num_inputs,num_hiddens))\n",
    "    W_hh=normal((num_hiddens,num_hiddens))\n",
    "    b_h=torch.zeros(num_hiddens,device=device)\n",
    "#     output layer\n",
    "    W_hq=normal((num_hiddens,num_outputs))\n",
    "    b_q=torch.zeros(num_outputs,device=device)\n",
    "    \n",
    "#     add grad\n",
    "    params=[W_xh,W_hh,b_h,W_hq,b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4981b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:27.473398Z",
     "start_time": "2023-05-24T06:12:27.468516Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14bc4e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:28.160108Z",
     "start_time": "2023-05-24T06:12:28.155226Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn(inputs,state,params):\n",
    "    W_xh,W_hh,b_h,W_hq,b_q=params\n",
    "    H,=state\n",
    "    outputs=[]\n",
    "    for X in inputs:\n",
    "        H=torch.tanh(torch.mm(X,W_xh)+torch.mm(H,W_hh)+b_h)\n",
    "        Y=torch.mm(H,W_hq)+b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs,dim=0),(H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2614fe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:28.939405Z",
     "start_time": "2023-05-24T06:12:28.933546Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModuelScatch:\n",
    "    def __init__(self,vocab_size,num_hiddens,device,get_params,init_state,forward_fn):\n",
    "        self.vocab_size,self.num_hiddens=vocab_size,num_hiddens\n",
    "        self.params=get_params(vocab_size,num_hiddens,device)\n",
    "        self.init_state,self.forward_fn=init_state,forward_fn\n",
    "    \n",
    "    def __call__(self,X,state):\n",
    "        X=F.one_hot(X.T,self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X,state,self.params)\n",
    "    \n",
    "    def begin_state(self,batch_size,device):\n",
    "        return self.init_state(batch_size,self.num_hiddens,device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2535ad8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:33.345721Z",
     "start_time": "2023-05-24T06:12:33.094343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 27]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens=512\n",
    "net=RNNModuelScatch(len(vocab),num_hiddens,'cpu',get_params,init_rnn_state,rnn)\n",
    "state=net.begin_state(X.shape[0],'cpu')\n",
    "Y,new_state=net(X.to('cpu'),state)\n",
    "Y.shape,len(new_state),new_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be7d79cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:48.585990Z",
     "start_time": "2023-05-24T06:12:48.580132Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ch8(prefix,num_preds,net,vocab,device):\n",
    "    state=net.begin_state(batch_size=1,device=device)\n",
    "    outputs=[vocab[prefix[0]]]\n",
    "    get_input=lambda : torch.tensor([outputs[-1]],device=device).reshape((1,1))\n",
    "    for y in prefix[1:]:\n",
    "        _,state=net(get_input(),state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):\n",
    "        y,state=net(get_input(),state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaeb821d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:12:49.634729Z",
     "start_time": "2023-05-24T06:12:49.627895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1], device='cpu').reshape((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c08360c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:13:05.857203Z",
     "start_time": "2023-05-24T06:13:05.852311Z"
    }
   },
   "outputs": [],
   "source": [
    "a=lambda: torch.tensor([1], device='cpu').reshape((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d7e3b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:13:06.568610Z",
     "start_time": "2023-05-24T06:13:06.563700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb30d179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:13:07.265500Z",
     "start_time": "2023-05-24T06:13:07.227548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller lz npxedld'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('time traveller ',10,net,vocab,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "817eee32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:13:19.849368Z",
     "start_time": "2023-05-24T06:13:19.844487Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params=[p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params=net.params\n",
    "    norm=torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm>theta:\n",
    "        for param in params:\n",
    "            param.grad[:]*=theta /norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6a45892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:15:36.723271Z",
     "start_time": "2023-05-24T06:15:36.714866Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch_ch8(net,train_iter,loss,updater,device,use_random_iter):\n",
    "    state=None\n",
    "    tr_l,tr_num=[],[]\n",
    "    for X,Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            state=net.begin_state(batch_size=X.shape[0],device=device)\n",
    "        else:\n",
    "            if isinstance(net,nn.Module) and not isinstance(state,tuple):\n",
    "                state.detach_()\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y=Y.T.reshape(-1)\n",
    "        X,y=X.to(device),y.to(device)\n",
    "        y_hat,state=net(X,state)\n",
    "        l=loss(y_hat,y.long()).mean()\n",
    "        if isinstance(updater,torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net,l)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net,l)\n",
    "            updater(batch_size=1)\n",
    "        tr_l.append(l*y.numel())\n",
    "        tr_num.append(y.numel())\n",
    "    return math.exp(sum(tr_l)/sum(tr_num))\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "203bbe36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T06:15:37.960022Z",
     "start_time": "2023-05-24T06:15:37.955137Z"
    }
   },
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for p in params:\n",
    "            p.data -=lr*p.grad.data/batch_size\n",
    "            p.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8377d23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:11:17.060682Z",
     "start_time": "2023-05-24T07:11:17.053829Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch8(net,train_iter,vocab,lr,num_epochs,device,use_random_iter=False):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    if isinstance(net,nn.Module):\n",
    "        updater=torch.optim.SGD(net.parameters(),lr)\n",
    "    else:\n",
    "        updater=lambda batch_size:sgd(net.params,lr,batch_size)\n",
    "    predict=lambda prefix:predict_ch8(prefix,50,net,vocab,device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        ppl=train_epoch_ch8(net,train_iter,loss,updater,device,use_random_iter)\n",
    "        \n",
    "        if(epoch+1) %10==0:\n",
    "            print(predict(\"time traveller\"))\n",
    "    print(f'困惑度 {ppl:.1f}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f092a632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T07:16:35.031104Z",
     "start_time": "2023-05-24T07:11:17.878871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time travellere the the the the the the the the the the the the \n",
      "time travellere the the the the the the the the the the the the \n",
      "time traveller the the the the the the the the the the the the t\n",
      "time travellere and and and and and and and and and and and and \n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller and the the this the thimens of the that simens o\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller andithe mane the the the and and and and and and \n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller and the the the the the the the the the the the t\n",
      "time traveller at in the that he pare the thing the thing the th\n",
      "time traveller thee this the thitht thee that ne sime and the th\n",
      "time traveller dimentions of space the thing time that leat our \n",
      "time traveller said the midit yome thave at in and thick ond wis\n",
      "time traveller th ef and ther the thavell thick and ther the tha\n",
      "time traveller and three dimensions of space and an anoun the me\n",
      "time traveller the fire wh chis th the indithe mone s inllest mo\n",
      "time traveller tardet an thin time thiventhe risection in wa the\n",
      "time travellerit s againtt riscedent sime there is a wover candl\n",
      "time traveller peree said the time travellerit s against reason \n",
      "time traveller fite fis you cannot metteat ol shi fould i shered\n",
      "time traveller ffres hand whith re ard anvent wist r all grever \n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller cimespace pane are thee armal see sare wo can goo\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time traveller fite fis that veryoube acon this they hese that f\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time traveller fite fichty anl mom saill the tile pere ward lo m\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "time travelleryou can show black is white by argument said filby\n",
      "困惑度 1.0\n",
      "time travelleryou can show black is white by argument said filby\n",
      "travelleryou can show black is white by argument said filby\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb24ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be353df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78624642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4a7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
