{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10dc60c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:07.117059Z",
     "start_time": "2023-05-22T06:55:07.084352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2c8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:07.927370Z",
     "start_time": "2023-05-22T06:55:07.922489Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path=r'F:\\study\\ml\\LM\\8\\timemachine.txt'\n",
    "def read_time_machine():\n",
    "    with open(file_path) as f:\n",
    "        lines=f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+',' ',line).strip().lower() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538d4292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:08.566507Z",
     "start_time": "2023-05-22T06:55:08.561943Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(lines,token='word'):\n",
    "    if token=='word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token=='char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print(\"error : unknown token type : \",token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e7a485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:09.917981Z",
     "start_time": "2023-05-22T06:55:09.908444Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter=count_corpus(tokens)\n",
    "        self._token_freqs=sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        self.idx_to_token=['<unk>']+reserved_tokens\n",
    "        self.token_to_idx={token:idx for idx,token in enumerate(self.idx_to_token)}\n",
    "        self.idx_to_token,self.token_to_idx=[],dict()\n",
    "        for token,freq in self._token_freqs:\n",
    "            if freq<min_freq:\n",
    "                break;\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0;\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e2f4602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:10.926267Z",
     "start_time": "2023-05-22T06:55:10.921386Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_corpus(tokens):\n",
    "    if len(tokens)==0 or isinstance(tokens[0],list):\n",
    "        tokens=[token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f3f28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:11.641171Z",
     "start_time": "2023-05-22T06:55:11.564041Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens=tokenize(read_time_machine())\n",
    "corpus=[token for line in tokens for token in line]\n",
    "vocab=Vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4d21d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:43.246786Z",
     "start_time": "2023-05-22T06:55:43.241285Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_corpus_time_machine(max_tokens=-1):\n",
    "    lines=read_time_machine()\n",
    "    tokens=tokenize(lines,'char')\n",
    "    vocab=Vocab(tokens)\n",
    "    corpus=[vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens>0:\n",
    "        corpus=corpus[:max_tokens]\n",
    "    return corpus,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78d3c26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:44.284249Z",
     "start_time": "2023-05-22T06:55:44.147439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170580, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus,vocab=load_corpus_time_machine()\n",
    "len(corpus),len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507814eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:45.224827Z",
     "start_time": "2023-05-22T06:55:45.218970Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    corpus=corpus[random.randint(0,num_step-1):]\n",
    "    num_subseqs=(len(corpus)-1)//num_steps\n",
    "    initial_indices=list(range(0,num_subseqs*num_steps,num_steps))\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "    \n",
    "    num_batches=num_subseqs // batch_size\n",
    "    for i in range(0,batch_size*num_batches,batch_size):\n",
    "        initial_indices_per_batch=initial_indices[i:i+batch_size]\n",
    "        X=[data(j) for j in initial_indices_per_batch]\n",
    "        Y=[data(j+1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X),torch.tensor(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8739de94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:46.104704Z",
     "start_time": "2023-05-22T06:55:46.097851Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "    offset=random.randint(0,num_steps)\n",
    "    num_tokens=((len(corpus)-offset -1) //batch_size)*batch_size\n",
    "    Xs=torch.tensor(corpus[offset:offset+num_tokens])\n",
    "    Ys=torch.tensor(corpus[offset+1:offset+1+num_tokens])\n",
    "    Xs,Ys=Xs.reshape(batch_size,-1),Ys.reshape(batch_size,-1)\n",
    "    num_batches=Xs.shape[1]//num_steps\n",
    "    for i in range(0,num_steps*num_batches,num_steps):\n",
    "        X=Xs[:,i:i+num_steps]\n",
    "        Y=Ys[:,i:i+num_steps]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5a55de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:47.340699Z",
     "start_time": "2023-05-22T06:55:47.329938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[ 2,  3,  4,  5,  6],\n",
      "        [18, 19, 20, 21, 22]]) \n",
      "Y: tensor([[ 3,  4,  5,  6,  7],\n",
      "        [19, 20, 21, 22, 23]])\n",
      "X:  tensor([[ 7,  8,  9, 10, 11],\n",
      "        [23, 24, 25, 26, 27]]) \n",
      "Y: tensor([[ 8,  9, 10, 11, 12],\n",
      "        [24, 25, 26, 27, 28]])\n",
      "X:  tensor([[12, 13, 14, 15, 16],\n",
      "        [28, 29, 30, 31, 32]]) \n",
      "Y: tensor([[13, 14, 15, 16, 17],\n",
      "        [29, 30, 31, 32, 33]])\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
    "    print('X: ', X, '\\nY:', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37b4c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:55:48.191363Z",
     "start_time": "2023-05-22T06:55:48.185505Z"
    }
   },
   "outputs": [],
   "source": [
    "class SeqDataLoader:\n",
    "    def __init__(self,batch_size,num_steps,use_random_iter,max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn=seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn=seq_data_iter_sequential\n",
    "        self.corpus,self.vocab=load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size,self.num_steps=batch_size,num_steps\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus,self.batch_size,self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9b2b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:56:50.110634Z",
     "start_time": "2023-05-22T06:56:50.105733Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_time_machine(batch_size,num_steps,use_random_iter=False,max_tokens=10000):\n",
    "    data_iter=SeqDataLoader(batch_size,num_steps,use_random_iter,max_tokens)\n",
    "    return data_iter,data_iter.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf7cb8",
   "metadata": {},
   "source": [
    "### 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3286bc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:56:51.558972Z",
     "start_time": "2023-05-22T06:56:51.418380Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size,num_steps=32,35\n",
    "train_iter,vocab=load_data_time_machine(batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475eddfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:56:58.951779Z",
     "start_time": "2023-05-22T06:56:58.913756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(10).reshape((2,5))\n",
    "F.one_hot(X.T,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e2d10d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:57:00.032163Z",
     "start_time": "2023-05-22T06:57:00.026286Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_params(vocab_size,num_hiddens,device):\n",
    "    num_inputs=num_outputs=vocab_size\n",
    "    \n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape,device=device)*0.01\n",
    "#     hidden layer\n",
    "    W_xh=normal((num_inputs,num_hiddens))\n",
    "    W_hh=normal((num_hiddens,num_hiddens))\n",
    "    b_h=torch.zeros(num_hiddens,device=device)\n",
    "#     output layer\n",
    "    W_hq=normal((num_hiddens,num_outputs))\n",
    "    b_q=torch.zeros(num_outputs,device=device)\n",
    "    \n",
    "#     add grad\n",
    "    params=[W_xh,W_hh,b_h,W_hq,b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4981b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:57:01.047607Z",
     "start_time": "2023-05-22T06:57:01.043696Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14bc4e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:57:01.666006Z",
     "start_time": "2023-05-22T06:57:01.658177Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn(inputs,state,params):\n",
    "    W_xh,W_hh,b_h,W_hq,b_q=params\n",
    "    H,=state\n",
    "    outputs=[]\n",
    "    for X in inputs:\n",
    "        H=torch.tanh(torch.mm(X,W_xh)+torch.mm(H,W_hh)+b_h)\n",
    "        Y=torch.mm(H,W_hq)+b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs,dim=0),(H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2614fe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:00:58.256868Z",
     "start_time": "2023-05-22T07:00:58.250004Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModuelScatch:\n",
    "    def __init__(self,vocab_size,num_hiddens,device,get_params,init_state,forward_fn):\n",
    "        self.vocab_size,self.num_hiddens=vocab_size,num_hiddens\n",
    "        self.params=get_params(vocab_size,num_hiddens,device)\n",
    "        self.init_state,self.forward_fn=init_state,forward_fn\n",
    "    \n",
    "    def __call__(self,X,state):\n",
    "        X=F.one_hot(X.T,self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X,state,self.params)\n",
    "    \n",
    "    def begin_state(self,batch_size,device):\n",
    "        return self.init_state(batch_size,self.num_hiddens,device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2535ad8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:02:26.795556Z",
     "start_time": "2023-05-22T07:02:26.777458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 27]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens=512\n",
    "net=RNNModuelScatch(len(vocab),num_hiddens,'cpu',get_params,init_rnn_state,rnn)\n",
    "state=net.begin_state(X.shape[0],'cpu')\n",
    "Y,new_state=net(X.to('cpu'),state)\n",
    "Y.shape,len(new_state),new_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be7d79cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:26:44.495682Z",
     "start_time": "2023-05-22T07:26:44.488305Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ch8(prefix,num_preds,net,vocab,device):\n",
    "    state=net.begin_state(batch_size=1,device=device)\n",
    "    outputs=[vocab[prefix[0]]]\n",
    "    get_input=lambda : torch.tensor([outputs[-1]],device=device).reshape((1,1))\n",
    "    for y in prefix[1:]:\n",
    "        _,state=net(get_input(),state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):\n",
    "        y,state=net(get_input(),state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aaeb821d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:26:44.877793Z",
     "start_time": "2023-05-22T07:26:44.870955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1], device='cpu').reshape((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c08360c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:26:45.115099Z",
     "start_time": "2023-05-22T07:26:45.110217Z"
    }
   },
   "outputs": [],
   "source": [
    "a=lambda: torch.tensor([1], device='cpu').reshape((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d7e3b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:26:45.526720Z",
     "start_time": "2023-05-22T07:26:45.519899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb30d179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:26:46.082254Z",
     "start_time": "2023-05-22T07:26:46.047124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller ya gzgzgzg'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('time traveller ',10,net,vocab,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "817eee32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T08:18:46.055167Z",
     "start_time": "2023-05-22T08:18:46.050275Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    if isinstance(net,nn.Module):\n",
    "        params=[p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params=net.params\n",
    "    norm=torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm>theta:\n",
    "        for param in params:\n",
    "            param.grad[:]*=theta /norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6a45892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T09:35:05.646657Z",
     "start_time": "2023-05-22T09:35:05.637870Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch_ch8(net,train_iter,loss,updater,device,use_random_iter):\n",
    "    state=None\n",
    "    tr_l,tr_num=[],[]\n",
    "    for X,Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            state=net.begin_state(batch_size=X.shape[0],device=device)\n",
    "        else:\n",
    "            if isinstance(net,nn.Module) and not isinstance(state,tuple):\n",
    "                state.detach_()\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y=Y.T.reshape(-1)\n",
    "        X,y=X.to(device),y.to(device)\n",
    "        y_hat,state=net(X,state)\n",
    "        l=loss(y_hat,y.long()).mean()\n",
    "        if isinstance(updater,torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net,l)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net,l)\n",
    "            updater(batch_size=1)\n",
    "        tr_l.append(l*y.numel())\n",
    "        tr_num.append(y.numel())\n",
    "    return math.exp(sum(tr_l)/sum(tr_num))\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "203bbe36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T09:43:39.079256Z",
     "start_time": "2023-05-22T09:43:39.074381Z"
    }
   },
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for p in params:\n",
    "            p.data -=lr*p.grad.data/batch_size\n",
    "            p.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8377d23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T09:59:11.794866Z",
     "start_time": "2023-05-22T09:59:11.787068Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch8(net,train_iter,vocab,lr,num_epochs,device,use_random_iter=False):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    if isinstance(net,nn.Module):\n",
    "        updater=torch.optim.SGD(net.parameters(),lr)\n",
    "    else:\n",
    "        updater=lambda batch_size:sgd(net.parameters(),lr)\n",
    "    predict=lambda prefix:predict_ch8(prefix,50,net,vocab,device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        ppl=train_epoch_ch8(net,train_iter,loss,updater,device,use_random_iter)\n",
    "        \n",
    "        if(epoch+1) %10==0:\n",
    "            print(predict(\"time traveller\"))\n",
    "    print(f'困惑度 {ppl:.1f}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f092a632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T09:59:28.884732Z",
     "start_time": "2023-05-22T09:59:28.418064Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RNNModuelScatch' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0ed88b1510fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_ch8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-020b1bca2973>\u001b[0m in \u001b[0;36mtrain_ch8\u001b[1;34m(net, train_iter, vocab, lr, num_epochs, device, use_random_iter)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mppl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_epoch_ch8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupdater\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_random_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-47488fb810aa>\u001b[0m in \u001b[0;36mtrain_epoch_ch8\u001b[1;34m(net, train_iter, loss, updater, device, use_random_iter)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mgrad_clipping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mupdater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtr_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtr_num\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-020b1bca2973>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mupdater\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mupdater\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mpredict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpredict_ch8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RNNModuelScatch' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb24ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be353df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78624642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4a7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
