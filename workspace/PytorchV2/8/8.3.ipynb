{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b06de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T09:22:54.411556Z",
     "start_time": "2023-04-28T09:22:54.379337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560fc55a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T09:22:55.146736Z",
     "start_time": "2023-04-28T09:22:55.141855Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path=r'F:\\study\\ml\\LM\\8\\timemachine.txt'\n",
    "def read_time_machine():\n",
    "    with open(file_path) as f:\n",
    "        lines=f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+',' ',line).strip().lower() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88302390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T09:22:55.842118Z",
     "start_time": "2023-04-28T09:22:55.838199Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(lines,token='word'):\n",
    "    if token=='word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token=='char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print(\"error : unknown token type : \",token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d2b7fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T07:40:49.683320Z",
     "start_time": "2023-04-28T07:40:49.674547Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter=count_corpus(tokens)\n",
    "        self._token_freqs=sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        self.idx_to_token=['<unk>']+reserved_tokens\n",
    "        self.token_to_idx={token:idx for idx,token in enumerate(self.idx_to_token)}\n",
    "        self.idx_to_token,self.token_to_idx=[],dict()\n",
    "        for token,freq in self._token_freqs:\n",
    "            if freq<min_freq:\n",
    "                break;\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0;\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2764cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T07:41:16.757806Z",
     "start_time": "2023-04-28T07:41:16.753901Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_corpus(tokens):\n",
    "    if len(tokens)==0 or isinstance(tokens[0],list):\n",
    "        tokens=[token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb26e4ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T08:43:42.896150Z",
     "start_time": "2023-04-18T08:43:42.864857Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens=tokenize(read_time_machine())\n",
    "corpus=[token for line in tokens for token in line]\n",
    "vocab=Vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c009f123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T08:44:08.319378Z",
     "start_time": "2023-04-18T08:44:08.312544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2261),\n",
       " ('i', 1267),\n",
       " ('and', 1245),\n",
       " ('of', 1155),\n",
       " ('a', 816),\n",
       " ('to', 695),\n",
       " ('was', 552),\n",
       " ('in', 541),\n",
       " ('that', 443),\n",
       " ('my', 440)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.token_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be3b4f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T09:12:34.669707Z",
     "start_time": "2023-04-18T09:12:34.664754Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    corpus=corpus[random.randint(0,num_step-1):]\n",
    "    num_subseqs=(len(corpus)-1)//num_steps\n",
    "    initial_indices=list(range(0,num_subseqs*num_steps,num_steps))\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "    \n",
    "    num_batches=num_subseqs // batch_size\n",
    "    for i in range(0,batch_size*num_batches,batch_size):\n",
    "        initial_indices_per_batch=initial_indices[i:i+batch_size]\n",
    "        X=[data(j) for j in initial_indices_per_batch]\n",
    "        Y=[data(j+1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X),torch.tensor(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daecf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e9fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494bc72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
