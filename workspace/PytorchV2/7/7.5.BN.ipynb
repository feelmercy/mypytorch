{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f436e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T01:56:29.786435Z",
     "start_time": "2022-06-07T01:56:19.005066Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f71cf0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:21.339076Z",
     "start_time": "2022-06-07T02:23:21.319574Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_norm(X,gamma,beta,moving_mean,moving_var,eps,momentum):\n",
    "    if not torch.is_grad_enabled():\n",
    "        X_hat=(X-moving_mean) / torch.sqrt(moving_var+eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2,4)\n",
    "        if len(X.shape)==2:\n",
    "            mean=X.mean(dim=0)\n",
    "            var=((X-mean)**2).mean(dim=0)\n",
    "        else:\n",
    "            mean=X.mean(dim=(0,2,3),keepdim=True)\n",
    "            var=((X-mean)**2).mean(dim=(0,2,3),keepdim=True)\n",
    "        X_hat=(X-mean)/torch.sqrt(var+eps)\n",
    "        moving_mean=momentum*moving_mean+(1.0-momentum)*mean\n",
    "        moving_var=momentum*moving_var+(1.0-momentum)*var\n",
    "    Y=gamma*X_hat+beta\n",
    "    return Y,moving_mean.data,moving_var.data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f096862c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:21.773631Z",
     "start_time": "2022-06-07T02:23:21.757629Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self,num_features,num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims==2:\n",
    "            shape=(1,num_features)\n",
    "        else:\n",
    "            shape=(1,num_features,1,1)\n",
    "        self.gamma=nn.Parameter(torch.ones(shape))\n",
    "        self.beta=nn.Parameter(torch.zeros(shape))\n",
    "        \n",
    "        self.moving_mean=torch.zeros(shape)\n",
    "        self.moving_var=torch.ones(shape)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean=self.moving_mean.to(X.device)\n",
    "            self.moving_var=self.moving_var.to(X.device)\n",
    "        Y,self.moving_mean,self.moving_var=batch_norm(X,self.gamma,self.beta,self.moving_mean,self.moving_var,eps=1e-5,momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "748e2942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:22.164681Z",
     "start_time": "2022-06-07T02:23:22.143678Z"
    }
   },
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "    nn.Conv2d(1,6,kernel_size=5),BatchNorm(6,num_dims=4),nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "    nn.Conv2d(6,16,kernel_size=5),BatchNorm(16,num_dims=4),nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2,stride=2),nn.Flatten(),\n",
    "    nn.Linear(16*4*4,120),BatchNorm(120,num_dims=2),nn.Sigmoid(),\n",
    "    nn.Linear(120,84),BatchNorm(84,num_dims=2),nn.Sigmoid(),\n",
    "    nn.Linear(84,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2d16211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:22.565232Z",
     "start_time": "2022-06-07T02:23:22.558731Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "516646dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:23.007788Z",
     "start_time": "2022-06-07T02:23:22.957282Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "mnist_train=torchvision.datasets.FashionMNIST(\n",
    "    root='F:\\study\\ml\\DataSet\\FashionMNIST',train=True,\n",
    "    download=True,transform=transforms.ToTensor())\n",
    "mnist_test=torchvision.datasets.FashionMNIST(\n",
    "    root='F:\\study\\ml\\DataSet\\FashionMNIST',train=False,\n",
    "    download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9feb61c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:23.409839Z",
     "start_time": "2022-06-07T02:23:23.404338Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter=torch.utils.data.DataLoader(mnist_train,batch_size,shuffle=True)\n",
    "test_iter=torch.utils.data.DataLoader(mnist_test,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a08b0819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:23.869898Z",
     "start_time": "2022-06-07T02:23:23.854396Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net,data_iter,device=None):\n",
    "    if isinstance(net,nn.Module):\n",
    "        net.eval()\n",
    "        if not device:\n",
    "            device=next(iter(net.parameters())).device\n",
    "    l_sum=[]\n",
    "    for X,y in data_iter:\n",
    "        y_hat=net(X)\n",
    "        l_sum.append( (sum(torch.argmax(y_hat,dim=1).reshape(y.shape) == y)/y.shape[0]).item())\n",
    "    return sum(l_sum)/len(l_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d0f110f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:23:24.305953Z",
     "start_time": "2022-06-07T02:23:24.285950Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch6(net,train_iter,test_iter,num_epochs,lr,device):\n",
    "    def init_weight(m):\n",
    "        if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weight)\n",
    "    print('training on',device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        tr_l=[]\n",
    "        tr_acc=[]\n",
    "        net.train()\n",
    "        for X,y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_hat=net(X)\n",
    "#             print(y_hat)\n",
    "            l=loss(y_hat,y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                tr_l.append(l.item())\n",
    "#                 print(y.shape)\n",
    "#                 print(y_hat.shape)\n",
    "#                 print(y_hat)\n",
    "#                 print(y)\n",
    "#                 print(torch.argmax(y_hat,dim=1))\n",
    "                tr_acc.append( (sum(torch.argmax(y_hat,dim=1).reshape(y.shape) == y)/y.shape[0]).item())\n",
    "        test_acc=evaluate_accuracy_gpu(net,test_iter)\n",
    "        print('epoch : ',epoch ,' train loss : ',sum(tr_l)/len(tr_l),' train acc : ', sum(tr_acc)/len(tr_acc),'test acc : ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb644322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:27:29.578599Z",
     "start_time": "2022-06-07T02:23:24.800016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu\n",
      "epoch :  0  train loss :  0.742442106693349  train acc :  0.7330562944107867 test acc :  0.7291015625\n",
      "epoch :  1  train loss :  0.49389492007012065  train acc :  0.8191988031914894 test acc :  0.83701171875\n",
      "epoch :  2  train loss :  0.4033650502245477  train acc :  0.853407579787234 test acc :  0.85224609375\n",
      "epoch :  3  train loss :  0.3601266277597306  train acc :  0.8678025265957446 test acc :  0.8529296875\n",
      "epoch :  4  train loss :  0.3331690793341779  train acc :  0.8779421542553192 test acc :  0.85576171875\n",
      "epoch :  5  train loss :  0.31196352199037025  train acc :  0.8865359042553191 test acc :  0.84599609375\n",
      "epoch :  6  train loss :  0.2955932251316436  train acc :  0.8908300087807026 test acc :  0.88388671875\n",
      "epoch :  7  train loss :  0.28437234112556947  train acc :  0.8952349289934686 test acc :  0.8599609375\n",
      "epoch :  8  train loss :  0.27344608154702693  train acc :  0.8999168882978723 test acc :  0.8734375\n",
      "epoch :  9  train loss :  0.2651952926782852  train acc :  0.9020999555892133 test acc :  0.86044921875\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 1.0, 10, 256\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025654c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
