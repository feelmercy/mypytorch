{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466f1bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:05:49.794462Z",
     "start_time": "2022-06-22T09:05:47.169129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from torch import nn,optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f950c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:05:50.765586Z",
     "start_time": "2022-06-22T09:05:50.721580Z"
    }
   },
   "outputs": [],
   "source": [
    "train_imgs=torchvision.datasets.ImageFolder(r'F:\\study\\ml\\HotDog\\train')\n",
    "test_imgs=torchvision.datasets.ImageFolder(r'F:\\study\\ml\\HotDog\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e69cf41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:05:53.893483Z",
     "start_time": "2022-06-22T09:05:53.882481Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_images(imgs,num_rows,num_cols,scale=1.5):\n",
    "    figsize=(num_cols*scale,num_rows*scale)\n",
    "    plt.subplots(num_rows,num_cols,figsize=figsize)\n",
    "    for i in range(num_cols*num_rows):\n",
    "        plt.subplot(num_rows,num_cols,i+1)\n",
    "        if isinstance(imgs[i],PIL.Image.Image):\n",
    "            plt.imshow(np.array(imgs[i]))\n",
    "        else:\n",
    "            plt.imshow(imgs[i])\n",
    "    plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c8e79c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:05:56.155770Z",
     "start_time": "2022-06-22T09:05:55.584198Z"
    }
   },
   "outputs": [],
   "source": [
    "hotdogs=[train_imgs[i][0] for i in range(8)]\n",
    "not_hotdogs=[train_imgs[-i-1][0] for i in range(8)]\n",
    "show_images(hotdogs+not_hotdogs,2,8,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a249d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:06:01.030389Z",
     "start_time": "2022-06-22T09:06:01.024388Z"
    }
   },
   "outputs": [],
   "source": [
    "normize=torchvision.transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007b8349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:06:03.227668Z",
     "start_time": "2022-06-22T09:06:03.220167Z"
    }
   },
   "outputs": [],
   "source": [
    "train_augs = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), normize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1102b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:06:04.148785Z",
     "start_time": "2022-06-22T09:06:04.140784Z"
    }
   },
   "outputs": [],
   "source": [
    "test_augs=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c705e7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:06:06.091532Z",
     "start_time": "2022-06-22T09:06:05.785993Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_net=torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225c0c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:06:06.975644Z",
     "start_time": "2022-06-22T09:06:06.955642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for i in pretrained_net.named_parameters():\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992cdcd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:06:17.886530Z",
     "start_time": "2022-06-22T09:06:17.641999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0130,  0.0993, -0.0658,  ..., -0.0859, -0.0830,  0.0915],\n",
       "        [ 0.0081,  0.0690,  0.0885,  ..., -0.0378,  0.1051,  0.1031]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_net=torchvision.models.resnet18(pretrained=True)\n",
    "finetune_net.fc=nn.Linear(finetune_net.fc.in_features,2)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5a50f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:07:48.737066Z",
     "start_time": "2022-06-22T09:07:48.724064Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_acc_gpu(net,data_iter,device):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.to(device)\n",
    "        net.eval()\n",
    "        l_sum=[]\n",
    "        with torch.no_grad():\n",
    "            for X,y in data_iter:\n",
    "                X,y=X.to(device),y.to(device)\n",
    "                y_hat=net(X)\n",
    "                l_sum.append((sum(torch.argmax(y_hat,dim=1).reshape(y.shape)==y)/y.shape[0]).item())\n",
    "        return sum(l_sum)/len(l_sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c425fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:17:08.181107Z",
     "start_time": "2022-06-22T09:17:08.158604Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch66(net,train_iter,test_iter,loss,trainer,num_epochs,device):\n",
    "#     def init_weight(m):\n",
    "#         if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "#             nn.init.xavier_uniform_(m.weight)\n",
    "#     net.apply(init_weight)\n",
    "    print('train on : ',device)\n",
    "    net.to(device)\n",
    "    loss=loss\n",
    "    optimizer=trainer\n",
    "    for epoch in range(num_epochs):\n",
    "        tr_l,tr_acc=[],[]\n",
    "        net.train()\n",
    "        for X,y in train_iter:\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y).sum()\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                tr_l.append(l.item())\n",
    "                tr_acc.append((sum(torch.argmax(y_hat,dim=1).reshape(y.shape)==y)/y.shape[0]).item())\n",
    "        test_acc=evaluate_acc_gpu(net,test_iter,device)\n",
    "        print('epoch : ',epoch+1,' train loss : ',sum(tr_l)/len(tr_l),' train acc : ',sum(tr_acc)/len(tr_acc),' test acc : ',test_acc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a2e42b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:33:25.581721Z",
     "start_time": "2022-06-22T09:33:25.560718Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fine_tuning(net,lr,batch_size=128,num_epochs=5,param_group=True):\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    train_iter=torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(r'F:\\study\\ml\\HotDog\\train',transform=train_augs),\n",
    "                                          batch_size=batch_size,shuffle=True)\n",
    "    test_iter=torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(r'F:\\study\\ml\\HotDog\\test',transform=test_augs),\n",
    "                                          batch_size=batch_size,shuffle=True)\n",
    "    loss=nn.CrossEntropyLoss(reduction='none')\n",
    "    if param_group:\n",
    "        params_1x=[p for n,p in net.named_parameters() if n not in [\"fc.weight\",\"fc.bias\"]]\n",
    "        trainer=torch.optim.SGD([{'params':params_1x},\n",
    "                                {'params':net.fc.parameters(),'lr':lr*10}],\n",
    "                               lr=lr,weight_decay=0.001)\n",
    "    else:\n",
    "        trainer=torch.optim.SGD(net.parameters(),lr=lr,weight_decay=0.001)\n",
    "    train_ch66(net,train_iter,test_iter,loss,trainer,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0578bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:51:17.611351Z",
     "start_time": "2022-06-22T09:33:26.314814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on :  cpu\n",
      "epoch :  1  train loss :  243.84019720554352  train acc :  0.6927734389901161  test acc :  0.9073660714285714\n",
      "epoch :  2  train loss :  36.0447438955307  train acc :  0.8987304680049419  test acc :  0.9263392857142857\n",
      "epoch :  3  train loss :  31.070427179336548  train acc :  0.9092773422598839  test acc :  0.8839285714285714\n",
      "epoch :  4  train loss :  24.14473992586136  train acc :  0.9327148422598839  test acc :  0.9508928571428571\n",
      "epoch :  5  train loss :  28.214502960443497  train acc :  0.9170898422598839  test acc :  0.9475446428571429\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(finetune_net,5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b746d2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:51:21.586356Z",
     "start_time": "2022-06-22T09:51:21.349326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1019,  0.0707, -0.0856,  ..., -0.0540, -0.0223, -0.0031],\n",
       "        [ 0.1012,  0.0827, -0.0777,  ...,  0.0032, -0.0235, -0.0919]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_net=torchvision.models.resnet18(pretrained=True)\n",
    "finetune_net.fc=nn.Linear(finetune_net.fc.in_features,2)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb40ed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:51:22.699997Z",
     "start_time": "2022-06-22T09:51:22.459967Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_net=torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8002a553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:51:23.359081Z",
     "start_time": "2022-06-22T09:51:23.327077Z"
    }
   },
   "outputs": [],
   "source": [
    "weight=pretrained_net.fc.weight\n",
    "hotdog_w=torch.split(weight,1,dim=0)[713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fba9395a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T09:51:28.079680Z",
     "start_time": "2022-06-22T09:51:28.071179Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    finetune_net.fc.weight.data[0]=hotdog_w.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bd85b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-22T09:51:28.743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on :  cpu\n",
      "epoch :  1  train loss :  302.06534075737  train acc :  0.6920898444950581  test acc :  0.9095982142857143\n",
      "epoch :  2  train loss :  36.60175085067749  train acc :  0.9041015617549419  test acc :  0.9408482142857143\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(finetune_net,5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721efe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
