{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T02:31:05.900398Z",
     "start_time": "2020-10-12T02:31:01.693558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T02:34:47.317106Z",
     "start_time": "2020-10-12T02:34:46.828479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start download data . . .\n",
      "data type <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('start download data . . .')\n",
    "remove = ()\n",
    "categories = 'alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space'\n",
    "data_train = fetch_20newsgroups(subset='train',\n",
    "                                categories=categories,\n",
    "                                shuffle=True,\n",
    "                                random_state=0,\n",
    "                                remove=remove)\n",
    "data_test = fetch_20newsgroups(subset='test',\n",
    "                                categories=categories,\n",
    "                                shuffle=True,\n",
    "                                random_state=0,\n",
    "                                remove=remove)\n",
    "print('data type',type(data_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T02:36:58.078986Z",
     "start_time": "2020-10-12T02:36:58.050385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data sample num: 2034\n",
      "test data sample num: 1353\n",
      "train set and test category name: ('alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space')\n",
      "('alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space')\n"
     ]
    }
   ],
   "source": [
    "print('train data sample num:',len(data_train.data))\n",
    "print('test data sample num:',len(data_test.data))\n",
    "print('train set and test category name:',categories)\n",
    "pprint(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:12:19.410348Z",
     "start_time": "2020-10-12T03:12:19.391748Z"
    }
   },
   "outputs": [],
   "source": [
    "categories=data_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:12:21.111380Z",
     "start_time": "2020-10-12T03:12:21.095780Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=data_train.target\n",
    "y_test=data_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:12:21.588408Z",
     "start_time": "2020-10-12T03:12:21.578407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 3, 3, 3, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:13:14.311098Z",
     "start_time": "2020-10-12T03:13:14.286497Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 sample:\n",
      "0 category: alt.atheism\n",
      "From: healta@saturn.wwc.edu (Tammy R Healy)\n",
      "Subject: Re: note to Bobby M.\n",
      "Lines: 52\n",
      "Organization: Walla Walla College\n",
      "Lines: 52\n",
      "\n",
      "In article <1993Apr14.190904.21222@daffy.cs.wisc.edu> mccullou@snake2.cs.wisc.edu (Mark McCullough) writes:\n",
      ">From: mccullou@snake2.cs.wisc.edu (Mark McCullough)\n",
      ">Subject: Re: note to Bobby M.\n",
      ">Date: Wed, 14 Apr 1993 19:09:04 GMT\n",
      ">In article <1993Apr14.131548.15938@monu6.cc.monash.edu.au> darice@yoyo.cc.monash.edu.au (Fred Rice) writes:\n",
      ">>In <madhausC5CKIp.21H@netcom.com> madhaus@netcom.com (Maddi Hausmann) writes:\n",
      ">>\n",
      ">>>Mark, how much do you *REALLY* know about vegetarian diets?\n",
      ">>>The problem is not \"some\" B-vitamins, it's balancing proteins.  \n",
      ">>>There is also one vitamin that cannot be obtained from non-animal\n",
      ">>>products, and this is only of concern to VEGANS, who eat no\n",
      ">>>meat, dairy, or eggs.  I believe it is B12, and it is the only\n",
      ">>>problem.  Supplements are available for vegans; yes, the B12\n",
      ">>>does come from animal by-products.  If you are on an ovo-lacto\n",
      ">>>vegetarian diet (eat dairy and eggs) this is not an issue.\n",
      ">\n",
      ">I didn't see the original posting, but...\n",
      ">Yes, I do know about vegetarian diets, considering that several of my\n",
      ">close friends are devout vegetarians, and have to take vitamin supplements.\n",
      ">B12 was one of the ones I was thinking of, it has been a long time since\n",
      ">I read the article I once saw talking about the special dietary needs\n",
      ">of vegetarians so I didn't quote full numbers.  (Considering how nice\n",
      ">this place is. ;)\n",
      ">\n",
      ">>B12 can also come from whole-grain rice, I understand.  Some brands here\n",
      ">>in Australia (and other places too, I'm sure) get the B12 in the B12\n",
      ">>tablets from whole-grain rice.\n",
      ">\n",
      ">Are you sure those aren't an enriched type?  I know it is basically\n",
      ">rice and soybeans to get almost everything you need, but I hadn't heard\n",
      ">of any rice having B12.  \n",
      ">\n",
      ">>Just thought I'd contribute on a different issue from the norm :)\n",
      ">\n",
      ">You should have contributed to the programming thread earlier. :)\n",
      ">\n",
      ">> Fred Rice\n",
      ">> darice@yoyo.cc.monash.edu.au   \n",
      ">\n",
      ">M^2\n",
      ">\n",
      "If one is a vegan (a vegetarian taht eats no animal products at at i.e eggs, \n",
      "milk, cheese, etc., after about 3 years of a vegan diet, you need to start \n",
      "taking B12 supplements because b12 is found only in animals.) Acutally our \n",
      "bodies make B12, I think, but our bodies use up our own B12 after 2 or 3 \n",
      "years.  \n",
      "Lacto-oveo vegetarians, like myself, still get B12 through milk products \n",
      "and eggs, so we don't need supplements.\n",
      "And If anyone knows more, PLEASE post it.  I'm nearly contridicting myself \n",
      "with the mish-mash of knowledge I've gleaned.\n",
      "\n",
      "Tammy\n",
      "\n",
      "-----------------------\n",
      "1 category: comp.graphics\n",
      "From: ch381@cleveland.Freenet.Edu (James K. Black)\n",
      "Subject: NEEDED: algorithms for 2-d & 3-d object recognition\n",
      "Organization: Case Western Reserve University, Cleveland, OH (USA)\n",
      "Lines: 23\n",
      "Reply-To: ch381@cleveland.Freenet.Edu (James K. Black)\n",
      "NNTP-Posting-Host: hela.ins.cwru.edu\n",
      "\n",
      "\n",
      "Hi,\n",
      "         I have a friend who is working on 2-d and 3-d object recognition. He is looking\n",
      "for references describing algorithms on the following subject areas:\n",
      "\n",
      "Thresholding\n",
      "Edge Segmentation\n",
      "Marr-Hildreth\n",
      "Sobel Operator\n",
      "Chain Codes\n",
      "Thinning - Skeletonising\n",
      "\n",
      "If anybody is willing to post an algorithm that they have implemented which demonstrates\n",
      "any of the above topics, it would be much appreciated.\n",
      "\n",
      "Please post all replies to my e-mail address. If requested I will post a summary to the\n",
      "newsgroup in a couple of weeks.\n",
      "\n",
      "\n",
      "Thanks in advance for all replies\n",
      "\n",
      "James\n",
      "eb192@city.ac.uk\n",
      "\n",
      "-----------------------\n",
      "2 category: comp.graphics\n",
      "From: andreasa@dhhalden.no (ANDREAS ARFF)\n",
      "Subject: comp.graphics.programmer\n",
      "Organization: Ostfold College\n",
      "Lines: 20\n",
      "Nntp-Posting-Host: pc105\n",
      "\n",
      "Hello netters\n",
      "\n",
      "Sorry, I don't know if this is the right way of doing this kind of thing,\n",
      "probably should be a CFV, but since I don't have tha ability to create a \n",
      "news group myself, I just want to start the discussion. \n",
      "\n",
      "I enjoy reading c.g very much, but I often find it difficult to sort out what\n",
      "I'm interested in. Everything from screen-drivers, graphics cards, graphics\n",
      "programming and graphics programs are discused here. What I'd like is a \n",
      "comp.graphics.programmer news group.\n",
      "What do you other think.\n",
      "\n",
      "\n",
      "Arff\n",
      "\"Also for the not religous confessor, there is a mystery of higher values,\n",
      "who's birth mankind - to the last - builds upon. They are indisputible. And \n",
      "often disregarded. Seldom you hear them beeing prized, as seldom as you hear \n",
      "a seeing man prizeing what he sees.\" Per Lagerkvist, The Fist \n",
      "(Free translation from Swedish)\n",
      "              --Andreas Arff  andreasa@dhhalden.no--\n",
      "\n",
      "-----------------------\n",
      "3 category: comp.graphics\n",
      "From: rob@rjck.UUCP (Robert J.C. Kyanko)\n",
      "Subject: Re: VGA 640x400 graphics mode\n",
      "Distribution: world\n",
      "Organization: Neptune Software Inc\n",
      "Lines: 26\n",
      "\n",
      "dutc0006@student.tc.umn.edu writes in article <C5G7qB.BMp@news2.cis.umn.edu>:\n",
      "> >\n",
      "> >Some VESA bios's support this mode (0x100).  And *any* VGA should be able to\n",
      "> >support this (640x480 by 256 colors) since it only requires 256,000 bytes.\n",
      "> >My 8514/a VESA TSR supports this; it's the only VESA mode by card can support\n",
      "> >due to 8514/a restrictions. (A WD/Paradise)\n",
      "> >\n",
      "> >--\n",
      "> >I am not responsible for anything I do or say -- I'm just an opinion.\n",
      "> >             Robert J.C. Kyanko (rob@rjck.UUCP)\n",
      "> \n",
      "> \tAhh no.  Possibly you punched in the wrong numbers on your\n",
      "> calculator.  256 color modes take a byte per pixel so 640 time 480 is\n",
      "> 307,200 which is 300k to be exact.  640x400x256 only takes 250k but I\n",
      "> don't think it is a BIOS mode.  I wouldn't bet that all VGA cards can do\n",
      "> that either.  If a VGA card has 512k I bet it can do both 640x400 and\n",
      "> 640x480.  That by definition is SVGA, though not very high SVGA.\n",
      "> \n",
      "\n",
      "Yes, I did punch in the wrong numbers (working too many late nites).  I\n",
      "intended on stating 640x400 is 256,000 bytes.  It's not in the bios, just my\n",
      "VESA TSR.\n",
      "\n",
      "--\n",
      "I am not responsible for anything I do or say -- I'm just an opinion.\n",
      "             Robert J.C. Kyanko (rob@rjck.UUCP)\n",
      "\n",
      "-----------------------\n",
      "4 category: talk.religion.misc\n",
      "From: zxmkr08@studserv.zdv.uni-tuebingen.de (Cornelius Krasel)\n",
      "Subject: Re: The _real_ probability of abiogenesis (was Re: Albert Sabin)\n",
      "Organization: InterNetNews at ZDV Uni-Tuebingen\n",
      "Lines: 27\n",
      "NNTP-Posting-Host: studserv.zdv.uni-tuebingen.de\n",
      "\n",
      "In <1qc6tiINNhie@ctron-news.ctron.com> king@ctron.com (John E. King) writes:\n",
      "\n",
      ">adpeters@sunflower.bio.indiana.edu (Andy Peters) writes:\n",
      "\n",
      ">>1) We're not just talking about proteins.  In fact, we shouldn't be\n",
      ">>talking about proteins at all, since (if I have to say this again I'm\n",
      ">>goint to be really upset) *nobody*claims*that*proteins*appeared*de*\n",
      ">>*novo*\n",
      ">>the proteins did not form randomly.\n",
      ">> \n",
      "\n",
      ">Before I repond to 2.), Andy, please clarify 1.).  You state that\n",
      ">proteins did not form randomly.  That seems to be my point.  \n",
      "\n",
      "Well, I am not Andy, but if you had familiarized yourself with some of\n",
      "the current theories/hypotheses about abiogenesis before posting :-), you\n",
      "would be aware of the fact that none of them claims that proteins were\n",
      "assembled randomly from amino acids. It is current thinking that RNA-\n",
      "based replicators came before proteinaceous enzymes, and that proteins\n",
      "were assembled by some kind of primitive translation machinery.\n",
      "\n",
      "Now respond to 2. :-)\n",
      "--Cornelius.\n",
      "-- \n",
      "/* Cornelius Krasel, Department of Physiological Chemistry, U Tuebingen    */ \n",
      "/* email: krasel@studserv.zdv.uni-tuebingen.de                             */\n",
      "/* \"People are DNA's way of making more DNA.\" (R. Dawkins / anonymous)     */\n",
      "\n",
      "-----------------------\n",
      "5 category: talk.religion.misc\n",
      "From: livesey@solntze.wpd.sgi.com (Jon Livesey)\n",
      "Subject: Re: After 2000 years, can we say that Christian Morality is\n",
      "Organization: sgi\n",
      "Lines: 40\n",
      "NNTP-Posting-Host: solntze.wpd.sgi.com\n",
      "\n",
      "In article <1qlvh1$fh0@horus.ap.mchp.sni.de>, frank@D012S658.uucp (Frank O'Dwyer) writes:\n",
      "|> In article <1qkn25$k@fido.asd.sgi.com> livesey@solntze.wpd.sgi.com (Jon Livesey) writes:\n",
      "|> \n",
      "|> #Do you mean it's moral to use force on someone who advocates\n",
      "|> #the use of force?\n",
      "|> \n",
      "|> With a few provisos, yes.  Minimum force, for a start. And, it\n",
      "|> depends on what is being forced (on either side).   \n",
      "|> \n",
      "|> #Or do you mean that sometimes we have to use force on such\n",
      "|> #people out of necessity or self-defence, while recognizing\n",
      "|> #that our own actions in doing so are not moral?\n",
      "|> \n",
      "|> My opinion is that our actions would be moral, and it would be\n",
      "|> immoral not to act if action would be both necessary and effective.  \n",
      "|> Again, there many caveats and provisios.\n",
      "|> \n",
      "|> Note, my usage of \"my opinion\" is an admission that I don't have a lock\n",
      "|> on morals, not that there is no truth about morality to have a lock on.\n",
      "\n",
      "You're admitting a lot more than that.  You are admitting that\n",
      "your morals are situational.   You are admitting that the actions\n",
      "of other people and the situation you are in help to determine\n",
      "how you judge the moral significance of one of your own actions.\n",
      "\n",
      "If you employ X degree of force, that's not moral, but if you employ\n",
      "X degree of force, but previously someone else has employed Y degree\n",
      "of force, and the situation is thus-and-so, that *is* moral.\n",
      "\n",
      "This is quite different from saying \"Employing force on other people\n",
      "is immoral, period.   Unfortunately, from time to time we are obliged\n",
      "to do this immoral thing for reasons of self-preservation, and so\n",
      "we have to bear the moral consequences of that.\n",
      "\n",
      "For what it's worth - and yes, I know you claim to be an agnostic -\n",
      "it's this ability to re-label things from \"immoral\" to \"moral\" \n",
      "that I find one of the *least* attractive qualities of the religious\n",
      "mind.\n",
      "\n",
      "jon.\n",
      "\n",
      "-----------------------\n",
      "6 category: talk.religion.misc\n",
      "Subject: Re: Catholic Lit-Crit of a.s.s.\n",
      "From: NUNNALLY@acs.harding.edu (John Nunnally)\n",
      "Distribution: world\n",
      "Organization: Harding University, Searcy, AR\n",
      "Nntp-Posting-Host: acs.harding.edu\n",
      "X-News-Reader: VMS NEWS 1.24In-Reply-To: dlphknob@camelot.bradley.edu's message of 16 Apr 93 18:57:20 GMTLines: 45\n",
      "Lines: 45\n",
      "\n",
      "In <dlphknob.734986640@camelot> dlphknob@camelot.bradley.edu writes:\n",
      "\n",
      "> In <1993Apr14.101241.476@mtechca.maintech.com> foster@mtechca.maintech.com writes:\n",
      "> \n",
      "> >I am surprised and saddened. I would expect this kind of behavior\n",
      "> >from the Evangelical Born-Again Gospel-Thumping In-Your-Face We're-\n",
      "> >The-Only-True-Christian Protestants, but I have always thought \n",
      "> >that Catholics behaved better than this.\n",
      "> >                                   Please do not stoop to the\n",
      "> >level of the E B-A G-T I-Y-F W-T-O-T-C Protestants, who think\n",
      "> >that the best way to witness is to be strident, intrusive, loud,\n",
      "> >insulting and overbearingly self-righteous.\n",
      "> \n",
      "> (Pleading mode on)\n",
      "> \n",
      "> Please!  I'm begging you!  Quit confusing religious groups, and stop\n",
      "> making generalizations!  I'm a Protestant!  I'm an evangelical!  I don't\n",
      "> believe that my way is the only way!  I'm not a \"creation scientist\"!  I\n",
      "> don't think that homosexuals should be hung by their toenails!  \n",
      "> \n",
      "> If you want to discuss bible thumpers, you would be better off singling\n",
      "> out (and making obtuse generalizations about) Fundamentalists.  If you\n",
      "> compared the actions of Presbyterians or Methodists with those of Southern \n",
      "> Baptists, you would think that they were different religions!\n",
      "> \n",
      "[Sarcasm on]\n",
      "Be sure we pick on the \"correct groups\" here.  \"Bible thumpers\",\n",
      "\"fundamentalists\", and Southern Baptists *deserve* our hasty generalizations\n",
      "and prejudicial statements.  Just don't pick on the Presbyterians\n",
      "and the Methodists!\n",
      "[Sarcasm off] \n",
      "> Please, prejudice is about thinking that all people of a group are the\n",
      "> same, so please don't write off all Protestants or all evangelicals!\n",
      "> \n",
      "> (Pleading mode off.)\n",
      "> \n",
      "> God.......I wish I could get ahold of all the Thomas Stories......\n",
      "> --\n",
      "> \t\"Fbzr enval jvagre Fhaqnlf jura gurer'f n yvggyr oberqbz, lbh fubhyq\n",
      "> nyjnlf pneel n tha.  Abg gb fubbg lbhefrys, ohg gb xabj rknpgyl gung lbh'er \n",
      "> nyjnlf znxvat n pubvpr.\"\n",
      "> \t\t\t--Yvan Jregzhyyre\n",
      "> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      ">         Jemaleddin Sasha David Cole IV - Chief of Knobbery Research\n",
      ">                         dlphknob@camelot.bradley.edu\n",
      "\n",
      "-----------------------\n",
      "7 category: sci.space\n",
      "From: abdkw@stdvax (David Ward)\n",
      "Subject: Re: Keeping Spacecraft on after Funding Cuts.\n",
      "News-Software: VAX/VMS VNEWS 1.4-b1  \n",
      "Organization: Goddard Space Flight Center - Robotics Lab\n",
      "Lines: 34\n",
      "\n",
      "In article <20APR199321040621@kelvin.jpl.nasa.gov>, baalke@kelvin.jpl.nasa.gov (Ron Baalke) writes...\n",
      ">In article <1993Apr20.204335.157595@zeus.calpoly.edu>, jgreen@trumpet.calpoly.edu (James Thomas Green) writes...\n",
      ">>Why do spacecraft have to be shut off after funding cuts.  For\n",
      ">>example, Why couldn't Magellan just be told to go into a \"safe\"\n",
      ">>mode and stay bobbing about Venus in a low-power-use mode and if\n",
      ">>maybe in a few years if funding gets restored after the economy\n",
      ">>gets better (hopefully), it could be turned on again.  \n",
      "> \n",
      ">It can be, but the problem is a political one, not a technical one.\n",
      "\n",
      "Also remember that every dollar spent keeping one spacecraft in safe mode\n",
      "(probably a spin-stabilized sun-pointing orientation) is a dollar not\n",
      "spent on mission analysis for a newer spacecraft.  In order to turn the\n",
      "spacecraft back on, you either need to insure that the Ops guys will be\n",
      "available, or you need to retrain a new team.\n",
      "\n",
      "Having said that, there are some spacecraft that do what you have proposed.\n",
      "Many of the operational satellites Goddard flies (like the Tiros NOAA \n",
      "series) require more than one satellite in orbit for an operational set.\n",
      "Extras which get replaced on-orbit are powered into a \"standby\" mode for\n",
      "use in an emergency.  In that case, however, the same ops team is still\n",
      "required to fly the operational birds; so the standby maintenance is\n",
      "relatively cheap.\n",
      "\n",
      "Finally, Pat's explanation (some spacecraft require continuous maintenance\n",
      "to stay under control) is also right on the mark.  I suggested a spin-\n",
      "stabilized control mode because it would require little power or \n",
      "maintenance, but it still might require some momentum dumping from time\n",
      "to time.\n",
      "\n",
      "In the end, it *is* a political decision (since the difference is money),\n",
      "but there is some technical rationale behind the decision.\n",
      "\n",
      "David W. @ GSFC  \n",
      "\n",
      "-----------------------\n",
      "8 category: comp.graphics\n",
      "From: diablo.UUCP!cboesel (Charles Boesel)\n",
      "Subject: Re: Postscript drawing prog\n",
      "Organization: Diablo Creative\n",
      "Reply-To: diablo.UUCP!cboesel (Charles Boesel)\n",
      "X-Mailer: uAccess LITE - Macintosh Release: 1.6v2\n",
      "Lines: 22\n",
      "\n",
      "\n",
      "In article <1993Apr19.171704.2147@Informatik.TU-Muenchen.DE> (comp.graphics.gnuplot,comp.graphics), rdd@uts.ipp-garching.mpg.de (Reinhard Drube) writes:\n",
      ">In article <C5ECnn.7qo@mentor.cc.purdue.edu>, nish@cv4.chem.purdue.edu (Nishantha I.) writes:\n",
      ">|> \tCould somebody let me know of a drawing utility that can be\n",
      ">|> used to manipulate postscript files.I am specifically interested in\n",
      ">|> drawing lines, boxes and the sort on Postscript contour plots.\n",
      ">|> \tI have tried xfig and I am impressed by it's features. However\n",
      ">|> it is of no use since I cannot use postscript files as input for the\n",
      ">|> programme.Is there a utility that converts postscript to xfig format?\n",
      ">|> \tAny help would be greatly appreciated.\n",
      ">|> \t\t\t\tNishantha\n",
      "Have you checked out Adobe Illustrator? There are a few Unix versions\n",
      "for it available, depending on your platform. I know of two Unix versions:\n",
      "One for Mach (NeXT) and for Irix (SGI). There may be others, such\n",
      "as for Sun SparcStation, but I don't know for sure.\n",
      "\n",
      "ttyl,\n",
      "\n",
      "--\n",
      "charles boesel @ diablo creative |  If Pro = for   and   Con = against\n",
      "cboesel@diablo.uu.holonet.net    |  Then what's the opposite of Progress?\n",
      "+1.510.980.1958(pager)           |  What else, Congress.\n",
      "\n",
      "-----------------------\n",
      "9 category: alt.atheism\n",
      "From: bil@okcforum.osrhe.edu (Bill Conner)\n",
      "Subject: Re: some thoughts.\n",
      "Nntp-Posting-Host: okcforum.osrhe.edu\n",
      "Organization: Okcforum Unix Users Group\n",
      "X-Newsreader: TIN [version 1.1 PL9]\n",
      "Lines: 12\n",
      "\n",
      "James Felder (spbach@lerc.nasa.gov) wrote:\n",
      "\n",
      ": Logic alert -  argument from incredulity.  Just because it is hard for you \n",
      ": to believe this doesn't mean that it isn't true.  Liars can be very pursuasive\n",
      ": just look at Koresh that you yourself cite.\n",
      "\n",
      "This is whole basis of a great many here rejecting the Christian\n",
      "account of things. In the words of St. Madalyn Murrey-O'Hair, \"Face it\n",
      "folks, it's just silly ...\". Why is it okay to disbelieve because of\n",
      "your incredulity if you admit that it's a fallacy?\n",
      "\n",
      "Bill\n",
      "\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "print('top 10 sample:')\n",
    "for i in np.arange(10):\n",
    "    print('%i category: %s' % (i,categories[y_train[i]]))\n",
    "    print(data_train.data[i])\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:19:11.328791Z",
     "start_time": "2020-10-12T03:19:10.468143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample num :2034  feature num : 33809\n",
      "stop word num:  318\n",
      "frozenset({'a',\n",
      "           'about',\n",
      "           'above',\n",
      "           'across',\n",
      "           'after',\n",
      "           'afterwards',\n",
      "           'again',\n",
      "           'against',\n",
      "           'all',\n",
      "           'almost',\n",
      "           'alone',\n",
      "           'along',\n",
      "           'already',\n",
      "           'also',\n",
      "           'although',\n",
      "           'always',\n",
      "           'am',\n",
      "           'among',\n",
      "           'amongst',\n",
      "           'amoungst',\n",
      "           'amount',\n",
      "           'an',\n",
      "           'and',\n",
      "           'another',\n",
      "           'any',\n",
      "           'anyhow',\n",
      "           'anyone',\n",
      "           'anything',\n",
      "           'anyway',\n",
      "           'anywhere',\n",
      "           'are',\n",
      "           'around',\n",
      "           'as',\n",
      "           'at',\n",
      "           'back',\n",
      "           'be',\n",
      "           'became',\n",
      "           'because',\n",
      "           'become',\n",
      "           'becomes',\n",
      "           'becoming',\n",
      "           'been',\n",
      "           'before',\n",
      "           'beforehand',\n",
      "           'behind',\n",
      "           'being',\n",
      "           'below',\n",
      "           'beside',\n",
      "           'besides',\n",
      "           'between',\n",
      "           'beyond',\n",
      "           'bill',\n",
      "           'both',\n",
      "           'bottom',\n",
      "           'but',\n",
      "           'by',\n",
      "           'call',\n",
      "           'can',\n",
      "           'cannot',\n",
      "           'cant',\n",
      "           'co',\n",
      "           'con',\n",
      "           'could',\n",
      "           'couldnt',\n",
      "           'cry',\n",
      "           'de',\n",
      "           'describe',\n",
      "           'detail',\n",
      "           'do',\n",
      "           'done',\n",
      "           'down',\n",
      "           'due',\n",
      "           'during',\n",
      "           'each',\n",
      "           'eg',\n",
      "           'eight',\n",
      "           'either',\n",
      "           'eleven',\n",
      "           'else',\n",
      "           'elsewhere',\n",
      "           'empty',\n",
      "           'enough',\n",
      "           'etc',\n",
      "           'even',\n",
      "           'ever',\n",
      "           'every',\n",
      "           'everyone',\n",
      "           'everything',\n",
      "           'everywhere',\n",
      "           'except',\n",
      "           'few',\n",
      "           'fifteen',\n",
      "           'fifty',\n",
      "           'fill',\n",
      "           'find',\n",
      "           'fire',\n",
      "           'first',\n",
      "           'five',\n",
      "           'for',\n",
      "           'former',\n",
      "           'formerly',\n",
      "           'forty',\n",
      "           'found',\n",
      "           'four',\n",
      "           'from',\n",
      "           'front',\n",
      "           'full',\n",
      "           'further',\n",
      "           'get',\n",
      "           'give',\n",
      "           'go',\n",
      "           'had',\n",
      "           'has',\n",
      "           'hasnt',\n",
      "           'have',\n",
      "           'he',\n",
      "           'hence',\n",
      "           'her',\n",
      "           'here',\n",
      "           'hereafter',\n",
      "           'hereby',\n",
      "           'herein',\n",
      "           'hereupon',\n",
      "           'hers',\n",
      "           'herself',\n",
      "           'him',\n",
      "           'himself',\n",
      "           'his',\n",
      "           'how',\n",
      "           'however',\n",
      "           'hundred',\n",
      "           'i',\n",
      "           'ie',\n",
      "           'if',\n",
      "           'in',\n",
      "           'inc',\n",
      "           'indeed',\n",
      "           'interest',\n",
      "           'into',\n",
      "           'is',\n",
      "           'it',\n",
      "           'its',\n",
      "           'itself',\n",
      "           'keep',\n",
      "           'last',\n",
      "           'latter',\n",
      "           'latterly',\n",
      "           'least',\n",
      "           'less',\n",
      "           'ltd',\n",
      "           'made',\n",
      "           'many',\n",
      "           'may',\n",
      "           'me',\n",
      "           'meanwhile',\n",
      "           'might',\n",
      "           'mill',\n",
      "           'mine',\n",
      "           'more',\n",
      "           'moreover',\n",
      "           'most',\n",
      "           'mostly',\n",
      "           'move',\n",
      "           'much',\n",
      "           'must',\n",
      "           'my',\n",
      "           'myself',\n",
      "           'name',\n",
      "           'namely',\n",
      "           'neither',\n",
      "           'never',\n",
      "           'nevertheless',\n",
      "           'next',\n",
      "           'nine',\n",
      "           'no',\n",
      "           'nobody',\n",
      "           'none',\n",
      "           'noone',\n",
      "           'nor',\n",
      "           'not',\n",
      "           'nothing',\n",
      "           'now',\n",
      "           'nowhere',\n",
      "           'of',\n",
      "           'off',\n",
      "           'often',\n",
      "           'on',\n",
      "           'once',\n",
      "           'one',\n",
      "           'only',\n",
      "           'onto',\n",
      "           'or',\n",
      "           'other',\n",
      "           'others',\n",
      "           'otherwise',\n",
      "           'our',\n",
      "           'ours',\n",
      "           'ourselves',\n",
      "           'out',\n",
      "           'over',\n",
      "           'own',\n",
      "           'part',\n",
      "           'per',\n",
      "           'perhaps',\n",
      "           'please',\n",
      "           'put',\n",
      "           'rather',\n",
      "           're',\n",
      "           'same',\n",
      "           'see',\n",
      "           'seem',\n",
      "           'seemed',\n",
      "           'seeming',\n",
      "           'seems',\n",
      "           'serious',\n",
      "           'several',\n",
      "           'she',\n",
      "           'should',\n",
      "           'show',\n",
      "           'side',\n",
      "           'since',\n",
      "           'sincere',\n",
      "           'six',\n",
      "           'sixty',\n",
      "           'so',\n",
      "           'some',\n",
      "           'somehow',\n",
      "           'someone',\n",
      "           'something',\n",
      "           'sometime',\n",
      "           'sometimes',\n",
      "           'somewhere',\n",
      "           'still',\n",
      "           'such',\n",
      "           'system',\n",
      "           'take',\n",
      "           'ten',\n",
      "           'than',\n",
      "           'that',\n",
      "           'the',\n",
      "           'their',\n",
      "           'them',\n",
      "           'themselves',\n",
      "           'then',\n",
      "           'thence',\n",
      "           'there',\n",
      "           'thereafter',\n",
      "           'thereby',\n",
      "           'therefore',\n",
      "           'therein',\n",
      "           'thereupon',\n",
      "           'these',\n",
      "           'they',\n",
      "           'thick',\n",
      "           'thin',\n",
      "           'third',\n",
      "           'this',\n",
      "           'those',\n",
      "           'though',\n",
      "           'three',\n",
      "           'through',\n",
      "           'throughout',\n",
      "           'thru',\n",
      "           'thus',\n",
      "           'to',\n",
      "           'together',\n",
      "           'too',\n",
      "           'top',\n",
      "           'toward',\n",
      "           'towards',\n",
      "           'twelve',\n",
      "           'twenty',\n",
      "           'two',\n",
      "           'un',\n",
      "           'under',\n",
      "           'until',\n",
      "           'up',\n",
      "           'upon',\n",
      "           'us',\n",
      "           'very',\n",
      "           'via',\n",
      "           'was',\n",
      "           'we',\n",
      "           'well',\n",
      "           'were',\n",
      "           'what',\n",
      "           'whatever',\n",
      "           'when',\n",
      "           'whence',\n",
      "           'whenever',\n",
      "           'where',\n",
      "           'whereafter',\n",
      "           'whereas',\n",
      "           'whereby',\n",
      "           'wherein',\n",
      "           'whereupon',\n",
      "           'wherever',\n",
      "           'whether',\n",
      "           'which',\n",
      "           'while',\n",
      "           'whither',\n",
      "           'who',\n",
      "           'whoever',\n",
      "           'whole',\n",
      "           'whom',\n",
      "           'whose',\n",
      "           'why',\n",
      "           'will',\n",
      "           'with',\n",
      "           'within',\n",
      "           'without',\n",
      "           'would',\n",
      "           'yet',\n",
      "           'you',\n",
      "           'your',\n",
      "           'yours',\n",
      "           'yourself',\n",
      "           'yourselves'})\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(input='content',\n",
    "                             stop_words='english',\n",
    "                             max_df=0.5,\n",
    "                             sublinear_tf=True)\n",
    "x_train=vectorizer.fit_transform(data_train.data)\n",
    "x_test=vectorizer.transform(data_test.data)\n",
    "print('train sample num :%d  feature num : %d' % x_train.shape)\n",
    "print('stop word num: ',len(vectorizer.get_stop_words()))\n",
    "pprint(vectorizer.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:22:03.481759Z",
     "start_time": "2020-10-12T03:22:03.422756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33809"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.asarray(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:30:55.073259Z",
     "start_time": "2020-10-12T03:30:54.985254Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_clf(clf):\n",
    "    print('clf : ',clf)\n",
    "    model=GridSearchCV(clf,param_grid={},cv=5)\n",
    "    if hasattr(clf,'alpha'):\n",
    "        alpha_can = np.logspace(-3, 2, 10)\n",
    "        m=alpha_can.size\n",
    "    if hasattr(clf, 'n_neighbors'):\n",
    "        neighbors_can = np.arange(1, 15)\n",
    "        model.set_params(param_grid={'n_neighbors': neighbors_can})\n",
    "        m = neighbors_can.size\n",
    "    if hasattr(clf, 'C'):\n",
    "        C_can = np.logspace(1, 3, 3)\n",
    "        gamma_can = np.logspace(-3, 0, 3)\n",
    "        model.set_params(param_grid={'C':C_can, 'gamma':gamma_can})\n",
    "        m = C_can.size * gamma_can.size\n",
    "    if hasattr(clf, 'max_depth'):\n",
    "        max_depth_can = np.arange(4, 10)\n",
    "        model.set_params(param_grid={'max_depth': max_depth_can})\n",
    "        m = max_depth_can.size\n",
    "    t_start = time()\n",
    "    model.fit(x_train, y_train)\n",
    "    t_end = time()\n",
    "    t_train = (t_end - t_start) / (5*m)\n",
    "    print('5 fold cv train time %.3f/(5*%d)=%.3f' %(\n",
    "        (t_end-t_start),m,t_train))\n",
    "    print('best params :',model.best_params_)\n",
    "    t_start = time()\n",
    "    y_hat = model.predict(x_test)\n",
    "    t_end = time()\n",
    "    t_test = t_end - t_start\n",
    "    print('test time %.3f' % (t_test))\n",
    "    acc=metrics.accuracy_score(y_test,y_hat)\n",
    "    print('test acc %.2f%%' % (100*acc))\n",
    "    name=str(clf).split('(')[0]\n",
    "    index=name.find('Classifier')\n",
    "    if index !=-1:\n",
    "        name=name[:index]\n",
    "    if name=='SVC':\n",
    "        name='SVM'\n",
    "    return t_train,t_test,1-acc,name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:34:32.902555Z",
     "start_time": "2020-10-12T03:34:32.891555Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = (MultinomialNB(),                # 0.87(0.017), 0.002, 90.39%\n",
    "        BernoulliNB(),                  # 1.592(0.032), 0.010, 88.54%\n",
    "        KNeighborsClassifier(),         # 19.737(0.282), 0.208, 86.03%\n",
    "        RidgeClassifier(),              # 25.6(0.512), 0.003, 89.73%\n",
    "        RandomForestClassifier(n_estimators=200),   # 59.319(1.977), 0.248, 77.01%\n",
    "        SVC()                           # 236.59(5.258), 1.574, 90.10%\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:39:35.033782Z",
     "start_time": "2020-10-12T03:34:34.623600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf :  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "5 fold cv train time 0.082/(5*10)=0.002\n",
      "best params : {}\n",
      "test time 0.002\n",
      "test acc 87.07%\n",
      "\n",
      "\n",
      "clf :  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "5 fold cv train time 0.116/(5*10)=0.002\n",
      "best params : {}\n",
      "test time 0.007\n",
      "test acc 79.67%\n",
      "\n",
      "\n",
      "clf :  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "5 fold cv train time 14.110/(5*14)=0.202\n",
      "best params : {'n_neighbors': 3}\n",
      "test time 0.145\n",
      "test acc 86.03%\n",
      "\n",
      "\n",
      "clf :  RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001)\n",
      "5 fold cv train time 1.759/(5*10)=0.035\n",
      "best params : {}\n",
      "test time 0.002\n",
      "test acc 89.65%\n",
      "\n",
      "\n",
      "clf :  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "5 fold cv train time 31.634/(5*6)=1.054\n",
      "best params : {'max_depth': 9}\n",
      "test time 0.148\n",
      "test acc 76.27%\n",
      "\n",
      "\n",
      "clf :  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "5 fold cv train time 250.722/(5*9)=5.572\n",
      "best params : {'C': 100.0, 'gamma': 0.031622776601683791}\n",
      "test time 1.661\n",
      "test acc 90.10%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for clf in clfs:\n",
    "    a = test_clf(clf)\n",
    "    result.append(a)\n",
    "    print('\\n')\n",
    "result = np.array(result)\n",
    "time_train, time_test, err, names = result.T\n",
    "x = np.arange(len(time_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
