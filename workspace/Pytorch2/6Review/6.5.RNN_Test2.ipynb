{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T02:27:31.722812Z",
     "start_time": "2022-01-26T02:27:31.715812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T02:27:32.280844Z",
     "start_time": "2022-01-26T02:27:32.271843Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T02:29:36.894971Z",
     "start_time": "2022-01-26T02:29:36.856969Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_jay_lyrics(): \n",
    "    with zipfile.ZipFile(r'F:\\study\\ml\\ebooks3\\6\\jaychou_lyrics.txt.zip') as zif:\n",
    "        with zif.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars =f.read().decode('utf-8')\n",
    "    corpus_chars=corpus_chars.replace('\\n',' ').replace('\\r',' ')\n",
    "    corpus_chars=corpus_chars[0:10000]\n",
    "    \n",
    "    idx_to_char=list(set(corpus_chars))\n",
    "    char_to_idx=dict([(char,i) for i,char in enumerate(idx_to_char)])\n",
    "    vocab_size=len(char_to_idx)\n",
    "    corpus_indices=[char_to_idx[char] for char in corpus_chars]\n",
    "    \n",
    "    return corpus_indices,char_to_idx,idx_to_char,vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T02:29:37.504006Z",
     "start_time": "2022-01-26T02:29:37.485005Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_indices,char_to_idx,idx_to_char,vocab_size=load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T02:29:41.369227Z",
     "start_time": "2022-01-26T02:29:41.343226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(1027, 256)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens=256\n",
    "rnn_layer=nn.RNN(input_size=vocab_size,hidden_size=num_hiddens)\n",
    "rnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T02:29:42.369285Z",
     "start_time": "2022-01-26T02:29:42.339283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 2, 1027])\n",
      "torch.Size([35, 2, 256]) 1 torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "num_steps=35\n",
    "batch_size=2\n",
    "state=None\n",
    "X=torch.rand(num_steps,batch_size,vocab_size)\n",
    "Y,state_new=rnn_layer(X,state)\n",
    "print(X.shape)\n",
    "print(Y.shape,len(state_new),state_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:50:56.934727Z",
     "start_time": "2022-01-26T07:50:56.911725Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_clipping(params,theta):\n",
    "    norm=torch.Tensor([0.0])\n",
    "    for p in params:\n",
    "        norm +=(p.grad.data **2).sum()\n",
    "    norm = np.sqrt(norm.item())\n",
    "    if norm > theta:\n",
    "        for p in params:\n",
    "            p.grad.data *= (theta/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:50:57.534761Z",
     "start_time": "2022-01-26T07:50:57.519760Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(x,n_class,dtype=torch.float32):\n",
    "    x=x.long()\n",
    "    res=torch.zeros(x.shape[0],n_class,dtype=dtype,device=x.device)\n",
    "    res.scatter_(1,x.view(-1,1),1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:50:57.945784Z",
     "start_time": "2022-01-26T07:50:57.938784Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_onehot(x,n_class):\n",
    "    return [one_hot(x[:,i],n_class) for i in range(x.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:50:58.263803Z",
     "start_time": "2022-01-26T07:50:58.246802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor([[1,2,3],[4,5,6]])\n",
    "to_onehot(x,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:50:58.919840Z",
     "start_time": "2022-01-26T07:50:58.884838Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,rnn_layer,vocab_size):\n",
    "        super().__init__()\n",
    "        self.rnn=rnn_layer\n",
    "        self.hidden_size=rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1)\n",
    "        self.vocab_size=vocab_size\n",
    "        self.dense=nn.Linear(self.hidden_size,vocab_size)\n",
    "        self.state=None\n",
    "        \n",
    "    def forward(self,inputs,state):\n",
    "        X=to_onehot(inputs,self.vocab_size)\n",
    "        Y,self.state=self.rnn(torch.stack(X),state)\n",
    "        # state : num_layers, batch_size, hidden_nums\n",
    "        #X     :  num_steps , batch_size, vocab_size\n",
    "        #Y     :  num_steps , batch_size, hidden_nums\n",
    "        #output:  hidden_nums,           vocab_size\n",
    "        output=self.dense(Y.view(-1,Y.shape[-1]))\n",
    "        return output,self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:50:59.277861Z",
     "start_time": "2022-01-26T07:50:59.238858Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(prefix,num_chars,model,vocab_size,device,idx_to_char,char_to_idx):\n",
    "    state=None\n",
    "    output=[char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X=torch.tensor([output[-1]],device=device).view(-1,1)\n",
    "        if state is not None:\n",
    "            if isinstance(state,tuple):\n",
    "                state=(state[0].to(device),state[1].to(device))\n",
    "            else:\n",
    "                state=state.to(device)\n",
    "        (Y,state)=model(X,state)\n",
    "        if t<len(prefix) -1:\n",
    "            output.append(char_to_idx[prefix[t+1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:50:59.696885Z",
     "start_time": "2022-01-26T07:50:59.648882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开童整视理黑理疗黑理疗'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RNNModel(rnn_layer,vocab_size).to(device)\n",
    "predict_rnn_pytorch('分开',10,model,vocab_size,device,idx_to_char,char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:51:00.097908Z",
     "start_time": "2022-01-26T07:51:00.085907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:51:00.609937Z",
     "start_time": "2022-01-26T07:51:00.580935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[676,\n",
       " 230,\n",
       " 927,\n",
       " 81,\n",
       " 111,\n",
       " 541,\n",
       " 554,\n",
       " 676,\n",
       " 230,\n",
       " 125,\n",
       " 897,\n",
       " 38,\n",
       " 43,\n",
       " 472,\n",
       " 405,\n",
       " 819,\n",
       " 554,\n",
       " 676,\n",
       " 230,\n",
       " 125,\n",
       " 897,\n",
       " 392,\n",
       " 426,\n",
       " 820,\n",
       " 72,\n",
       " 1002,\n",
       " 554,\n",
       " 392,\n",
       " 426,\n",
       " 820,\n",
       " 472,\n",
       " 405,\n",
       " 21,\n",
       " 554,\n",
       " 949,\n",
       " 673,\n",
       " 711,\n",
       " 673,\n",
       " 711,\n",
       " 673,\n",
       " 711,\n",
       " 820,\n",
       " 676,\n",
       " 676,\n",
       " 676,\n",
       " 676,\n",
       " 304,\n",
       " 897,\n",
       " 554,\n",
       " 818,\n",
       " 227,\n",
       " 983,\n",
       " 132,\n",
       " 870,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 1026,\n",
       " 590,\n",
       " 462,\n",
       " 613,\n",
       " 915,\n",
       " 600,\n",
       " 894,\n",
       " 554,\n",
       " 45,\n",
       " 572,\n",
       " 955,\n",
       " 598,\n",
       " 452,\n",
       " 427,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 491,\n",
       " 43,\n",
       " 897,\n",
       " 554,\n",
       " 928,\n",
       " 88,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 851,\n",
       " 285,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 984,\n",
       " 46,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 598,\n",
       " 402,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 1022,\n",
       " 877,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 45,\n",
       " 482,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 928,\n",
       " 88,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 851,\n",
       " 285,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 984,\n",
       " 46,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 598,\n",
       " 402,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 1022,\n",
       " 877,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 45,\n",
       " 482,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 676,\n",
       " 230,\n",
       " 927,\n",
       " 81,\n",
       " 111,\n",
       " 541,\n",
       " 554,\n",
       " 676,\n",
       " 230,\n",
       " 125,\n",
       " 897,\n",
       " 38,\n",
       " 43,\n",
       " 472,\n",
       " 405,\n",
       " 819,\n",
       " 554,\n",
       " 676,\n",
       " 230,\n",
       " 125,\n",
       " 897,\n",
       " 392,\n",
       " 426,\n",
       " 820,\n",
       " 72,\n",
       " 1002,\n",
       " 554,\n",
       " 392,\n",
       " 426,\n",
       " 820,\n",
       " 472,\n",
       " 405,\n",
       " 21,\n",
       " 554,\n",
       " 949,\n",
       " 673,\n",
       " 711,\n",
       " 673,\n",
       " 711,\n",
       " 673,\n",
       " 711,\n",
       " 820,\n",
       " 676,\n",
       " 676,\n",
       " 676,\n",
       " 676,\n",
       " 304,\n",
       " 897,\n",
       " 554,\n",
       " 818,\n",
       " 227,\n",
       " 983,\n",
       " 132,\n",
       " 870,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 1026,\n",
       " 590,\n",
       " 462,\n",
       " 613,\n",
       " 915,\n",
       " 600,\n",
       " 894,\n",
       " 554,\n",
       " 45,\n",
       " 572,\n",
       " 955,\n",
       " 598,\n",
       " 452,\n",
       " 427,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 491,\n",
       " 43,\n",
       " 897,\n",
       " 554,\n",
       " 928,\n",
       " 88,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 851,\n",
       " 285,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 984,\n",
       " 46,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 598,\n",
       " 402,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 1022,\n",
       " 877,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 45,\n",
       " 482,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 928,\n",
       " 88,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 851,\n",
       " 285,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 984,\n",
       " 46,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 598,\n",
       " 402,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 1022,\n",
       " 877,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 45,\n",
       " 482,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 928,\n",
       " 88,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 851,\n",
       " 285,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 984,\n",
       " 46,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 598,\n",
       " 402,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 1022,\n",
       " 877,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 45,\n",
       " 482,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 928,\n",
       " 88,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 851,\n",
       " 285,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 984,\n",
       " 46,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 598,\n",
       " 402,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 1022,\n",
       " 877,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 45,\n",
       " 482,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 114,\n",
       " 114,\n",
       " 983,\n",
       " 771,\n",
       " 949,\n",
       " 962,\n",
       " 872,\n",
       " 983,\n",
       " 788,\n",
       " 207,\n",
       " 40,\n",
       " 381,\n",
       " 554,\n",
       " 303,\n",
       " 359,\n",
       " 798,\n",
       " 65,\n",
       " 245,\n",
       " 554,\n",
       " 788,\n",
       " 933,\n",
       " 1001,\n",
       " 977,\n",
       " 303,\n",
       " 359,\n",
       " 798,\n",
       " 370,\n",
       " 948,\n",
       " 554,\n",
       " 316,\n",
       " 585,\n",
       " 698,\n",
       " 780,\n",
       " 554,\n",
       " 303,\n",
       " 359,\n",
       " 818,\n",
       " 72,\n",
       " 199,\n",
       " 554,\n",
       " 523,\n",
       " 983,\n",
       " 788,\n",
       " 933,\n",
       " 554,\n",
       " 949,\n",
       " 676,\n",
       " 230,\n",
       " 856,\n",
       " 949,\n",
       " 983,\n",
       " 293,\n",
       " 259,\n",
       " 807,\n",
       " 610,\n",
       " 554,\n",
       " 342,\n",
       " 486,\n",
       " 820,\n",
       " 818,\n",
       " 21,\n",
       " 554,\n",
       " 87,\n",
       " 710,\n",
       " 354,\n",
       " 960,\n",
       " 554,\n",
       " 342,\n",
       " 486,\n",
       " 856,\n",
       " 262,\n",
       " 819,\n",
       " 554,\n",
       " 31,\n",
       " 31,\n",
       " 984,\n",
       " 713,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 207,\n",
       " 1015,\n",
       " 897,\n",
       " 554,\n",
       " 156,\n",
       " 844,\n",
       " 733,\n",
       " 120,\n",
       " 554,\n",
       " 518,\n",
       " 897,\n",
       " 750,\n",
       " 10,\n",
       " 1,\n",
       " 54,\n",
       " 983,\n",
       " 72,\n",
       " 844,\n",
       " 397,\n",
       " 554,\n",
       " 781,\n",
       " 468,\n",
       " 598,\n",
       " 235,\n",
       " 731,\n",
       " 335,\n",
       " 554,\n",
       " 576,\n",
       " 2,\n",
       " 2,\n",
       " 16,\n",
       " 351,\n",
       " 554,\n",
       " 897,\n",
       " 207,\n",
       " 262,\n",
       " 949,\n",
       " 983,\n",
       " 355,\n",
       " 658,\n",
       " 554,\n",
       " 771,\n",
       " 944,\n",
       " 75,\n",
       " 983,\n",
       " 821,\n",
       " 831,\n",
       " 554,\n",
       " 406,\n",
       " 95,\n",
       " 116,\n",
       " 312,\n",
       " 840,\n",
       " 554,\n",
       " 560,\n",
       " 381,\n",
       " 983,\n",
       " 10,\n",
       " 611,\n",
       " 554,\n",
       " 897,\n",
       " 983,\n",
       " 750,\n",
       " 10,\n",
       " 760,\n",
       " 924,\n",
       " 554,\n",
       " 228,\n",
       " 157,\n",
       " 411,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 478,\n",
       " 504,\n",
       " 508,\n",
       " 196,\n",
       " 933,\n",
       " 22,\n",
       " 386,\n",
       " 554,\n",
       " 856,\n",
       " 523,\n",
       " 598,\n",
       " 812,\n",
       " 948,\n",
       " 969,\n",
       " 116,\n",
       " 354,\n",
       " 351,\n",
       " 554,\n",
       " 626,\n",
       " 518,\n",
       " 72,\n",
       " 844,\n",
       " 656,\n",
       " 120,\n",
       " 554,\n",
       " 897,\n",
       " 983,\n",
       " 750,\n",
       " 10,\n",
       " 760,\n",
       " 924,\n",
       " 554,\n",
       " 228,\n",
       " 157,\n",
       " 411,\n",
       " 554,\n",
       " 370,\n",
       " 1023,\n",
       " 983,\n",
       " 454,\n",
       " 626,\n",
       " 360,\n",
       " 322,\n",
       " 601,\n",
       " 427,\n",
       " 554,\n",
       " 949,\n",
       " 206,\n",
       " 477,\n",
       " 316,\n",
       " 4,\n",
       " 427,\n",
       " 576,\n",
       " 60,\n",
       " 1002,\n",
       " 554,\n",
       " 412,\n",
       " 242,\n",
       " 795,\n",
       " 880,\n",
       " 147,\n",
       " 28,\n",
       " 554,\n",
       " 342,\n",
       " 486,\n",
       " 820,\n",
       " 818,\n",
       " 21,\n",
       " 554,\n",
       " 87,\n",
       " 710,\n",
       " 354,\n",
       " 960,\n",
       " 554,\n",
       " 342,\n",
       " 486,\n",
       " 856,\n",
       " 262,\n",
       " 819,\n",
       " 554,\n",
       " 31,\n",
       " 31,\n",
       " 984,\n",
       " 713,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 207,\n",
       " 1015,\n",
       " 897,\n",
       " 554,\n",
       " 156,\n",
       " 844,\n",
       " 733,\n",
       " 120,\n",
       " 554,\n",
       " 518,\n",
       " 897,\n",
       " 750,\n",
       " 10,\n",
       " 1,\n",
       " 54,\n",
       " 983,\n",
       " 72,\n",
       " 844,\n",
       " 397,\n",
       " 554,\n",
       " 781,\n",
       " 468,\n",
       " 598,\n",
       " 235,\n",
       " 731,\n",
       " 335,\n",
       " 554,\n",
       " 576,\n",
       " 2,\n",
       " 2,\n",
       " 16,\n",
       " 351,\n",
       " 554,\n",
       " 897,\n",
       " 207,\n",
       " 262,\n",
       " 949,\n",
       " 983,\n",
       " 355,\n",
       " 658,\n",
       " 554,\n",
       " 771,\n",
       " 944,\n",
       " 75,\n",
       " 983,\n",
       " 821,\n",
       " 831,\n",
       " 554,\n",
       " 406,\n",
       " 95,\n",
       " 116,\n",
       " 312,\n",
       " 840,\n",
       " 554,\n",
       " 560,\n",
       " 381,\n",
       " 983,\n",
       " 10,\n",
       " 611,\n",
       " 554,\n",
       " 897,\n",
       " 983,\n",
       " 750,\n",
       " 10,\n",
       " 760,\n",
       " 924,\n",
       " 554,\n",
       " 228,\n",
       " 157,\n",
       " 411,\n",
       " 554,\n",
       " 771,\n",
       " 949,\n",
       " 478,\n",
       " 504,\n",
       " 508,\n",
       " 196,\n",
       " 933,\n",
       " 22,\n",
       " 386,\n",
       " 554,\n",
       " 856,\n",
       " 523,\n",
       " 598,\n",
       " 812,\n",
       " 948,\n",
       " 969,\n",
       " 116,\n",
       " 354,\n",
       " 351,\n",
       " 554,\n",
       " 626,\n",
       " 518,\n",
       " 72,\n",
       " 844,\n",
       " 656,\n",
       " 120,\n",
       " 554,\n",
       " 897,\n",
       " 983,\n",
       " 750,\n",
       " 10,\n",
       " 760,\n",
       " 924,\n",
       " 554,\n",
       " 228,\n",
       " 157,\n",
       " 411,\n",
       " 554,\n",
       " 370,\n",
       " 1023,\n",
       " 983,\n",
       " 454,\n",
       " 626,\n",
       " 360,\n",
       " 322,\n",
       " 601,\n",
       " 427,\n",
       " 554,\n",
       " 949,\n",
       " 206,\n",
       " 477,\n",
       " 316,\n",
       " 4,\n",
       " 427,\n",
       " 576,\n",
       " 60,\n",
       " 1002,\n",
       " 554,\n",
       " 412,\n",
       " 242,\n",
       " 795,\n",
       " 880,\n",
       " 147,\n",
       " 28,\n",
       " 554,\n",
       " 786,\n",
       " 850,\n",
       " 164,\n",
       " 554,\n",
       " 786,\n",
       " 850,\n",
       " 164,\n",
       " 554,\n",
       " 72,\n",
       " 487,\n",
       " 373,\n",
       " 487,\n",
       " 707,\n",
       " 487,\n",
       " 575,\n",
       " 487,\n",
       " 629,\n",
       " 304,\n",
       " 711,\n",
       " 554,\n",
       " 104,\n",
       " 435,\n",
       " 435,\n",
       " 554,\n",
       " 72,\n",
       " 753,\n",
       " 373,\n",
       " 753,\n",
       " 707,\n",
       " 753,\n",
       " 575,\n",
       " 753,\n",
       " 554,\n",
       " 478,\n",
       " 116,\n",
       " 1004,\n",
       " 72,\n",
       " 487,\n",
       " 373,\n",
       " 487,\n",
       " 707,\n",
       " 487,\n",
       " 575,\n",
       " 487,\n",
       " 629,\n",
       " 304,\n",
       " 711,\n",
       " 554,\n",
       " 104,\n",
       " 435,\n",
       " 435,\n",
       " 554,\n",
       " 72,\n",
       " 753,\n",
       " 373,\n",
       " 753,\n",
       " 707,\n",
       " 753,\n",
       " 575,\n",
       " 753,\n",
       " 554,\n",
       " 478,\n",
       " 116,\n",
       " 1004,\n",
       " 313,\n",
       " 304,\n",
       " 765,\n",
       " 554,\n",
       " 344,\n",
       " 23,\n",
       " 820,\n",
       " 376,\n",
       " 711,\n",
       " 838,\n",
       " 554,\n",
       " 72,\n",
       " 457,\n",
       " 660,\n",
       " 938,\n",
       " 743,\n",
       " 820,\n",
       " 949,\n",
       " 851,\n",
       " 100,\n",
       " 554,\n",
       " 167,\n",
       " 116,\n",
       " 897,\n",
       " 983,\n",
       " 706,\n",
       " 717,\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:51:01.087964Z",
     "start_time": "2022-01-26T07:51:01.054962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    corpus_indices=torch.tensor(corpus_indices,dtype=torch.float32,device=device)\n",
    "    data_len=len(corpus_indices)\n",
    "    batch_len=data_len//batch_size\n",
    "    indices=corpus_indices[0:batch_size*batch_len].view(batch_size,batch_len)\n",
    "    epoch_size=(batch_len-1) // num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i=i+num_steps\n",
    "        X=indices[:,i:i+num_steps]\n",
    "        Y=indices[:,i+1:i+num_steps+1]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:51:01.656997Z",
     "start_time": "2022-01-26T07:51:01.558991Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_predict_rnn_pytorch(model,num_hiddens,vocab_size,device,corpus_indices,idx_to_char,char_to_idx,num_epochs,num_steps,lr,\n",
    "                                 clipping_theta,batch_size,pred_period,pred_len,prefixes):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    model.to(device)\n",
    "    state=None\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum,n,start=0.0,0,time.time()\n",
    "        data_iter=data_iter_consecutive(corpus_indices,batch_size,num_steps,device)\n",
    "        for X,Y in data_iter:\n",
    "            if state is not None:\n",
    "                if isinstance(state,tuple):\n",
    "                    state=(state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state=state.detach()\n",
    "            (output,state)=model(X,state)\n",
    "            y=torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l=loss(output,y.long())\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(model.parameters(),clipping_theta)\n",
    "            optimizer.step()\n",
    "            l_sum +=l.item() * y.shape[0]\n",
    "            n+=y.shape[0]\n",
    "            \n",
    "            try:\n",
    "                perplexity=math.exp(l_sum/n)\n",
    "            except OverflowError:\n",
    "                perplexity=float('inf')\n",
    "            if (epoch +1) % pred_period ==0:\n",
    "                print('epoch %d ,perplexity %f,time %.2f sec' % (epoch +1 ,perplexity,time.time()-start))\n",
    "                \n",
    "                for prefix in prefixes:\n",
    "                    print('- ',predict_rnn_pytorch(prefix,pred_len,model,vocab_size,device,idx_to_char,char_to_idx))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T07:54:37.240327Z",
     "start_time": "2022-01-26T07:51:02.233030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 ,perplexity 1.380694,time 0.11 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 50 ,perplexity 1.313758,time 0.28 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 50 ,perplexity 1.260181,time 0.42 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 50 ,perplexity 1.228829,time 0.56 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 50 ,perplexity 1.211987,time 0.73 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 50 ,perplexity 1.197511,time 0.87 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 50 ,perplexity 1.187435,time 1.02 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 50 ,perplexity 1.190808,time 1.15 sec\n",
      "-  分开始想像 爸和妈当年的模样 说著你 一片云掉落在我面前 捏成你的形状 随风跟著我 一口一口吃掉落 我面\n",
      "-  不分开  我跟了你 我该好好生活 我该好好生活 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 100 ,perplexity 1.036855,time 0.10 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 100 ,perplexity 1.035962,time 0.23 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 100 ,perplexity 1.034701,time 0.38 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 100 ,perplexity 1.033084,time 0.51 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 100 ,perplexity 1.032575,time 0.64 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 100 ,perplexity 1.031243,time 0.76 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 100 ,perplexity 1.030332,time 0.89 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 100 ,perplexity 1.031206,time 1.03 sec\n",
      "-  分开  什么都有 这故事 告诉我 印地安的传说 还真是 瞎透了 什么都有 这故事 告诉我 印地安的传说 \n",
      "-  不分开 爱你的失等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多  我知不觉 却只不你已经离开我 不知不觉\n",
      "epoch 150 ,perplexity 1.012212,time 0.10 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 150 ,perplexity 1.013149,time 0.22 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 150 ,perplexity 1.013218,time 0.39 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 150 ,perplexity 1.013161,time 0.53 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 150 ,perplexity 1.013290,time 0.70 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 150 ,perplexity 1.012926,time 0.88 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 150 ,perplexity 1.012667,time 1.02 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 150 ,perplexity 1.013337,time 1.21 sec\n",
      "-  分开 我说的在 你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生\n",
      "-  不分开 爱你的我等著我 家乡的爹娘早已苍老了轮廓 娘子我欠你太多 每天 印地安老斑鸠 腿短毛不多 几天都没\n",
      "epoch 200 ,perplexity 1.006793,time 0.16 sec\n",
      "-  分开 我说的在想你的手我你的黑不下不 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 干什么 你 日\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 200 ,perplexity 1.007690,time 0.30 sec\n",
      "-  分开 我说的在想你的手我你的完不下去 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 却只有你和汉堡\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 200 ,perplexity 1.007774,time 0.44 sec\n",
      "-  分开 我说的在想你的手我你的完不下去 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 却只有你和汉堡\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 200 ,perplexity 1.007916,time 0.58 sec\n",
      "-  分开 我说的在想你的手我你的完不下去 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 却只有你和汉堡\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 200 ,perplexity 1.007960,time 0.73 sec\n",
      "-  分开 我说的在想你的手我你的完不下去 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 却只有你和汉堡\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 200 ,perplexity 1.007725,time 0.86 sec\n",
      "-  分开 我说的在想你的手我你的完不下去 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 却只有你和汉堡\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 200 ,perplexity 1.007569,time 1.01 sec\n",
      "-  分开 我说的在想你的手我你的完不下去 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 却只有你和汉堡\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 200 ,perplexity 1.008091,time 1.15 sec\n",
      "-  分开 我说的在想你的手我你的黑不下不 以为我较细汉 从小到大只有妈妈的温暖  为什么我想 干什么 你 日\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 听错弄\n",
      "epoch 250 ,perplexity 1.004479,time 0.12 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n",
      "epoch 250 ,perplexity 1.005559,time 0.26 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n",
      "epoch 250 ,perplexity 1.005637,time 0.41 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n",
      "epoch 250 ,perplexity 1.005896,time 0.54 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n",
      "epoch 250 ,perplexity 1.005993,time 0.68 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n",
      "epoch 250 ,perplexity 1.005742,time 0.81 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n",
      "epoch 250 ,perplexity 1.005578,time 0.94 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n",
      "epoch 250 ,perplexity 1.006329,time 1.07 sec\n",
      "-  分开 我说的话就这样 要再的让我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起\n",
      "-  不分开 爱你的我跟 我 我想揍你已经很久 别想躲 说你眼睛看着我 别发抖 快给我抬起头 有话去对著 象一场\n"
     ]
    }
   ],
   "source": [
    "num_steps=35\n",
    "num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n",
    "                              corpus_indices, idx_to_char, char_to_idx,\n",
    "                              num_epochs, num_steps, lr, clipping_theta,\n",
    "                              batch_size, pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
