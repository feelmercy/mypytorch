{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:18:55.763885Z",
     "start_time": "2022-02-11T03:18:55.496870Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import zipfile\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:18:56.254913Z",
     "start_time": "2022-02-11T03:18:56.226911Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_jay_lyrics():\n",
    "    with zipfile.ZipFile(r'F:\\study\\ml\\ebooks3\\6\\jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars=f.read().decode('utf-8')\n",
    "    corpus_chars=corpus_chars.replace('\\n',' ').replace('\\r',' ')\n",
    "    corpus_chars=corpus_chars[0:10000]\n",
    "    idx_to_char=list(set(corpus_chars))\n",
    "    char_to_idx=dict([( char,i ) for i , char in enumerate(idx_to_char)])\n",
    "    vocab_size=len(char_to_idx)\n",
    "    corpus_indices=[char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:18:56.620934Z",
     "start_time": "2022-02-11T03:18:56.602933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_indices,char_to_idx,idx_to_char,vocab_size=load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:18:56.974954Z",
     "start_time": "2022-02-11T03:18:56.942952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(1027, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens=256\n",
    "rnn_layer=nn.RNN(input_size=vocab_size,hidden_size=num_hiddens)\n",
    "rnn_layer2=nn.RNN(input_size=vocab_size,hidden_size=num_hiddens,num_layers=2)\n",
    "rnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:18:57.333975Z",
     "start_time": "2022-02-11T03:18:57.322974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(1027, 256, num_layers=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:18:57.891006Z",
     "start_time": "2022-02-11T03:18:57.819002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 2, 1027])\n",
      "torch.Size([35, 2, 256]) 1 torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "num_steps=35\n",
    "batch_size=2\n",
    "state=None\n",
    "X=torch.rand(num_steps,batch_size,vocab_size)\n",
    "Y,state_new=rnn_layer(X,state)\n",
    "print(X.shape)\n",
    "print(Y.shape,len(state_new),state_new[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T02:39:14.156927Z",
     "start_time": "2022-02-16T02:39:14.150926Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_onehot(x,n_class):\n",
    "    def one_hot(x,n_class):\n",
    "        x=x.long()\n",
    "        res=torch.zeros(x.shape[0],n_class)\n",
    "        res=res.scatter(1,x.view(-1,1),1)\n",
    "        return res\n",
    "    return [one_hot(x[:,i],n_class) for i in range(x.shape[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T02:39:14.590952Z",
     "start_time": "2022-02-16T02:39:14.501946Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b963cb1b2ebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mto_onehot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "x=torch.arange(10).view(2,5)\n",
    "to_onehot(x,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:18:59.387092Z",
     "start_time": "2022-02-11T03:18:59.356090Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,rnn_layer,vocab_size):\n",
    "        super().__init__()\n",
    "        self.rnn=rnn_layer\n",
    "        self.hidden_size=rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1)\n",
    "        self.vocab_size=vocab_size\n",
    "        self.dense=nn.Linear(self.hidden_size,self.vocab_size)\n",
    "        self.state=None\n",
    "        \n",
    "    def forward(self,inputs,state):\n",
    "        X=to_onehot(inputs,self.vocab_size)\n",
    "        Y,self.state=self.rnn(torch.stack(X),state)\n",
    "        output=self.dense(Y.view(-1,Y.shape[-1]))\n",
    "        return output,self.state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T06:04:16.935343Z",
     "start_time": "2022-02-11T06:04:16.890341Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(prefix,num_chars,model,vocab_size,device,idx_to_char,char_to_idx):\n",
    "    state=None\n",
    "    output=[char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix)-1):\n",
    "#         print(output[-1])\n",
    "        X=torch.Tensor([output[-1]]).view(1,1)\n",
    "        if state is not None:\n",
    "            if isinstance(state,tuple):\n",
    "                state=(state[0],state[1])\n",
    "            else:\n",
    "                state=state\n",
    "        (Y,state)=model(X,state)\n",
    "        if t < len(prefix)-1 :\n",
    "            output.append(char_to_idx[prefix[t+1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T06:04:17.306365Z",
     "start_time": "2022-02-11T06:04:17.249361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开公难夜公话忧著歌努将'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RNNModel(rnn_layer,vocab_size)\n",
    "predict_rnn_pytorch('分开',10,model,vocab_size,device,idx_to_char,char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T06:04:17.841395Z",
     "start_time": "2022-02-11T06:04:17.811393Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    corpus_indices=torch.Tensor(corpus_indices,device=device)\n",
    "    data_len=len(corpus_indices)\n",
    "    batch_len=data_len//batch_size\n",
    "    indices=corpus_indices[0:batch_size*batch_len].view(batch_size,batch_len)\n",
    "    epoch_size=(batch_len-1)//num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i=i*num_steps\n",
    "        X=indices[:,i:i+num_steps]\n",
    "        Y=indices[:,i+1:i+num_steps+1]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T06:04:18.309422Z",
     "start_time": "2022-02-11T06:04:18.291421Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_clipping(params,theta,device):\n",
    "    norm=torch.Tensor([0.0])\n",
    "    for p in params:\n",
    "        norm+=(p.grad.data **2).sum()\n",
    "    norm=norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for p in params:\n",
    "            p.grad.data *= (theta/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T06:04:18.789449Z",
     "start_time": "2022-02-11T06:04:18.719445Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_predict_rnn_pytorch(model,num_hiddens,vocab_size,device,corpus_indices,idx_to_char,char_to_idx,num_epochs,num_steps,lr,\n",
    "                                 clipping_theta,batch_size,pred_period,pred_len,prefixes):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    model.to(device)\n",
    "    state=None\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum,n,start=0.0,0,time.time()\n",
    "        data_iter=data_iter_consecutive(corpus_indices,batch_size,num_steps)\n",
    "        for X,Y in data_iter:\n",
    "            if state is not None :\n",
    "                if isinstance(state,tuple):\n",
    "                    state=(state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state=state.detach()\n",
    "            (output,state)=model(X,state)\n",
    "            Y=torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l=loss(output,Y.long())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(model.parameters(),clipping_theta,device)\n",
    "            \n",
    "            optimizer.step()\n",
    "            l_sum +=l.item() * Y.shape[0]\n",
    "            n+=Y.shape[0]\n",
    "            \n",
    "            try:\n",
    "                perplexity = math.exp(l_sum/n)\n",
    "            except OverflowError:\n",
    "                perplexity=float('inf')\n",
    "            if (epoch+1) % pred_period ==0:\n",
    "                print('epoch %d ,perplexity %f ,tim %.2f sec' % (epoch +1,perplexity,time.time()-start))\n",
    "                \n",
    "                for prefix in prefixes:\n",
    "                    print('- ',predict_rnn_pytorch(prefix,pred_len,model,vocab_size,device,idx_to_char,char_to_idx))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T06:07:38.029845Z",
     "start_time": "2022-02-11T06:04:19.872511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 ,perplexity 1.202714 ,tim 0.12 sec\n",
      "-  分开 你要再 小打我妈爸 一只两步三分四步 有天  是再人的你 著一直在我说 一定实现 在人开 快使上双\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要 想要你却只笑每天叹手 到底说的我想要 一着两听 回的像 \n",
      "epoch 50 ,perplexity 1.169291 ,tim 0.24 sec\n",
      "-  分开 你要再 小打我妈爸 一只两步三分四步 有天  是再人的你 著一直在我说 一定实现 在人开始痛久 回\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要不想  我想要你想很  一个秋 后知后觉 我该好好生活 我\n",
      "epoch 50 ,perplexity 1.154009 ,tim 0.42 sec\n",
      "-  分开 你要再 小打我 爸想一你 手不能 平常话不多 除非是乌鸦抢了它的窝 它在灌木丛旁邂逅 一只令它心仪\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要不想  我想要你想很  一个  后怎么会 手不要 想然到在\n",
      "epoch 50 ,perplexity 1.152706 ,tim 0.57 sec\n",
      "-  分开 你要再 已打我 别想就  什么 干跟你 我不懂 想你这样 我不的 爱情来的太多 像想你这样打我妈妈\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要不想  我想要你想很  一个  后怎么会 手不要 想然到在\n",
      "epoch 50 ,perplexity 1.152904 ,tim 0.70 sec\n",
      "-  分开 你要再 已打我 别想就  什么 干跟你 我不懂 想你这样 我不的我爱你的让我 不的 爱女人 漂亮的\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要不想  我想要你想很  一个  后怎么会 手不要 想然到在\n",
      "epoch 50 ,perplexity 1.151290 ,tim 0.83 sec\n",
      "-  分开 你要再 已打我 别想就  什么 干跟你 我不懂 想你这样 我不的我爱你的让我 不的 爱女人 漂亮的\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要不想  我想要你想很  一个秋 后知后觉 我该好好生活 我\n",
      "epoch 50 ,perplexity 1.147198 ,tim 1.12 sec\n",
      "-  分开 你要再 小打我 爸想一你 手不能 语言走  为什么看我 的爸家你在你我有多难熬  没有你在我有多难\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要不想  一定两银够著风 几色两秋三著四 装著走 游里的河盒\n",
      "epoch 50 ,perplexity 1.141929 ,tim 1.24 sec\n",
      "-  分开 你要再 小打我 爸想一你 手不放 语爱还 说有别有多烦恼  没有你 我是我的难过 我不透 说 是你\n",
      "-  不分开 我 我的到 可爱你在 打来的可爱 我不要不想  一只饿昏的老斑鸠 印地安老斑鸠 腿短毛不多 几天都\n",
      "epoch 100 ,perplexity 1.050777 ,tim 0.11 sec\n",
      "-  分开 你过让我已多  你都没有妈说 说有些你爸妈有轻轻 家不多  是我已无能为力再提我 决定中 熟如 几\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 100 ,perplexity 1.045149 ,tim 0.24 sec\n",
      "-  分开 你过让我已多  你都没有妈说 说有些你爸妈有轻轻 家不多  是我已无能为力再提我 决定中 熟如 几\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 100 ,perplexity 1.043900 ,tim 0.39 sec\n",
      "-  分开 你过让我已多  你都没有妈说 说有些你爸妈有轻轻 家不多  是我不起 你已经没有我 不想太多 说你\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 100 ,perplexity 1.043238 ,tim 0.52 sec\n",
      "-  分开 你过让我已多  你都没有妈说 说有些你爸妈有轻轻 家不安  是我已无 为什么 我不是不同 你 有我\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 100 ,perplexity 1.042948 ,tim 0.66 sec\n",
      "-  分开 你过让我已多  你都没有妈说 说你些你爸种种开暴 为来我一个人 飞知一那底慢开香 恨就是你不懂 几\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 100 ,perplexity 1.042504 ,tim 0.78 sec\n",
      "-  分开 你过让我已多  你都没有妈说 说你些你爸种种开暴 为来我一个人 飞知一那底慢开香 恨就是你 那 几\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 100 ,perplexity 1.041237 ,tim 0.92 sec\n",
      "-  分开 你过让我已多  你却在你面模妈  有后悔爸说你的了从小到你只能我感的 爱 在没有话不多  说是那说\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 100 ,perplexity 1.040274 ,tim 1.06 sec\n",
      "-  分开 你过让我已多  你却在你面模妈  有后悔爸说你怎么每天每 一想好不想   是那已风 不懂 想了这样\n",
      "-  不分开 我 我不多 语你 我在一起国呼花内快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 习武之人切记 仁\n",
      "epoch 150 ,perplexity 1.023629 ,tim 0.09 sec\n",
      "-  分开 我过去看家乡 你以是我已不能 爱情走的太快就像龙卷风 离不开暴风圈来不及逃 我不能再想 我不能再想\n",
      "-  不分开 我不想不多  我一直好身  能不能看到  所有回忆对着我进攻       所有回忆对着我进攻   \n",
      "epoch 150 ,perplexity 1.022452 ,tim 0.21 sec\n",
      "-  分开 我过去看家乡 是跟是那么想我想想你 我打我妈妈常难过 你我想 你 我打我的妈 我只想是你的棒球 想\n",
      "-  不分开 我不想不多  我一直好身  能不能看到  所有回忆对着我进攻       所有回忆对着我进攻   \n",
      "epoch 150 ,perplexity 1.022286 ,tim 0.36 sec\n",
      "-  分开 我过去看家乡 是跟是那么想我想想你 我打我妈妈常难过 你我想 你 我面我的生活 我爱你 你爱我 我\n",
      "-  不分开 我不想不多  我一直好身  我不能看平  一起 在吃温头  她就的爸 你跟我球 想你和你然无能不是\n",
      "epoch 150 ,perplexity 1.021644 ,tim 0.50 sec\n",
      "-  分开 我过去看家乡 是跟是那么想我想想你 我打我妈妈常难过 你我想 你 我面我的生活 我爱你 你爱我 我\n",
      "-  不分开 我不想不多  我一直好身  我不能看平  一起 在吃温头  她就的爸 你跟我球 想你和你袋有你说不\n",
      "epoch 150 ,perplexity 1.021302 ,tim 0.66 sec\n",
      "-  分开 我过去看家乡 是跟是那么想我想想你 我打我妈妈常难过 你我想 你 我面我的生活 我爱你 你爱我 我\n",
      "-  不分开 我不想不多  我一直好身  我不能看平  一起 在吃温头  她就的爸 你跟我球 想你和你袋有你我不\n",
      "epoch 150 ,perplexity 1.021215 ,tim 0.78 sec\n",
      "-  分开 我过去看家乡 是跟是那么想我想想你 我打我妈妈常难过 你我想 你 我面我的生活 我爱你 你爱我 我\n",
      "-  不分开 我不想不多  我一直好身  我不能看平  一起 在吃温头  她就的爸 你跟我球 想你和你袋有你我不\n",
      "epoch 150 ,perplexity 1.021138 ,tim 0.93 sec\n",
      "-  分开 我过去看家乡 是跟是那么想我想想你 我打我妈妈常难过 你我想 你 我面我的生活 我爱你 你爱我 我\n",
      "-  不分开 我不想不多  我一直好身  我不能看平  一起 在吃温头  她就的爸 你跟我球 想你和你袋有你我不\n",
      "epoch 150 ,perplexity 1.020579 ,tim 1.06 sec\n",
      "-  分开 我过去看家乡 是跟是那么想我想想你 我打我妈妈常难过 你我想 你 我面我的生活 我爱你 你爱我 我\n",
      "-  不分开 我不想不多  我一直好身  我不能看平  一起 在吃温头  她就的爸 你跟我球 想你和你袋有你我不\n",
      "epoch 200 ,perplexity 1.016702 ,tim 0.09 sec\n",
      "-  分开 我过去 爱透 说你说没有你在对我痛大不怪 我 你看棒我 你这样 我妈妈 难道 手不会痛吗 其实我回\n",
      "-  不分开 我不想不你 看我我的你爱你看棒我 想这样你生活 我爱你看棒球 想这样没担忧 唱着歌 一直走 我想就\n",
      "epoch 200 ,perplexity 1.017182 ,tim 0.21 sec\n",
      "-  分开 我过去看家乡 你以是我已无能为力再提个 决定这样美快乐的飞像 一定心到 在吹在它发片 你什么 干什\n",
      "-  不分开 我不想不你 看我我的爸想你你我你 我 我你看棒 我不要 你爱我每天每天不能不想要你却只想你看棒球 \n",
      "epoch 200 ,perplexity 1.017471 ,tim 0.35 sec\n",
      "-  分开 我过去看家乡 你以是我已无能为力再提个 决定这样美快乐的飞像 一定心到 在吹在它发片 你什么 干什\n",
      "-  不分开 我不想不你 看我我想 想是你看我过去 我有没没 你 你你是你我爱你 爱情走 太快就我龙卷风 不能承\n",
      "epoch 200 ,perplexity 1.016874 ,tim 0.49 sec\n",
      "-  分开 我过去看家乡 你以是我已无能为力再提个 决定这样美快乐的对像 你说的可口 我单著我  为想是你是你\n",
      "-  不分开 我不想不你 看我我想 想是你看我过去 我有没没 你 没你是让我不多  你我一你在我  这样对 干的\n",
      "epoch 200 ,perplexity 1.016653 ,tim 0.63 sec\n",
      "-  分开 我过去看家乡 你以是我已无能为力再提个 决定这样美快乐的的像 你说的在真有当难不了 不要再这样打生\n",
      "-  不分开 我不想不多  我一直好身  能想道你在你 中你 我有家乡 你打一空 我想要有些瘦 说有尽头 迷心中\n",
      "epoch 200 ,perplexity 1.016714 ,tim 0.75 sec\n",
      "-  分开 我过去看家乡 你以是我已无能为力再提到 决静中断熟悉 然后在这里 不限日期 然后将过去 慢慢温习 \n",
      "-  不分开 我不想不多  我一直好身  能想道你在你 中你 我有家乡 你打一空 我想要你平常话不多 除非是乌鸦\n",
      "epoch 200 ,perplexity 1.016278 ,tim 0.90 sec\n",
      "-  分开 我过去 家乡 是跟是我 想你 你可来  不要再这样打我妈妈 难道你手不会痛吗 其实我回家就想要阻止\n",
      "-  不分开 我不想不多  我一直好身  能想道你在你 中你 我有家乡 你打一空 我想要你平常话不多 除非是乌鸦\n",
      "epoch 200 ,perplexity 1.015913 ,tim 1.01 sec\n",
      "-  分开 我过去 家乡 是跟是那 简单几句 我办不到 整颗心悬在半空 我只能够远远看著 这些我都做得到 但那\n",
      "-  不分开 我不想不多  我一直好身  能想道你在你 想你 我有快远但种著的这样牵着你的手 一阵莫名感动 我想\n",
      "epoch 250 ,perplexity 1.011903 ,tim 0.09 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回忆你眼对我轻在 所有回我对着我进攻    人  南有当 快给你双\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n",
      "epoch 250 ,perplexity 1.012385 ,tim 0.21 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回忆你眼对我妈妈 难道 你已经离开我 不知不觉 我跟了这节奏 后知\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n",
      "epoch 250 ,perplexity 1.013050 ,tim 0.35 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回到你眼啊我妈妈 难道你手不会痛吗 其实我回家就想要阻止一切 让家\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n",
      "epoch 250 ,perplexity 1.012564 ,tim 0.46 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回到你眼啊我妈妈 难道你手不会痛吗 其实我回家就想要阻止一切 让家\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n",
      "epoch 250 ,perplexity 1.012366 ,tim 0.60 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回到你眼啊我妈妈 难道你手不会痛吗 其实我回家就想要阻止一切 让家\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n",
      "epoch 250 ,perplexity 1.012374 ,tim 0.72 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回到你眼啊我妈妈 难道你手不会痛吗 其实我回家就想要阻止一切 让家\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n",
      "epoch 250 ,perplexity 1.012102 ,tim 0.85 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回了其实我的家 想要再想我 说你我的睡是不直到你 是你不懂 你开单\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n",
      "epoch 250 ,perplexity 1.011845 ,tim 0.98 sec\n",
      "-  分开 我开始 担 从天的你是我 想 我回了其实我的家 想要再想我 说你我的睡是不直到你 是你不能 你以单\n",
      "-  不分开 我不想 你 看着我的话不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样的生活 我\n"
     ]
    }
   ],
   "source": [
    "num_steps=35\n",
    "num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n",
    "                              corpus_indices, idx_to_char, char_to_idx,\n",
    "                              num_epochs, num_steps, lr, clipping_theta,\n",
    "                              batch_size, pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
