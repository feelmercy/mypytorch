{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T07:41:31.060378Z",
     "start_time": "2021-01-12T07:41:31.053378Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.nn import init\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T07:41:00.874652Z",
     "start_time": "2021-01-12T07:41:00.868651Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs,num_outputs,num_hiddens=784,10,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:00:30.491550Z",
     "start_time": "2021-01-12T08:00:30.476549Z"
    }
   },
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "    FlattenLayer(),\n",
    "    nn.Linear(num_inputs,num_hiddens),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hiddens,num_outputs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:00:31.404602Z",
     "start_time": "2021-01-12T08:00:31.388601Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for params in net.parameters():\n",
    "    init.normal_(params, mean=0, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:00:31.888630Z",
     "start_time": "2021-01-12T08:00:31.837627Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "mnist_train=torchvision.datasets.FashionMNIST(\n",
    "    root='F:\\study\\ml\\DataSet\\FashionMNIST',train=True,\n",
    "    download=True,transform=transforms.ToTensor())\n",
    "mnist_test=torchvision.datasets.FashionMNIST(\n",
    "    root='F:\\study\\ml\\DataSet\\FashionMNIST',train=False,\n",
    "    download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:00:32.299653Z",
     "start_time": "2021-01-12T08:00:32.290653Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter=torch.utils.data.DataLoader(mnist_train,batch_size=batch_size,\n",
    "                                      shuffle=True,num_workers=4)\n",
    "test_iter=torch.utils.data.DataLoader(mnist_test,batch_size=batch_size,\n",
    "                                      shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:02:39.512930Z",
     "start_time": "2021-01-12T08:02:39.455926Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs, lr = 5, 0.1\n",
    "\n",
    "\n",
    "def train_ch3(net,\n",
    "              train_iter,\n",
    "              test_iter,\n",
    "              loss,\n",
    "              num_epochs,\n",
    "              batch_size,\n",
    "              params=None,\n",
    "              lr=None,\n",
    "              optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for x, y in train_iter:\n",
    "            y_hat = net(x)\n",
    "            l = loss(y_hat, y).sum()\n",
    "#             print('-----------')\n",
    "#             print('y_hat: \\n',y_hat)\n",
    "#             print('y: \\n',y)\n",
    "#             print(l.item())\n",
    "#             print('-----------')\n",
    "            \n",
    "            if params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "#             if optimizer is None:\n",
    "#             sgd(x, lr, params)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d ,loss %.4f,train acc %.3f,test acc %.3f' %\n",
    "              (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:02:40.543989Z",
     "start_time": "2021-01-12T08:02:40.531988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(FlattenLayer, self).__init__()\n",
    "\tdef forward(self, x): # x shape: (batch, *, *, ...)\n",
    "\t\treturn x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:03:15.176969Z",
     "start_time": "2021-01-12T08:03:15.162969Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        acc_sum += (net(x).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:04:01.511620Z",
     "start_time": "2021-01-12T08:03:15.673998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ,loss 0.0188,train acc 0.140,test acc 0.142\n",
      "epoch 2 ,loss 0.0181,train acc 0.111,test acc 0.100\n",
      "epoch 3 ,loss 0.0174,train acc 0.105,test acc 0.103\n",
      "epoch 4 ,loss 0.0185,train acc 0.103,test acc 0.103\n",
      "epoch 5 ,loss 0.0186,train acc 0.106,test acc 0.103\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "num_epochs = 5\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs,\n",
    "batch_size, None, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.convolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
