{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:52:59.665597Z",
     "start_time": "2021-08-04T08:52:59.630595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "myseed = 1357  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:00.502645Z",
     "start_time": "2021-08-04T08:53:00.406639Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatteryDataset(Dataset):\n",
    "    def __init__(self, path, mode='train', target_only=False):\n",
    "        self.mode = mode\n",
    "\n",
    "        with open(path, 'r') as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array(data[1:])[:, 1:].astype(float)\n",
    "        if not target_only:\n",
    "#             feats = list(range(93))\n",
    "            feats=list(range(1,5))\n",
    "        else:\n",
    "            pass\n",
    "        if mode == 'test':\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "        print('Finish reading the {} set of ZF Dataset ({} samples found \\\n",
    "        ,each dim={})'.format(mode, len(self.data), self.dim))\n",
    "\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if self.mode in ['train','dev']:\n",
    "            return self.data[index],self.target[index]\n",
    "        else:\n",
    "            return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:01.070677Z",
     "start_time": "2021-08-04T08:53:01.058677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish reading the train set of ZF Dataset (736 samples found         ,each dim=4)\n"
     ]
    }
   ],
   "source": [
    "path=r'F:\\study\\workreport\\dataset\\train.csv'\n",
    "zfdata=BatteryDataset(path,mode='train',target_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:01.678712Z",
     "start_time": "2021-08-04T08:53:01.662711Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_dataloader(path,mode,batch_size,n_jobs=0,target_only=False):\n",
    "    dataset=BatteryDataset(path,mode=mode,target_only=target_only)\n",
    "    dataloader=DataLoader(\n",
    "    dataset,batch_size,\n",
    "    shuffle=(mode=='train'),drop_last=False,num_workers=n_jobs,pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:02.340750Z",
     "start_time": "2021-08-04T08:53:02.309748Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        self.criterion = nn.MSELoss(reduce='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        return self.criterion(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:04.440870Z",
     "start_time": "2021-08-04T08:53:04.365866Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "    n_epochs = config['n_epochs']\n",
    "    optimizer = getattr(torch.optim,\n",
    "                        config['optimizer'])(model.parameters(),\n",
    "                                             **config['optim_hparas'])\n",
    "\n",
    "    min_mse = 1000.\n",
    "    loss_record = {'train': [], 'dev': []}\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()\n",
    "        for x, y in tr_set:\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            mse_loss = model.cal_loss(pred, y)\n",
    "            mse_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
    "        dev_mse = dev(dv_set, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            min_mse = dev_mse\n",
    "            print('save model (epoch={:4d},,loss={:.4})'.format(\n",
    "                epoch + 1, min_mse))\n",
    "            torch.save(model.state_dict(), config['save_path'])\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            break\n",
    "    print('finished training after {} epochs'.format(epoch))\n",
    "    return min_mse, loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:05.116909Z",
     "start_time": "2021-08-04T08:53:05.085907Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dev(dev_set,model,device):\n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    for x,y in dv_set:\n",
    "        x,y =x.to(device),y.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred=model(x)\n",
    "            mse_loss=model.cal_loss(pred,y)\n",
    "        total_loss +=mse_loss.detach().cpu().item() *len(x)\n",
    "    total_loss=total_loss / len(dev_set.dataset)\n",
    "    return total_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:06.452985Z",
     "start_time": "2021-08-04T08:53:06.430984Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []\n",
    "    for x in tt_set:                            # iterate through the dataloader\n",
    "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())   # collect prediction\n",
    "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:11.783290Z",
     "start_time": "2021-08-04T08:53:11.766289Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(r'F:\\study\\workreport\\dataset\\models',\n",
    "           exist_ok=True)\n",
    "target_only=False\n",
    "\n",
    "config={\n",
    "    'n_epochs':3000,\n",
    "    'batch_size':64,\n",
    "    'optimizer':'SGD',\n",
    "    'optim_hparas':{\n",
    "        'lr':0.001,\n",
    "        'momentum': 0.7\n",
    "    },\n",
    "    'early_stop':100,\n",
    "    'save_path':r'F:\\study\\workreport\\dataset\\models\\model',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:13.059363Z",
     "start_time": "2021-08-04T08:53:13.056363Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_path=r'F:\\study\\workreport\\dataset\\train.csv'\n",
    "tt_path=r'F:\\study\\workreport\\dataset\\test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:15.309492Z",
     "start_time": "2021-08-04T08:53:15.282490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish reading the train set of ZF Dataset (736 samples found         ,each dim=4)\n",
      "Finish reading the dev set of ZF Dataset (82 samples found         ,each dim=4)\n",
      "Finish reading the test set of ZF Dataset (169 samples found         ,each dim=4)\n"
     ]
    }
   ],
   "source": [
    "tr_set=prep_dataloader(tr_path,'train',config['batch_size'],target_only=target_only)\n",
    "dv_set=prep_dataloader(tr_path,'dev',config['batch_size'],target_only=target_only)\n",
    "tt_set=prep_dataloader(tt_path,'test',config['batch_size'],target_only=target_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:17.168598Z",
     "start_time": "2021-08-04T08:53:17.159598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[18.3300, 29.2000,  7.4700, 29.2000],\n",
      "        [18.7900, 30.8000,  6.7700, 30.8000],\n",
      "        [18.7900, 29.9000,  7.6700, 29.9000],\n",
      "        [18.5900, 28.5400,  8.6400, 28.5400],\n",
      "        [17.9100, 27.1600,  8.6700, 27.1600],\n",
      "        [17.2500, 28.7000,  5.8000, 28.7000],\n",
      "        [19.3500, 29.1900,  9.5100, 29.1900],\n",
      "        [17.6800, 28.5400,  6.8200, 28.5400],\n",
      "        [19.6800, 31.5000,  7.8700, 31.5000],\n",
      "        [19.6700, 31.1400,  8.2000, 31.1400],\n",
      "        [20.9000, 32.3300,  9.4700, 32.3300],\n",
      "        [19.4600, 30.3400,  8.5700, 30.3400],\n",
      "        [18.6900, 30.9900,  6.3900, 30.9900],\n",
      "        [19.9700, 31.7300,  8.2100, 31.7300],\n",
      "        [19.1400, 30.1100,  8.1600, 30.1100],\n",
      "        [19.0300, 31.9700,  6.0900, 31.9700],\n",
      "        [19.6800, 29.6000,  9.7700, 29.6000],\n",
      "        [21.3500, 33.4300,  9.2700, 33.4300],\n",
      "        [17.8700, 28.2100,  7.5300, 28.2100],\n",
      "        [18.5900, 28.1300,  9.0400, 28.1300],\n",
      "        [18.0000, 28.3900,  7.6100, 28.3900],\n",
      "        [16.9600, 26.8700,  7.0400, 26.8700],\n",
      "        [18.3300, 29.9000,  6.7600, 29.9000],\n",
      "        [19.3200, 30.9700,  7.6700, 30.9700],\n",
      "        [21.3700, 33.5700,  9.1700, 33.5700],\n",
      "        [16.9100, 28.5100,  5.3100, 28.5100],\n",
      "        [18.6600, 29.2900,  8.0300, 29.2900],\n",
      "        [17.4600, 28.1800,  6.7400, 28.1800],\n",
      "        [16.1000, 28.2500,  3.9500, 28.2500],\n",
      "        [21.0800, 31.2200, 10.9400, 31.2200],\n",
      "        [17.9000, 28.7600,  7.0400, 28.7600],\n",
      "        [15.6000, 26.8000,  4.4000, 26.8000],\n",
      "        [21.6500, 34.1700,  9.1400, 34.1700],\n",
      "        [19.7300, 32.4900,  6.9600, 32.4900],\n",
      "        [22.0600, 36.2100,  7.9000, 36.2100],\n",
      "        [20.5000, 34.1200,  6.8800, 34.1200],\n",
      "        [21.5700, 34.7800,  8.3600, 34.7800],\n",
      "        [21.9300, 35.8500,  8.0000, 35.8500],\n",
      "        [21.2000, 35.0500,  7.3400, 35.0500],\n",
      "        [21.7800, 36.1300,  7.4400, 36.1300],\n",
      "        [22.2000, 35.7100,  8.6800, 35.7100],\n",
      "        [22.6600, 35.7700,  9.5500, 35.7700],\n",
      "        [27.2300, 48.2900,  6.1600, 48.2900],\n",
      "        [20.0700, 32.9000,  7.2500, 32.9000],\n",
      "        [18.1300, 31.3500,  4.9000, 31.3500],\n",
      "        [19.8200, 31.8000,  7.8500, 31.8000],\n",
      "        [21.1300, 33.6300,  8.6300, 33.6300],\n",
      "        [21.2000, 34.0000,  8.3900, 34.0000],\n",
      "        [22.4900, 32.7600, 12.2300, 32.7600],\n",
      "        [21.9700, 31.6800, 12.2600, 31.6800],\n",
      "        [20.9200, 30.0800, 11.7600, 30.0800],\n",
      "        [21.6800, 31.9500, 11.4200, 31.9500],\n",
      "        [21.9100, 31.9200, 11.9000, 31.9200],\n",
      "        [21.2700, 30.5700, 11.9700, 30.5700],\n",
      "        [21.5700, 30.7700, 12.3800, 30.7700],\n",
      "        [21.4700, 31.0200, 11.9100, 31.0200],\n",
      "        [20.9200, 30.5100, 11.3400, 30.5100],\n",
      "        [21.2800, 31.0600, 11.5000, 31.0600],\n",
      "        [22.2900, 32.9100, 11.6600, 32.9100],\n",
      "        [22.0600, 32.3500, 11.7800, 32.3500],\n",
      "        [21.0300, 29.7400, 12.3300, 29.7400],\n",
      "        [20.9900, 30.5200, 11.4500, 30.5200],\n",
      "        [20.9200, 30.4700, 11.3700, 30.4700],\n",
      "        [20.5800, 30.5800, 10.5800, 30.5800]]), tensor([0.8200, 0.7800, 0.8025, 0.8366, 0.8711, 0.8325, 0.8203, 0.8365, 0.7625,\n",
      "        0.7714, 0.7417, 0.7914, 0.7754, 0.7568, 0.7972, 0.7507, 0.8100, 0.7142,\n",
      "        0.8448, 0.8468, 0.8403, 0.8782, 0.8025, 0.7758, 0.7108, 0.8371, 0.8179,\n",
      "        0.8455, 0.8438, 0.7695, 0.8309, 0.8800, 0.6957, 0.7377, 0.6448, 0.6971,\n",
      "        0.6806, 0.6537, 0.6737, 0.6468, 0.6572, 0.6558, 0.3428, 0.7276, 0.7662,\n",
      "        0.7550, 0.7094, 0.7000, 0.7310, 0.7580, 0.7979, 0.7513, 0.7519, 0.7857,\n",
      "        0.7808, 0.7744, 0.7873, 0.7736, 0.7271, 0.7413, 0.8066, 0.7871, 0.7882,\n",
      "        0.7855])]\n",
      "[tensor([[20.9300, 30.1900, 11.6700, 30.1900],\n",
      "        [32.6000, 50.3700, 14.8200, 50.3700],\n",
      "        [33.0300, 49.9100, 16.1400, 49.9100],\n",
      "        [33.2200, 49.4500, 16.9900, 49.4500],\n",
      "        [33.5800, 51.6400, 15.5200, 51.6400],\n",
      "        [32.6800, 50.5600, 14.8100, 50.5600],\n",
      "        [32.8100, 50.5600, 15.0600, 50.5600],\n",
      "        [34.1500, 52.2700, 16.0400, 52.2700],\n",
      "        [32.3300, 49.1500, 15.5200, 49.1500],\n",
      "        [32.5100, 49.7500, 15.2700, 49.7500],\n",
      "        [32.0100, 48.7000, 15.3200, 48.7000],\n",
      "        [32.7300, 49.9300, 15.5200, 49.9300],\n",
      "        [33.6400, 50.9100, 16.3700, 50.9100],\n",
      "        [29.0700, 45.6800, 12.4600, 45.6800],\n",
      "        [30.4200, 45.1700, 15.6700, 45.1700],\n",
      "        [31.6600, 45.0600, 18.2600, 45.0600],\n",
      "        [31.3700, 48.7500, 14.0000, 48.7500],\n",
      "        [29.0100, 45.6000, 12.4200, 45.6000]]), tensor([0.7953, 0.2908, 0.3022, 0.3136, 0.2590, 0.2861, 0.2860, 0.2432, 0.3212,\n",
      "        0.3063, 0.3326, 0.3018, 0.2773, 0.4080, 0.4206, 0.4235, 0.3313, 0.4100])]\n"
     ]
    }
   ],
   "source": [
    "for i in dv_set:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:18.072650Z",
     "start_time": "2021-08-04T08:53:18.061649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(tr_set.dataset.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:55.502791Z",
     "start_time": "2021-08-04T08:53:20.557792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model (epoch=   1,,loss=0.09937)\n",
      "save model (epoch=   2,,loss=0.09684)\n",
      "save model (epoch=   4,,loss=0.09381)\n",
      "save model (epoch=   5,,loss=0.0928)\n",
      "save model (epoch=  10,,loss=0.0914)\n",
      "save model (epoch=  11,,loss=0.08887)\n",
      "save model (epoch=  13,,loss=0.08566)\n",
      "save model (epoch=  14,,loss=0.08522)\n",
      "save model (epoch=  16,,loss=0.08505)\n",
      "save model (epoch=  17,,loss=0.08291)\n",
      "save model (epoch=  18,,loss=0.0821)\n",
      "save model (epoch=  19,,loss=0.0813)\n",
      "save model (epoch=  21,,loss=0.0806)\n",
      "save model (epoch=  23,,loss=0.07857)\n",
      "save model (epoch=  24,,loss=0.07804)\n",
      "save model (epoch=  26,,loss=0.07683)\n",
      "save model (epoch=  29,,loss=0.07481)\n",
      "save model (epoch=  31,,loss=0.07355)\n",
      "save model (epoch=  33,,loss=0.07323)\n",
      "save model (epoch=  34,,loss=0.07176)\n",
      "save model (epoch=  36,,loss=0.07049)\n",
      "save model (epoch=  39,,loss=0.07041)\n",
      "save model (epoch=  42,,loss=0.06721)\n",
      "save model (epoch=  44,,loss=0.06613)\n",
      "save model (epoch=  45,,loss=0.0657)\n",
      "save model (epoch=  47,,loss=0.06493)\n",
      "save model (epoch=  49,,loss=0.06396)\n",
      "save model (epoch=  50,,loss=0.06296)\n",
      "save model (epoch=  52,,loss=0.0619)\n",
      "save model (epoch=  54,,loss=0.06074)\n",
      "save model (epoch=  55,,loss=0.06033)\n",
      "save model (epoch=  56,,loss=0.0599)\n",
      "save model (epoch=  57,,loss=0.05966)\n",
      "save model (epoch=  58,,loss=0.05878)\n",
      "save model (epoch=  60,,loss=0.05776)\n",
      "save model (epoch=  63,,loss=0.05649)\n",
      "save model (epoch=  65,,loss=0.05564)\n",
      "save model (epoch=  66,,loss=0.05506)\n",
      "save model (epoch=  70,,loss=0.05357)\n",
      "save model (epoch=  73,,loss=0.05219)\n",
      "save model (epoch=  74,,loss=0.05218)\n",
      "save model (epoch=  77,,loss=0.05111)\n",
      "save model (epoch=  80,,loss=0.049)\n",
      "save model (epoch=  86,,loss=0.04639)\n",
      "save model (epoch=  88,,loss=0.04574)\n",
      "save model (epoch=  91,,loss=0.04439)\n",
      "save model (epoch=  94,,loss=0.04358)\n",
      "save model (epoch=  96,,loss=0.04322)\n",
      "save model (epoch=  97,,loss=0.04226)\n",
      "save model (epoch= 100,,loss=0.04111)\n",
      "save model (epoch= 102,,loss=0.03996)\n",
      "save model (epoch= 103,,loss=0.03944)\n",
      "save model (epoch= 104,,loss=0.03869)\n",
      "save model (epoch= 105,,loss=0.03832)\n",
      "save model (epoch= 106,,loss=0.03824)\n",
      "save model (epoch= 110,,loss=0.03746)\n",
      "save model (epoch= 111,,loss=0.03645)\n",
      "save model (epoch= 113,,loss=0.036)\n",
      "save model (epoch= 116,,loss=0.03474)\n",
      "save model (epoch= 118,,loss=0.0341)\n",
      "save model (epoch= 119,,loss=0.03371)\n",
      "save model (epoch= 121,,loss=0.03353)\n",
      "save model (epoch= 125,,loss=0.03259)\n",
      "save model (epoch= 126,,loss=0.03253)\n",
      "save model (epoch= 127,,loss=0.03144)\n",
      "save model (epoch= 130,,loss=0.03038)\n",
      "save model (epoch= 131,,loss=0.03034)\n",
      "save model (epoch= 133,,loss=0.02968)\n",
      "save model (epoch= 134,,loss=0.02931)\n",
      "save model (epoch= 135,,loss=0.02922)\n",
      "save model (epoch= 137,,loss=0.02908)\n",
      "save model (epoch= 138,,loss=0.02824)\n",
      "save model (epoch= 140,,loss=0.02774)\n",
      "save model (epoch= 142,,loss=0.02766)\n",
      "save model (epoch= 144,,loss=0.02715)\n",
      "save model (epoch= 147,,loss=0.02573)\n",
      "save model (epoch= 148,,loss=0.02545)\n",
      "save model (epoch= 149,,loss=0.02518)\n",
      "save model (epoch= 150,,loss=0.02493)\n",
      "save model (epoch= 152,,loss=0.02465)\n",
      "save model (epoch= 154,,loss=0.02426)\n",
      "save model (epoch= 156,,loss=0.02344)\n",
      "save model (epoch= 158,,loss=0.02315)\n",
      "save model (epoch= 161,,loss=0.02269)\n",
      "save model (epoch= 162,,loss=0.02213)\n",
      "save model (epoch= 163,,loss=0.02191)\n",
      "save model (epoch= 164,,loss=0.02165)\n",
      "save model (epoch= 166,,loss=0.02108)\n",
      "save model (epoch= 167,,loss=0.02097)\n",
      "save model (epoch= 168,,loss=0.02074)\n",
      "save model (epoch= 171,,loss=0.02065)\n",
      "save model (epoch= 172,,loss=0.0205)\n",
      "save model (epoch= 173,,loss=0.01955)\n",
      "save model (epoch= 176,,loss=0.01953)\n",
      "save model (epoch= 177,,loss=0.01892)\n",
      "save model (epoch= 178,,loss=0.01861)\n",
      "save model (epoch= 180,,loss=0.01827)\n",
      "save model (epoch= 181,,loss=0.01791)\n",
      "save model (epoch= 183,,loss=0.01775)\n",
      "save model (epoch= 189,,loss=0.01638)\n",
      "save model (epoch= 191,,loss=0.016)\n",
      "save model (epoch= 193,,loss=0.01566)\n",
      "save model (epoch= 194,,loss=0.01557)\n",
      "save model (epoch= 196,,loss=0.0151)\n",
      "save model (epoch= 201,,loss=0.01423)\n",
      "save model (epoch= 204,,loss=0.01386)\n",
      "save model (epoch= 207,,loss=0.01334)\n",
      "save model (epoch= 214,,loss=0.01253)\n",
      "save model (epoch= 215,,loss=0.0121)\n",
      "save model (epoch= 218,,loss=0.01169)\n",
      "save model (epoch= 219,,loss=0.01166)\n",
      "save model (epoch= 223,,loss=0.01096)\n",
      "save model (epoch= 225,,loss=0.01088)\n",
      "save model (epoch= 226,,loss=0.01072)\n",
      "save model (epoch= 229,,loss=0.0102)\n",
      "save model (epoch= 230,,loss=0.01016)\n",
      "save model (epoch= 234,,loss=0.01001)\n",
      "save model (epoch= 237,,loss=0.009373)\n",
      "save model (epoch= 240,,loss=0.008877)\n",
      "save model (epoch= 244,,loss=0.008574)\n",
      "save model (epoch= 248,,loss=0.008427)\n",
      "save model (epoch= 249,,loss=0.007939)\n",
      "save model (epoch= 253,,loss=0.00764)\n",
      "save model (epoch= 254,,loss=0.007609)\n",
      "save model (epoch= 255,,loss=0.007372)\n",
      "save model (epoch= 256,,loss=0.007216)\n",
      "save model (epoch= 258,,loss=0.007125)\n",
      "save model (epoch= 262,,loss=0.006802)\n",
      "save model (epoch= 265,,loss=0.006412)\n",
      "save model (epoch= 266,,loss=0.006373)\n",
      "save model (epoch= 268,,loss=0.006227)\n",
      "save model (epoch= 272,,loss=0.006026)\n",
      "save model (epoch= 274,,loss=0.005921)\n",
      "save model (epoch= 275,,loss=0.005675)\n",
      "save model (epoch= 278,,loss=0.0054)\n",
      "save model (epoch= 280,,loss=0.005251)\n",
      "save model (epoch= 287,,loss=0.00499)\n",
      "save model (epoch= 288,,loss=0.004735)\n",
      "save model (epoch= 292,,loss=0.004496)\n",
      "save model (epoch= 296,,loss=0.004233)\n",
      "save model (epoch= 299,,loss=0.004161)\n",
      "save model (epoch= 300,,loss=0.004069)\n",
      "save model (epoch= 302,,loss=0.003971)\n",
      "save model (epoch= 306,,loss=0.003732)\n",
      "save model (epoch= 312,,loss=0.003503)\n",
      "save model (epoch= 314,,loss=0.003347)\n",
      "save model (epoch= 319,,loss=0.003118)\n",
      "save model (epoch= 325,,loss=0.002876)\n",
      "save model (epoch= 327,,loss=0.002814)\n",
      "save model (epoch= 330,,loss=0.002753)\n",
      "save model (epoch= 334,,loss=0.002603)\n",
      "save model (epoch= 342,,loss=0.002531)\n",
      "save model (epoch= 344,,loss=0.002242)\n",
      "save model (epoch= 350,,loss=0.00208)\n",
      "save model (epoch= 356,,loss=0.00198)\n",
      "save model (epoch= 362,,loss=0.001857)\n",
      "save model (epoch= 364,,loss=0.001759)\n",
      "save model (epoch= 367,,loss=0.001697)\n",
      "save model (epoch= 375,,loss=0.001611)\n",
      "save model (epoch= 378,,loss=0.001485)\n",
      "save model (epoch= 391,,loss=0.001457)\n",
      "save model (epoch= 394,,loss=0.001278)\n",
      "save model (epoch= 395,,loss=0.001237)\n",
      "save model (epoch= 402,,loss=0.001144)\n",
      "save model (epoch= 411,,loss=0.001093)\n",
      "save model (epoch= 417,,loss=0.0009685)\n",
      "save model (epoch= 420,,loss=0.0009383)\n",
      "save model (epoch= 422,,loss=0.0009294)\n",
      "save model (epoch= 429,,loss=0.0008602)\n",
      "save model (epoch= 431,,loss=0.0008423)\n",
      "save model (epoch= 438,,loss=0.0007878)\n",
      "save model (epoch= 443,,loss=0.0007825)\n",
      "save model (epoch= 452,,loss=0.0007005)\n",
      "save model (epoch= 457,,loss=0.0006964)\n",
      "save model (epoch= 458,,loss=0.0006651)\n",
      "save model (epoch= 464,,loss=0.0006419)\n",
      "save model (epoch= 472,,loss=0.0005884)\n",
      "save model (epoch= 486,,loss=0.0005528)\n",
      "save model (epoch= 488,,loss=0.0005127)\n",
      "save model (epoch= 491,,loss=0.0005078)\n",
      "save model (epoch= 494,,loss=0.0004894)\n",
      "save model (epoch= 505,,loss=0.0004101)\n",
      "save model (epoch= 507,,loss=0.0004093)\n",
      "save model (epoch= 511,,loss=0.0003935)\n",
      "save model (epoch= 519,,loss=0.0003614)\n",
      "save model (epoch= 523,,loss=0.0003533)\n",
      "save model (epoch= 531,,loss=0.0003175)\n",
      "save model (epoch= 537,,loss=0.0002914)\n",
      "save model (epoch= 559,,loss=0.0002891)\n",
      "save model (epoch= 565,,loss=0.0002819)\n",
      "save model (epoch= 567,,loss=0.000249)\n",
      "save model (epoch= 569,,loss=0.0002355)\n",
      "save model (epoch= 579,,loss=0.0002324)\n",
      "save model (epoch= 580,,loss=0.0002142)\n",
      "save model (epoch= 584,,loss=0.0002058)\n",
      "save model (epoch= 585,,loss=0.0001931)\n",
      "save model (epoch= 591,,loss=0.0001754)\n",
      "save model (epoch= 598,,loss=0.0001667)\n",
      "save model (epoch= 609,,loss=0.0001501)\n",
      "save model (epoch= 617,,loss=0.0001385)\n",
      "save model (epoch= 624,,loss=0.0001288)\n",
      "save model (epoch= 639,,loss=0.0001117)\n",
      "save model (epoch= 650,,loss=0.0001057)\n",
      "save model (epoch= 657,,loss=8.839e-05)\n",
      "save model (epoch= 659,,loss=8.836e-05)\n",
      "save model (epoch= 665,,loss=8.168e-05)\n",
      "save model (epoch= 669,,loss=7.88e-05)\n",
      "save model (epoch= 672,,loss=7.413e-05)\n",
      "save model (epoch= 713,,loss=7.053e-05)\n",
      "save model (epoch= 717,,loss=6.506e-05)\n",
      "save model (epoch= 719,,loss=6.348e-05)\n",
      "save model (epoch= 725,,loss=6.159e-05)\n",
      "save model (epoch= 739,,loss=5.41e-05)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model (epoch= 749,,loss=4.737e-05)\n",
      "save model (epoch= 758,,loss=4.707e-05)\n",
      "save model (epoch= 764,,loss=4.45e-05)\n",
      "save model (epoch= 765,,loss=4.028e-05)\n",
      "save model (epoch= 782,,loss=3.274e-05)\n",
      "save model (epoch= 802,,loss=3.077e-05)\n",
      "save model (epoch= 814,,loss=2.793e-05)\n",
      "save model (epoch= 823,,loss=2.741e-05)\n",
      "save model (epoch= 834,,loss=2.697e-05)\n",
      "save model (epoch= 839,,loss=2.289e-05)\n",
      "save model (epoch= 850,,loss=2.249e-05)\n",
      "save model (epoch= 853,,loss=2.112e-05)\n",
      "save model (epoch= 855,,loss=2.059e-05)\n",
      "save model (epoch= 862,,loss=1.902e-05)\n",
      "save model (epoch= 870,,loss=1.832e-05)\n",
      "save model (epoch= 880,,loss=1.714e-05)\n",
      "save model (epoch= 881,,loss=1.652e-05)\n",
      "save model (epoch= 889,,loss=1.482e-05)\n",
      "save model (epoch= 902,,loss=1.454e-05)\n",
      "save model (epoch= 904,,loss=1.446e-05)\n",
      "save model (epoch= 913,,loss=1.279e-05)\n",
      "save model (epoch= 929,,loss=1.237e-05)\n",
      "save model (epoch= 954,,loss=1.01e-05)\n",
      "save model (epoch= 960,,loss=9.302e-06)\n",
      "save model (epoch= 971,,loss=8.988e-06)\n",
      "save model (epoch= 986,,loss=8.186e-06)\n",
      "save model (epoch=1002,,loss=7.274e-06)\n",
      "save model (epoch=1016,,loss=7.174e-06)\n",
      "save model (epoch=1019,,loss=6.836e-06)\n",
      "save model (epoch=1038,,loss=5.627e-06)\n",
      "save model (epoch=1046,,loss=5.116e-06)\n",
      "save model (epoch=1056,,loss=4.708e-06)\n",
      "save model (epoch=1071,,loss=4.521e-06)\n",
      "save model (epoch=1073,,loss=4.402e-06)\n",
      "save model (epoch=1075,,loss=4.068e-06)\n",
      "save model (epoch=1109,,loss=4.049e-06)\n",
      "save model (epoch=1115,,loss=3.93e-06)\n",
      "save model (epoch=1123,,loss=3.785e-06)\n",
      "save model (epoch=1145,,loss=3.489e-06)\n",
      "save model (epoch=1157,,loss=3.282e-06)\n",
      "save model (epoch=1188,,loss=3.24e-06)\n",
      "save model (epoch=1204,,loss=3.169e-06)\n",
      "save model (epoch=1261,,loss=2.761e-06)\n",
      "save model (epoch=1284,,loss=2.565e-06)\n",
      "save model (epoch=1299,,loss=2.561e-06)\n",
      "save model (epoch=1305,,loss=2.531e-06)\n",
      "save model (epoch=1354,,loss=2.374e-06)\n",
      "save model (epoch=1412,,loss=2.232e-06)\n",
      "save model (epoch=1463,,loss=2.228e-06)\n",
      "save model (epoch=1470,,loss=2.2e-06)\n",
      "save model (epoch=1502,,loss=2.111e-06)\n",
      "save model (epoch=1535,,loss=2.059e-06)\n",
      "save model (epoch=1554,,loss=1.957e-06)\n",
      "finished training after 1655 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:58.341953Z",
     "start_time": "2021-08-04T08:53:58.204945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8EVEAvH/AWOENqXHU4JzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11153f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_1=range(len(model_loss_record['train']))\n",
    "x_2=x_1[::len(model_loss_record['train']) // len(model_loss_record['dev'])]\n",
    "plt.plot(x_1,model_loss_record['train'],c='tab:red',label='train')\n",
    "plt.plot(x_2,model_loss_record['dev'],c='tab:cyan',label='dev')\n",
    "plt.ylim(-0.5,5.)\n",
    "# plt.xlim(-0.5,5.)\n",
    "plt.xlabel('train step')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:53:59.809037Z",
     "start_time": "2021-08-04T08:53:59.790036Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T08:54:01.128112Z",
     "start_time": "2021-08-04T08:54:01.078110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to F:\\study\\workreport\\dataset\\pred.csv\n"
     ]
    }
   ],
   "source": [
    "preds = test(tt_set, model, 'cpu')  # predict COVID-19 cases with your model\n",
    "save_pred(preds, r'F:\\study\\workreport\\dataset\\pred.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
