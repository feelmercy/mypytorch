{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:04.487332Z",
     "start_time": "2022-04-08T06:25:04.084308Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:04.981360Z",
     "start_time": "2022-04-08T06:25:04.956358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:05.226374Z",
     "start_time": "2022-04-08T06:25:05.219373Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(nn.Linear(1,10),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:05.461387Z",
     "start_time": "2022-04-08T06:25:05.454387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:05.699401Z",
     "start_time": "2022-04-08T06:25:05.686400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(-100,100)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:05.904413Z",
     "start_time": "2022-04-08T06:25:05.890412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,  -99,  -98,  -97,  -96,  -95,  -94,  -93,  -92,  -91,  -90,  -89,\n",
       "         -88,  -87,  -86,  -85,  -84,  -83,  -82,  -81,  -80,  -79,  -78,  -77,\n",
       "         -76,  -75,  -74,  -73,  -72,  -71,  -70,  -69,  -68,  -67,  -66,  -65,\n",
       "         -64,  -63,  -62,  -61,  -60,  -59,  -58,  -57,  -56,  -55,  -54,  -53,\n",
       "         -52,  -51,  -50,  -49,  -48,  -47,  -46,  -45,  -44,  -43,  -42,  -41,\n",
       "         -40,  -39,  -38,  -37,  -36,  -35,  -34,  -33,  -32,  -31,  -30,  -29,\n",
       "         -28,  -27,  -26,  -25,  -24,  -23,  -22,  -21,  -20,  -19,  -18,  -17,\n",
       "         -16,  -15,  -14,  -13,  -12,  -11,  -10,   -9,   -8,   -7,   -6,   -5,\n",
       "          -4,   -3,   -2,   -1,    0,    1,    2,    3,    4,    5,    6,    7,\n",
       "           8,    9,   10,   11,   12,   13,   14,   15,   16,   17,   18,   19,\n",
       "          20,   21,   22,   23,   24,   25,   26,   27,   28,   29,   30,   31,\n",
       "          32,   33,   34,   35,   36,   37,   38,   39,   40,   41,   42,   43,\n",
       "          44,   45,   46,   47,   48,   49,   50,   51,   52,   53,   54,   55,\n",
       "          56,   57,   58,   59,   60,   61,   62,   63,   64,   65,   66,   67,\n",
       "          68,   69,   70,   71,   72,   73,   74,   75,   76,   77,   78,   79,\n",
       "          80,   81,   82,   83,   84,   85,   86,   87,   88,   89,   90,   91,\n",
       "          92,   93,   94,   95,   96,   97,   98,   99])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:06.082423Z",
     "start_time": "2022-04-08T06:25:06.072422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.unsqueeze(torch.arange(-100,100),dim=1).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:06.300435Z",
     "start_time": "2022-04-08T06:25:06.275434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100.],\n",
       "        [ -99.],\n",
       "        [ -98.],\n",
       "        [ -97.],\n",
       "        [ -96.],\n",
       "        [ -95.],\n",
       "        [ -94.],\n",
       "        [ -93.],\n",
       "        [ -92.],\n",
       "        [ -91.],\n",
       "        [ -90.],\n",
       "        [ -89.],\n",
       "        [ -88.],\n",
       "        [ -87.],\n",
       "        [ -86.],\n",
       "        [ -85.],\n",
       "        [ -84.],\n",
       "        [ -83.],\n",
       "        [ -82.],\n",
       "        [ -81.],\n",
       "        [ -80.],\n",
       "        [ -79.],\n",
       "        [ -78.],\n",
       "        [ -77.],\n",
       "        [ -76.],\n",
       "        [ -75.],\n",
       "        [ -74.],\n",
       "        [ -73.],\n",
       "        [ -72.],\n",
       "        [ -71.],\n",
       "        [ -70.],\n",
       "        [ -69.],\n",
       "        [ -68.],\n",
       "        [ -67.],\n",
       "        [ -66.],\n",
       "        [ -65.],\n",
       "        [ -64.],\n",
       "        [ -63.],\n",
       "        [ -62.],\n",
       "        [ -61.],\n",
       "        [ -60.],\n",
       "        [ -59.],\n",
       "        [ -58.],\n",
       "        [ -57.],\n",
       "        [ -56.],\n",
       "        [ -55.],\n",
       "        [ -54.],\n",
       "        [ -53.],\n",
       "        [ -52.],\n",
       "        [ -51.],\n",
       "        [ -50.],\n",
       "        [ -49.],\n",
       "        [ -48.],\n",
       "        [ -47.],\n",
       "        [ -46.],\n",
       "        [ -45.],\n",
       "        [ -44.],\n",
       "        [ -43.],\n",
       "        [ -42.],\n",
       "        [ -41.],\n",
       "        [ -40.],\n",
       "        [ -39.],\n",
       "        [ -38.],\n",
       "        [ -37.],\n",
       "        [ -36.],\n",
       "        [ -35.],\n",
       "        [ -34.],\n",
       "        [ -33.],\n",
       "        [ -32.],\n",
       "        [ -31.],\n",
       "        [ -30.],\n",
       "        [ -29.],\n",
       "        [ -28.],\n",
       "        [ -27.],\n",
       "        [ -26.],\n",
       "        [ -25.],\n",
       "        [ -24.],\n",
       "        [ -23.],\n",
       "        [ -22.],\n",
       "        [ -21.],\n",
       "        [ -20.],\n",
       "        [ -19.],\n",
       "        [ -18.],\n",
       "        [ -17.],\n",
       "        [ -16.],\n",
       "        [ -15.],\n",
       "        [ -14.],\n",
       "        [ -13.],\n",
       "        [ -12.],\n",
       "        [ -11.],\n",
       "        [ -10.],\n",
       "        [  -9.],\n",
       "        [  -8.],\n",
       "        [  -7.],\n",
       "        [  -6.],\n",
       "        [  -5.],\n",
       "        [  -4.],\n",
       "        [  -3.],\n",
       "        [  -2.],\n",
       "        [  -1.],\n",
       "        [   0.],\n",
       "        [   1.],\n",
       "        [   2.],\n",
       "        [   3.],\n",
       "        [   4.],\n",
       "        [   5.],\n",
       "        [   6.],\n",
       "        [   7.],\n",
       "        [   8.],\n",
       "        [   9.],\n",
       "        [  10.],\n",
       "        [  11.],\n",
       "        [  12.],\n",
       "        [  13.],\n",
       "        [  14.],\n",
       "        [  15.],\n",
       "        [  16.],\n",
       "        [  17.],\n",
       "        [  18.],\n",
       "        [  19.],\n",
       "        [  20.],\n",
       "        [  21.],\n",
       "        [  22.],\n",
       "        [  23.],\n",
       "        [  24.],\n",
       "        [  25.],\n",
       "        [  26.],\n",
       "        [  27.],\n",
       "        [  28.],\n",
       "        [  29.],\n",
       "        [  30.],\n",
       "        [  31.],\n",
       "        [  32.],\n",
       "        [  33.],\n",
       "        [  34.],\n",
       "        [  35.],\n",
       "        [  36.],\n",
       "        [  37.],\n",
       "        [  38.],\n",
       "        [  39.],\n",
       "        [  40.],\n",
       "        [  41.],\n",
       "        [  42.],\n",
       "        [  43.],\n",
       "        [  44.],\n",
       "        [  45.],\n",
       "        [  46.],\n",
       "        [  47.],\n",
       "        [  48.],\n",
       "        [  49.],\n",
       "        [  50.],\n",
       "        [  51.],\n",
       "        [  52.],\n",
       "        [  53.],\n",
       "        [  54.],\n",
       "        [  55.],\n",
       "        [  56.],\n",
       "        [  57.],\n",
       "        [  58.],\n",
       "        [  59.],\n",
       "        [  60.],\n",
       "        [  61.],\n",
       "        [  62.],\n",
       "        [  63.],\n",
       "        [  64.],\n",
       "        [  65.],\n",
       "        [  66.],\n",
       "        [  67.],\n",
       "        [  68.],\n",
       "        [  69.],\n",
       "        [  70.],\n",
       "        [  71.],\n",
       "        [  72.],\n",
       "        [  73.],\n",
       "        [  74.],\n",
       "        [  75.],\n",
       "        [  76.],\n",
       "        [  77.],\n",
       "        [  78.],\n",
       "        [  79.],\n",
       "        [  80.],\n",
       "        [  81.],\n",
       "        [  82.],\n",
       "        [  83.],\n",
       "        [  84.],\n",
       "        [  85.],\n",
       "        [  86.],\n",
       "        [  87.],\n",
       "        [  88.],\n",
       "        [  89.],\n",
       "        [  90.],\n",
       "        [  91.],\n",
       "        [  92.],\n",
       "        [  93.],\n",
       "        [  94.],\n",
       "        [  95.],\n",
       "        [  96.],\n",
       "        [  97.],\n",
       "        [  98.],\n",
       "        [  99.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:06.735460Z",
     "start_time": "2022-04-08T06:25:06.729460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.pow(2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:07.020476Z",
     "start_time": "2022-04-08T06:25:06.993475Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save1():\n",
    "    optimizer=optim.Adam(net.parameters(),lr=0.1)\n",
    "    loss_func=nn.MSELoss()\n",
    "    for t in range(2000):\n",
    "        predictions=net(x)\n",
    "        l=loss_func(predictions,y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(net,r'F:\\study\\ml\\rknn\\models\\test_net2.pt')\n",
    "    input_shape=(1)\n",
    "    batch_size=1\n",
    "    \n",
    "    input_data_shape=torch.randn(batch_size,input_shape)\n",
    "    torch.onnx.export(net,input_shape,r'F:\\study\\ml\\rknn\\models\\test_net2.onnx',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:08.905584Z",
     "start_time": "2022-04-08T06:25:07.545506Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only tuples, lists and Variables supported as JIT inputs/outputs. Dictionaries and strings are also accepted but their usage is not recommended. But got unsupported type int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-cd05d5f58bc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-c45dded4cce9>\u001b[0m in \u001b[0;36msave1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0minput_data_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mr'F:\\study\\ml\\rknn\\models\\test_net2.onnx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[0;32m    206\u001b[0m                         \u001b[0mdo_constant_folding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mcustom_opsets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_opsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_onnx_checker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_onnx_checker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[0;32m    528\u001b[0m                                                             \u001b[0mexample_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                                                             \u001b[0m_retain_param_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_do_constant_folding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m                                                             fixed_batch_size=fixed_batch_size)\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[1;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, propagate, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size)\u001b[0m\n\u001b[0;32m    364\u001b[0m             graph, tuple(in_vars), False, propagate)\n\u001b[0;32m    365\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[0mtrace_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs_states\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m     \u001b[0mwarn_on_static_input_change\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\__init__.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[1;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\jit\\__init__.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         \u001b[0min_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_desc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m         \u001b[1;31m# NOTE: use full state, because we need it for BatchNorm export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;31m# This differs from the compiler path, which doesn't support it at the moment.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only tuples, lists and Variables supported as JIT inputs/outputs. Dictionaries and strings are also accepted but their usage is not recommended. But got unsupported type int"
     ]
    }
   ],
   "source": [
    "save1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:08.906584Z",
     "start_time": "2022-04-08T06:25:08.074Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    optimizer=optim.Adam(net.parameters(),lr=0.1)\n",
    "    loss_func=nn.MSELoss()\n",
    "    for t in range(2000):\n",
    "        predictions=net(x)\n",
    "        l=loss_func(predictions,y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(net,r'F:\\study\\ml\\rknn\\models\\test_net2.pt')\n",
    "    input_shape=(1)\n",
    "    batch_size=1\n",
    "    \n",
    "    input_data_shape=torch.randn(batch_size,input_shape)\n",
    "    torch.onnx.export(net,input_data_shape,r'F:\\study\\ml\\rknn\\models\\test_net2.onnx',verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:11.416728Z",
     "start_time": "2022-04-08T06:25:11.404727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(1)\n",
    "batch_size=1\n",
    "type(torch.randn(batch_size,input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:15.327952Z",
     "start_time": "2022-04-08T06:25:15.315951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.randn(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:15.816980Z",
     "start_time": "2022-04-08T06:25:15.796978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'' was not found in history, as a file, url, nor in the user namespace.\n"
     ]
    }
   ],
   "source": [
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:25:16.858039Z",
     "start_time": "2022-04-08T06:25:16.734032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[180.4134]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:29: UserWarning: Unsupported Windows version (7). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn('Unsupported Windows version (%s). ONNX Runtime supports Windows 10 and above, only.' % __my_distro_ver__)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "input_test_data=torch.Tensor([[15]])\n",
    "net=torch.load(r'F:\\study\\ml\\rknn\\models\\test_net2.pt')\n",
    "prediction=net(input_test_data)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:29:19.250903Z",
     "start_time": "2022-04-08T06:29:19.239903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:29:21.908055Z",
     "start_time": "2022-04-08T06:29:21.854052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.1\n",
      "[[203.70389]]\n"
     ]
    }
   ],
   "source": [
    "sess=rt.InferenceSession(r'F:\\study\\ml\\rknn\\models\\test_net2.onnx')\n",
    "input_name=sess.get_inputs()[0].name\n",
    "print(input_name)\n",
    "pred_oxn=sess.run(None,{input_name:input_test_data.numpy()})[0]\n",
    "print(pred_oxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:59:08.447833Z",
     "start_time": "2022-04-06T08:59:08.407831Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rknnlite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-62d903bfb788>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrknnlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRKNNLite\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRKNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'/tmp/test_net2.rknn'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput_test_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rknnlite'"
     ]
    }
   ],
   "source": [
    "from rknnlite.api import RKNNLite as RKNN\n",
    "import numpy as np\n",
    "\n",
    "model=r'/tmp/test_net2.rknn'\n",
    "input_test_data=np.array([15],dtype=np.float32)\n",
    "rknn=RKNN()\n",
    "ret=rknn.load_rknn(path=model)\n",
    "print('---- init runtime env ')\n",
    "ret=rknn.init_runtime()\n",
    "if ret !=0:\n",
    "    print(' ---- init runtime env failed !')\n",
    "    exit(ret)\n",
    "print('----init down')\n",
    "output=rknn.inference(inputs=[input_test_data])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
