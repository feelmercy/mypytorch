{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:13.531201Z",
     "start_time": "2021-01-15T06:14:13.505199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:14.851276Z",
     "start_time": "2021-01-15T06:14:14.828275Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples=1000\n",
    "num_input=2\n",
    "true_w=torch.tensor([2,-3.4,2.1],dtype=torch.float64)\n",
    "true_b=torch.tensor([4.2],dtype=torch.float64)\n",
    "features=torch.from_numpy(np.random.normal(0,1,(num_samples,num_input)))\n",
    "labels=true_w[0]*features[:,0]+true_w[1]*features[:,1]+true_b[0]\n",
    "labels+=torch.from_numpy(np.random.normal(0,0.01,num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:16.591376Z",
     "start_time": "2021-01-15T06:14:16.573375Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_iter(features,labels,batch_size):\n",
    "    f_len=len(features)\n",
    "    indices=list(range(0,f_len))\n",
    "    np.random.shuffle(indices)\n",
    "    for i in range(0,f_len,batch_size):\n",
    "        j=torch.LongTensor(indices[i:min(i+batch_size,f_len)])\n",
    "        yield features.index_select(0,j),labels.index_select(0,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:17.239413Z",
     "start_time": "2021-01-15T06:14:17.225412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0628, -0.2925],\n",
      "        [-0.4431,  0.1392],\n",
      "        [-0.5671,  0.2262],\n",
      "        [-1.2307,  0.2091],\n",
      "        [-0.0492,  0.2277],\n",
      "        [-0.1418, -0.3554],\n",
      "        [-0.4280, -1.9641],\n",
      "        [ 0.3402,  0.0057],\n",
      "        [-2.4252, -0.2089],\n",
      "        [ 0.3634,  0.0746],\n",
      "        [ 0.4223, -1.2214],\n",
      "        [ 0.6238,  1.6083],\n",
      "        [-1.7483, -2.0573],\n",
      "        [ 0.5167, -0.1906],\n",
      "        [-2.5024, -0.6466],\n",
      "        [ 1.3207,  0.5298],\n",
      "        [-1.2790, -0.0135],\n",
      "        [ 0.9656,  0.3033],\n",
      "        [ 0.6165,  1.0595],\n",
      "        [ 1.7639, -0.6480],\n",
      "        [ 0.1029,  0.6386],\n",
      "        [-2.2616, -1.1050],\n",
      "        [ 0.2739,  0.6882],\n",
      "        [ 1.4273,  0.1452],\n",
      "        [-1.0170, -0.6847],\n",
      "        [-0.3151, -0.4429],\n",
      "        [ 2.5980, -0.7195],\n",
      "        [ 0.1048,  0.0062],\n",
      "        [ 0.2139, -0.6376],\n",
      "        [-1.3277, -0.0759],\n",
      "        [ 0.8873,  0.3572],\n",
      "        [-0.9285,  1.1900],\n",
      "        [-0.2044,  0.8779],\n",
      "        [-0.2345,  2.0080],\n",
      "        [ 0.9650,  0.4840],\n",
      "        [ 1.0631, -0.5219],\n",
      "        [-0.5033,  0.7261],\n",
      "        [-0.1883, -0.1922],\n",
      "        [ 0.1887, -1.2405],\n",
      "        [-0.5712,  2.0227],\n",
      "        [ 0.4655,  0.9845],\n",
      "        [ 1.0458, -0.1295],\n",
      "        [ 1.2075, -0.2455],\n",
      "        [-0.0711, -0.0968],\n",
      "        [-1.0764, -0.6828],\n",
      "        [ 0.9239, -1.7236],\n",
      "        [-1.0668, -0.1371],\n",
      "        [-0.2187, -2.1755],\n",
      "        [ 0.1427,  0.9962],\n",
      "        [-2.8874, -0.3642]], dtype=torch.float64) tensor([ 5.3258,  2.8423,  2.3056,  1.0150,  3.3258,  5.1228, 10.0213,  4.8473,\n",
      "         0.0615,  4.6632,  9.2108, -0.0279,  7.6895,  5.8809,  1.3821,  5.0520,\n",
      "         1.6850,  5.1012,  1.8156,  9.9512,  2.2239,  3.4475,  2.4014,  6.5704,\n",
      "         4.4902,  5.0783, 11.8584,  4.3868,  6.8056,  1.8171,  4.7795, -1.7107,\n",
      "         0.8100, -3.0940,  4.4953,  8.0957,  0.7366,  4.4886,  8.7903, -3.8073,\n",
      "         1.7882,  6.7422,  7.4639,  4.3843,  4.3757, 11.9124,  2.5209, 11.1629,\n",
      "         1.1074, -0.3256], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i,j  in data_iter(features,labels,50):\n",
    "    print(i,j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:17.923452Z",
     "start_time": "2021-01-15T06:14:17.915451Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg(w,x,b):\n",
    "    return torch.mm(w,x)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:19.118520Z",
     "start_time": "2021-01-15T06:14:19.110520Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(y_hat,y):\n",
    "    return (y_hat-y.view(y_hat.size()))**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:21.219640Z",
     "start_time": "2021-01-15T06:14:21.211640Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(x,lm,params):\n",
    "    for param in params:\n",
    "        param.data -= lm * param.grad / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:22.159694Z",
     "start_time": "2021-01-15T06:14:22.148694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35207464505345554, 0.2889197740499131]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:23.259757Z",
     "start_time": "2021-01-15T06:14:23.249757Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w=torch.tensor(np.random.rand(2).tolist(),dtype=torch.float64).view(2,1)\n",
    "b=torch.tensor([1.0],dtype=torch.float64)\n",
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:24.162809Z",
     "start_time": "2021-01-15T06:14:24.028801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 ,loss 0.000078\n",
      "epoch 1 ,loss 0.000133\n",
      "epoch 2 ,loss 0.000070\n"
     ]
    }
   ],
   "source": [
    "w.requires_grad_(True)\n",
    "b.requires_grad_(True)\n",
    "lm=1\n",
    "epochs=3\n",
    "for i in range(epochs):\n",
    "    for x ,y in data_iter(features,labels,batch_size):\n",
    "        l=l2_loss(linreg(x,w,b),y).sum()\n",
    "        l.backward()\n",
    "        sgd(x,lm,[w,b])\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l=l2_loss(linreg(features,w,b),labels)\n",
    "    print('epoch %d ,loss %f' % (i, train_l.mean().item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:27.534002Z",
     "start_time": "2021-01-15T06:14:27.516001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.0000, -3.4000,  2.1000], dtype=torch.float64) \n",
      " tensor([[ 1.9946],\n",
      "        [-3.4020]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([4.2000], dtype=torch.float64) \n",
      " tensor([4.1980], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(true_w, '\\n', w)\n",
    "print(true_b, '\\n', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:14:31.840248Z",
     "start_time": "2021-01-15T06:14:31.628236Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train,n_test,num_inputs=20,100,200\n",
    "true_w,true_b=torch.ones(num_inputs,1)*0.01,0.05\n",
    "features=torch.randn((n_train+n_test,num_inputs))\n",
    "labels=torch.matmul(features,true_w)+true_b\n",
    "labels+=torch.tensor(np.random.normal(0,0.01,size=labels.size()),dtype=torch.float)\n",
    "train_features,test_features=features[:n_train,:],features[n_train:,:]\n",
    "train_labels,test_labels=labels[:n_train,:],labels[n_train:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:18:03.113332Z",
     "start_time": "2021-01-15T06:18:03.101331Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    w=torch.randn((num_inputs,1),requires_grad=True)\n",
    "    b=torch.zeros(1,requires_grad=True)\n",
    "    return [w,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:18:30.925923Z",
     "start_time": "2021-01-15T06:18:30.797915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 ,loss 28009.923828\n",
      "epoch 1 ,loss 20538112.000000\n",
      "epoch 2 ,loss 16657257472.000000\n",
      "epoch 3 ,loss 14250079682560.000000\n",
      "epoch 4 ,loss 12591792918626304.000000\n",
      "epoch 5 ,loss 11368463147552735232.000000\n",
      "epoch 6 ,loss 10423288603573233909760.000000\n",
      "epoch 7 ,loss 9668270033963750470451200.000000\n",
      "epoch 8 ,loss 9049403597400720230561349632.000000\n",
      "epoch 9 ,loss 8531359285874947720172116377600.000000\n",
      "epoch 10 ,loss 8089976532871177943254298676690944.000000\n",
      "epoch 11 ,loss inf\n",
      "epoch 12 ,loss inf\n",
      "epoch 13 ,loss inf\n",
      "epoch 14 ,loss inf\n",
      "epoch 15 ,loss inf\n",
      "epoch 16 ,loss inf\n",
      "epoch 17 ,loss inf\n",
      "epoch 18 ,loss inf\n",
      "epoch 19 ,loss inf\n",
      "epoch 20 ,loss inf\n",
      "epoch 21 ,loss inf\n",
      "epoch 22 ,loss inf\n",
      "epoch 23 ,loss inf\n",
      "epoch 24 ,loss inf\n",
      "epoch 25 ,loss nan\n",
      "epoch 26 ,loss nan\n",
      "epoch 27 ,loss nan\n",
      "epoch 28 ,loss nan\n",
      "epoch 29 ,loss nan\n",
      "epoch 30 ,loss nan\n",
      "epoch 31 ,loss nan\n",
      "epoch 32 ,loss nan\n",
      "epoch 33 ,loss nan\n",
      "epoch 34 ,loss nan\n",
      "epoch 35 ,loss nan\n",
      "epoch 36 ,loss nan\n",
      "epoch 37 ,loss nan\n",
      "epoch 38 ,loss nan\n",
      "epoch 39 ,loss nan\n",
      "epoch 40 ,loss nan\n",
      "epoch 41 ,loss nan\n",
      "epoch 42 ,loss nan\n",
      "epoch 43 ,loss nan\n",
      "epoch 44 ,loss nan\n",
      "epoch 45 ,loss nan\n",
      "epoch 46 ,loss nan\n",
      "epoch 47 ,loss nan\n",
      "epoch 48 ,loss nan\n",
      "epoch 49 ,loss nan\n",
      "epoch 50 ,loss nan\n",
      "epoch 51 ,loss nan\n",
      "epoch 52 ,loss nan\n",
      "epoch 53 ,loss nan\n",
      "epoch 54 ,loss nan\n",
      "epoch 55 ,loss nan\n",
      "epoch 56 ,loss nan\n",
      "epoch 57 ,loss nan\n",
      "epoch 58 ,loss nan\n",
      "epoch 59 ,loss nan\n",
      "epoch 60 ,loss nan\n",
      "epoch 61 ,loss nan\n",
      "epoch 62 ,loss nan\n",
      "epoch 63 ,loss nan\n",
      "epoch 64 ,loss nan\n",
      "epoch 65 ,loss nan\n",
      "epoch 66 ,loss nan\n",
      "epoch 67 ,loss nan\n",
      "epoch 68 ,loss nan\n",
      "epoch 69 ,loss nan\n",
      "epoch 70 ,loss nan\n",
      "epoch 71 ,loss nan\n",
      "epoch 72 ,loss nan\n",
      "epoch 73 ,loss nan\n",
      "epoch 74 ,loss nan\n",
      "epoch 75 ,loss nan\n",
      "epoch 76 ,loss nan\n",
      "epoch 77 ,loss nan\n",
      "epoch 78 ,loss nan\n",
      "epoch 79 ,loss nan\n",
      "epoch 80 ,loss nan\n",
      "epoch 81 ,loss nan\n",
      "epoch 82 ,loss nan\n",
      "epoch 83 ,loss nan\n",
      "epoch 84 ,loss nan\n",
      "epoch 85 ,loss nan\n",
      "epoch 86 ,loss nan\n",
      "epoch 87 ,loss nan\n",
      "epoch 88 ,loss nan\n",
      "epoch 89 ,loss nan\n",
      "epoch 90 ,loss nan\n",
      "epoch 91 ,loss nan\n",
      "epoch 92 ,loss nan\n",
      "epoch 93 ,loss nan\n",
      "epoch 94 ,loss nan\n",
      "epoch 95 ,loss nan\n",
      "epoch 96 ,loss nan\n",
      "epoch 97 ,loss nan\n",
      "epoch 98 ,loss nan\n",
      "epoch 99 ,loss nan\n"
     ]
    }
   ],
   "source": [
    "w,b=init_params()\n",
    "lm=2\n",
    "epochs=100\n",
    "for i in range(epochs):\n",
    "    for x ,y in data_iter(train_features,train_labels,20):\n",
    "        l=l2_loss(linreg(x,w,b),y).sum()\n",
    "        l.backward()\n",
    "        sgd(x,lm,[w,b])\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l=l2_loss(linreg(features,w,b),labels)\n",
    "    print('epoch %d ,loss %f' % (i, train_l.mean().item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
