{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T06:21:09.163116Z",
     "start_time": "2021-08-16T06:21:08.501078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:02:58.519643Z",
     "start_time": "2021-08-16T07:02:58.508642Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train,n_test,num_inputs=20,100,200\n",
    "true_w,true_b=torch.ones(num_inputs,1)*0.01,0.05\n",
    "\n",
    "features=torch.randn((n_train+n_test,num_inputs))\n",
    "labels=torch.matmul(features,true_w)+true_b\n",
    "labels+=torch.Tensor(np.random.normal(0,0.01,size=labels.size()))\n",
    "train_features,test_features=features[:n_train,:],features[n_train:,:]\n",
    "train_labels,test_labels=labels[:n_train],labels[n_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:02:58.983669Z",
     "start_time": "2021-08-16T07:02:58.979669Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    w=torch.randn((num_inputs,1),requires_grad=True)\n",
    "    b=torch.zeros(1,requires_grad=True)\n",
    "    return [w,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:02:59.600705Z",
     "start_time": "2021-08-16T07:02:59.596704Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ls_penalty(w):\n",
    "    return (w**2).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:03:03.375920Z",
     "start_time": "2021-08-16T07:03:03.371920Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(x,w,b):\n",
    "#     print(x.shape)\n",
    "    return torch.mm(x,w)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:03:03.703939Z",
     "start_time": "2021-08-16T07:03:03.699939Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_hat,y):\n",
    "#     print('y_hat:',y_hat)\n",
    "    return (y_hat-y.view(y_hat.size()))**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:15:13.463679Z",
     "start_time": "2021-08-16T07:15:13.451678Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    for p in params:\n",
    "        p.data -= lr*p.grad / batch_size\n",
    "#         print(p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:15:13.961708Z",
     "start_time": "2021-08-16T07:15:13.951707Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size,num_epochs,lr=1,100,0.003\n",
    "dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "train_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:15:14.592744Z",
     "start_time": "2021-08-16T07:15:14.558742Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_plot(ld):\n",
    "    w,b=init_params()\n",
    "    loss=squared_loss\n",
    "    train_ls,test_ls=[],[]\n",
    "    for _ in range(num_epochs):\n",
    "        for x,y in train_iter:\n",
    "            l=loss(net(x,w,b),y)+ld*ls_penalty(w)\n",
    "            l=l.sum()\n",
    "            \n",
    "            if w.grad is not None:\n",
    "#                 print(' reset 0')\n",
    "                w.grad.data.zero_()\n",
    "                b.grad.data.zero_()\n",
    "            l.backward()\n",
    "            sgd([w,b],lr,batch_size)\n",
    "#         print('train loss:',loss(net(train_features,w,b),train_labels))\n",
    "        train_ls.append(loss(net(train_features,w,b),train_labels).mean().item())\n",
    "        test_ls.append(loss(net(test_features,w,b),test_labels).mean().item())\n",
    "        print('L2 norm of w:',w.norm().item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:16:18.203382Z",
     "start_time": "2021-08-16T07:16:17.276329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of w: 9.609057426452637\n",
      "L2 norm of w: 7.93615198135376\n",
      "L2 norm of w: 6.6049723625183105\n",
      "L2 norm of w: 5.507937431335449\n",
      "L2 norm of w: 4.595791339874268\n",
      "L2 norm of w: 3.8354694843292236\n",
      "L2 norm of w: 3.201160192489624\n",
      "L2 norm of w: 2.6718990802764893\n",
      "L2 norm of w: 2.2302770614624023\n",
      "L2 norm of w: 1.8617419004440308\n",
      "L2 norm of w: 1.5542516708374023\n",
      "L2 norm of w: 1.2976802587509155\n",
      "L2 norm of w: 1.083652138710022\n",
      "L2 norm of w: 0.9050969481468201\n",
      "L2 norm of w: 0.7562064528465271\n",
      "L2 norm of w: 0.6321134567260742\n",
      "L2 norm of w: 0.5287802815437317\n",
      "L2 norm of w: 0.44256022572517395\n",
      "L2 norm of w: 0.3709110617637634\n",
      "L2 norm of w: 0.31149089336395264\n",
      "L2 norm of w: 0.26218631863594055\n",
      "L2 norm of w: 0.22125643491744995\n",
      "L2 norm of w: 0.18763087689876556\n",
      "L2 norm of w: 0.15962284803390503\n",
      "L2 norm of w: 0.13725747168064117\n",
      "L2 norm of w: 0.11921142786741257\n",
      "L2 norm of w: 0.10504072904586792\n",
      "L2 norm of w: 0.09310078620910645\n",
      "L2 norm of w: 0.08308923989534378\n",
      "L2 norm of w: 0.07590818405151367\n",
      "L2 norm of w: 0.07013288140296936\n",
      "L2 norm of w: 0.06646928936243057\n",
      "L2 norm of w: 0.06270541995763779\n",
      "L2 norm of w: 0.06085006892681122\n",
      "L2 norm of w: 0.05843032896518707\n",
      "L2 norm of w: 0.05799950659275055\n",
      "L2 norm of w: 0.05527891218662262\n",
      "L2 norm of w: 0.054830774664878845\n",
      "L2 norm of w: 0.05543218180537224\n",
      "L2 norm of w: 0.05491361767053604\n",
      "L2 norm of w: 0.05409717932343483\n",
      "L2 norm of w: 0.05409052595496178\n",
      "L2 norm of w: 0.05298362299799919\n",
      "L2 norm of w: 0.05258446931838989\n",
      "L2 norm of w: 0.052973225712776184\n",
      "L2 norm of w: 0.05141839385032654\n",
      "L2 norm of w: 0.05110201984643936\n",
      "L2 norm of w: 0.05056711658835411\n",
      "L2 norm of w: 0.04990101605653763\n",
      "L2 norm of w: 0.049289997667074203\n",
      "L2 norm of w: 0.04865087568759918\n",
      "L2 norm of w: 0.0485239140689373\n",
      "L2 norm of w: 0.048086632043123245\n",
      "L2 norm of w: 0.04842941090464592\n",
      "L2 norm of w: 0.04858837276697159\n",
      "L2 norm of w: 0.0477280355989933\n",
      "L2 norm of w: 0.04704238846898079\n",
      "L2 norm of w: 0.04775835946202278\n",
      "L2 norm of w: 0.0477067232131958\n",
      "L2 norm of w: 0.04756441339850426\n",
      "L2 norm of w: 0.04715675860643387\n",
      "L2 norm of w: 0.047450024634599686\n",
      "L2 norm of w: 0.046520721167325974\n",
      "L2 norm of w: 0.046861812472343445\n",
      "L2 norm of w: 0.045638307929039\n",
      "L2 norm of w: 0.0457865446805954\n",
      "L2 norm of w: 0.04572383314371109\n",
      "L2 norm of w: 0.04513416066765785\n",
      "L2 norm of w: 0.045002732425928116\n",
      "L2 norm of w: 0.04466195032000542\n",
      "L2 norm of w: 0.044385261833667755\n",
      "L2 norm of w: 0.0444105826318264\n",
      "L2 norm of w: 0.04447077959775925\n",
      "L2 norm of w: 0.044468868523836136\n",
      "L2 norm of w: 0.04338659346103668\n",
      "L2 norm of w: 0.04392949864268303\n",
      "L2 norm of w: 0.0441465824842453\n",
      "L2 norm of w: 0.0444716177880764\n",
      "L2 norm of w: 0.04374786838889122\n",
      "L2 norm of w: 0.0434889942407608\n",
      "L2 norm of w: 0.04380330815911293\n",
      "L2 norm of w: 0.04308484494686127\n",
      "L2 norm of w: 0.04298895597457886\n",
      "L2 norm of w: 0.04369571432471275\n",
      "L2 norm of w: 0.04279131814837456\n",
      "L2 norm of w: 0.04288901761174202\n",
      "L2 norm of w: 0.04284880310297012\n",
      "L2 norm of w: 0.042356666177511215\n",
      "L2 norm of w: 0.04233064129948616\n",
      "L2 norm of w: 0.04170186072587967\n",
      "L2 norm of w: 0.04146464541554451\n",
      "L2 norm of w: 0.041537828743457794\n",
      "L2 norm of w: 0.042540643364191055\n",
      "L2 norm of w: 0.04146227240562439\n",
      "L2 norm of w: 0.041623249650001526\n",
      "L2 norm of w: 0.04162367433309555\n",
      "L2 norm of w: 0.04133600369095802\n",
      "L2 norm of w: 0.04062432795763016\n",
      "L2 norm of w: 0.04129338636994362\n",
      "L2 norm of w: 0.041178371757268906\n"
     ]
    }
   ],
   "source": [
    "fit_and_plot(ld=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:28:30.865288Z",
     "start_time": "2021-08-16T07:28:30.861288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:40:51.548653Z",
     "start_time": "2021-08-16T07:40:51.469648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_plot_pytorch(wd):\n",
    "    net=nn.Linear(num_inputs,1)\n",
    "    nn.init.normal_(net.weight,mean=0,std=1)\n",
    "    nn.init.normal_(net.bias,mean=0,std=1)\n",
    "    optimizer_w=torch.optim.SGD(params=[net.weight],lr=lr,weight_decay=wd)\n",
    "    optimizer_b=torch.optim.SGD(params=[net.bias],lr=lr)\n",
    "    loss=squared_loss\n",
    "    \n",
    "    train_ls,test_ls=[],[]\n",
    "    for _ in range(num_epochs):\n",
    "        for x,y in train_iter:\n",
    "            l=loss(net(x),y).mean()\n",
    "            \n",
    "            optimizer_w.zero_grad()\n",
    "            optimizer_b.zero_grad()\n",
    "            \n",
    "            l.backward()\n",
    "            \n",
    "            optimizer_w.step()\n",
    "            optimizer_b.step()\n",
    "            \n",
    "        train_ls.append(loss(net(train_features),train_labels).mean().item())\n",
    "        test_ls.append(loss(net(test_features),test_labels).mean().item())\n",
    "        print('L2 norm of w:',net.weight.data.norm().item())\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T07:40:52.683717Z",
     "start_time": "2021-08-16T07:40:51.995678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of w: 14.151895523071289\n",
      "L2 norm of w: 14.063544273376465\n",
      "L2 norm of w: 14.042744636535645\n",
      "L2 norm of w: 14.037006378173828\n",
      "L2 norm of w: 14.035221099853516\n",
      "L2 norm of w: 14.034656524658203\n",
      "L2 norm of w: 14.034491539001465\n",
      "L2 norm of w: 14.034446716308594\n",
      "L2 norm of w: 14.034435272216797\n",
      "L2 norm of w: 14.034436225891113\n",
      "L2 norm of w: 14.034438133239746\n",
      "L2 norm of w: 14.034439086914062\n",
      "L2 norm of w: 14.034440040588379\n",
      "L2 norm of w: 14.034440040588379\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n",
      "L2 norm of w: 14.034440994262695\n"
     ]
    }
   ],
   "source": [
    "fit_and_plot_pytorch(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
