{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T02:23:02.193435Z",
     "start_time": "2021-02-02T02:23:02.182435Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn,optim\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T02:34:06.595437Z",
     "start_time": "2021-02-02T02:34:06.553434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4,1),  # inchannle,out_channel,kernel,stride,padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),  #kernel_size,stride\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self,img):\n",
    "        feature=self.conv(img)\n",
    "        output=self.fc(feature.view(img.shape[0],-1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T02:34:07.782505Z",
     "start_time": "2021-02-02T02:34:07.449486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T02:34:08.299534Z",
     "start_time": "2021-02-02T02:34:08.280533Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size,\n",
    "                            resize=None,\n",
    "                            root=r'F:\\study\\ml\\DataSet\\FashionMNIST'):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root,\n",
    "                                                    train=True,\n",
    "                                                    download=True,\n",
    "                                                    transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root,\n",
    "                                                   train=False,\n",
    "                                                   download=True,\n",
    "                                                   transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T02:34:09.333593Z",
     "start_time": "2021-02-02T02:34:09.327593Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n=0.0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in data_iter:\n",
    "            net.eval()\n",
    "            acc_sum +=(net(x).argmax(dim=1)==y).float().sum().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum /n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T02:34:59.455460Z",
     "start_time": "2021-02-02T02:34:59.433459Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, num_epochs):\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for x, y in train_iter:\n",
    "            y_hat = net(x)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d,loss %.4f,train acc %.3f,test acc %.3f,time %.1f sec' %\n",
    "              (epoch + 1, train_l_sum / batch_count, train_acc / n, test_acc,\n",
    "               time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T09:28:49.070633Z",
     "start_time": "2021-02-02T02:35:19.323597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss 0.5527,train acc 0.000,test acc 0.865,time 4972.6 sec\n",
      "epoch 2,loss 0.1465,train acc 0.000,test acc 0.895,time 4748.2 sec\n",
      "epoch 3,loss 0.0821,train acc 0.000,test acc 0.904,time 5363.0 sec\n",
      "epoch 4,loss 0.0542,train acc 0.000,test acc 0.907,time 4823.0 sec\n",
      "epoch 5,loss 0.0385,train acc 0.000,test acc 0.907,time 4902.9 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "train_iter,test_iter=load_data_fashion_mnist(batch_size,resize=224)\n",
    "lr,num_epochs=0.001,5\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "train_ch5(net,train_iter,test_iter,batch_size,optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    transform = torchvision.transforms.Compose(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T09:53:47.293326Z",
     "start_time": "2021-02-02T09:53:47.246324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Resize(size=224, interpolation=PIL.Image.BILINEAR)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize=224\n",
    "trans=[]\n",
    "trans.append(torchvision.transforms.Resize(size=resize))\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T09:54:17.798071Z",
     "start_time": "2021-02-02T09:54:17.787071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resize(size=224, interpolation=PIL.Image.BILINEAR)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T09:56:40.900256Z",
     "start_time": "2021-02-02T09:56:40.890256Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans.append(torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T09:56:44.232447Z",
     "start_time": "2021-02-02T09:56:44.220446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Resize(size=224, interpolation=PIL.Image.BILINEAR), ToTensor()]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T09:57:56.438577Z",
     "start_time": "2021-02-02T09:57:56.421576Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T09:57:59.591757Z",
     "start_time": "2021-02-02T09:57:59.579756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
