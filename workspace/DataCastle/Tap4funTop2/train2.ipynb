{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T10:20:52.095881Z",
     "start_time": "2018-10-22T09:44:22.313112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始扩展特征...\n",
      "扩展数据集的特征\n",
      "扩展数据集的特征\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f226c8c932e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#扩展特征\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"开始扩展特征...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mfeature_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# 扩展标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\tmp\\jupyter\\workspace\\Tap4funTop2\\preprocess.py\u001b[0m in \u001b[0;36mfeature_expand\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mtrain_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_expanded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mtest_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_expanded\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mtrain_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F:\\\\study\\ml\\\\DataSet\\\\p4fun\\\\top2\\\\train_expanded.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[0mtest_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F:\\\\study\\\\ml\\\\DataSet\\\\Tap4fun\\\\top2\\\\est_expanded.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;31m# GH 17778 handles zip compression for byte strings separately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 f, handles = _get_handle(path_or_buf, self.mode,\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from preprocess import  feature_expand\n",
    "from preprocess import Preprocessor\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "\tpreprocessor=Preprocessor()\n",
    "\n",
    "\t#扩展特征\n",
    "\tprint(\"开始扩展特征...\")\n",
    "\tfeature_expand()\n",
    "\n",
    "\t# 扩展标签\n",
    "\ttrain = pd.read_csv('F:\\\\study\\\\ml\\\\DataSet\\\\Tap4fun\\\\top2\\\\train_expanded.csv')\n",
    "\ttrain = train[train['pay_price'] > 0]\n",
    "\ttrain['new_pay_label']=train['prediction_pay_price']!=train['pay_price']\n",
    "\ttrain['new_pay_label']=train['new_pay_label'].map({True:1,False:0})\n",
    "\ttrain['new_pay_price']=train['prediction_pay_price']-train['pay_price']\n",
    "\ttrain['new_pay_rate']=(train['prediction_pay_price']-train['pay_price'])/train['pay_price']\n",
    "\n",
    "\t# train['new_pay_label']=round(train['new_pay_rate'])\n",
    "\ttrain.set_value(train[train['new_pay_rate']>0].index,'new_pay_label',1)\n",
    "\n",
    "\tclassify_train=train.iloc[:,1:-4]\n",
    "\tclassify_train=preprocessor.time_spliter(classify_train)\n",
    "\n",
    "\ttest=pd.read_csv('F:\\\\study\\\\ml\\\\DataSet\\\\Tap4fun\\\\top2\\\\test_expanded.csv')\n",
    "\n",
    "\ttest_for_pre=test[test['pay_price']>0]\n",
    "\n",
    "\tclassify_test=test_for_pre.iloc[:,1:]\n",
    "\tclassify_test=preprocessor.time_spliter(classify_test)\n",
    "\n",
    "\t# 训练分类模型\n",
    "\tprint(\"训练分类模型...\")\n",
    "\tcl_t = classify_train.iloc[:, :-3].drop_duplicates()\n",
    "\n",
    "\tfrom sklearn.model_selection import GridSearchCV\n",
    "\tfrom xgboost import XGBClassifier\n",
    "\n",
    "\tmodel = GridSearchCV(\n",
    "\t\testimator=XGBClassifier(tree_method='gpu_hist', max_bin=128),\n",
    "\t\tparam_grid={\n",
    "\t\t\t'n_estimators': [1000],\n",
    "\t\t\t'learning_rate': [0.1],\n",
    "\t\t\t'max_depth': [2],\n",
    "\t\t\t'subsample': [1],\n",
    "\t\t\t'colsample_bytree': [0.8],\n",
    "\t\t\t'scale_pos_weight': [2.5, ],\n",
    "\t\t\t'min_child_weight': [2, ]\n",
    "\t\t},\n",
    "\t\tscoring='f1',\n",
    "\t\tcv=3,\n",
    "\t\tn_jobs=1,\n",
    "\t\tverbose=1)\n",
    "\n",
    "\tmodel.fit(cl_t, train.loc[cl_t.index,'new_pay_label'])\n",
    "\tjoblib.dump(model,'F:\\\\study\\\\ml\\\\DataSet\\\\Tap4fun\\\\top2\\\\xgb_clf.model')\n",
    "\tprint(model.best_score_, model.best_params_)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练回归模型\n",
    "\tprint(\"训练回归模型...\")\n",
    "\tfrom xgboost import XGBRegressor\n",
    "\n",
    "\tmodel_reg = GridSearchCV(\n",
    "\t\testimator=XGBRegressor(tree_method='gpu_hist', max_bin=128),\n",
    "\t\t#     estimator=LinearRegression(),\n",
    "\t\tparam_grid={\n",
    "\t\t\t'n_estimators': [80],\n",
    "\t\t\t'learning_rate': [0.05],\n",
    "\t\t\t'max_depth': [2],\n",
    "\t\t\t'subsample': [1],\n",
    "\t\t\t'colsample_bytree': [0.5],\n",
    "\t\t\t'reg_alpha': [13.4],\n",
    "\t\t},\n",
    "\t\tscoring='neg_mean_squared_error',\n",
    "\t\tcv=3,\n",
    "\t\tn_jobs=1,\n",
    "\t\tverbose=1)\n",
    "\tmodel_reg.fit(classify_train.iloc[:, [105, 126, 121, 132, 150]][train['new_pay_label'] == 1],\n",
    "\t              train.iloc[:, -1][train['new_pay_label'] == 1])\n",
    "\t# model_reg.fit(cl_t.iloc[:,[105,126,121,132,150]][train.loc[cl_t.index,'new_pay_label']==1],train.iloc[cl_t.index,-1][train.loc[cl_t.index,'new_pay_label']==1])\n",
    "\tprint(np.sqrt(-model_reg.best_score_), model_reg.best_params_)\n",
    "\tjoblib.dump(model_reg,'model_save/xgb_reg.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
