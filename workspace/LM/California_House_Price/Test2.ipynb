{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T02:14:17.694916Z",
     "start_time": "2022-05-18T02:14:02.620501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn,optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:18:43.921790Z",
     "start_time": "2022-05-18T06:18:42.812149Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(r'F:\\study\\ml\\DataSet\\california-house-prices\\train.csv')\n",
    "test_data=pd.read_csv(r'F:\\study\\ml\\DataSet\\california-house-prices\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:18:48.017310Z",
     "start_time": "2022-05-18T06:18:48.005308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47439, 41)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:18:48.537876Z",
     "start_time": "2022-05-18T06:18:48.529875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31626, 40)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:18:58.851686Z",
     "start_time": "2022-05-18T06:18:58.784177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Address</th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Type</th>\n",
       "      <th>Year built</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Parking</th>\n",
       "      <th>Lot</th>\n",
       "      <th>...</th>\n",
       "      <th>Parking features</th>\n",
       "      <th>Tax assessed value</th>\n",
       "      <th>Annual tax amount</th>\n",
       "      <th>Listed On</th>\n",
       "      <th>Listed Price</th>\n",
       "      <th>Last Sold On</th>\n",
       "      <th>Last Sold Price</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>540 Pine Ln</td>\n",
       "      <td>3825000.0</td>\n",
       "      <td>540 Pine Ln, Los Altos, CA 94022 is a single f...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>Heating - 2+ Zones, Central Forced Air - Gas</td>\n",
       "      <td>Multi-Zone, Central AC, Whole House / Attic Fan</td>\n",
       "      <td>Garage, Garage - Attached, Covered</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Garage, Garage - Attached, Covered</td>\n",
       "      <td>886486.0</td>\n",
       "      <td>12580.0</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>4198000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Altos</td>\n",
       "      <td>94022</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1727 W 67th St</td>\n",
       "      <td>505000.0</td>\n",
       "      <td>HURRY, HURRY.......Great house 3 bed and 2 bat...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Wall/Window Unit(s), Evaporative Cooling, See ...</td>\n",
       "      <td>Detached Carport, Garage</td>\n",
       "      <td>4047.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Detached Carport, Garage</td>\n",
       "      <td>505000.0</td>\n",
       "      <td>6253.0</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>525000.0</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>328000.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90047</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28093 Pine Ave</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>'THE PERFECT CABIN TO FLIP!  Strawberry deligh...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>Forced air</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 spaces</td>\n",
       "      <td>9147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49627.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>95375</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10750 Braddock Dr</td>\n",
       "      <td>1775000.0</td>\n",
       "      <td>Rare 2-story Gated 5 bedroom Modern Mediterran...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Detached Carport, Driveway, Garage - Two Door</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Detached Carport, Driveway, Garage - Two Door</td>\n",
       "      <td>1775000.0</td>\n",
       "      <td>20787.0</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>1895000.0</td>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>Culver City</td>\n",
       "      <td>90230</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7415 O Donovan Rd</td>\n",
       "      <td>1175000.0</td>\n",
       "      <td>Beautiful 200 acre ranch land with several pas...</td>\n",
       "      <td>VacantLand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 spaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>1595000.0</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>Creston</td>\n",
       "      <td>93432</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Address  Sold Price  \\\n",
       "0   0        540 Pine Ln   3825000.0   \n",
       "1   1     1727 W 67th St    505000.0   \n",
       "2   2     28093 Pine Ave    140000.0   \n",
       "3   3  10750 Braddock Dr   1775000.0   \n",
       "4   4  7415 O Donovan Rd   1175000.0   \n",
       "\n",
       "                                             Summary          Type  \\\n",
       "0  540 Pine Ln, Los Altos, CA 94022 is a single f...  SingleFamily   \n",
       "1  HURRY, HURRY.......Great house 3 bed and 2 bat...  SingleFamily   \n",
       "2  'THE PERFECT CABIN TO FLIP!  Strawberry deligh...  SingleFamily   \n",
       "3  Rare 2-story Gated 5 bedroom Modern Mediterran...  SingleFamily   \n",
       "4  Beautiful 200 acre ranch land with several pas...    VacantLand   \n",
       "\n",
       "   Year built                                       Heating  \\\n",
       "0      1969.0  Heating - 2+ Zones, Central Forced Air - Gas   \n",
       "1      1926.0                                   Combination   \n",
       "2      1958.0                                    Forced air   \n",
       "3      1947.0                                       Central   \n",
       "4         NaN                                           NaN   \n",
       "\n",
       "                                             Cooling  \\\n",
       "0    Multi-Zone, Central AC, Whole House / Attic Fan   \n",
       "1  Wall/Window Unit(s), Evaporative Cooling, See ...   \n",
       "2                                                NaN   \n",
       "3                                        Central Air   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         Parking     Lot  ...  \\\n",
       "0             Garage, Garage - Attached, Covered     1.0  ...   \n",
       "1                       Detached Carport, Garage  4047.0  ...   \n",
       "2                                       0 spaces  9147.0  ...   \n",
       "3  Detached Carport, Driveway, Garage - Two Door     NaN  ...   \n",
       "4                                       0 spaces     NaN  ...   \n",
       "\n",
       "                                Parking features  Tax assessed value  \\\n",
       "0             Garage, Garage - Attached, Covered            886486.0   \n",
       "1                       Detached Carport, Garage            505000.0   \n",
       "2                                            NaN             49627.0   \n",
       "3  Detached Carport, Driveway, Garage - Two Door           1775000.0   \n",
       "4                                            NaN                 NaN   \n",
       "\n",
       "   Annual tax amount   Listed On  Listed Price  Last Sold On Last Sold Price  \\\n",
       "0            12580.0  2019-10-24     4198000.0           NaN             NaN   \n",
       "1             6253.0  2019-10-16      525000.0    2019-08-30        328000.0   \n",
       "2              468.0  2019-08-25      180000.0           NaN             NaN   \n",
       "3            20787.0  2019-10-24     1895000.0    2016-08-30       1500000.0   \n",
       "4                NaN  2019-06-07     1595000.0    2016-06-27        900000.0   \n",
       "\n",
       "          City    Zip  State  \n",
       "0    Los Altos  94022     CA  \n",
       "1  Los Angeles  90047     CA  \n",
       "2   Strawberry  95375     CA  \n",
       "3  Culver City  90230     CA  \n",
       "4      Creston  93432     CA  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:19:02.696674Z",
     "start_time": "2022-05-18T06:19:02.640167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Address</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Type</th>\n",
       "      <th>Year built</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Parking</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>Parking features</th>\n",
       "      <th>Tax assessed value</th>\n",
       "      <th>Annual tax amount</th>\n",
       "      <th>Listed On</th>\n",
       "      <th>Listed Price</th>\n",
       "      <th>Last Sold On</th>\n",
       "      <th>Last Sold Price</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47439</td>\n",
       "      <td>3034 N Coolidge Ave</td>\n",
       "      <td>Live within steps to the scenic views on the L...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Tandem Uncovered</td>\n",
       "      <td>940.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Tandem Uncovered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>799900.0</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>819000.0</td>\n",
       "      <td>Dodgertown</td>\n",
       "      <td>90090</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47440</td>\n",
       "      <td>565 Kenilworth Ave</td>\n",
       "      <td>duplex fixer. Input for comps only</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>Natural Gas</td>\n",
       "      <td>None</td>\n",
       "      <td>Detached</td>\n",
       "      <td>10018.8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Detached</td>\n",
       "      <td>521977.0</td>\n",
       "      <td>7494.0</td>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>479950.0</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>San Leandro</td>\n",
       "      <td>94577</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47441</td>\n",
       "      <td>3028 N Coolidge Ave</td>\n",
       "      <td>Live within steps to the scenic views on the L...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Tandem Uncovered</td>\n",
       "      <td>940.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Tandem Uncovered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>839900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90039</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47442</td>\n",
       "      <td>3022 N North Coolidge Ave</td>\n",
       "      <td>Live within steps to the scenic views on the L...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Tandem Uncovered</td>\n",
       "      <td>940.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Tandem Uncovered</td>\n",
       "      <td>442800.0</td>\n",
       "      <td>5370.0</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>809900.0</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>Dodgertown</td>\n",
       "      <td>90090</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47443</td>\n",
       "      <td>2515 Admiral Cir</td>\n",
       "      <td>This beautiful, spacious home built in 2017 is...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Forced Air</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Garage Door Opener, Attached</td>\n",
       "      <td>2613.6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Garage Door Opener, Attached</td>\n",
       "      <td>965282.0</td>\n",
       "      <td>12912.0</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>1095000.0</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>1041000.0</td>\n",
       "      <td>Hayward</td>\n",
       "      <td>94545</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                    Address  \\\n",
       "0  47439        3034 N Coolidge Ave   \n",
       "1  47440         565 Kenilworth Ave   \n",
       "2  47441        3028 N Coolidge Ave   \n",
       "3  47442  3022 N North Coolidge Ave   \n",
       "4  47443           2515 Admiral Cir   \n",
       "\n",
       "                                             Summary          Type  \\\n",
       "0  Live within steps to the scenic views on the L...  SingleFamily   \n",
       "1                 duplex fixer. Input for comps only  SingleFamily   \n",
       "2  Live within steps to the scenic views on the L...  SingleFamily   \n",
       "3  Live within steps to the scenic views on the L...  SingleFamily   \n",
       "4  This beautiful, spacious home built in 2017 is...  SingleFamily   \n",
       "\n",
       "   Year built      Heating      Cooling                       Parking  \\\n",
       "0      2020.0      Central  Central Air              Tandem Uncovered   \n",
       "1      1924.0  Natural Gas         None                      Detached   \n",
       "2      2020.0      Central  Central Air              Tandem Uncovered   \n",
       "3      2020.0      Central  Central Air              Tandem Uncovered   \n",
       "4      2017.0   Forced Air  Central Air  Garage Door Opener, Attached   \n",
       "\n",
       "       Lot Bedrooms  ...              Parking features  Tax assessed value  \\\n",
       "0    940.0        2  ...              Tandem Uncovered                 NaN   \n",
       "1  10018.8        3  ...                      Detached            521977.0   \n",
       "2    940.0        2  ...              Tandem Uncovered                 NaN   \n",
       "3    940.0        2  ...              Tandem Uncovered            442800.0   \n",
       "4   2613.6        4  ...  Garage Door Opener, Attached            965282.0   \n",
       "\n",
       "   Annual tax amount   Listed On  Listed Price Last Sold On Last Sold Price  \\\n",
       "0                NaN  2020-11-06      799900.0   2020-07-01        819000.0   \n",
       "1             7494.0  2014-04-04      479950.0   2020-11-03         15000.0   \n",
       "2                NaN  2020-11-12      839900.0          NaN             NaN   \n",
       "3             5370.0  2020-11-06      809900.0   2020-09-21        810000.0   \n",
       "4            12912.0  2020-12-02     1095000.0   2019-12-27       1041000.0   \n",
       "\n",
       "          City    Zip State  \n",
       "0   Dodgertown  90090    CA  \n",
       "1  San Leandro  94577    CA  \n",
       "2  Los Angeles  90039    CA  \n",
       "3   Dodgertown  90090    CA  \n",
       "4      Hayward  94545    CA  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:19:06.614671Z",
     "start_time": "2022-05-18T06:19:06.611671Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label=train_data['Sold Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:19:08.030851Z",
     "start_time": "2022-05-18T06:19:08.019850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47439, 41)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:19:09.806077Z",
     "start_time": "2022-05-18T06:19:09.772572Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.drop(labels=['Sold Price'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T06:19:11.213755Z",
     "start_time": "2022-05-18T06:19:11.203754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47439, 40)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:06:57.596240Z",
     "start_time": "2022-05-18T07:06:57.590739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_val_cols = ['Lot', 'Total interior livable area',\n",
    "                  'Tax assessed value', 'Annual tax amount',\n",
    "                  'Listed Price', 'Last Sold Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:07:44.581206Z",
     "start_time": "2022-05-18T07:07:44.270667Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in large_val_cols:\n",
    "    train_data[c]=np.log(train_data[c]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:08:12.926306Z",
     "start_time": "2022-05-18T07:08:12.903303Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in large_val_cols:\n",
    "    test_data[c]=np.log(test_data[c]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:16:35.626640Z",
     "start_time": "2022-05-18T07:16:35.618639Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels=np.log(train_label+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:08:56.126291Z",
     "start_time": "2022-05-18T07:08:56.006776Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features=pd.concat((train_data.iloc[:,1:],test_data.iloc[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:09:15.680774Z",
     "start_time": "2022-05-18T07:09:15.670773Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_features=all_features.dtypes[all_features.dtypes != 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:09:19.739290Z",
     "start_time": "2022-05-18T07:09:19.727288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year built', 'Lot', 'Bathrooms', 'Full bathrooms',\n",
       "       'Total interior livable area', 'Total spaces', 'Garage spaces',\n",
       "       'Elementary School Score', 'Elementary School Distance',\n",
       "       'Middle School Score', 'Middle School Distance', 'High School Score',\n",
       "       'High School Distance', 'Tax assessed value', 'Annual tax amount',\n",
       "       'Listed Price', 'Last Sold Price', 'Zip'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:09:22.578650Z",
     "start_time": "2022-05-18T07:09:22.566149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year built',\n",
       " 'Lot',\n",
       " 'Bathrooms',\n",
       " 'Full bathrooms',\n",
       " 'Total interior livable area',\n",
       " 'Total spaces',\n",
       " 'Garage spaces',\n",
       " 'Elementary School Score',\n",
       " 'Elementary School Distance',\n",
       " 'Middle School Score',\n",
       " 'Middle School Distance',\n",
       " 'High School Score',\n",
       " 'High School Distance',\n",
       " 'Tax assessed value',\n",
       " 'Annual tax amount',\n",
       " 'Listed Price',\n",
       " 'Last Sold Price',\n",
       " 'Zip']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features_name=numeric_features.tolist()\n",
    "numeric_features_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:09:28.900453Z",
     "start_time": "2022-05-18T07:09:28.818943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year built</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Full bathrooms</th>\n",
       "      <th>Total interior livable area</th>\n",
       "      <th>Total spaces</th>\n",
       "      <th>Garage spaces</th>\n",
       "      <th>Elementary School Score</th>\n",
       "      <th>Elementary School Distance</th>\n",
       "      <th>Middle School Score</th>\n",
       "      <th>Middle School Distance</th>\n",
       "      <th>High School Score</th>\n",
       "      <th>High School Distance</th>\n",
       "      <th>Tax assessed value</th>\n",
       "      <th>Annual tax amount</th>\n",
       "      <th>Listed Price</th>\n",
       "      <th>Last Sold Price</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1969.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>13.695022</td>\n",
       "      <td>9.439943</td>\n",
       "      <td>15.250119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926.0</td>\n",
       "      <td>8.305978</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.771936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>13.132316</td>\n",
       "      <td>8.740977</td>\n",
       "      <td>13.171155</td>\n",
       "      <td>12.700772</td>\n",
       "      <td>90047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1958.0</td>\n",
       "      <td>9.121291</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.050123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.812310</td>\n",
       "      <td>6.150603</td>\n",
       "      <td>12.100718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.868254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14.389312</td>\n",
       "      <td>9.942131</td>\n",
       "      <td>14.454730</td>\n",
       "      <td>14.220976</td>\n",
       "      <td>90230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.282385</td>\n",
       "      <td>13.710151</td>\n",
       "      <td>93432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1905.0</td>\n",
       "      <td>8.182280</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.179308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>12.245683</td>\n",
       "      <td>7.836765</td>\n",
       "      <td>12.323416</td>\n",
       "      <td>12.206078</td>\n",
       "      <td>95202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.278616</td>\n",
       "      <td>9.863759</td>\n",
       "      <td>14.284890</td>\n",
       "      <td>13.122365</td>\n",
       "      <td>90039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>14.387140</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.832014</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.120363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.379008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13.899014</td>\n",
       "      <td>9.531989</td>\n",
       "      <td>14.316286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1973.0</td>\n",
       "      <td>11.100620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.661056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.030337</td>\n",
       "      <td>7.554859</td>\n",
       "      <td>13.864302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1953.0</td>\n",
       "      <td>8.932080</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.365180</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>11.175325</td>\n",
       "      <td>6.807935</td>\n",
       "      <td>14.171786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>6.483107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.239933</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.429702</td>\n",
       "      <td>9.134862</td>\n",
       "      <td>13.651816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1926.0</td>\n",
       "      <td>8.293800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.117312</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>14.548263</td>\n",
       "      <td>10.130623</td>\n",
       "      <td>14.626441</td>\n",
       "      <td>14.508658</td>\n",
       "      <td>94116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1923.0</td>\n",
       "      <td>8.476580</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.164720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.047857</td>\n",
       "      <td>8.654343</td>\n",
       "      <td>13.244583</td>\n",
       "      <td>13.028055</td>\n",
       "      <td>90047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>8.944159</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.149132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>11.908825</td>\n",
       "      <td>7.369601</td>\n",
       "      <td>12.141539</td>\n",
       "      <td>11.608245</td>\n",
       "      <td>95369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14.046385</td>\n",
       "      <td>9.678530</td>\n",
       "      <td>13.959179</td>\n",
       "      <td>14.026582</td>\n",
       "      <td>94107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.268988</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.820162</td>\n",
       "      <td>9.429396</td>\n",
       "      <td>14.403298</td>\n",
       "      <td>13.116347</td>\n",
       "      <td>90026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1986.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.983790</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>12.441737</td>\n",
       "      <td>8.047510</td>\n",
       "      <td>13.696728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1939.0</td>\n",
       "      <td>8.846929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.650169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14.423100</td>\n",
       "      <td>9.976831</td>\n",
       "      <td>14.686804</td>\n",
       "      <td>14.403298</td>\n",
       "      <td>94402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1949.0</td>\n",
       "      <td>7.871693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.453625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>12.030379</td>\n",
       "      <td>8.136518</td>\n",
       "      <td>12.971543</td>\n",
       "      <td>12.100718</td>\n",
       "      <td>90220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year built        Lot  Bathrooms  Full bathrooms  \\\n",
       "0       1969.0   0.693147        0.0             NaN   \n",
       "1       1926.0   8.305978        2.0             2.0   \n",
       "2       1958.0   9.121291        3.0             1.0   \n",
       "3       1947.0        NaN        3.0             3.0   \n",
       "4          NaN        NaN        NaN             NaN   \n",
       "5       1905.0   8.182280        2.0             2.0   \n",
       "6       1926.0        NaN        NaN             NaN   \n",
       "7       2005.0  14.387140        2.0             2.0   \n",
       "8       2001.0        NaN        3.0             3.0   \n",
       "9       1973.0  11.100620        2.0             2.0   \n",
       "10      1953.0   8.932080        2.0             2.0   \n",
       "11      2002.0   6.483107        2.0             2.0   \n",
       "12      1926.0   8.293800        3.0             3.0   \n",
       "13      1923.0   8.476580        2.0             2.0   \n",
       "14      1947.0   8.944159        2.0             2.0   \n",
       "15      2001.0        NaN        2.0             2.0   \n",
       "16      2018.0        NaN        NaN             NaN   \n",
       "17      1986.0        NaN        2.0             NaN   \n",
       "18      1939.0   8.846929        2.0             2.0   \n",
       "19      1949.0   7.871693        1.0             1.0   \n",
       "\n",
       "    Total interior livable area  Total spaces  Garage spaces  \\\n",
       "0                      0.693147           0.0            0.0   \n",
       "1                      6.771936           1.0            1.0   \n",
       "2                      7.050123           0.0            0.0   \n",
       "3                      7.868254           0.0            0.0   \n",
       "4                           NaN           NaN            NaN   \n",
       "5                      7.179308           0.0            0.0   \n",
       "6                           NaN           0.0            0.0   \n",
       "7                      7.832014           4.0            4.0   \n",
       "8                      7.379008           1.0            1.0   \n",
       "9                      7.661056           0.0            0.0   \n",
       "10                     7.365180           2.0            2.0   \n",
       "11                     7.239933           2.0            2.0   \n",
       "12                     8.117312           2.0            2.0   \n",
       "13                     7.164720           0.0            0.0   \n",
       "14                     7.149132           0.0            0.0   \n",
       "15                          NaN           1.0            1.0   \n",
       "16                     8.268988           4.0            1.0   \n",
       "17                     6.983790           2.0            2.0   \n",
       "18                     7.650169           0.0            0.0   \n",
       "19                     6.453625           0.0            0.0   \n",
       "\n",
       "    Elementary School Score  Elementary School Distance  Middle School Score  \\\n",
       "0                       7.0                         0.4                  NaN   \n",
       "1                       3.0                         0.8                  2.0   \n",
       "2                       NaN                         NaN                  NaN   \n",
       "3                       9.0                         0.2                  7.0   \n",
       "4                       6.0                         8.5                  5.0   \n",
       "5                       NaN                         NaN                  NaN   \n",
       "6                       8.0                         0.3                  NaN   \n",
       "7                       4.0                         6.3                  NaN   \n",
       "8                       8.0                         0.3                  8.0   \n",
       "9                       6.0                         0.6                  NaN   \n",
       "10                      7.0                         0.4                  5.0   \n",
       "11                      4.0                         0.6                  4.0   \n",
       "12                      8.0                         0.3                  7.0   \n",
       "13                      2.0                         0.1                  2.0   \n",
       "14                      4.0                         0.3                  NaN   \n",
       "15                      NaN                         NaN                  NaN   \n",
       "16                      NaN                         NaN                  NaN   \n",
       "17                      4.0                         0.8                  3.0   \n",
       "18                      6.0                         0.4                  6.0   \n",
       "19                      7.0                         0.2                  NaN   \n",
       "\n",
       "    Middle School Distance  High School Score  High School Distance  \\\n",
       "0                      NaN                8.0                   1.3   \n",
       "1                      1.1                2.0                   1.3   \n",
       "2                      NaN                NaN                  10.1   \n",
       "3                      0.2                8.0                   0.2   \n",
       "4                     10.2                6.0                  10.6   \n",
       "5                      NaN                2.0                   3.3   \n",
       "6                      NaN                NaN                   NaN   \n",
       "7                      NaN                2.0                   6.3   \n",
       "8                      0.3                7.0                   0.5   \n",
       "9                      NaN                7.0                   1.5   \n",
       "10                     0.9                6.0                   1.9   \n",
       "11                     1.0                5.0                   0.2   \n",
       "12                     0.5                7.0                   0.4   \n",
       "13                     1.6                NaN                   NaN   \n",
       "14                     NaN                5.0                  13.8   \n",
       "15                     NaN                2.0                   0.2   \n",
       "16                     NaN                3.0                   0.6   \n",
       "17                     0.3                7.0                   2.7   \n",
       "18                     1.0                8.0                   0.5   \n",
       "19                     NaN                3.0                   1.3   \n",
       "\n",
       "    Tax assessed value  Annual tax amount  Listed Price  Last Sold Price  \\\n",
       "0            13.695022           9.439943     15.250119              NaN   \n",
       "1            13.132316           8.740977     13.171155        12.700772   \n",
       "2            10.812310           6.150603     12.100718              NaN   \n",
       "3            14.389312           9.942131     14.454730        14.220976   \n",
       "4                  NaN                NaN     14.282385        13.710151   \n",
       "5            12.245683           7.836765     12.323416        12.206078   \n",
       "6            14.278616           9.863759     14.284890        13.122365   \n",
       "7                  NaN                NaN     13.120363              NaN   \n",
       "8            13.899014           9.531989     14.316286              NaN   \n",
       "9            12.030337           7.554859     13.864302              NaN   \n",
       "10           11.175325           6.807935     14.171786              NaN   \n",
       "11           13.429702           9.134862     13.651816              NaN   \n",
       "12           14.548263          10.130623     14.626441        14.508658   \n",
       "13           13.047857           8.654343     13.244583        13.028055   \n",
       "14           11.908825           7.369601     12.141539        11.608245   \n",
       "15           14.046385           9.678530     13.959179        14.026582   \n",
       "16           13.820162           9.429396     14.403298        13.116347   \n",
       "17           12.441737           8.047510     13.696728              NaN   \n",
       "18           14.423100           9.976831     14.686804        14.403298   \n",
       "19           12.030379           8.136518     12.971543        12.100718   \n",
       "\n",
       "      Zip  \n",
       "0   94022  \n",
       "1   90047  \n",
       "2   95375  \n",
       "3   90230  \n",
       "4   93432  \n",
       "5   95202  \n",
       "6   90039  \n",
       "7   95983  \n",
       "8   94121  \n",
       "9   95003  \n",
       "10  95050  \n",
       "11  95128  \n",
       "12  94116  \n",
       "13  90047  \n",
       "14  95369  \n",
       "15  94107  \n",
       "16  90026  \n",
       "17  94085  \n",
       "18  94402  \n",
       "19  90220  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[numeric_features].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:10:02.685243Z",
     "start_time": "2022-05-18T07:10:02.678242Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_features_name.remove('Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:10:03.834389Z",
     "start_time": "2022-05-18T07:10:03.821887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year built',\n",
       " 'Lot',\n",
       " 'Bathrooms',\n",
       " 'Full bathrooms',\n",
       " 'Total interior livable area',\n",
       " 'Total spaces',\n",
       " 'Garage spaces',\n",
       " 'Elementary School Score',\n",
       " 'Elementary School Distance',\n",
       " 'Middle School Score',\n",
       " 'Middle School Distance',\n",
       " 'High School Score',\n",
       " 'High School Distance',\n",
       " 'Tax assessed value',\n",
       " 'Annual tax amount',\n",
       " 'Listed Price',\n",
       " 'Last Sold Price']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T07:47:36.782239Z",
     "start_time": "2022-05-13T07:47:36.686727Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:10:44.395040Z",
     "start_time": "2022-05-18T07:10:44.358535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year built                      1942\n",
       "Lot                            22989\n",
       "Bathrooms                       5410\n",
       "Full bathrooms                 12928\n",
       "Total interior livable area     3878\n",
       "Total spaces                    1667\n",
       "Garage spaces                   1667\n",
       "Elementary School Score         8735\n",
       "Elementary School Distance      8493\n",
       "Middle School Score            28279\n",
       "Middle School Distance         28277\n",
       "High School Score               7784\n",
       "High School Distance            7175\n",
       "Tax assessed value              6323\n",
       "Annual tax amount               7209\n",
       "Listed Price                       0\n",
       "Last Sold Price                29545\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[numeric_features_name].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:10:55.341930Z",
     "start_time": "2022-05-18T07:10:55.246418Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features[numeric_features_name]=all_features[numeric_features_name].apply(lambda x : (x-x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:10:57.351185Z",
     "start_time": "2022-05-18T07:10:57.322181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year built                    -1.430044e-16\n",
       "Lot                           -2.763149e-14\n",
       "Bathrooms                     -1.436180e-14\n",
       "Full bathrooms                 2.410896e-15\n",
       "Total interior livable area    3.150520e-13\n",
       "Total spaces                   1.849120e-14\n",
       "Garage spaces                 -5.168904e-15\n",
       "Elementary School Score        1.841204e-14\n",
       "Elementary School Distance     2.700541e-16\n",
       "Middle School Score           -1.330250e-15\n",
       "Middle School Distance        -1.630889e-15\n",
       "High School Score             -6.248362e-15\n",
       "High School Distance           1.493850e-14\n",
       "Tax assessed value            -4.857645e-14\n",
       "Annual tax amount             -9.769432e-14\n",
       "Listed Price                  -1.570527e-13\n",
       "Last Sold Price               -1.278824e-13\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[numeric_features_name].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:11:49.658327Z",
     "start_time": "2022-05-18T07:11:49.598819Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features[numeric_features_name]=all_features[numeric_features_name].fillna(all_features[numeric_features_name].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:11:51.757094Z",
     "start_time": "2022-05-18T07:11:51.750093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train=train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:11:53.452309Z",
     "start_time": "2022-05-18T07:11:53.389801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Type</th>\n",
       "      <th>Year built</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Parking</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>Parking features</th>\n",
       "      <th>Tax assessed value</th>\n",
       "      <th>Annual tax amount</th>\n",
       "      <th>Listed On</th>\n",
       "      <th>Listed Price</th>\n",
       "      <th>Last Sold On</th>\n",
       "      <th>Last Sold Price</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540 Pine Ln</td>\n",
       "      <td>540 Pine Ln, Los Altos, CA 94022 is a single f...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>4.850534e-02</td>\n",
       "      <td>Heating - 2+ Zones, Central Forced Air - Gas</td>\n",
       "      <td>Multi-Zone, Central AC, Whole House / Attic Fan</td>\n",
       "      <td>Garage, Garage - Attached, Covered</td>\n",
       "      <td>-5.378320e+00</td>\n",
       "      <td>Ground Floor Bedroom, Master Bedroom on Ground...</td>\n",
       "      <td>-2.058002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>Garage, Garage - Attached, Covered</td>\n",
       "      <td>7.318137e-01</td>\n",
       "      <td>8.558527e-01</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>1.759273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.278824e-13</td>\n",
       "      <td>Los Altos</td>\n",
       "      <td>94022</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1727 W 67th St</td>\n",
       "      <td>HURRY, HURRY.......Great house 3 bed and 2 bat...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>-2.846555e-01</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Wall/Window Unit(s), Evaporative Cooling, See ...</td>\n",
       "      <td>Detached Carport, Garage</td>\n",
       "      <td>-4.461969e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.367686e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Detached Carport, Garage</td>\n",
       "      <td>1.853176e-01</td>\n",
       "      <td>1.278330e-01</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.421097</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>-3.493563e-01</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90047</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28093 Pine Ave</td>\n",
       "      <td>'THE PERFECT CABIN TO FLIP!  Strawberry deligh...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>-3.672186e-02</td>\n",
       "      <td>Forced air</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 spaces</td>\n",
       "      <td>8.201942e-02</td>\n",
       "      <td>2</td>\n",
       "      <td>5.238479e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.067855e+00</td>\n",
       "      <td>-2.570212e+00</td>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>-1.543748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.278824e-13</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>95375</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10750 Braddock Dr</td>\n",
       "      <td>Rare 2-story Gated 5 bedroom Modern Mediterran...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>-1.219491e-01</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Detached Carport, Driveway, Garage - Two Door</td>\n",
       "      <td>-2.763149e-14</td>\n",
       "      <td>5</td>\n",
       "      <td>5.238479e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Detached Carport, Driveway, Garage - Two Door</td>\n",
       "      <td>1.406103e+00</td>\n",
       "      <td>1.378915e+00</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>0.925087</td>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>1.219168e+00</td>\n",
       "      <td>Culver City</td>\n",
       "      <td>90230</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7415 O Donovan Rd</td>\n",
       "      <td>Beautiful 200 acre ranch land with several pas...</td>\n",
       "      <td>VacantLand</td>\n",
       "      <td>-1.430044e-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 spaces</td>\n",
       "      <td>-2.763149e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.436180e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.857645e-14</td>\n",
       "      <td>-9.769432e-14</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>0.744336</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>6.921063e-01</td>\n",
       "      <td>Creston</td>\n",
       "      <td>93432</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Address                                            Summary  \\\n",
       "0        540 Pine Ln  540 Pine Ln, Los Altos, CA 94022 is a single f...   \n",
       "1     1727 W 67th St  HURRY, HURRY.......Great house 3 bed and 2 bat...   \n",
       "2     28093 Pine Ave  'THE PERFECT CABIN TO FLIP!  Strawberry deligh...   \n",
       "3  10750 Braddock Dr  Rare 2-story Gated 5 bedroom Modern Mediterran...   \n",
       "4  7415 O Donovan Rd  Beautiful 200 acre ranch land with several pas...   \n",
       "\n",
       "           Type    Year built                                       Heating  \\\n",
       "0  SingleFamily  4.850534e-02  Heating - 2+ Zones, Central Forced Air - Gas   \n",
       "1  SingleFamily -2.846555e-01                                   Combination   \n",
       "2  SingleFamily -3.672186e-02                                    Forced air   \n",
       "3  SingleFamily -1.219491e-01                                       Central   \n",
       "4    VacantLand -1.430044e-16                                           NaN   \n",
       "\n",
       "                                             Cooling  \\\n",
       "0    Multi-Zone, Central AC, Whole House / Attic Fan   \n",
       "1  Wall/Window Unit(s), Evaporative Cooling, See ...   \n",
       "2                                                NaN   \n",
       "3                                        Central Air   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         Parking           Lot  \\\n",
       "0             Garage, Garage - Attached, Covered -5.378320e+00   \n",
       "1                       Detached Carport, Garage -4.461969e-01   \n",
       "2                                       0 spaces  8.201942e-02   \n",
       "3  Detached Carport, Driveway, Garage - Two Door -2.763149e-14   \n",
       "4                                       0 spaces -2.763149e-14   \n",
       "\n",
       "                                            Bedrooms     Bathrooms  ...  \\\n",
       "0  Ground Floor Bedroom, Master Bedroom on Ground... -2.058002e+00  ...   \n",
       "1                                                  3 -3.367686e-01  ...   \n",
       "2                                                  2  5.238479e-01  ...   \n",
       "3                                                  5  5.238479e-01  ...   \n",
       "4                                                NaN -1.436180e-14  ...   \n",
       "\n",
       "                                Parking features  Tax assessed value  \\\n",
       "0             Garage, Garage - Attached, Covered        7.318137e-01   \n",
       "1                       Detached Carport, Garage        1.853176e-01   \n",
       "2                                            NaN       -2.067855e+00   \n",
       "3  Detached Carport, Driveway, Garage - Two Door        1.406103e+00   \n",
       "4                                            NaN       -4.857645e-14   \n",
       "\n",
       "   Annual tax amount   Listed On Listed Price Last Sold On  Last Sold Price  \\\n",
       "0       8.558527e-01  2019-10-24     1.759273          NaN    -1.278824e-13   \n",
       "1       1.278330e-01  2019-10-16    -0.421097   2019-08-30    -3.493563e-01   \n",
       "2      -2.570212e+00  2019-08-25    -1.543748          NaN    -1.278824e-13   \n",
       "3       1.378915e+00  2019-10-24     0.925087   2016-08-30     1.219168e+00   \n",
       "4      -9.769432e-14  2019-06-07     0.744336   2016-06-27     6.921063e-01   \n",
       "\n",
       "          City    Zip  State  \n",
       "0    Los Altos  94022     CA  \n",
       "1  Los Angeles  90047     CA  \n",
       "2   Strawberry  95375     CA  \n",
       "3  Culver City  90230     CA  \n",
       "4      Creston  93432     CA  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:11:59.114028Z",
     "start_time": "2022-05-18T07:11:59.054020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year built</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Full bathrooms</th>\n",
       "      <th>Total interior livable area</th>\n",
       "      <th>Total spaces</th>\n",
       "      <th>Garage spaces</th>\n",
       "      <th>Elementary School Score</th>\n",
       "      <th>Elementary School Distance</th>\n",
       "      <th>Middle School Score</th>\n",
       "      <th>Middle School Distance</th>\n",
       "      <th>High School Score</th>\n",
       "      <th>High School Distance</th>\n",
       "      <th>Tax assessed value</th>\n",
       "      <th>Annual tax amount</th>\n",
       "      <th>Listed Price</th>\n",
       "      <th>Last Sold Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.850534e-02</td>\n",
       "      <td>-5.378320e+00</td>\n",
       "      <td>-2.058002e+00</td>\n",
       "      <td>2.410896e-15</td>\n",
       "      <td>-1.346885e+01</td>\n",
       "      <td>-1.355188e-01</td>\n",
       "      <td>-1.236235e-01</td>\n",
       "      <td>6.227580e-01</td>\n",
       "      <td>-3.392817e-01</td>\n",
       "      <td>-1.330250e-15</td>\n",
       "      <td>-1.630889e-15</td>\n",
       "      <td>9.293295e-01</td>\n",
       "      <td>-0.318177</td>\n",
       "      <td>7.318137e-01</td>\n",
       "      <td>8.558527e-01</td>\n",
       "      <td>1.759273</td>\n",
       "      <td>-1.278824e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.846555e-01</td>\n",
       "      <td>-4.461969e-01</td>\n",
       "      <td>-3.367686e-01</td>\n",
       "      <td>-1.064242e-01</td>\n",
       "      <td>-1.260004e+00</td>\n",
       "      <td>-6.273141e-02</td>\n",
       "      <td>-5.050667e-02</td>\n",
       "      <td>-1.308481e+00</td>\n",
       "      <td>-1.561423e-01</td>\n",
       "      <td>-1.607235e+00</td>\n",
       "      <td>-2.630715e-01</td>\n",
       "      <td>-2.101186e+00</td>\n",
       "      <td>-0.318177</td>\n",
       "      <td>1.853176e-01</td>\n",
       "      <td>1.278330e-01</td>\n",
       "      <td>-0.421097</td>\n",
       "      <td>-3.493563e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.672186e-02</td>\n",
       "      <td>8.201942e-02</td>\n",
       "      <td>5.238479e-01</td>\n",
       "      <td>-1.167570e+00</td>\n",
       "      <td>-7.012844e-01</td>\n",
       "      <td>-1.355188e-01</td>\n",
       "      <td>-1.236235e-01</td>\n",
       "      <td>1.841204e-14</td>\n",
       "      <td>2.700541e-16</td>\n",
       "      <td>-1.330250e-15</td>\n",
       "      <td>-1.630889e-15</td>\n",
       "      <td>-6.248362e-15</td>\n",
       "      <td>2.350838</td>\n",
       "      <td>-2.067855e+00</td>\n",
       "      <td>-2.570212e+00</td>\n",
       "      <td>-1.543748</td>\n",
       "      <td>-1.278824e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.219491e-01</td>\n",
       "      <td>-2.763149e-14</td>\n",
       "      <td>5.238479e-01</td>\n",
       "      <td>9.547215e-01</td>\n",
       "      <td>9.418787e-01</td>\n",
       "      <td>-1.355188e-01</td>\n",
       "      <td>-1.236235e-01</td>\n",
       "      <td>1.588378e+00</td>\n",
       "      <td>-4.308514e-01</td>\n",
       "      <td>8.654868e-01</td>\n",
       "      <td>-6.507716e-01</td>\n",
       "      <td>9.293295e-01</td>\n",
       "      <td>-0.651804</td>\n",
       "      <td>1.406103e+00</td>\n",
       "      <td>1.378915e+00</td>\n",
       "      <td>0.925087</td>\n",
       "      <td>1.219168e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.430044e-16</td>\n",
       "      <td>-2.763149e-14</td>\n",
       "      <td>-1.436180e-14</td>\n",
       "      <td>2.410896e-15</td>\n",
       "      <td>3.150520e-13</td>\n",
       "      <td>1.849120e-14</td>\n",
       "      <td>-5.168904e-15</td>\n",
       "      <td>1.399482e-01</td>\n",
       "      <td>3.369292e+00</td>\n",
       "      <td>-1.236020e-01</td>\n",
       "      <td>3.657007e+00</td>\n",
       "      <td>-8.084238e-02</td>\n",
       "      <td>2.502486</td>\n",
       "      <td>-4.857645e-14</td>\n",
       "      <td>-9.769432e-14</td>\n",
       "      <td>0.744336</td>\n",
       "      <td>6.921063e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year built           Lot     Bathrooms  Full bathrooms  \\\n",
       "0  4.850534e-02 -5.378320e+00 -2.058002e+00    2.410896e-15   \n",
       "1 -2.846555e-01 -4.461969e-01 -3.367686e-01   -1.064242e-01   \n",
       "2 -3.672186e-02  8.201942e-02  5.238479e-01   -1.167570e+00   \n",
       "3 -1.219491e-01 -2.763149e-14  5.238479e-01    9.547215e-01   \n",
       "4 -1.430044e-16 -2.763149e-14 -1.436180e-14    2.410896e-15   \n",
       "\n",
       "   Total interior livable area  Total spaces  Garage spaces  \\\n",
       "0                -1.346885e+01 -1.355188e-01  -1.236235e-01   \n",
       "1                -1.260004e+00 -6.273141e-02  -5.050667e-02   \n",
       "2                -7.012844e-01 -1.355188e-01  -1.236235e-01   \n",
       "3                 9.418787e-01 -1.355188e-01  -1.236235e-01   \n",
       "4                 3.150520e-13  1.849120e-14  -5.168904e-15   \n",
       "\n",
       "   Elementary School Score  Elementary School Distance  Middle School Score  \\\n",
       "0             6.227580e-01               -3.392817e-01        -1.330250e-15   \n",
       "1            -1.308481e+00               -1.561423e-01        -1.607235e+00   \n",
       "2             1.841204e-14                2.700541e-16        -1.330250e-15   \n",
       "3             1.588378e+00               -4.308514e-01         8.654868e-01   \n",
       "4             1.399482e-01                3.369292e+00        -1.236020e-01   \n",
       "\n",
       "   Middle School Distance  High School Score  High School Distance  \\\n",
       "0           -1.630889e-15       9.293295e-01             -0.318177   \n",
       "1           -2.630715e-01      -2.101186e+00             -0.318177   \n",
       "2           -1.630889e-15      -6.248362e-15              2.350838   \n",
       "3           -6.507716e-01       9.293295e-01             -0.651804   \n",
       "4            3.657007e+00      -8.084238e-02              2.502486   \n",
       "\n",
       "   Tax assessed value  Annual tax amount  Listed Price  Last Sold Price  \n",
       "0        7.318137e-01       8.558527e-01      1.759273    -1.278824e-13  \n",
       "1        1.853176e-01       1.278330e-01     -0.421097    -3.493563e-01  \n",
       "2       -2.067855e+00      -2.570212e+00     -1.543748    -1.278824e-13  \n",
       "3        1.406103e+00       1.378915e+00      0.925087     1.219168e+00  \n",
       "4       -4.857645e-14      -9.769432e-14      0.744336     6.921063e-01  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[numeric_features_name].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:16:51.440148Z",
     "start_time": "2022-05-18T07:16:51.367139Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features=torch.Tensor(all_features[numeric_features_name].iloc[:n_train,:].values)\n",
    "test_features=torch.Tensor(all_features[numeric_features_name].iloc[n_train:,:].values)\n",
    "train_labels=torch.Tensor(train_labels.values).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:12.364305Z",
     "start_time": "2022-05-18T07:17:12.357305Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:12.649342Z",
     "start_time": "2022-05-18T07:17:12.638840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47439, 17])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:12.901374Z",
     "start_time": "2022-05-18T07:17:12.887372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31626, 17])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:13.601963Z",
     "start_time": "2022-05-18T07:17:13.590461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47439, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:14.345057Z",
     "start_time": "2022-05-18T07:17:14.333055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_rmse(net,features,labels):\n",
    "    clipped_preds=torch.clamp(net(features),1,float('inf'))\n",
    "    rmse=torch.sqrt(loss(torch.log(clipped_preds),torch.log(labels)))\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:15.247172Z",
     "start_time": "2022-05-18T07:17:15.152159Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_k_fold_data(net,num_epochs,lr,train_features,train_labels,test_features,test_labels,batch_size,montum,wd):\n",
    "#     net=nn.Linear(train_features.shape[1],1)\n",
    "#     net=nn.Sequential(nn.Linear(train_features.shape[1],1))\n",
    "    loss=nn.MSELoss()\n",
    "#     optimizer=optim.SGD(net.parameters(),lr=lr,momentum=montum,weight_decay=wd)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=lr,weight_decay=wd)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    train_l,test_l=[],[]\n",
    "    \n",
    "    min_test_loss=10000\n",
    "    early_stop_cnt=0\n",
    "    train_loss,test_loss=0,0\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            l=loss(net(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "#         if (e+1) %1000==0 and test_features is not  None:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss=log_rmse(net,test_features,test_labels)\n",
    "            if test_loss<min_test_loss:\n",
    "                min_test_loss=test_loss\n",
    "#                 test_l.append(test_loss)\n",
    "                train_loss=log_rmse(net,train_features,train_labels)\n",
    "                test_l.append(test_loss)\n",
    "                train_l.append(train_loss)\n",
    "                print('epoch = %d train_loss : %f , test loss : %f' % (e+1,train_loss,test_loss))\n",
    "                early_stop_cnt=0\n",
    "            else:\n",
    "                early_stop_cnt+=1\n",
    "        if early_stop_cnt > 500:\n",
    "            \n",
    "            break\n",
    "                \n",
    "#             net.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 train_l.append(loss(net(train_features),train_labels).item())\n",
    "#                 test_l.append(loss(net(test_features),test_labels).item())\n",
    "# #                 print('epoch ',(e+1),'train loss : ',train_l[-1],'test loss : ',test_l[-1])\n",
    "    print('train log loss: ',train_loss)\n",
    "    print('test log loss: ',test_loss)\n",
    "    return train_l,test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:15.540209Z",
     "start_time": "2022-05-18T07:17:15.507705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kfold_data(k,j,x,y,random_state=13):\n",
    "    assert k>=1, 'k must >=1'\n",
    "    fold_size = x.shape[0] // k\n",
    "    x_train,y_train=None,None\n",
    "    row_list=list(range(x.shape[0]))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(row_list)\n",
    "    for i in range(k):\n",
    "        idx=slice(fold_size*i,fold_size*(i+1))\n",
    "        x_part,y_part=x[row_list[idx],:],y[row_list[idx],:]\n",
    "        if i==j:\n",
    "            x_val,y_val=x_part,y_part\n",
    "        elif x_train is None:\n",
    "            x_train,y_train=x_part,y_part\n",
    "        else:\n",
    "            x_train=torch.cat((x_train,x_part))\n",
    "            y_train=torch.cat((y_train,y_part))\n",
    "    return x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T07:17:16.051774Z",
     "start_time": "2022-05-18T07:17:16.019270Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T10:16:02.370343Z",
     "start_time": "2022-05-18T07:17:18.874632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 2.618810 , test loss : 2.619861\n",
      "epoch = 2 train_loss : 2.584249 , test loss : 2.582546\n",
      "epoch = 3 train_loss : 1.952256 , test loss : 1.947923\n",
      "epoch = 4 train_loss : 1.174174 , test loss : 1.170664\n",
      "epoch = 5 train_loss : 0.694669 , test loss : 0.693096\n",
      "epoch = 6 train_loss : 0.484049 , test loss : 0.484487\n",
      "epoch = 7 train_loss : 0.405370 , test loss : 0.406706\n",
      "epoch = 8 train_loss : 0.366340 , test loss : 0.367950\n",
      "epoch = 9 train_loss : 0.336313 , test loss : 0.338123\n",
      "epoch = 10 train_loss : 0.319150 , test loss : 0.320848\n",
      "epoch = 11 train_loss : 0.306656 , test loss : 0.308151\n",
      "epoch = 12 train_loss : 0.293792 , test loss : 0.295168\n",
      "epoch = 13 train_loss : 0.279042 , test loss : 0.280421\n",
      "epoch = 14 train_loss : 0.267185 , test loss : 0.268496\n",
      "epoch = 15 train_loss : 0.254594 , test loss : 0.255885\n",
      "epoch = 16 train_loss : 0.248011 , test loss : 0.249077\n",
      "epoch = 17 train_loss : 0.233914 , test loss : 0.235047\n",
      "epoch = 18 train_loss : 0.224354 , test loss : 0.225388\n",
      "epoch = 19 train_loss : 0.216753 , test loss : 0.217657\n",
      "epoch = 20 train_loss : 0.205507 , test loss : 0.206422\n",
      "epoch = 21 train_loss : 0.195349 , test loss : 0.196242\n",
      "epoch = 22 train_loss : 0.187248 , test loss : 0.188044\n",
      "epoch = 23 train_loss : 0.176387 , test loss : 0.177212\n",
      "epoch = 24 train_loss : 0.165138 , test loss : 0.166018\n",
      "epoch = 25 train_loss : 0.157495 , test loss : 0.158290\n",
      "epoch = 26 train_loss : 0.149795 , test loss : 0.150535\n",
      "epoch = 27 train_loss : 0.143252 , test loss : 0.143907\n",
      "epoch = 28 train_loss : 0.132101 , test loss : 0.132817\n",
      "epoch = 29 train_loss : 0.125011 , test loss : 0.125683\n",
      "epoch = 30 train_loss : 0.116547 , test loss : 0.117206\n",
      "epoch = 31 train_loss : 0.109141 , test loss : 0.109802\n",
      "epoch = 32 train_loss : 0.102403 , test loss : 0.103085\n",
      "epoch = 33 train_loss : 0.095962 , test loss : 0.096664\n",
      "epoch = 34 train_loss : 0.088340 , test loss : 0.089098\n",
      "epoch = 35 train_loss : 0.082387 , test loss : 0.083167\n",
      "epoch = 36 train_loss : 0.076764 , test loss : 0.077585\n",
      "epoch = 37 train_loss : 0.072482 , test loss : 0.073324\n",
      "epoch = 38 train_loss : 0.067409 , test loss : 0.068284\n",
      "epoch = 39 train_loss : 0.063307 , test loss : 0.064175\n",
      "epoch = 40 train_loss : 0.061267 , test loss : 0.062044\n",
      "epoch = 41 train_loss : 0.056665 , test loss : 0.057420\n",
      "epoch = 42 train_loss : 0.054074 , test loss : 0.054759\n",
      "epoch = 43 train_loss : 0.051332 , test loss : 0.051912\n",
      "epoch = 44 train_loss : 0.048974 , test loss : 0.049455\n",
      "epoch = 45 train_loss : 0.047769 , test loss : 0.048050\n",
      "epoch = 46 train_loss : 0.045170 , test loss : 0.045491\n",
      "epoch = 47 train_loss : 0.043590 , test loss : 0.043830\n",
      "epoch = 48 train_loss : 0.041955 , test loss : 0.042133\n",
      "epoch = 49 train_loss : 0.040567 , test loss : 0.040711\n",
      "epoch = 50 train_loss : 0.039276 , test loss : 0.039421\n",
      "epoch = 51 train_loss : 0.038278 , test loss : 0.038383\n",
      "epoch = 52 train_loss : 0.038149 , test loss : 0.038188\n",
      "epoch = 53 train_loss : 0.036232 , test loss : 0.036392\n",
      "epoch = 54 train_loss : 0.036001 , test loss : 0.036155\n",
      "epoch = 55 train_loss : 0.034528 , test loss : 0.034784\n",
      "epoch = 56 train_loss : 0.033717 , test loss : 0.034037\n",
      "epoch = 57 train_loss : 0.032975 , test loss : 0.033346\n",
      "epoch = 58 train_loss : 0.032248 , test loss : 0.032668\n",
      "epoch = 59 train_loss : 0.031667 , test loss : 0.032174\n",
      "epoch = 60 train_loss : 0.031160 , test loss : 0.031711\n",
      "epoch = 61 train_loss : 0.030471 , test loss : 0.031115\n",
      "epoch = 62 train_loss : 0.029936 , test loss : 0.030629\n",
      "epoch = 63 train_loss : 0.029510 , test loss : 0.030221\n",
      "epoch = 64 train_loss : 0.028977 , test loss : 0.029771\n",
      "epoch = 65 train_loss : 0.028487 , test loss : 0.029325\n",
      "epoch = 66 train_loss : 0.028132 , test loss : 0.029044\n",
      "epoch = 67 train_loss : 0.027625 , test loss : 0.028618\n",
      "epoch = 68 train_loss : 0.027262 , test loss : 0.028301\n",
      "epoch = 69 train_loss : 0.026904 , test loss : 0.027971\n",
      "epoch = 70 train_loss : 0.026513 , test loss : 0.027606\n",
      "epoch = 71 train_loss : 0.026223 , test loss : 0.027361\n",
      "epoch = 72 train_loss : 0.025855 , test loss : 0.027048\n",
      "epoch = 73 train_loss : 0.025569 , test loss : 0.026843\n",
      "epoch = 74 train_loss : 0.025277 , test loss : 0.026545\n",
      "epoch = 75 train_loss : 0.025046 , test loss : 0.026345\n",
      "epoch = 76 train_loss : 0.024786 , test loss : 0.026151\n",
      "epoch = 77 train_loss : 0.024537 , test loss : 0.025906\n",
      "epoch = 78 train_loss : 0.024315 , test loss : 0.025729\n",
      "epoch = 79 train_loss : 0.024148 , test loss : 0.025503\n",
      "epoch = 80 train_loss : 0.023886 , test loss : 0.025308\n",
      "epoch = 81 train_loss : 0.023730 , test loss : 0.025195\n",
      "epoch = 82 train_loss : 0.023488 , test loss : 0.024947\n",
      "epoch = 83 train_loss : 0.023391 , test loss : 0.024868\n",
      "epoch = 84 train_loss : 0.023181 , test loss : 0.024676\n",
      "epoch = 85 train_loss : 0.023001 , test loss : 0.024510\n",
      "epoch = 86 train_loss : 0.022884 , test loss : 0.024340\n",
      "epoch = 88 train_loss : 0.022572 , test loss : 0.023988\n",
      "epoch = 89 train_loss : 0.022544 , test loss : 0.023986\n",
      "epoch = 90 train_loss : 0.022302 , test loss : 0.023794\n",
      "epoch = 91 train_loss : 0.022256 , test loss : 0.023737\n",
      "epoch = 92 train_loss : 0.022066 , test loss : 0.023535\n",
      "epoch = 94 train_loss : 0.021843 , test loss : 0.023305\n",
      "epoch = 96 train_loss : 0.021661 , test loss : 0.023121\n",
      "epoch = 97 train_loss : 0.021546 , test loss : 0.022988\n",
      "epoch = 99 train_loss : 0.021397 , test loss : 0.022849\n",
      "epoch = 100 train_loss : 0.021278 , test loss : 0.022744\n",
      "epoch = 101 train_loss : 0.021212 , test loss : 0.022687\n",
      "epoch = 102 train_loss : 0.021151 , test loss : 0.022603\n",
      "epoch = 104 train_loss : 0.021008 , test loss : 0.022432\n",
      "epoch = 105 train_loss : 0.020948 , test loss : 0.022360\n",
      "epoch = 106 train_loss : 0.020904 , test loss : 0.022305\n",
      "epoch = 108 train_loss : 0.020685 , test loss : 0.022116\n",
      "epoch = 109 train_loss : 0.020588 , test loss : 0.022018\n",
      "epoch = 111 train_loss : 0.020496 , test loss : 0.021925\n",
      "epoch = 112 train_loss : 0.020436 , test loss : 0.021864\n",
      "epoch = 114 train_loss : 0.020313 , test loss : 0.021708\n",
      "epoch = 115 train_loss : 0.020225 , test loss : 0.021651\n",
      "epoch = 116 train_loss : 0.020171 , test loss : 0.021583\n",
      "epoch = 117 train_loss : 0.020124 , test loss : 0.021532\n",
      "epoch = 118 train_loss : 0.020058 , test loss : 0.021482\n",
      "epoch = 119 train_loss : 0.019999 , test loss : 0.021417\n",
      "epoch = 120 train_loss : 0.019964 , test loss : 0.021360\n",
      "epoch = 121 train_loss : 0.019899 , test loss : 0.021314\n",
      "epoch = 123 train_loss : 0.019802 , test loss : 0.021241\n",
      "epoch = 125 train_loss : 0.019683 , test loss : 0.021111\n",
      "epoch = 126 train_loss : 0.019645 , test loss : 0.021043\n",
      "epoch = 127 train_loss : 0.019610 , test loss : 0.021036\n",
      "epoch = 129 train_loss : 0.019544 , test loss : 0.020969\n",
      "epoch = 130 train_loss : 0.019460 , test loss : 0.020874\n",
      "epoch = 131 train_loss : 0.019433 , test loss : 0.020840\n",
      "epoch = 133 train_loss : 0.019389 , test loss : 0.020783\n",
      "epoch = 134 train_loss : 0.019370 , test loss : 0.020754\n",
      "epoch = 135 train_loss : 0.019296 , test loss : 0.020691\n",
      "epoch = 136 train_loss : 0.019241 , test loss : 0.020674\n",
      "epoch = 138 train_loss : 0.019145 , test loss : 0.020563\n",
      "epoch = 139 train_loss : 0.019120 , test loss : 0.020526\n",
      "epoch = 141 train_loss : 0.019048 , test loss : 0.020471\n",
      "epoch = 142 train_loss : 0.018988 , test loss : 0.020414\n",
      "epoch = 143 train_loss : 0.018970 , test loss : 0.020372\n",
      "epoch = 146 train_loss : 0.018928 , test loss : 0.020369\n",
      "epoch = 147 train_loss : 0.018925 , test loss : 0.020348\n",
      "epoch = 148 train_loss : 0.018796 , test loss : 0.020217\n",
      "epoch = 152 train_loss : 0.018695 , test loss : 0.020135\n",
      "epoch = 154 train_loss : 0.018646 , test loss : 0.020101\n",
      "epoch = 156 train_loss : 0.018571 , test loss : 0.020005\n",
      "epoch = 158 train_loss : 0.018510 , test loss : 0.019983\n",
      "epoch = 159 train_loss : 0.018503 , test loss : 0.019957\n",
      "epoch = 160 train_loss : 0.018450 , test loss : 0.019890\n",
      "epoch = 163 train_loss : 0.018394 , test loss : 0.019850\n",
      "epoch = 166 train_loss : 0.018307 , test loss : 0.019762\n",
      "epoch = 167 train_loss : 0.018298 , test loss : 0.019752\n",
      "epoch = 168 train_loss : 0.018259 , test loss : 0.019728\n",
      "epoch = 170 train_loss : 0.018240 , test loss : 0.019723\n",
      "epoch = 171 train_loss : 0.018169 , test loss : 0.019663\n",
      "epoch = 173 train_loss : 0.018132 , test loss : 0.019608\n",
      "epoch = 174 train_loss : 0.018114 , test loss : 0.019604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 175 train_loss : 0.018101 , test loss : 0.019601\n",
      "epoch = 176 train_loss : 0.018059 , test loss : 0.019568\n",
      "epoch = 178 train_loss : 0.018062 , test loss : 0.019566\n",
      "epoch = 179 train_loss : 0.018006 , test loss : 0.019520\n",
      "epoch = 183 train_loss : 0.017974 , test loss : 0.019476\n",
      "epoch = 184 train_loss : 0.017934 , test loss : 0.019454\n",
      "epoch = 185 train_loss : 0.017877 , test loss : 0.019374\n",
      "epoch = 188 train_loss : 0.017820 , test loss : 0.019335\n",
      "epoch = 189 train_loss : 0.017800 , test loss : 0.019312\n",
      "epoch = 190 train_loss : 0.017807 , test loss : 0.019308\n",
      "epoch = 193 train_loss : 0.017762 , test loss : 0.019294\n",
      "epoch = 194 train_loss : 0.017741 , test loss : 0.019280\n",
      "epoch = 195 train_loss : 0.017685 , test loss : 0.019208\n",
      "epoch = 196 train_loss : 0.017660 , test loss : 0.019191\n",
      "epoch = 197 train_loss : 0.017682 , test loss : 0.019170\n",
      "epoch = 199 train_loss : 0.017608 , test loss : 0.019136\n",
      "epoch = 204 train_loss : 0.017547 , test loss : 0.019101\n",
      "epoch = 206 train_loss : 0.017503 , test loss : 0.019075\n",
      "epoch = 209 train_loss : 0.017452 , test loss : 0.019017\n",
      "epoch = 210 train_loss : 0.017441 , test loss : 0.019012\n",
      "epoch = 212 train_loss : 0.017445 , test loss : 0.018980\n",
      "epoch = 213 train_loss : 0.017393 , test loss : 0.018975\n",
      "epoch = 214 train_loss : 0.017385 , test loss : 0.018967\n",
      "epoch = 215 train_loss : 0.017356 , test loss : 0.018912\n",
      "epoch = 218 train_loss : 0.017318 , test loss : 0.018883\n",
      "epoch = 219 train_loss : 0.017325 , test loss : 0.018875\n",
      "epoch = 221 train_loss : 0.017266 , test loss : 0.018845\n",
      "epoch = 223 train_loss : 0.017267 , test loss : 0.018841\n",
      "epoch = 226 train_loss : 0.017207 , test loss : 0.018815\n",
      "epoch = 227 train_loss : 0.017206 , test loss : 0.018785\n",
      "epoch = 230 train_loss : 0.017197 , test loss : 0.018757\n",
      "epoch = 231 train_loss : 0.017225 , test loss : 0.018749\n",
      "epoch = 232 train_loss : 0.017131 , test loss : 0.018725\n",
      "epoch = 236 train_loss : 0.017120 , test loss : 0.018682\n",
      "epoch = 240 train_loss : 0.017033 , test loss : 0.018648\n",
      "epoch = 241 train_loss : 0.017019 , test loss : 0.018632\n",
      "epoch = 244 train_loss : 0.017012 , test loss : 0.018624\n",
      "epoch = 245 train_loss : 0.016978 , test loss : 0.018600\n",
      "epoch = 248 train_loss : 0.016983 , test loss : 0.018584\n",
      "epoch = 249 train_loss : 0.016945 , test loss : 0.018558\n",
      "epoch = 252 train_loss : 0.016925 , test loss : 0.018547\n",
      "epoch = 253 train_loss : 0.016907 , test loss : 0.018533\n",
      "epoch = 255 train_loss : 0.016884 , test loss : 0.018500\n",
      "epoch = 257 train_loss : 0.016863 , test loss : 0.018487\n",
      "epoch = 260 train_loss : 0.016839 , test loss : 0.018482\n",
      "epoch = 262 train_loss : 0.016812 , test loss : 0.018449\n",
      "epoch = 267 train_loss : 0.016754 , test loss : 0.018427\n",
      "epoch = 268 train_loss : 0.016752 , test loss : 0.018405\n",
      "epoch = 271 train_loss : 0.016718 , test loss : 0.018369\n",
      "epoch = 274 train_loss : 0.016699 , test loss : 0.018360\n",
      "epoch = 278 train_loss : 0.016692 , test loss : 0.018360\n",
      "epoch = 279 train_loss : 0.016669 , test loss : 0.018329\n",
      "epoch = 280 train_loss : 0.016649 , test loss : 0.018310\n",
      "epoch = 284 train_loss : 0.016639 , test loss : 0.018301\n",
      "epoch = 285 train_loss : 0.016626 , test loss : 0.018300\n",
      "epoch = 286 train_loss : 0.016593 , test loss : 0.018286\n",
      "epoch = 288 train_loss : 0.016579 , test loss : 0.018265\n",
      "epoch = 289 train_loss : 0.016578 , test loss : 0.018240\n",
      "epoch = 293 train_loss : 0.016536 , test loss : 0.018237\n",
      "epoch = 294 train_loss : 0.016526 , test loss : 0.018231\n",
      "epoch = 295 train_loss : 0.016545 , test loss : 0.018224\n",
      "epoch = 300 train_loss : 0.016479 , test loss : 0.018183\n",
      "epoch = 301 train_loss : 0.016486 , test loss : 0.018180\n",
      "epoch = 304 train_loss : 0.016466 , test loss : 0.018161\n",
      "epoch = 306 train_loss : 0.016453 , test loss : 0.018155\n",
      "epoch = 311 train_loss : 0.016416 , test loss : 0.018123\n",
      "epoch = 313 train_loss : 0.016402 , test loss : 0.018114\n",
      "epoch = 315 train_loss : 0.016397 , test loss : 0.018107\n",
      "epoch = 316 train_loss : 0.016373 , test loss : 0.018090\n",
      "epoch = 320 train_loss : 0.016377 , test loss : 0.018062\n",
      "epoch = 322 train_loss : 0.016345 , test loss : 0.018052\n",
      "epoch = 323 train_loss : 0.016332 , test loss : 0.018044\n",
      "epoch = 324 train_loss : 0.016316 , test loss : 0.018039\n",
      "epoch = 332 train_loss : 0.016279 , test loss : 0.017997\n",
      "epoch = 339 train_loss : 0.016272 , test loss : 0.017991\n",
      "epoch = 341 train_loss : 0.016238 , test loss : 0.017964\n",
      "epoch = 345 train_loss : 0.016224 , test loss : 0.017956\n",
      "epoch = 347 train_loss : 0.016226 , test loss : 0.017951\n",
      "epoch = 351 train_loss : 0.016210 , test loss : 0.017940\n",
      "epoch = 352 train_loss : 0.016195 , test loss : 0.017921\n",
      "epoch = 354 train_loss : 0.016190 , test loss : 0.017920\n",
      "epoch = 357 train_loss : 0.016163 , test loss : 0.017898\n",
      "epoch = 359 train_loss : 0.016136 , test loss : 0.017896\n",
      "epoch = 363 train_loss : 0.016119 , test loss : 0.017876\n",
      "epoch = 364 train_loss : 0.016119 , test loss : 0.017860\n",
      "epoch = 368 train_loss : 0.016113 , test loss : 0.017846\n",
      "epoch = 370 train_loss : 0.016084 , test loss : 0.017830\n",
      "epoch = 373 train_loss : 0.016072 , test loss : 0.017828\n",
      "epoch = 376 train_loss : 0.016073 , test loss : 0.017818\n",
      "epoch = 377 train_loss : 0.016039 , test loss : 0.017792\n",
      "epoch = 383 train_loss : 0.016040 , test loss : 0.017772\n",
      "epoch = 384 train_loss : 0.016018 , test loss : 0.017767\n",
      "epoch = 387 train_loss : 0.015990 , test loss : 0.017741\n",
      "epoch = 400 train_loss : 0.015942 , test loss : 0.017718\n",
      "epoch = 402 train_loss : 0.015950 , test loss : 0.017713\n",
      "epoch = 409 train_loss : 0.015918 , test loss : 0.017687\n",
      "epoch = 414 train_loss : 0.015898 , test loss : 0.017676\n",
      "epoch = 415 train_loss : 0.015904 , test loss : 0.017660\n",
      "epoch = 418 train_loss : 0.015878 , test loss : 0.017651\n",
      "epoch = 424 train_loss : 0.015848 , test loss : 0.017641\n",
      "epoch = 426 train_loss : 0.015847 , test loss : 0.017629\n",
      "epoch = 430 train_loss : 0.015838 , test loss : 0.017625\n",
      "epoch = 433 train_loss : 0.015840 , test loss : 0.017614\n",
      "epoch = 435 train_loss : 0.015830 , test loss : 0.017614\n",
      "epoch = 436 train_loss : 0.015800 , test loss : 0.017592\n",
      "epoch = 439 train_loss : 0.015797 , test loss : 0.017583\n",
      "epoch = 440 train_loss : 0.015788 , test loss : 0.017576\n",
      "epoch = 443 train_loss : 0.015791 , test loss : 0.017572\n",
      "epoch = 445 train_loss : 0.015792 , test loss : 0.017571\n",
      "epoch = 449 train_loss : 0.015781 , test loss : 0.017566\n",
      "epoch = 456 train_loss : 0.015745 , test loss : 0.017537\n",
      "epoch = 459 train_loss : 0.015752 , test loss : 0.017535\n",
      "epoch = 462 train_loss : 0.015729 , test loss : 0.017529\n",
      "epoch = 464 train_loss : 0.015707 , test loss : 0.017514\n",
      "epoch = 466 train_loss : 0.015712 , test loss : 0.017505\n",
      "epoch = 475 train_loss : 0.015701 , test loss : 0.017494\n",
      "epoch = 477 train_loss : 0.015665 , test loss : 0.017470\n",
      "epoch = 482 train_loss : 0.015672 , test loss : 0.017466\n",
      "epoch = 483 train_loss : 0.015654 , test loss : 0.017465\n",
      "epoch = 486 train_loss : 0.015654 , test loss : 0.017465\n",
      "epoch = 490 train_loss : 0.015634 , test loss : 0.017446\n",
      "epoch = 495 train_loss : 0.015617 , test loss : 0.017436\n",
      "epoch = 496 train_loss : 0.015627 , test loss : 0.017434\n",
      "epoch = 499 train_loss : 0.015611 , test loss : 0.017430\n",
      "epoch = 509 train_loss : 0.015595 , test loss : 0.017429\n",
      "epoch = 510 train_loss : 0.015587 , test loss : 0.017406\n",
      "epoch = 524 train_loss : 0.015545 , test loss : 0.017369\n",
      "epoch = 533 train_loss : 0.015520 , test loss : 0.017362\n",
      "epoch = 537 train_loss : 0.015507 , test loss : 0.017352\n",
      "epoch = 538 train_loss : 0.015501 , test loss : 0.017338\n",
      "epoch = 546 train_loss : 0.015481 , test loss : 0.017332\n",
      "epoch = 549 train_loss : 0.015502 , test loss : 0.017326\n",
      "epoch = 554 train_loss : 0.015472 , test loss : 0.017316\n",
      "epoch = 557 train_loss : 0.015478 , test loss : 0.017312\n",
      "epoch = 562 train_loss : 0.015446 , test loss : 0.017311\n",
      "epoch = 566 train_loss : 0.015485 , test loss : 0.017305\n",
      "epoch = 568 train_loss : 0.015448 , test loss : 0.017295\n",
      "epoch = 573 train_loss : 0.015425 , test loss : 0.017292\n",
      "epoch = 574 train_loss : 0.015419 , test loss : 0.017282\n",
      "epoch = 580 train_loss : 0.015430 , test loss : 0.017263\n",
      "epoch = 589 train_loss : 0.015388 , test loss : 0.017261\n",
      "epoch = 591 train_loss : 0.015384 , test loss : 0.017249\n",
      "epoch = 595 train_loss : 0.015373 , test loss : 0.017249\n",
      "epoch = 598 train_loss : 0.015370 , test loss : 0.017248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 603 train_loss : 0.015362 , test loss : 0.017234\n",
      "epoch = 612 train_loss : 0.015331 , test loss : 0.017218\n",
      "epoch = 614 train_loss : 0.015350 , test loss : 0.017218\n",
      "epoch = 635 train_loss : 0.015303 , test loss : 0.017205\n",
      "epoch = 638 train_loss : 0.015315 , test loss : 0.017201\n",
      "epoch = 642 train_loss : 0.015281 , test loss : 0.017200\n",
      "epoch = 646 train_loss : 0.015310 , test loss : 0.017194\n",
      "epoch = 647 train_loss : 0.015284 , test loss : 0.017178\n",
      "epoch = 658 train_loss : 0.015266 , test loss : 0.017166\n",
      "epoch = 669 train_loss : 0.015242 , test loss : 0.017158\n",
      "epoch = 678 train_loss : 0.015228 , test loss : 0.017144\n",
      "epoch = 681 train_loss : 0.015228 , test loss : 0.017143\n",
      "epoch = 701 train_loss : 0.015181 , test loss : 0.017138\n",
      "epoch = 704 train_loss : 0.015179 , test loss : 0.017132\n",
      "epoch = 705 train_loss : 0.015179 , test loss : 0.017127\n",
      "epoch = 718 train_loss : 0.015173 , test loss : 0.017125\n",
      "epoch = 720 train_loss : 0.015149 , test loss : 0.017104\n",
      "epoch = 743 train_loss : 0.015114 , test loss : 0.017091\n",
      "epoch = 748 train_loss : 0.015107 , test loss : 0.017085\n",
      "epoch = 753 train_loss : 0.015101 , test loss : 0.017080\n",
      "epoch = 767 train_loss : 0.015085 , test loss : 0.017066\n",
      "epoch = 780 train_loss : 0.015061 , test loss : 0.017046\n",
      "epoch = 795 train_loss : 0.015047 , test loss : 0.017037\n",
      "epoch = 807 train_loss : 0.015018 , test loss : 0.017033\n",
      "epoch = 816 train_loss : 0.015026 , test loss : 0.017031\n",
      "epoch = 819 train_loss : 0.015011 , test loss : 0.017027\n",
      "epoch = 826 train_loss : 0.015011 , test loss : 0.017012\n",
      "epoch = 839 train_loss : 0.014976 , test loss : 0.017010\n",
      "epoch = 845 train_loss : 0.014977 , test loss : 0.017005\n",
      "epoch = 850 train_loss : 0.014973 , test loss : 0.017003\n",
      "epoch = 856 train_loss : 0.014961 , test loss : 0.016999\n",
      "epoch = 867 train_loss : 0.014953 , test loss : 0.016994\n",
      "epoch = 883 train_loss : 0.014928 , test loss : 0.016983\n",
      "epoch = 896 train_loss : 0.014908 , test loss : 0.016977\n",
      "epoch = 897 train_loss : 0.014907 , test loss : 0.016973\n",
      "epoch = 904 train_loss : 0.014907 , test loss : 0.016967\n",
      "epoch = 921 train_loss : 0.014886 , test loss : 0.016965\n",
      "epoch = 933 train_loss : 0.014880 , test loss : 0.016963\n",
      "epoch = 945 train_loss : 0.014861 , test loss : 0.016962\n",
      "epoch = 948 train_loss : 0.014886 , test loss : 0.016962\n",
      "epoch = 949 train_loss : 0.014857 , test loss : 0.016952\n",
      "epoch = 965 train_loss : 0.014848 , test loss : 0.016947\n",
      "epoch = 972 train_loss : 0.014835 , test loss : 0.016944\n",
      "epoch = 979 train_loss : 0.014834 , test loss : 0.016940\n",
      "epoch = 982 train_loss : 0.014826 , test loss : 0.016939\n",
      "epoch = 1005 train_loss : 0.014801 , test loss : 0.016937\n",
      "epoch = 1006 train_loss : 0.014810 , test loss : 0.016933\n",
      "epoch = 1010 train_loss : 0.014794 , test loss : 0.016927\n",
      "epoch = 1012 train_loss : 0.014782 , test loss : 0.016920\n",
      "epoch = 1024 train_loss : 0.014780 , test loss : 0.016916\n",
      "epoch = 1035 train_loss : 0.014763 , test loss : 0.016916\n",
      "epoch = 1048 train_loss : 0.014761 , test loss : 0.016911\n",
      "epoch = 1055 train_loss : 0.014750 , test loss : 0.016895\n",
      "epoch = 1065 train_loss : 0.014740 , test loss : 0.016890\n",
      "epoch = 1081 train_loss : 0.014718 , test loss : 0.016884\n",
      "epoch = 1132 train_loss : 0.014673 , test loss : 0.016875\n",
      "epoch = 1139 train_loss : 0.014678 , test loss : 0.016860\n",
      "epoch = 1182 train_loss : 0.014635 , test loss : 0.016851\n",
      "epoch = 1219 train_loss : 0.014628 , test loss : 0.016849\n",
      "epoch = 1236 train_loss : 0.014590 , test loss : 0.016848\n",
      "epoch = 1240 train_loss : 0.014595 , test loss : 0.016847\n",
      "epoch = 1244 train_loss : 0.014595 , test loss : 0.016845\n",
      "epoch = 1256 train_loss : 0.014580 , test loss : 0.016839\n",
      "epoch = 1261 train_loss : 0.014567 , test loss : 0.016828\n",
      "epoch = 1310 train_loss : 0.014535 , test loss : 0.016823\n",
      "epoch = 1338 train_loss : 0.014531 , test loss : 0.016817\n",
      "epoch = 1345 train_loss : 0.014526 , test loss : 0.016814\n",
      "epoch = 1373 train_loss : 0.014489 , test loss : 0.016808\n",
      "epoch = 1386 train_loss : 0.014475 , test loss : 0.016804\n",
      "epoch = 1426 train_loss : 0.014444 , test loss : 0.016800\n",
      "epoch = 1430 train_loss : 0.014442 , test loss : 0.016795\n",
      "epoch = 1440 train_loss : 0.014438 , test loss : 0.016793\n",
      "epoch = 1514 train_loss : 0.014386 , test loss : 0.016787\n",
      "epoch = 1521 train_loss : 0.014412 , test loss : 0.016784\n",
      "epoch = 1622 train_loss : 0.014330 , test loss : 0.016782\n",
      "epoch = 1644 train_loss : 0.014317 , test loss : 0.016768\n",
      "epoch = 1700 train_loss : 0.014280 , test loss : 0.016765\n",
      "epoch = 1727 train_loss : 0.014250 , test loss : 0.016762\n",
      "epoch = 1831 train_loss : 0.014196 , test loss : 0.016762\n",
      "epoch = 1837 train_loss : 0.014207 , test loss : 0.016760\n",
      "train log loss:  0.014207466505467892\n",
      "test log loss:  0.016807548701763153\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.014207,test loss : 0.016760\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 2.619076 , test loss : 2.619685\n",
      "epoch = 2 train_loss : 2.617934 , test loss : 2.618326\n",
      "epoch = 3 train_loss : 2.505769 , test loss : 2.509755\n",
      "epoch = 4 train_loss : 1.672482 , test loss : 1.677630\n",
      "epoch = 5 train_loss : 0.977576 , test loss : 0.981925\n",
      "epoch = 6 train_loss : 0.614271 , test loss : 0.617849\n",
      "epoch = 7 train_loss : 0.474923 , test loss : 0.478065\n",
      "epoch = 8 train_loss : 0.417716 , test loss : 0.420747\n",
      "epoch = 9 train_loss : 0.386694 , test loss : 0.389776\n",
      "epoch = 10 train_loss : 0.369426 , test loss : 0.372622\n",
      "epoch = 11 train_loss : 0.355046 , test loss : 0.358352\n",
      "epoch = 12 train_loss : 0.337264 , test loss : 0.340636\n",
      "epoch = 13 train_loss : 0.324944 , test loss : 0.328406\n",
      "epoch = 14 train_loss : 0.312024 , test loss : 0.315546\n",
      "epoch = 15 train_loss : 0.303091 , test loss : 0.306669\n",
      "epoch = 16 train_loss : 0.291704 , test loss : 0.295321\n",
      "epoch = 17 train_loss : 0.275576 , test loss : 0.279220\n",
      "epoch = 18 train_loss : 0.265459 , test loss : 0.269075\n",
      "epoch = 19 train_loss : 0.251911 , test loss : 0.255492\n",
      "epoch = 20 train_loss : 0.242284 , test loss : 0.245830\n",
      "epoch = 21 train_loss : 0.229834 , test loss : 0.233310\n",
      "epoch = 22 train_loss : 0.222190 , test loss : 0.225618\n",
      "epoch = 23 train_loss : 0.209976 , test loss : 0.213293\n",
      "epoch = 24 train_loss : 0.199188 , test loss : 0.202402\n",
      "epoch = 25 train_loss : 0.190212 , test loss : 0.193297\n",
      "epoch = 26 train_loss : 0.180031 , test loss : 0.182981\n",
      "epoch = 27 train_loss : 0.172489 , test loss : 0.175321\n",
      "epoch = 28 train_loss : 0.169615 , test loss : 0.172340\n",
      "epoch = 29 train_loss : 0.153142 , test loss : 0.155708\n",
      "epoch = 30 train_loss : 0.146345 , test loss : 0.148816\n",
      "epoch = 31 train_loss : 0.140585 , test loss : 0.143008\n",
      "epoch = 32 train_loss : 0.132138 , test loss : 0.134422\n",
      "epoch = 33 train_loss : 0.122402 , test loss : 0.124513\n",
      "epoch = 34 train_loss : 0.117560 , test loss : 0.119566\n",
      "epoch = 35 train_loss : 0.108687 , test loss : 0.110609\n",
      "epoch = 36 train_loss : 0.101875 , test loss : 0.103646\n",
      "epoch = 37 train_loss : 0.096536 , test loss : 0.098215\n",
      "epoch = 38 train_loss : 0.089336 , test loss : 0.090844\n",
      "epoch = 39 train_loss : 0.083836 , test loss : 0.085222\n",
      "epoch = 40 train_loss : 0.081241 , test loss : 0.082560\n",
      "epoch = 41 train_loss : 0.076021 , test loss : 0.077133\n",
      "epoch = 42 train_loss : 0.069194 , test loss : 0.069966\n",
      "epoch = 43 train_loss : 0.065736 , test loss : 0.066362\n",
      "epoch = 44 train_loss : 0.061931 , test loss : 0.062303\n",
      "epoch = 45 train_loss : 0.058535 , test loss : 0.058605\n",
      "epoch = 46 train_loss : 0.055721 , test loss : 0.055580\n",
      "epoch = 47 train_loss : 0.055159 , test loss : 0.054896\n",
      "epoch = 48 train_loss : 0.052837 , test loss : 0.052354\n",
      "epoch = 49 train_loss : 0.048860 , test loss : 0.047944\n",
      "epoch = 50 train_loss : 0.046987 , test loss : 0.045856\n",
      "epoch = 51 train_loss : 0.045328 , test loss : 0.044015\n",
      "epoch = 52 train_loss : 0.043872 , test loss : 0.042423\n",
      "epoch = 53 train_loss : 0.042569 , test loss : 0.040998\n",
      "epoch = 54 train_loss : 0.041288 , test loss : 0.039643\n",
      "epoch = 55 train_loss : 0.040154 , test loss : 0.038454\n",
      "epoch = 56 train_loss : 0.039034 , test loss : 0.037311\n",
      "epoch = 57 train_loss : 0.038215 , test loss : 0.036510\n",
      "epoch = 58 train_loss : 0.037269 , test loss : 0.035651\n",
      "epoch = 59 train_loss : 0.036453 , test loss : 0.034892\n",
      "epoch = 60 train_loss : 0.035857 , test loss : 0.034406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 61 train_loss : 0.035181 , test loss : 0.033739\n",
      "epoch = 62 train_loss : 0.034436 , test loss : 0.033108\n",
      "epoch = 63 train_loss : 0.033985 , test loss : 0.032686\n",
      "epoch = 64 train_loss : 0.033285 , test loss : 0.032106\n",
      "epoch = 66 train_loss : 0.032312 , test loss : 0.031200\n",
      "epoch = 67 train_loss : 0.032073 , test loss : 0.031012\n",
      "epoch = 68 train_loss : 0.031490 , test loss : 0.030478\n",
      "epoch = 69 train_loss : 0.031025 , test loss : 0.030074\n",
      "epoch = 70 train_loss : 0.030712 , test loss : 0.029801\n",
      "epoch = 71 train_loss : 0.030339 , test loss : 0.029466\n",
      "epoch = 72 train_loss : 0.030118 , test loss : 0.029248\n",
      "epoch = 73 train_loss : 0.029627 , test loss : 0.028912\n",
      "epoch = 74 train_loss : 0.029290 , test loss : 0.028580\n",
      "epoch = 75 train_loss : 0.028993 , test loss : 0.028397\n",
      "epoch = 76 train_loss : 0.028696 , test loss : 0.028065\n",
      "epoch = 77 train_loss : 0.028399 , test loss : 0.027803\n",
      "epoch = 78 train_loss : 0.028072 , test loss : 0.027532\n",
      "epoch = 79 train_loss : 0.027790 , test loss : 0.027318\n",
      "epoch = 80 train_loss : 0.027431 , test loss : 0.026989\n",
      "epoch = 81 train_loss : 0.027163 , test loss : 0.026714\n",
      "epoch = 82 train_loss : 0.026909 , test loss : 0.026511\n",
      "epoch = 83 train_loss : 0.026780 , test loss : 0.026337\n",
      "epoch = 84 train_loss : 0.026475 , test loss : 0.026197\n",
      "epoch = 85 train_loss : 0.026340 , test loss : 0.025910\n",
      "epoch = 86 train_loss : 0.026039 , test loss : 0.025791\n",
      "epoch = 87 train_loss : 0.025831 , test loss : 0.025479\n",
      "epoch = 88 train_loss : 0.025664 , test loss : 0.025383\n",
      "epoch = 89 train_loss : 0.025439 , test loss : 0.025169\n",
      "epoch = 90 train_loss : 0.025274 , test loss : 0.025141\n",
      "epoch = 91 train_loss : 0.025217 , test loss : 0.025010\n",
      "epoch = 92 train_loss : 0.024906 , test loss : 0.024769\n",
      "epoch = 93 train_loss : 0.024757 , test loss : 0.024634\n",
      "epoch = 94 train_loss : 0.024589 , test loss : 0.024432\n",
      "epoch = 95 train_loss : 0.024404 , test loss : 0.024229\n",
      "epoch = 96 train_loss : 0.024242 , test loss : 0.024162\n",
      "epoch = 97 train_loss : 0.024087 , test loss : 0.023879\n",
      "epoch = 99 train_loss : 0.023754 , test loss : 0.023619\n",
      "epoch = 100 train_loss : 0.023631 , test loss : 0.023600\n",
      "epoch = 101 train_loss : 0.023560 , test loss : 0.023534\n",
      "epoch = 102 train_loss : 0.023375 , test loss : 0.023298\n",
      "epoch = 103 train_loss : 0.023288 , test loss : 0.023211\n",
      "epoch = 104 train_loss : 0.023105 , test loss : 0.023089\n",
      "epoch = 105 train_loss : 0.023011 , test loss : 0.023047\n",
      "epoch = 106 train_loss : 0.022864 , test loss : 0.022941\n",
      "epoch = 107 train_loss : 0.022752 , test loss : 0.022667\n",
      "epoch = 109 train_loss : 0.022565 , test loss : 0.022456\n",
      "epoch = 114 train_loss : 0.022052 , test loss : 0.022229\n",
      "epoch = 115 train_loss : 0.021948 , test loss : 0.022144\n",
      "epoch = 116 train_loss : 0.021886 , test loss : 0.021955\n",
      "epoch = 119 train_loss : 0.021652 , test loss : 0.021834\n",
      "epoch = 121 train_loss : 0.021474 , test loss : 0.021748\n",
      "epoch = 122 train_loss : 0.021421 , test loss : 0.021611\n",
      "epoch = 123 train_loss : 0.021422 , test loss : 0.021588\n",
      "epoch = 124 train_loss : 0.021444 , test loss : 0.021549\n",
      "epoch = 125 train_loss : 0.021179 , test loss : 0.021497\n",
      "epoch = 126 train_loss : 0.021128 , test loss : 0.021447\n",
      "epoch = 128 train_loss : 0.021022 , test loss : 0.021280\n",
      "epoch = 131 train_loss : 0.020804 , test loss : 0.021087\n",
      "epoch = 134 train_loss : 0.020648 , test loss : 0.020890\n",
      "epoch = 135 train_loss : 0.020581 , test loss : 0.020733\n",
      "epoch = 138 train_loss : 0.020405 , test loss : 0.020597\n",
      "epoch = 143 train_loss : 0.020201 , test loss : 0.020534\n",
      "epoch = 147 train_loss : 0.020025 , test loss : 0.020495\n",
      "epoch = 149 train_loss : 0.019874 , test loss : 0.020324\n",
      "epoch = 150 train_loss : 0.019833 , test loss : 0.020248\n",
      "epoch = 153 train_loss : 0.019731 , test loss : 0.020235\n",
      "epoch = 154 train_loss : 0.019723 , test loss : 0.020116\n",
      "epoch = 157 train_loss : 0.019571 , test loss : 0.020096\n",
      "epoch = 161 train_loss : 0.019408 , test loss : 0.020075\n",
      "epoch = 163 train_loss : 0.019313 , test loss : 0.019856\n",
      "epoch = 165 train_loss : 0.019303 , test loss : 0.019712\n",
      "epoch = 170 train_loss : 0.019099 , test loss : 0.019625\n",
      "epoch = 172 train_loss : 0.019028 , test loss : 0.019556\n",
      "epoch = 175 train_loss : 0.018968 , test loss : 0.019412\n",
      "epoch = 180 train_loss : 0.018844 , test loss : 0.019408\n",
      "epoch = 181 train_loss : 0.018759 , test loss : 0.019324\n",
      "epoch = 182 train_loss : 0.018937 , test loss : 0.019288\n",
      "epoch = 184 train_loss : 0.018672 , test loss : 0.019258\n",
      "epoch = 185 train_loss : 0.018649 , test loss : 0.019239\n",
      "epoch = 191 train_loss : 0.018515 , test loss : 0.019042\n",
      "epoch = 197 train_loss : 0.018376 , test loss : 0.019035\n",
      "epoch = 201 train_loss : 0.018289 , test loss : 0.018829\n",
      "epoch = 210 train_loss : 0.018111 , test loss : 0.018802\n",
      "epoch = 213 train_loss : 0.018054 , test loss : 0.018676\n",
      "epoch = 218 train_loss : 0.017947 , test loss : 0.018639\n",
      "epoch = 222 train_loss : 0.017912 , test loss : 0.018559\n",
      "epoch = 226 train_loss : 0.017811 , test loss : 0.018556\n",
      "epoch = 228 train_loss : 0.017777 , test loss : 0.018478\n",
      "epoch = 234 train_loss : 0.017692 , test loss : 0.018434\n",
      "epoch = 237 train_loss : 0.017645 , test loss : 0.018420\n",
      "epoch = 242 train_loss : 0.017585 , test loss : 0.018303\n",
      "epoch = 250 train_loss : 0.017477 , test loss : 0.018275\n",
      "epoch = 252 train_loss : 0.017463 , test loss : 0.018219\n",
      "epoch = 255 train_loss : 0.017422 , test loss : 0.018104\n",
      "epoch = 265 train_loss : 0.017298 , test loss : 0.018100\n",
      "epoch = 268 train_loss : 0.017249 , test loss : 0.018046\n",
      "epoch = 273 train_loss : 0.017206 , test loss : 0.018029\n",
      "epoch = 277 train_loss : 0.017174 , test loss : 0.018019\n",
      "epoch = 283 train_loss : 0.017124 , test loss : 0.017965\n",
      "epoch = 284 train_loss : 0.017136 , test loss : 0.017962\n",
      "epoch = 287 train_loss : 0.017127 , test loss : 0.017952\n",
      "epoch = 288 train_loss : 0.017092 , test loss : 0.017911\n",
      "epoch = 295 train_loss : 0.017036 , test loss : 0.017837\n",
      "epoch = 309 train_loss : 0.016895 , test loss : 0.017799\n",
      "epoch = 311 train_loss : 0.016863 , test loss : 0.017797\n",
      "epoch = 315 train_loss : 0.016820 , test loss : 0.017783\n",
      "epoch = 320 train_loss : 0.016798 , test loss : 0.017775\n",
      "epoch = 321 train_loss : 0.016778 , test loss : 0.017724\n",
      "epoch = 323 train_loss : 0.016794 , test loss : 0.017671\n",
      "epoch = 329 train_loss : 0.016743 , test loss : 0.017658\n",
      "epoch = 346 train_loss : 0.016666 , test loss : 0.017565\n",
      "epoch = 351 train_loss : 0.016589 , test loss : 0.017546\n",
      "epoch = 354 train_loss : 0.016597 , test loss : 0.017544\n",
      "epoch = 364 train_loss : 0.016510 , test loss : 0.017516\n",
      "epoch = 369 train_loss : 0.016472 , test loss : 0.017490\n",
      "epoch = 372 train_loss : 0.016458 , test loss : 0.017486\n",
      "epoch = 381 train_loss : 0.016421 , test loss : 0.017468\n",
      "epoch = 384 train_loss : 0.016405 , test loss : 0.017376\n",
      "epoch = 406 train_loss : 0.016286 , test loss : 0.017344\n",
      "epoch = 421 train_loss : 0.016264 , test loss : 0.017336\n",
      "epoch = 423 train_loss : 0.016235 , test loss : 0.017281\n",
      "epoch = 442 train_loss : 0.016168 , test loss : 0.017277\n",
      "epoch = 445 train_loss : 0.016174 , test loss : 0.017245\n",
      "epoch = 448 train_loss : 0.016112 , test loss : 0.017219\n",
      "epoch = 474 train_loss : 0.016006 , test loss : 0.017214\n",
      "epoch = 482 train_loss : 0.015980 , test loss : 0.017164\n",
      "epoch = 486 train_loss : 0.015975 , test loss : 0.017152\n",
      "epoch = 508 train_loss : 0.015896 , test loss : 0.017134\n",
      "epoch = 513 train_loss : 0.015895 , test loss : 0.017108\n",
      "epoch = 537 train_loss : 0.015820 , test loss : 0.017094\n",
      "epoch = 546 train_loss : 0.015794 , test loss : 0.017077\n",
      "epoch = 550 train_loss : 0.015785 , test loss : 0.017061\n",
      "epoch = 559 train_loss : 0.015758 , test loss : 0.017052\n",
      "epoch = 573 train_loss : 0.015722 , test loss : 0.017049\n",
      "epoch = 574 train_loss : 0.015716 , test loss : 0.017043\n",
      "epoch = 579 train_loss : 0.015723 , test loss : 0.017007\n",
      "epoch = 589 train_loss : 0.015686 , test loss : 0.017006\n",
      "epoch = 614 train_loss : 0.015642 , test loss : 0.017002\n",
      "epoch = 618 train_loss : 0.015614 , test loss : 0.016967\n",
      "epoch = 646 train_loss : 0.015573 , test loss : 0.016965\n",
      "epoch = 651 train_loss : 0.015555 , test loss : 0.016928\n",
      "epoch = 678 train_loss : 0.015488 , test loss : 0.016921\n",
      "epoch = 680 train_loss : 0.015518 , test loss : 0.016898\n",
      "epoch = 690 train_loss : 0.015513 , test loss : 0.016893\n",
      "epoch = 704 train_loss : 0.015501 , test loss : 0.016892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 711 train_loss : 0.015482 , test loss : 0.016887\n",
      "epoch = 713 train_loss : 0.015439 , test loss : 0.016884\n",
      "epoch = 720 train_loss : 0.015421 , test loss : 0.016873\n",
      "epoch = 737 train_loss : 0.015454 , test loss : 0.016872\n",
      "epoch = 738 train_loss : 0.015414 , test loss : 0.016871\n",
      "epoch = 740 train_loss : 0.015409 , test loss : 0.016861\n",
      "epoch = 742 train_loss : 0.015421 , test loss : 0.016823\n",
      "epoch = 754 train_loss : 0.015378 , test loss : 0.016812\n",
      "epoch = 801 train_loss : 0.015320 , test loss : 0.016793\n",
      "epoch = 829 train_loss : 0.015264 , test loss : 0.016788\n",
      "epoch = 841 train_loss : 0.015262 , test loss : 0.016756\n",
      "epoch = 856 train_loss : 0.015241 , test loss : 0.016747\n",
      "epoch = 873 train_loss : 0.015230 , test loss : 0.016729\n",
      "epoch = 875 train_loss : 0.015231 , test loss : 0.016726\n",
      "epoch = 935 train_loss : 0.015131 , test loss : 0.016711\n",
      "epoch = 972 train_loss : 0.015103 , test loss : 0.016697\n",
      "epoch = 997 train_loss : 0.015076 , test loss : 0.016685\n",
      "epoch = 1005 train_loss : 0.015065 , test loss : 0.016680\n",
      "epoch = 1016 train_loss : 0.015056 , test loss : 0.016668\n",
      "epoch = 1025 train_loss : 0.015056 , test loss : 0.016653\n",
      "epoch = 1049 train_loss : 0.015014 , test loss : 0.016637\n",
      "epoch = 1096 train_loss : 0.014980 , test loss : 0.016630\n",
      "epoch = 1105 train_loss : 0.014956 , test loss : 0.016626\n",
      "epoch = 1139 train_loss : 0.014960 , test loss : 0.016612\n",
      "epoch = 1189 train_loss : 0.014887 , test loss : 0.016596\n",
      "epoch = 1209 train_loss : 0.014885 , test loss : 0.016586\n",
      "epoch = 1263 train_loss : 0.014843 , test loss : 0.016564\n",
      "epoch = 1327 train_loss : 0.014815 , test loss : 0.016552\n",
      "epoch = 1360 train_loss : 0.014757 , test loss : 0.016549\n",
      "epoch = 1392 train_loss : 0.014763 , test loss : 0.016544\n",
      "epoch = 1478 train_loss : 0.014681 , test loss : 0.016530\n",
      "epoch = 1562 train_loss : 0.014639 , test loss : 0.016530\n",
      "epoch = 1597 train_loss : 0.014606 , test loss : 0.016529\n",
      "epoch = 1647 train_loss : 0.014583 , test loss : 0.016519\n",
      "epoch = 1653 train_loss : 0.014581 , test loss : 0.016507\n",
      "epoch = 1745 train_loss : 0.014523 , test loss : 0.016495\n",
      "epoch = 1903 train_loss : 0.014443 , test loss : 0.016488\n",
      "epoch = 2149 train_loss : 0.014322 , test loss : 0.016476\n",
      "epoch = 2246 train_loss : 0.014300 , test loss : 0.016470\n",
      "epoch = 2255 train_loss : 0.014268 , test loss : 0.016469\n",
      "epoch = 2272 train_loss : 0.014266 , test loss : 0.016464\n",
      "epoch = 2459 train_loss : 0.014187 , test loss : 0.016456\n",
      "epoch = 2511 train_loss : 0.014164 , test loss : 0.016450\n",
      "epoch = 2587 train_loss : 0.014119 , test loss : 0.016449\n",
      "epoch = 2650 train_loss : 0.014095 , test loss : 0.016445\n",
      "epoch = 2660 train_loss : 0.014074 , test loss : 0.016441\n",
      "epoch = 2721 train_loss : 0.014076 , test loss : 0.016428\n",
      "train log loss:  0.014075996354222298\n",
      "test log loss:  0.016537507995963097\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.014076,test loss : 0.016428\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 2.619217 , test loss : 2.618519\n",
      "epoch = 2 train_loss : 2.596279 , test loss : 2.595190\n",
      "epoch = 3 train_loss : 2.027578 , test loss : 2.027208\n",
      "epoch = 4 train_loss : 1.204036 , test loss : 1.204215\n",
      "epoch = 5 train_loss : 0.711728 , test loss : 0.711932\n",
      "epoch = 6 train_loss : 0.501457 , test loss : 0.501236\n",
      "epoch = 7 train_loss : 0.423470 , test loss : 0.422753\n",
      "epoch = 8 train_loss : 0.382790 , test loss : 0.381674\n",
      "epoch = 9 train_loss : 0.356814 , test loss : 0.355378\n",
      "epoch = 10 train_loss : 0.336252 , test loss : 0.334574\n",
      "epoch = 11 train_loss : 0.318506 , test loss : 0.316600\n",
      "epoch = 12 train_loss : 0.302808 , test loss : 0.300686\n",
      "epoch = 13 train_loss : 0.287424 , test loss : 0.285104\n",
      "epoch = 14 train_loss : 0.281442 , test loss : 0.279049\n",
      "epoch = 15 train_loss : 0.262797 , test loss : 0.260146\n",
      "epoch = 16 train_loss : 0.251598 , test loss : 0.248799\n",
      "epoch = 17 train_loss : 0.240102 , test loss : 0.237138\n",
      "epoch = 18 train_loss : 0.228425 , test loss : 0.225352\n",
      "epoch = 19 train_loss : 0.221227 , test loss : 0.218229\n",
      "epoch = 20 train_loss : 0.209266 , test loss : 0.206190\n",
      "epoch = 21 train_loss : 0.197856 , test loss : 0.194758\n",
      "epoch = 22 train_loss : 0.187935 , test loss : 0.184866\n",
      "epoch = 23 train_loss : 0.180328 , test loss : 0.177430\n",
      "epoch = 24 train_loss : 0.170382 , test loss : 0.167506\n",
      "epoch = 25 train_loss : 0.163494 , test loss : 0.160794\n",
      "epoch = 26 train_loss : 0.153062 , test loss : 0.150295\n",
      "epoch = 27 train_loss : 0.145029 , test loss : 0.142328\n",
      "epoch = 28 train_loss : 0.140145 , test loss : 0.137690\n",
      "epoch = 29 train_loss : 0.132081 , test loss : 0.129666\n",
      "epoch = 30 train_loss : 0.123890 , test loss : 0.121504\n",
      "epoch = 31 train_loss : 0.114982 , test loss : 0.112517\n",
      "epoch = 32 train_loss : 0.108109 , test loss : 0.105708\n",
      "epoch = 33 train_loss : 0.100896 , test loss : 0.098504\n",
      "epoch = 34 train_loss : 0.094396 , test loss : 0.092000\n",
      "epoch = 35 train_loss : 0.088899 , test loss : 0.086492\n",
      "epoch = 36 train_loss : 0.083056 , test loss : 0.080564\n",
      "epoch = 37 train_loss : 0.077958 , test loss : 0.075393\n",
      "epoch = 38 train_loss : 0.075438 , test loss : 0.072868\n",
      "epoch = 39 train_loss : 0.069019 , test loss : 0.066240\n",
      "epoch = 40 train_loss : 0.065394 , test loss : 0.062547\n",
      "epoch = 41 train_loss : 0.061839 , test loss : 0.058972\n",
      "epoch = 42 train_loss : 0.061553 , test loss : 0.058762\n",
      "epoch = 43 train_loss : 0.055775 , test loss : 0.052861\n",
      "epoch = 44 train_loss : 0.053549 , test loss : 0.050670\n",
      "epoch = 46 train_loss : 0.049182 , test loss : 0.046393\n",
      "epoch = 47 train_loss : 0.047478 , test loss : 0.044765\n",
      "epoch = 48 train_loss : 0.045468 , test loss : 0.042815\n",
      "epoch = 49 train_loss : 0.044038 , test loss : 0.041471\n",
      "epoch = 50 train_loss : 0.042573 , test loss : 0.040073\n",
      "epoch = 52 train_loss : 0.040760 , test loss : 0.038494\n",
      "epoch = 53 train_loss : 0.040461 , test loss : 0.038443\n",
      "epoch = 54 train_loss : 0.037680 , test loss : 0.035540\n",
      "epoch = 56 train_loss : 0.037016 , test loss : 0.035256\n",
      "epoch = 57 train_loss : 0.034876 , test loss : 0.033124\n",
      "epoch = 58 train_loss : 0.034112 , test loss : 0.032453\n",
      "epoch = 59 train_loss : 0.033217 , test loss : 0.031651\n",
      "epoch = 61 train_loss : 0.031884 , test loss : 0.030549\n",
      "epoch = 62 train_loss : 0.031211 , test loss : 0.030005\n",
      "epoch = 63 train_loss : 0.030580 , test loss : 0.029442\n",
      "epoch = 64 train_loss : 0.030028 , test loss : 0.029036\n",
      "epoch = 65 train_loss : 0.029531 , test loss : 0.028628\n",
      "epoch = 66 train_loss : 0.029074 , test loss : 0.028300\n",
      "epoch = 67 train_loss : 0.028643 , test loss : 0.027976\n",
      "epoch = 68 train_loss : 0.028290 , test loss : 0.027798\n",
      "epoch = 69 train_loss : 0.027797 , test loss : 0.027364\n",
      "epoch = 70 train_loss : 0.027416 , test loss : 0.027058\n",
      "epoch = 71 train_loss : 0.027081 , test loss : 0.026847\n",
      "epoch = 72 train_loss : 0.026780 , test loss : 0.026657\n",
      "epoch = 73 train_loss : 0.026453 , test loss : 0.026410\n",
      "epoch = 74 train_loss : 0.026165 , test loss : 0.026246\n",
      "epoch = 75 train_loss : 0.025907 , test loss : 0.026123\n",
      "epoch = 76 train_loss : 0.025652 , test loss : 0.025894\n",
      "epoch = 77 train_loss : 0.025387 , test loss : 0.025764\n",
      "epoch = 78 train_loss : 0.025173 , test loss : 0.025586\n",
      "epoch = 79 train_loss : 0.025022 , test loss : 0.025552\n",
      "epoch = 80 train_loss : 0.024722 , test loss : 0.025299\n",
      "epoch = 81 train_loss : 0.024530 , test loss : 0.025134\n",
      "epoch = 82 train_loss : 0.024338 , test loss : 0.025031\n",
      "epoch = 83 train_loss : 0.024148 , test loss : 0.024870\n",
      "epoch = 84 train_loss : 0.023979 , test loss : 0.024783\n",
      "epoch = 85 train_loss : 0.023848 , test loss : 0.024677\n",
      "epoch = 86 train_loss : 0.023649 , test loss : 0.024520\n",
      "epoch = 87 train_loss : 0.023488 , test loss : 0.024413\n",
      "epoch = 88 train_loss : 0.023331 , test loss : 0.024210\n",
      "epoch = 89 train_loss : 0.023201 , test loss : 0.024180\n",
      "epoch = 90 train_loss : 0.023185 , test loss : 0.024066\n",
      "epoch = 91 train_loss : 0.022908 , test loss : 0.023876\n",
      "epoch = 93 train_loss : 0.022727 , test loss : 0.023704\n",
      "epoch = 94 train_loss : 0.022575 , test loss : 0.023654\n",
      "epoch = 95 train_loss : 0.022380 , test loss : 0.023473\n",
      "epoch = 96 train_loss : 0.022287 , test loss : 0.023342\n",
      "epoch = 97 train_loss : 0.022176 , test loss : 0.023276\n",
      "epoch = 98 train_loss : 0.022030 , test loss : 0.023138\n",
      "epoch = 99 train_loss : 0.021921 , test loss : 0.023004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 100 train_loss : 0.021911 , test loss : 0.022968\n",
      "epoch = 101 train_loss : 0.021699 , test loss : 0.022841\n",
      "epoch = 102 train_loss : 0.021588 , test loss : 0.022758\n",
      "epoch = 103 train_loss : 0.021509 , test loss : 0.022715\n",
      "epoch = 104 train_loss : 0.021418 , test loss : 0.022606\n",
      "epoch = 105 train_loss : 0.021337 , test loss : 0.022571\n",
      "epoch = 108 train_loss : 0.021102 , test loss : 0.022342\n",
      "epoch = 109 train_loss : 0.021020 , test loss : 0.022278\n",
      "epoch = 110 train_loss : 0.020945 , test loss : 0.022158\n",
      "epoch = 111 train_loss : 0.020804 , test loss : 0.022104\n",
      "epoch = 112 train_loss : 0.020766 , test loss : 0.022049\n",
      "epoch = 114 train_loss : 0.020624 , test loss : 0.021986\n",
      "epoch = 115 train_loss : 0.020533 , test loss : 0.021907\n",
      "epoch = 116 train_loss : 0.020444 , test loss : 0.021778\n",
      "epoch = 117 train_loss : 0.020461 , test loss : 0.021763\n",
      "epoch = 118 train_loss : 0.020394 , test loss : 0.021625\n",
      "epoch = 121 train_loss : 0.020143 , test loss : 0.021580\n",
      "epoch = 122 train_loss : 0.020066 , test loss : 0.021488\n",
      "epoch = 123 train_loss : 0.020009 , test loss : 0.021458\n",
      "epoch = 125 train_loss : 0.019878 , test loss : 0.021313\n",
      "epoch = 126 train_loss : 0.019925 , test loss : 0.021251\n",
      "epoch = 127 train_loss : 0.019809 , test loss : 0.021224\n",
      "epoch = 130 train_loss : 0.019677 , test loss : 0.021138\n",
      "epoch = 131 train_loss : 0.019579 , test loss : 0.021107\n",
      "epoch = 132 train_loss : 0.019526 , test loss : 0.021025\n",
      "epoch = 133 train_loss : 0.019495 , test loss : 0.020995\n",
      "epoch = 134 train_loss : 0.019473 , test loss : 0.020922\n",
      "epoch = 135 train_loss : 0.019414 , test loss : 0.020908\n",
      "epoch = 138 train_loss : 0.019270 , test loss : 0.020810\n",
      "epoch = 140 train_loss : 0.019188 , test loss : 0.020723\n",
      "epoch = 141 train_loss : 0.019157 , test loss : 0.020701\n",
      "epoch = 143 train_loss : 0.019073 , test loss : 0.020655\n",
      "epoch = 145 train_loss : 0.018999 , test loss : 0.020589\n",
      "epoch = 147 train_loss : 0.018965 , test loss : 0.020566\n",
      "epoch = 150 train_loss : 0.018888 , test loss : 0.020515\n",
      "epoch = 151 train_loss : 0.018803 , test loss : 0.020439\n",
      "epoch = 152 train_loss : 0.018788 , test loss : 0.020433\n",
      "epoch = 154 train_loss : 0.018697 , test loss : 0.020375\n",
      "epoch = 160 train_loss : 0.018596 , test loss : 0.020239\n",
      "epoch = 162 train_loss : 0.018479 , test loss : 0.020155\n",
      "epoch = 163 train_loss : 0.018471 , test loss : 0.020154\n",
      "epoch = 164 train_loss : 0.018441 , test loss : 0.020120\n",
      "epoch = 166 train_loss : 0.018363 , test loss : 0.020055\n",
      "epoch = 171 train_loss : 0.018288 , test loss : 0.020013\n",
      "epoch = 172 train_loss : 0.018351 , test loss : 0.019995\n",
      "epoch = 173 train_loss : 0.018320 , test loss : 0.019976\n",
      "epoch = 177 train_loss : 0.018115 , test loss : 0.019869\n",
      "epoch = 182 train_loss : 0.018033 , test loss : 0.019858\n",
      "epoch = 183 train_loss : 0.018032 , test loss : 0.019792\n",
      "epoch = 186 train_loss : 0.017943 , test loss : 0.019775\n",
      "epoch = 187 train_loss : 0.017958 , test loss : 0.019763\n",
      "epoch = 188 train_loss : 0.017900 , test loss : 0.019691\n",
      "epoch = 193 train_loss : 0.017844 , test loss : 0.019687\n",
      "epoch = 195 train_loss : 0.017762 , test loss : 0.019634\n",
      "epoch = 197 train_loss : 0.017742 , test loss : 0.019614\n",
      "epoch = 201 train_loss : 0.017720 , test loss : 0.019608\n",
      "epoch = 202 train_loss : 0.017660 , test loss : 0.019544\n",
      "epoch = 205 train_loss : 0.017602 , test loss : 0.019528\n",
      "epoch = 208 train_loss : 0.017574 , test loss : 0.019485\n",
      "epoch = 211 train_loss : 0.017542 , test loss : 0.019459\n",
      "epoch = 214 train_loss : 0.017470 , test loss : 0.019404\n",
      "epoch = 216 train_loss : 0.017458 , test loss : 0.019394\n",
      "epoch = 223 train_loss : 0.017357 , test loss : 0.019351\n",
      "epoch = 228 train_loss : 0.017336 , test loss : 0.019340\n",
      "epoch = 229 train_loss : 0.017313 , test loss : 0.019280\n",
      "epoch = 231 train_loss : 0.017311 , test loss : 0.019250\n",
      "epoch = 234 train_loss : 0.017236 , test loss : 0.019200\n",
      "epoch = 237 train_loss : 0.017203 , test loss : 0.019184\n",
      "epoch = 242 train_loss : 0.017184 , test loss : 0.019145\n",
      "epoch = 245 train_loss : 0.017099 , test loss : 0.019120\n",
      "epoch = 249 train_loss : 0.017089 , test loss : 0.019105\n",
      "epoch = 252 train_loss : 0.017035 , test loss : 0.019051\n",
      "epoch = 259 train_loss : 0.016983 , test loss : 0.019020\n",
      "epoch = 263 train_loss : 0.016966 , test loss : 0.019013\n",
      "epoch = 268 train_loss : 0.016887 , test loss : 0.018947\n",
      "epoch = 270 train_loss : 0.016853 , test loss : 0.018923\n",
      "epoch = 274 train_loss : 0.016860 , test loss : 0.018914\n",
      "epoch = 278 train_loss : 0.016825 , test loss : 0.018878\n",
      "epoch = 280 train_loss : 0.016796 , test loss : 0.018873\n",
      "epoch = 286 train_loss : 0.016743 , test loss : 0.018806\n",
      "epoch = 295 train_loss : 0.016670 , test loss : 0.018791\n",
      "epoch = 297 train_loss : 0.016673 , test loss : 0.018776\n",
      "epoch = 301 train_loss : 0.016632 , test loss : 0.018741\n",
      "epoch = 304 train_loss : 0.016618 , test loss : 0.018733\n",
      "epoch = 311 train_loss : 0.016566 , test loss : 0.018713\n",
      "epoch = 312 train_loss : 0.016572 , test loss : 0.018674\n",
      "epoch = 319 train_loss : 0.016495 , test loss : 0.018662\n",
      "epoch = 327 train_loss : 0.016512 , test loss : 0.018660\n",
      "epoch = 328 train_loss : 0.016443 , test loss : 0.018634\n",
      "epoch = 331 train_loss : 0.016415 , test loss : 0.018631\n",
      "epoch = 333 train_loss : 0.016396 , test loss : 0.018626\n",
      "epoch = 334 train_loss : 0.016451 , test loss : 0.018595\n",
      "epoch = 340 train_loss : 0.016365 , test loss : 0.018578\n",
      "epoch = 342 train_loss : 0.016350 , test loss : 0.018549\n",
      "epoch = 346 train_loss : 0.016320 , test loss : 0.018532\n",
      "epoch = 350 train_loss : 0.016340 , test loss : 0.018531\n",
      "epoch = 354 train_loss : 0.016303 , test loss : 0.018508\n",
      "epoch = 356 train_loss : 0.016300 , test loss : 0.018501\n",
      "epoch = 359 train_loss : 0.016273 , test loss : 0.018496\n",
      "epoch = 364 train_loss : 0.016263 , test loss : 0.018487\n",
      "epoch = 365 train_loss : 0.016272 , test loss : 0.018483\n",
      "epoch = 367 train_loss : 0.016260 , test loss : 0.018469\n",
      "epoch = 368 train_loss : 0.016203 , test loss : 0.018431\n",
      "epoch = 375 train_loss : 0.016172 , test loss : 0.018422\n",
      "epoch = 379 train_loss : 0.016158 , test loss : 0.018414\n",
      "epoch = 384 train_loss : 0.016136 , test loss : 0.018414\n",
      "epoch = 389 train_loss : 0.016116 , test loss : 0.018352\n",
      "epoch = 400 train_loss : 0.016096 , test loss : 0.018343\n",
      "epoch = 405 train_loss : 0.016019 , test loss : 0.018308\n",
      "epoch = 416 train_loss : 0.015978 , test loss : 0.018285\n",
      "epoch = 422 train_loss : 0.015971 , test loss : 0.018239\n",
      "epoch = 426 train_loss : 0.015942 , test loss : 0.018232\n",
      "epoch = 438 train_loss : 0.015907 , test loss : 0.018229\n",
      "epoch = 439 train_loss : 0.015895 , test loss : 0.018215\n",
      "epoch = 441 train_loss : 0.015915 , test loss : 0.018211\n",
      "epoch = 447 train_loss : 0.015878 , test loss : 0.018192\n",
      "epoch = 459 train_loss : 0.015839 , test loss : 0.018191\n",
      "epoch = 460 train_loss : 0.015818 , test loss : 0.018182\n",
      "epoch = 461 train_loss : 0.015864 , test loss : 0.018174\n",
      "epoch = 465 train_loss : 0.015810 , test loss : 0.018148\n",
      "epoch = 478 train_loss : 0.015772 , test loss : 0.018123\n",
      "epoch = 481 train_loss : 0.015738 , test loss : 0.018110\n",
      "epoch = 488 train_loss : 0.015730 , test loss : 0.018109\n",
      "epoch = 495 train_loss : 0.015713 , test loss : 0.018084\n",
      "epoch = 499 train_loss : 0.015718 , test loss : 0.018073\n",
      "epoch = 508 train_loss : 0.015651 , test loss : 0.018062\n",
      "epoch = 510 train_loss : 0.015666 , test loss : 0.018056\n",
      "epoch = 511 train_loss : 0.015668 , test loss : 0.018053\n",
      "epoch = 520 train_loss : 0.015704 , test loss : 0.018052\n",
      "epoch = 526 train_loss : 0.015626 , test loss : 0.018032\n",
      "epoch = 527 train_loss : 0.015627 , test loss : 0.018025\n",
      "epoch = 532 train_loss : 0.015613 , test loss : 0.017994\n",
      "epoch = 551 train_loss : 0.015610 , test loss : 0.017987\n",
      "epoch = 555 train_loss : 0.015547 , test loss : 0.017952\n",
      "epoch = 572 train_loss : 0.015491 , test loss : 0.017949\n",
      "epoch = 576 train_loss : 0.015479 , test loss : 0.017936\n",
      "epoch = 588 train_loss : 0.015507 , test loss : 0.017911\n",
      "epoch = 589 train_loss : 0.015463 , test loss : 0.017907\n",
      "epoch = 606 train_loss : 0.015440 , test loss : 0.017897\n",
      "epoch = 612 train_loss : 0.015420 , test loss : 0.017895\n",
      "epoch = 616 train_loss : 0.015409 , test loss : 0.017891\n",
      "epoch = 625 train_loss : 0.015377 , test loss : 0.017883\n",
      "epoch = 627 train_loss : 0.015368 , test loss : 0.017866\n",
      "epoch = 635 train_loss : 0.015408 , test loss : 0.017861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 636 train_loss : 0.015362 , test loss : 0.017856\n",
      "epoch = 643 train_loss : 0.015345 , test loss : 0.017836\n",
      "epoch = 646 train_loss : 0.015381 , test loss : 0.017831\n",
      "epoch = 662 train_loss : 0.015333 , test loss : 0.017824\n",
      "epoch = 665 train_loss : 0.015334 , test loss : 0.017808\n",
      "epoch = 687 train_loss : 0.015282 , test loss : 0.017780\n",
      "epoch = 708 train_loss : 0.015252 , test loss : 0.017775\n",
      "epoch = 711 train_loss : 0.015258 , test loss : 0.017769\n",
      "epoch = 735 train_loss : 0.015212 , test loss : 0.017764\n",
      "epoch = 737 train_loss : 0.015240 , test loss : 0.017759\n",
      "epoch = 751 train_loss : 0.015219 , test loss : 0.017753\n",
      "epoch = 758 train_loss : 0.015146 , test loss : 0.017743\n",
      "epoch = 765 train_loss : 0.015156 , test loss : 0.017725\n",
      "epoch = 774 train_loss : 0.015158 , test loss : 0.017698\n",
      "epoch = 872 train_loss : 0.015039 , test loss : 0.017695\n",
      "epoch = 893 train_loss : 0.014991 , test loss : 0.017690\n",
      "epoch = 906 train_loss : 0.014968 , test loss : 0.017674\n",
      "epoch = 915 train_loss : 0.014978 , test loss : 0.017674\n",
      "epoch = 922 train_loss : 0.014973 , test loss : 0.017668\n",
      "epoch = 937 train_loss : 0.014948 , test loss : 0.017667\n",
      "epoch = 962 train_loss : 0.014919 , test loss : 0.017659\n",
      "epoch = 963 train_loss : 0.014980 , test loss : 0.017636\n",
      "epoch = 971 train_loss : 0.014925 , test loss : 0.017636\n",
      "epoch = 1073 train_loss : 0.014804 , test loss : 0.017632\n",
      "epoch = 1075 train_loss : 0.014807 , test loss : 0.017606\n",
      "epoch = 1262 train_loss : 0.014664 , test loss : 0.017606\n",
      "train log loss:  0.014663799665868282\n",
      "test log loss:  0.017649920657277107\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.014664,test loss : 0.017606\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 2.618546 , test loss : 2.617238\n",
      "epoch = 2 train_loss : 2.531317 , test loss : 2.526625\n",
      "epoch = 3 train_loss : 1.635659 , test loss : 1.632609\n",
      "epoch = 4 train_loss : 0.902049 , test loss : 0.900433\n",
      "epoch = 5 train_loss : 0.538403 , test loss : 0.538861\n",
      "epoch = 6 train_loss : 0.420382 , test loss : 0.422180\n",
      "epoch = 7 train_loss : 0.381273 , test loss : 0.383529\n",
      "epoch = 8 train_loss : 0.360182 , test loss : 0.362614\n",
      "epoch = 9 train_loss : 0.344203 , test loss : 0.346778\n",
      "epoch = 10 train_loss : 0.324495 , test loss : 0.327314\n",
      "epoch = 11 train_loss : 0.309183 , test loss : 0.312154\n",
      "epoch = 12 train_loss : 0.297256 , test loss : 0.300275\n",
      "epoch = 13 train_loss : 0.279761 , test loss : 0.283013\n",
      "epoch = 14 train_loss : 0.266507 , test loss : 0.269855\n",
      "epoch = 15 train_loss : 0.253891 , test loss : 0.257325\n",
      "epoch = 16 train_loss : 0.240512 , test loss : 0.244068\n",
      "epoch = 17 train_loss : 0.227795 , test loss : 0.231448\n",
      "epoch = 18 train_loss : 0.214119 , test loss : 0.217940\n",
      "epoch = 19 train_loss : 0.203299 , test loss : 0.207161\n",
      "epoch = 20 train_loss : 0.193199 , test loss : 0.197066\n",
      "epoch = 21 train_loss : 0.180543 , test loss : 0.184572\n",
      "epoch = 22 train_loss : 0.167175 , test loss : 0.171430\n",
      "epoch = 23 train_loss : 0.155889 , test loss : 0.160289\n",
      "epoch = 24 train_loss : 0.144849 , test loss : 0.149403\n",
      "epoch = 25 train_loss : 0.132706 , test loss : 0.137539\n",
      "epoch = 26 train_loss : 0.123680 , test loss : 0.128596\n",
      "epoch = 27 train_loss : 0.112525 , test loss : 0.117746\n",
      "epoch = 28 train_loss : 0.103554 , test loss : 0.108932\n",
      "epoch = 29 train_loss : 0.094610 , test loss : 0.100209\n",
      "epoch = 30 train_loss : 0.086729 , test loss : 0.092470\n",
      "epoch = 31 train_loss : 0.079021 , test loss : 0.084976\n",
      "epoch = 32 train_loss : 0.072791 , test loss : 0.078801\n",
      "epoch = 33 train_loss : 0.067444 , test loss : 0.073445\n",
      "epoch = 34 train_loss : 0.062225 , test loss : 0.068296\n",
      "epoch = 35 train_loss : 0.058425 , test loss : 0.064328\n",
      "epoch = 36 train_loss : 0.054690 , test loss : 0.060506\n",
      "epoch = 37 train_loss : 0.051601 , test loss : 0.057243\n",
      "epoch = 38 train_loss : 0.049147 , test loss : 0.054513\n",
      "epoch = 39 train_loss : 0.046733 , test loss : 0.051897\n",
      "epoch = 40 train_loss : 0.044672 , test loss : 0.049592\n",
      "epoch = 41 train_loss : 0.042958 , test loss : 0.047544\n",
      "epoch = 42 train_loss : 0.041402 , test loss : 0.045682\n",
      "epoch = 43 train_loss : 0.040124 , test loss : 0.044004\n",
      "epoch = 44 train_loss : 0.038765 , test loss : 0.042322\n",
      "epoch = 45 train_loss : 0.037515 , test loss : 0.040807\n",
      "epoch = 46 train_loss : 0.036445 , test loss : 0.039378\n",
      "epoch = 47 train_loss : 0.035529 , test loss : 0.038120\n",
      "epoch = 48 train_loss : 0.034678 , test loss : 0.036985\n",
      "epoch = 49 train_loss : 0.033840 , test loss : 0.035911\n",
      "epoch = 50 train_loss : 0.033150 , test loss : 0.034939\n",
      "epoch = 51 train_loss : 0.032443 , test loss : 0.034085\n",
      "epoch = 52 train_loss : 0.031759 , test loss : 0.033297\n",
      "epoch = 53 train_loss : 0.031214 , test loss : 0.032591\n",
      "epoch = 54 train_loss : 0.030741 , test loss : 0.032012\n",
      "epoch = 55 train_loss : 0.030289 , test loss : 0.031454\n",
      "epoch = 56 train_loss : 0.029640 , test loss : 0.030855\n",
      "epoch = 57 train_loss : 0.029181 , test loss : 0.030423\n",
      "epoch = 58 train_loss : 0.028790 , test loss : 0.030002\n",
      "epoch = 59 train_loss : 0.028416 , test loss : 0.029684\n",
      "epoch = 60 train_loss : 0.028087 , test loss : 0.029366\n",
      "epoch = 61 train_loss : 0.027863 , test loss : 0.029121\n",
      "epoch = 62 train_loss : 0.027346 , test loss : 0.028698\n",
      "epoch = 63 train_loss : 0.027001 , test loss : 0.028371\n",
      "epoch = 64 train_loss : 0.026776 , test loss : 0.028172\n",
      "epoch = 65 train_loss : 0.026463 , test loss : 0.027952\n",
      "epoch = 66 train_loss : 0.026175 , test loss : 0.027742\n",
      "epoch = 67 train_loss : 0.026025 , test loss : 0.027580\n",
      "epoch = 68 train_loss : 0.025664 , test loss : 0.027255\n",
      "epoch = 69 train_loss : 0.025391 , test loss : 0.027094\n",
      "epoch = 70 train_loss : 0.025259 , test loss : 0.026980\n",
      "epoch = 71 train_loss : 0.024976 , test loss : 0.026749\n",
      "epoch = 72 train_loss : 0.024793 , test loss : 0.026550\n",
      "epoch = 73 train_loss : 0.024603 , test loss : 0.026371\n",
      "epoch = 74 train_loss : 0.024430 , test loss : 0.026207\n",
      "epoch = 76 train_loss : 0.024024 , test loss : 0.025810\n",
      "epoch = 77 train_loss : 0.023907 , test loss : 0.025797\n",
      "epoch = 78 train_loss : 0.023677 , test loss : 0.025558\n",
      "epoch = 79 train_loss : 0.023516 , test loss : 0.025320\n",
      "epoch = 81 train_loss : 0.023250 , test loss : 0.025072\n",
      "epoch = 82 train_loss : 0.023089 , test loss : 0.024897\n",
      "epoch = 83 train_loss : 0.022958 , test loss : 0.024792\n",
      "epoch = 84 train_loss : 0.022907 , test loss : 0.024653\n",
      "epoch = 85 train_loss : 0.022825 , test loss : 0.024593\n",
      "epoch = 86 train_loss : 0.022557 , test loss : 0.024310\n",
      "epoch = 87 train_loss : 0.022458 , test loss : 0.024218\n",
      "epoch = 88 train_loss : 0.022441 , test loss : 0.024181\n",
      "epoch = 89 train_loss : 0.022211 , test loss : 0.023974\n",
      "epoch = 90 train_loss : 0.022155 , test loss : 0.023891\n",
      "epoch = 91 train_loss : 0.021981 , test loss : 0.023770\n",
      "epoch = 92 train_loss : 0.021890 , test loss : 0.023665\n",
      "epoch = 93 train_loss : 0.021790 , test loss : 0.023512\n",
      "epoch = 95 train_loss : 0.021607 , test loss : 0.023248\n",
      "epoch = 96 train_loss : 0.021460 , test loss : 0.023233\n",
      "epoch = 97 train_loss : 0.021399 , test loss : 0.023121\n",
      "epoch = 98 train_loss : 0.021370 , test loss : 0.023023\n",
      "epoch = 99 train_loss : 0.021223 , test loss : 0.022946\n",
      "epoch = 100 train_loss : 0.021157 , test loss : 0.022882\n",
      "epoch = 101 train_loss : 0.021129 , test loss : 0.022840\n",
      "epoch = 102 train_loss : 0.020983 , test loss : 0.022687\n",
      "epoch = 103 train_loss : 0.020941 , test loss : 0.022617\n",
      "epoch = 105 train_loss : 0.020818 , test loss : 0.022498\n",
      "epoch = 106 train_loss : 0.020693 , test loss : 0.022383\n",
      "epoch = 107 train_loss : 0.020597 , test loss : 0.022343\n",
      "epoch = 108 train_loss : 0.020508 , test loss : 0.022245\n",
      "epoch = 109 train_loss : 0.020507 , test loss : 0.022155\n",
      "epoch = 111 train_loss : 0.020347 , test loss : 0.022060\n",
      "epoch = 112 train_loss : 0.020295 , test loss : 0.021984\n",
      "epoch = 114 train_loss : 0.020224 , test loss : 0.021935\n",
      "epoch = 115 train_loss : 0.020106 , test loss : 0.021855\n",
      "epoch = 116 train_loss : 0.020083 , test loss : 0.021787\n",
      "epoch = 119 train_loss : 0.020001 , test loss : 0.021709\n",
      "epoch = 120 train_loss : 0.019904 , test loss : 0.021682\n",
      "epoch = 121 train_loss : 0.019796 , test loss : 0.021638\n",
      "epoch = 122 train_loss : 0.019744 , test loss : 0.021590\n",
      "epoch = 123 train_loss : 0.019693 , test loss : 0.021506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 124 train_loss : 0.019654 , test loss : 0.021502\n",
      "epoch = 125 train_loss : 0.019578 , test loss : 0.021442\n",
      "epoch = 128 train_loss : 0.019451 , test loss : 0.021369\n",
      "epoch = 131 train_loss : 0.019376 , test loss : 0.021337\n",
      "epoch = 132 train_loss : 0.019295 , test loss : 0.021316\n",
      "epoch = 133 train_loss : 0.019377 , test loss : 0.021286\n",
      "epoch = 134 train_loss : 0.019208 , test loss : 0.021205\n",
      "epoch = 137 train_loss : 0.019101 , test loss : 0.021156\n",
      "epoch = 138 train_loss : 0.019061 , test loss : 0.021116\n",
      "epoch = 141 train_loss : 0.018958 , test loss : 0.021073\n",
      "epoch = 142 train_loss : 0.018928 , test loss : 0.020996\n",
      "epoch = 147 train_loss : 0.018769 , test loss : 0.020983\n",
      "epoch = 148 train_loss : 0.018738 , test loss : 0.020976\n",
      "epoch = 150 train_loss : 0.018700 , test loss : 0.020892\n",
      "epoch = 154 train_loss : 0.018616 , test loss : 0.020849\n",
      "epoch = 155 train_loss : 0.018609 , test loss : 0.020793\n",
      "epoch = 157 train_loss : 0.018467 , test loss : 0.020783\n",
      "epoch = 163 train_loss : 0.018379 , test loss : 0.020762\n",
      "epoch = 164 train_loss : 0.018392 , test loss : 0.020723\n",
      "epoch = 166 train_loss : 0.018256 , test loss : 0.020707\n",
      "epoch = 170 train_loss : 0.018170 , test loss : 0.020695\n",
      "epoch = 171 train_loss : 0.018129 , test loss : 0.020686\n",
      "epoch = 174 train_loss : 0.018059 , test loss : 0.020676\n",
      "epoch = 178 train_loss : 0.017982 , test loss : 0.020638\n",
      "epoch = 179 train_loss : 0.017978 , test loss : 0.020590\n",
      "epoch = 185 train_loss : 0.017891 , test loss : 0.020538\n",
      "epoch = 186 train_loss : 0.017840 , test loss : 0.020531\n",
      "epoch = 200 train_loss : 0.017606 , test loss : 0.020516\n",
      "epoch = 203 train_loss : 0.017560 , test loss : 0.020467\n",
      "epoch = 204 train_loss : 0.017578 , test loss : 0.020439\n",
      "epoch = 212 train_loss : 0.017442 , test loss : 0.020420\n",
      "epoch = 219 train_loss : 0.017399 , test loss : 0.020400\n",
      "epoch = 222 train_loss : 0.017351 , test loss : 0.020398\n",
      "epoch = 228 train_loss : 0.017270 , test loss : 0.020381\n",
      "epoch = 230 train_loss : 0.017235 , test loss : 0.020346\n",
      "epoch = 237 train_loss : 0.017185 , test loss : 0.020308\n",
      "epoch = 247 train_loss : 0.017067 , test loss : 0.020305\n",
      "epoch = 248 train_loss : 0.017041 , test loss : 0.020297\n",
      "epoch = 251 train_loss : 0.017043 , test loss : 0.020270\n",
      "epoch = 256 train_loss : 0.016936 , test loss : 0.020245\n",
      "epoch = 258 train_loss : 0.016918 , test loss : 0.020240\n",
      "epoch = 261 train_loss : 0.016882 , test loss : 0.020224\n",
      "epoch = 265 train_loss : 0.016876 , test loss : 0.020172\n",
      "epoch = 268 train_loss : 0.016860 , test loss : 0.020153\n",
      "epoch = 282 train_loss : 0.016718 , test loss : 0.020152\n",
      "epoch = 285 train_loss : 0.016667 , test loss : 0.020145\n",
      "epoch = 287 train_loss : 0.016691 , test loss : 0.020099\n",
      "epoch = 299 train_loss : 0.016622 , test loss : 0.020078\n",
      "epoch = 310 train_loss : 0.016507 , test loss : 0.020055\n",
      "epoch = 316 train_loss : 0.016508 , test loss : 0.020028\n",
      "epoch = 318 train_loss : 0.016464 , test loss : 0.020013\n",
      "epoch = 319 train_loss : 0.016468 , test loss : 0.019990\n",
      "epoch = 330 train_loss : 0.016431 , test loss : 0.019986\n",
      "epoch = 331 train_loss : 0.016376 , test loss : 0.019968\n",
      "epoch = 343 train_loss : 0.016387 , test loss : 0.019936\n",
      "epoch = 352 train_loss : 0.016308 , test loss : 0.019931\n",
      "epoch = 361 train_loss : 0.016247 , test loss : 0.019898\n",
      "epoch = 369 train_loss : 0.016202 , test loss : 0.019895\n",
      "epoch = 381 train_loss : 0.016165 , test loss : 0.019872\n",
      "epoch = 382 train_loss : 0.016168 , test loss : 0.019853\n",
      "epoch = 393 train_loss : 0.016090 , test loss : 0.019831\n",
      "epoch = 396 train_loss : 0.016069 , test loss : 0.019828\n",
      "epoch = 421 train_loss : 0.015976 , test loss : 0.019815\n",
      "epoch = 431 train_loss : 0.015930 , test loss : 0.019805\n",
      "epoch = 447 train_loss : 0.015925 , test loss : 0.019790\n",
      "epoch = 462 train_loss : 0.015926 , test loss : 0.019771\n",
      "epoch = 473 train_loss : 0.015801 , test loss : 0.019727\n",
      "epoch = 528 train_loss : 0.015691 , test loss : 0.019718\n",
      "epoch = 544 train_loss : 0.015631 , test loss : 0.019688\n",
      "train log loss:  0.015630897134542465\n",
      "test log loss:  0.020050864666700363\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.015631,test loss : 0.019688\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 2.618947 , test loss : 2.619514\n",
      "epoch = 2 train_loss : 2.581752 , test loss : 2.583946\n",
      "epoch = 3 train_loss : 1.881110 , test loss : 1.883165\n",
      "epoch = 4 train_loss : 1.102987 , test loss : 1.103597\n",
      "epoch = 5 train_loss : 0.655852 , test loss : 0.654428\n",
      "epoch = 6 train_loss : 0.465159 , test loss : 0.461912\n",
      "epoch = 7 train_loss : 0.400261 , test loss : 0.396278\n",
      "epoch = 8 train_loss : 0.368058 , test loss : 0.363785\n",
      "epoch = 9 train_loss : 0.350723 , test loss : 0.346456\n",
      "epoch = 10 train_loss : 0.337586 , test loss : 0.333417\n",
      "epoch = 11 train_loss : 0.326097 , test loss : 0.322014\n",
      "epoch = 12 train_loss : 0.315342 , test loss : 0.311349\n",
      "epoch = 13 train_loss : 0.304538 , test loss : 0.300645\n",
      "epoch = 14 train_loss : 0.289232 , test loss : 0.285314\n",
      "epoch = 15 train_loss : 0.278771 , test loss : 0.274986\n",
      "epoch = 16 train_loss : 0.270008 , test loss : 0.266414\n",
      "epoch = 17 train_loss : 0.255100 , test loss : 0.251497\n",
      "epoch = 18 train_loss : 0.248486 , test loss : 0.245132\n",
      "epoch = 19 train_loss : 0.234983 , test loss : 0.231641\n",
      "epoch = 20 train_loss : 0.225234 , test loss : 0.222028\n",
      "epoch = 21 train_loss : 0.217369 , test loss : 0.214325\n",
      "epoch = 22 train_loss : 0.211730 , test loss : 0.208870\n",
      "epoch = 23 train_loss : 0.197205 , test loss : 0.194336\n",
      "epoch = 24 train_loss : 0.187738 , test loss : 0.184954\n",
      "epoch = 25 train_loss : 0.176774 , test loss : 0.174034\n",
      "epoch = 26 train_loss : 0.167886 , test loss : 0.165214\n",
      "epoch = 27 train_loss : 0.160807 , test loss : 0.158262\n",
      "epoch = 28 train_loss : 0.151307 , test loss : 0.148798\n",
      "epoch = 29 train_loss : 0.144270 , test loss : 0.141921\n",
      "epoch = 30 train_loss : 0.133162 , test loss : 0.130911\n",
      "epoch = 31 train_loss : 0.125057 , test loss : 0.122883\n",
      "epoch = 32 train_loss : 0.116483 , test loss : 0.114427\n",
      "epoch = 33 train_loss : 0.110840 , test loss : 0.108882\n",
      "epoch = 34 train_loss : 0.101673 , test loss : 0.099763\n",
      "epoch = 35 train_loss : 0.095364 , test loss : 0.093507\n",
      "epoch = 36 train_loss : 0.088573 , test loss : 0.086737\n",
      "epoch = 37 train_loss : 0.082741 , test loss : 0.080915\n",
      "epoch = 38 train_loss : 0.079280 , test loss : 0.077393\n",
      "epoch = 39 train_loss : 0.072154 , test loss : 0.070202\n",
      "epoch = 40 train_loss : 0.067650 , test loss : 0.065626\n",
      "epoch = 41 train_loss : 0.064298 , test loss : 0.062209\n",
      "epoch = 42 train_loss : 0.061061 , test loss : 0.058948\n",
      "epoch = 43 train_loss : 0.057852 , test loss : 0.055675\n",
      "epoch = 44 train_loss : 0.054885 , test loss : 0.052629\n",
      "epoch = 45 train_loss : 0.052570 , test loss : 0.050350\n",
      "epoch = 46 train_loss : 0.050266 , test loss : 0.048051\n",
      "epoch = 47 train_loss : 0.048304 , test loss : 0.046099\n",
      "epoch = 48 train_loss : 0.046363 , test loss : 0.044211\n",
      "epoch = 49 train_loss : 0.044638 , test loss : 0.042494\n",
      "epoch = 50 train_loss : 0.043094 , test loss : 0.041003\n",
      "epoch = 51 train_loss : 0.041798 , test loss : 0.039780\n",
      "epoch = 52 train_loss : 0.040392 , test loss : 0.038374\n",
      "epoch = 54 train_loss : 0.038225 , test loss : 0.036279\n",
      "epoch = 55 train_loss : 0.037154 , test loss : 0.035269\n",
      "epoch = 56 train_loss : 0.036336 , test loss : 0.034512\n",
      "epoch = 57 train_loss : 0.035433 , test loss : 0.033631\n",
      "epoch = 58 train_loss : 0.034514 , test loss : 0.032733\n",
      "epoch = 59 train_loss : 0.033936 , test loss : 0.032305\n",
      "epoch = 60 train_loss : 0.033591 , test loss : 0.031936\n",
      "epoch = 61 train_loss : 0.032416 , test loss : 0.030860\n",
      "epoch = 62 train_loss : 0.031885 , test loss : 0.030425\n",
      "epoch = 63 train_loss : 0.031201 , test loss : 0.029771\n",
      "epoch = 64 train_loss : 0.030689 , test loss : 0.029326\n",
      "epoch = 65 train_loss : 0.030235 , test loss : 0.028934\n",
      "epoch = 66 train_loss : 0.029777 , test loss : 0.028595\n",
      "epoch = 67 train_loss : 0.029292 , test loss : 0.028151\n",
      "epoch = 68 train_loss : 0.028807 , test loss : 0.027734\n",
      "epoch = 69 train_loss : 0.028413 , test loss : 0.027417\n",
      "epoch = 70 train_loss : 0.028030 , test loss : 0.027113\n",
      "epoch = 72 train_loss : 0.027321 , test loss : 0.026537\n",
      "epoch = 73 train_loss : 0.027046 , test loss : 0.026332\n",
      "epoch = 74 train_loss : 0.026734 , test loss : 0.026123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 75 train_loss : 0.026421 , test loss : 0.025811\n",
      "epoch = 76 train_loss : 0.026131 , test loss : 0.025587\n",
      "epoch = 78 train_loss : 0.025668 , test loss : 0.025257\n",
      "epoch = 79 train_loss : 0.025440 , test loss : 0.025068\n",
      "epoch = 80 train_loss : 0.025217 , test loss : 0.024872\n",
      "epoch = 81 train_loss : 0.025023 , test loss : 0.024691\n",
      "epoch = 82 train_loss : 0.024842 , test loss : 0.024567\n",
      "epoch = 83 train_loss : 0.024644 , test loss : 0.024370\n",
      "epoch = 84 train_loss : 0.024466 , test loss : 0.024276\n",
      "epoch = 85 train_loss : 0.024238 , test loss : 0.024045\n",
      "epoch = 86 train_loss : 0.024088 , test loss : 0.023921\n",
      "epoch = 87 train_loss : 0.024040 , test loss : 0.023873\n",
      "epoch = 88 train_loss : 0.023839 , test loss : 0.023717\n",
      "epoch = 89 train_loss : 0.023651 , test loss : 0.023565\n",
      "epoch = 90 train_loss : 0.023517 , test loss : 0.023414\n",
      "epoch = 91 train_loss : 0.023349 , test loss : 0.023267\n",
      "epoch = 93 train_loss : 0.023082 , test loss : 0.023018\n",
      "epoch = 94 train_loss : 0.023041 , test loss : 0.023010\n",
      "epoch = 95 train_loss : 0.022855 , test loss : 0.022810\n",
      "epoch = 96 train_loss : 0.022731 , test loss : 0.022710\n",
      "epoch = 98 train_loss : 0.022511 , test loss : 0.022498\n",
      "epoch = 99 train_loss : 0.022489 , test loss : 0.022492\n",
      "epoch = 100 train_loss : 0.022311 , test loss : 0.022314\n",
      "epoch = 101 train_loss : 0.022156 , test loss : 0.022145\n",
      "epoch = 102 train_loss : 0.022042 , test loss : 0.022013\n",
      "epoch = 104 train_loss : 0.021880 , test loss : 0.021911\n",
      "epoch = 105 train_loss : 0.021790 , test loss : 0.021788\n",
      "epoch = 106 train_loss : 0.021672 , test loss : 0.021705\n",
      "epoch = 107 train_loss : 0.021589 , test loss : 0.021642\n",
      "epoch = 108 train_loss : 0.021487 , test loss : 0.021515\n",
      "epoch = 109 train_loss : 0.021446 , test loss : 0.021493\n",
      "epoch = 110 train_loss : 0.021328 , test loss : 0.021345\n",
      "epoch = 111 train_loss : 0.021295 , test loss : 0.021334\n",
      "epoch = 112 train_loss : 0.021165 , test loss : 0.021209\n",
      "epoch = 113 train_loss : 0.021092 , test loss : 0.021109\n",
      "epoch = 114 train_loss : 0.021134 , test loss : 0.021107\n",
      "epoch = 115 train_loss : 0.020999 , test loss : 0.021053\n",
      "epoch = 116 train_loss : 0.020946 , test loss : 0.021005\n",
      "epoch = 117 train_loss : 0.020787 , test loss : 0.020818\n",
      "epoch = 118 train_loss : 0.020708 , test loss : 0.020752\n",
      "epoch = 119 train_loss : 0.020653 , test loss : 0.020702\n",
      "epoch = 121 train_loss : 0.020524 , test loss : 0.020587\n",
      "epoch = 122 train_loss : 0.020505 , test loss : 0.020583\n",
      "epoch = 123 train_loss : 0.020432 , test loss : 0.020471\n",
      "epoch = 124 train_loss : 0.020395 , test loss : 0.020469\n",
      "epoch = 125 train_loss : 0.020380 , test loss : 0.020465\n",
      "epoch = 126 train_loss : 0.020258 , test loss : 0.020346\n",
      "epoch = 128 train_loss : 0.020113 , test loss : 0.020154\n",
      "epoch = 130 train_loss : 0.020065 , test loss : 0.020115\n",
      "epoch = 132 train_loss : 0.019921 , test loss : 0.019984\n",
      "epoch = 133 train_loss : 0.019880 , test loss : 0.019950\n",
      "epoch = 134 train_loss : 0.019901 , test loss : 0.019931\n",
      "epoch = 135 train_loss : 0.019777 , test loss : 0.019791\n",
      "epoch = 138 train_loss : 0.019668 , test loss : 0.019711\n",
      "epoch = 139 train_loss : 0.019603 , test loss : 0.019655\n",
      "epoch = 140 train_loss : 0.019569 , test loss : 0.019616\n",
      "epoch = 142 train_loss : 0.019580 , test loss : 0.019607\n",
      "epoch = 143 train_loss : 0.019442 , test loss : 0.019466\n",
      "epoch = 145 train_loss : 0.019334 , test loss : 0.019385\n",
      "epoch = 146 train_loss : 0.019327 , test loss : 0.019366\n",
      "epoch = 147 train_loss : 0.019277 , test loss : 0.019339\n",
      "epoch = 148 train_loss : 0.019238 , test loss : 0.019284\n",
      "epoch = 150 train_loss : 0.019207 , test loss : 0.019223\n",
      "epoch = 153 train_loss : 0.019081 , test loss : 0.019096\n",
      "epoch = 154 train_loss : 0.019010 , test loss : 0.019052\n",
      "epoch = 156 train_loss : 0.018971 , test loss : 0.019025\n",
      "epoch = 157 train_loss : 0.018955 , test loss : 0.019011\n",
      "epoch = 158 train_loss : 0.018893 , test loss : 0.018943\n",
      "epoch = 160 train_loss : 0.018839 , test loss : 0.018882\n",
      "epoch = 161 train_loss : 0.018803 , test loss : 0.018824\n",
      "epoch = 162 train_loss : 0.018781 , test loss : 0.018817\n",
      "epoch = 165 train_loss : 0.018703 , test loss : 0.018734\n",
      "epoch = 166 train_loss : 0.018676 , test loss : 0.018731\n",
      "epoch = 167 train_loss : 0.018620 , test loss : 0.018659\n",
      "epoch = 171 train_loss : 0.018518 , test loss : 0.018555\n",
      "epoch = 173 train_loss : 0.018483 , test loss : 0.018525\n",
      "epoch = 175 train_loss : 0.018491 , test loss : 0.018516\n",
      "epoch = 176 train_loss : 0.018391 , test loss : 0.018453\n",
      "epoch = 177 train_loss : 0.018367 , test loss : 0.018436\n",
      "epoch = 179 train_loss : 0.018306 , test loss : 0.018394\n",
      "epoch = 180 train_loss : 0.018331 , test loss : 0.018389\n",
      "epoch = 181 train_loss : 0.018275 , test loss : 0.018354\n",
      "epoch = 182 train_loss : 0.018247 , test loss : 0.018332\n",
      "epoch = 183 train_loss : 0.018229 , test loss : 0.018328\n",
      "epoch = 184 train_loss : 0.018220 , test loss : 0.018316\n",
      "epoch = 186 train_loss : 0.018222 , test loss : 0.018307\n",
      "epoch = 187 train_loss : 0.018171 , test loss : 0.018249\n",
      "epoch = 189 train_loss : 0.018118 , test loss : 0.018203\n",
      "epoch = 191 train_loss : 0.018052 , test loss : 0.018137\n",
      "epoch = 194 train_loss : 0.018007 , test loss : 0.018105\n",
      "epoch = 196 train_loss : 0.017946 , test loss : 0.018061\n",
      "epoch = 199 train_loss : 0.017925 , test loss : 0.018028\n",
      "epoch = 201 train_loss : 0.017919 , test loss : 0.018025\n",
      "epoch = 203 train_loss : 0.017823 , test loss : 0.017935\n",
      "epoch = 207 train_loss : 0.017757 , test loss : 0.017884\n",
      "epoch = 210 train_loss : 0.017752 , test loss : 0.017872\n",
      "epoch = 211 train_loss : 0.017734 , test loss : 0.017871\n",
      "epoch = 212 train_loss : 0.017689 , test loss : 0.017818\n",
      "epoch = 213 train_loss : 0.017656 , test loss : 0.017797\n",
      "epoch = 217 train_loss : 0.017596 , test loss : 0.017741\n",
      "epoch = 221 train_loss : 0.017542 , test loss : 0.017706\n",
      "epoch = 222 train_loss : 0.017554 , test loss : 0.017695\n",
      "epoch = 223 train_loss : 0.017515 , test loss : 0.017686\n",
      "epoch = 224 train_loss : 0.017514 , test loss : 0.017678\n",
      "epoch = 225 train_loss : 0.017510 , test loss : 0.017670\n",
      "epoch = 227 train_loss : 0.017457 , test loss : 0.017621\n",
      "epoch = 229 train_loss : 0.017450 , test loss : 0.017620\n",
      "epoch = 230 train_loss : 0.017415 , test loss : 0.017599\n",
      "epoch = 231 train_loss : 0.017427 , test loss : 0.017599\n",
      "epoch = 233 train_loss : 0.017388 , test loss : 0.017575\n",
      "epoch = 235 train_loss : 0.017354 , test loss : 0.017549\n",
      "epoch = 236 train_loss : 0.017342 , test loss : 0.017534\n",
      "epoch = 238 train_loss : 0.017323 , test loss : 0.017513\n",
      "epoch = 241 train_loss : 0.017278 , test loss : 0.017493\n",
      "epoch = 243 train_loss : 0.017271 , test loss : 0.017465\n",
      "epoch = 244 train_loss : 0.017285 , test loss : 0.017461\n",
      "epoch = 247 train_loss : 0.017219 , test loss : 0.017425\n",
      "epoch = 251 train_loss : 0.017194 , test loss : 0.017407\n",
      "epoch = 252 train_loss : 0.017171 , test loss : 0.017382\n",
      "epoch = 257 train_loss : 0.017143 , test loss : 0.017376\n",
      "epoch = 259 train_loss : 0.017098 , test loss : 0.017324\n",
      "epoch = 262 train_loss : 0.017100 , test loss : 0.017318\n",
      "epoch = 265 train_loss : 0.017103 , test loss : 0.017311\n",
      "epoch = 267 train_loss : 0.017013 , test loss : 0.017254\n",
      "epoch = 271 train_loss : 0.017011 , test loss : 0.017252\n",
      "epoch = 276 train_loss : 0.016951 , test loss : 0.017221\n",
      "epoch = 277 train_loss : 0.016964 , test loss : 0.017197\n",
      "epoch = 279 train_loss : 0.016911 , test loss : 0.017162\n",
      "epoch = 285 train_loss : 0.016859 , test loss : 0.017128\n",
      "epoch = 292 train_loss : 0.016800 , test loss : 0.017087\n",
      "epoch = 298 train_loss : 0.016793 , test loss : 0.017084\n",
      "epoch = 299 train_loss : 0.016773 , test loss : 0.017078\n",
      "epoch = 302 train_loss : 0.016747 , test loss : 0.017045\n",
      "epoch = 304 train_loss : 0.016722 , test loss : 0.017024\n",
      "epoch = 307 train_loss : 0.016702 , test loss : 0.017023\n",
      "epoch = 308 train_loss : 0.016698 , test loss : 0.017005\n",
      "epoch = 313 train_loss : 0.016655 , test loss : 0.016991\n",
      "epoch = 316 train_loss : 0.016631 , test loss : 0.016962\n",
      "epoch = 319 train_loss : 0.016645 , test loss : 0.016956\n",
      "epoch = 323 train_loss : 0.016597 , test loss : 0.016948\n",
      "epoch = 327 train_loss : 0.016579 , test loss : 0.016939\n",
      "epoch = 328 train_loss : 0.016547 , test loss : 0.016908\n",
      "epoch = 338 train_loss : 0.016509 , test loss : 0.016882\n",
      "epoch = 339 train_loss : 0.016495 , test loss : 0.016866\n",
      "epoch = 341 train_loss : 0.016472 , test loss : 0.016859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 346 train_loss : 0.016452 , test loss : 0.016855\n",
      "epoch = 348 train_loss : 0.016433 , test loss : 0.016847\n",
      "epoch = 350 train_loss : 0.016432 , test loss : 0.016831\n",
      "epoch = 354 train_loss : 0.016420 , test loss : 0.016817\n",
      "epoch = 356 train_loss : 0.016387 , test loss : 0.016807\n",
      "epoch = 360 train_loss : 0.016384 , test loss : 0.016802\n",
      "epoch = 363 train_loss : 0.016362 , test loss : 0.016778\n",
      "epoch = 364 train_loss : 0.016338 , test loss : 0.016773\n",
      "epoch = 368 train_loss : 0.016343 , test loss : 0.016753\n",
      "epoch = 372 train_loss : 0.016332 , test loss : 0.016745\n",
      "epoch = 376 train_loss : 0.016305 , test loss : 0.016726\n",
      "epoch = 383 train_loss : 0.016248 , test loss : 0.016699\n",
      "epoch = 386 train_loss : 0.016226 , test loss : 0.016696\n",
      "epoch = 391 train_loss : 0.016210 , test loss : 0.016679\n",
      "epoch = 396 train_loss : 0.016185 , test loss : 0.016653\n",
      "epoch = 401 train_loss : 0.016193 , test loss : 0.016644\n",
      "epoch = 406 train_loss : 0.016162 , test loss : 0.016643\n",
      "epoch = 408 train_loss : 0.016151 , test loss : 0.016636\n",
      "epoch = 412 train_loss : 0.016119 , test loss : 0.016630\n",
      "epoch = 415 train_loss : 0.016112 , test loss : 0.016627\n",
      "epoch = 416 train_loss : 0.016098 , test loss : 0.016584\n",
      "epoch = 425 train_loss : 0.016059 , test loss : 0.016578\n",
      "epoch = 431 train_loss : 0.016040 , test loss : 0.016560\n",
      "epoch = 437 train_loss : 0.016032 , test loss : 0.016555\n",
      "epoch = 440 train_loss : 0.016025 , test loss : 0.016551\n",
      "epoch = 444 train_loss : 0.015983 , test loss : 0.016526\n",
      "epoch = 446 train_loss : 0.015994 , test loss : 0.016521\n",
      "epoch = 456 train_loss : 0.015958 , test loss : 0.016505\n",
      "epoch = 464 train_loss : 0.015928 , test loss : 0.016484\n",
      "epoch = 475 train_loss : 0.015901 , test loss : 0.016481\n",
      "epoch = 477 train_loss : 0.015886 , test loss : 0.016453\n",
      "epoch = 495 train_loss : 0.015847 , test loss : 0.016445\n",
      "epoch = 505 train_loss : 0.015809 , test loss : 0.016424\n",
      "epoch = 513 train_loss : 0.015777 , test loss : 0.016406\n",
      "epoch = 524 train_loss : 0.015738 , test loss : 0.016382\n",
      "epoch = 536 train_loss : 0.015718 , test loss : 0.016372\n",
      "epoch = 541 train_loss : 0.015717 , test loss : 0.016366\n",
      "epoch = 558 train_loss : 0.015680 , test loss : 0.016359\n",
      "epoch = 570 train_loss : 0.015642 , test loss : 0.016358\n",
      "epoch = 573 train_loss : 0.015654 , test loss : 0.016346\n",
      "epoch = 575 train_loss : 0.015618 , test loss : 0.016312\n",
      "epoch = 579 train_loss : 0.015604 , test loss : 0.016311\n",
      "epoch = 591 train_loss : 0.015580 , test loss : 0.016305\n",
      "epoch = 598 train_loss : 0.015581 , test loss : 0.016300\n",
      "epoch = 603 train_loss : 0.015555 , test loss : 0.016292\n",
      "epoch = 609 train_loss : 0.015536 , test loss : 0.016273\n",
      "epoch = 618 train_loss : 0.015528 , test loss : 0.016267\n",
      "epoch = 624 train_loss : 0.015512 , test loss : 0.016264\n",
      "epoch = 644 train_loss : 0.015474 , test loss : 0.016250\n",
      "epoch = 647 train_loss : 0.015474 , test loss : 0.016238\n",
      "epoch = 654 train_loss : 0.015474 , test loss : 0.016227\n",
      "epoch = 669 train_loss : 0.015430 , test loss : 0.016222\n",
      "epoch = 670 train_loss : 0.015426 , test loss : 0.016216\n",
      "epoch = 690 train_loss : 0.015401 , test loss : 0.016214\n",
      "epoch = 692 train_loss : 0.015388 , test loss : 0.016212\n",
      "epoch = 697 train_loss : 0.015394 , test loss : 0.016203\n",
      "epoch = 713 train_loss : 0.015363 , test loss : 0.016181\n",
      "epoch = 748 train_loss : 0.015331 , test loss : 0.016178\n",
      "epoch = 755 train_loss : 0.015295 , test loss : 0.016172\n",
      "epoch = 756 train_loss : 0.015304 , test loss : 0.016169\n",
      "epoch = 761 train_loss : 0.015319 , test loss : 0.016156\n",
      "epoch = 771 train_loss : 0.015280 , test loss : 0.016149\n",
      "epoch = 795 train_loss : 0.015245 , test loss : 0.016148\n",
      "epoch = 809 train_loss : 0.015215 , test loss : 0.016147\n",
      "epoch = 812 train_loss : 0.015218 , test loss : 0.016135\n",
      "epoch = 821 train_loss : 0.015196 , test loss : 0.016123\n",
      "epoch = 853 train_loss : 0.015158 , test loss : 0.016106\n",
      "epoch = 915 train_loss : 0.015083 , test loss : 0.016099\n",
      "epoch = 934 train_loss : 0.015071 , test loss : 0.016098\n",
      "epoch = 953 train_loss : 0.015043 , test loss : 0.016079\n",
      "epoch = 1283 train_loss : 0.014747 , test loss : 0.016078\n",
      "train log loss:  0.014747404493391514\n",
      "test log loss:  0.01628529094159603\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.014747,test loss : 0.016078\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.014665,total test loss mean : 0.017312 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(train_features.shape[1],256),nn.ReLU(),nn.Linear(256,128),nn.ReLU(),nn.Linear(128,64),nn.ReLU(),nn.Linear(64,32),\n",
    "                        nn.ReLU(),nn.Linear(32,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,100000,0.00002,5,train_features,train_labels,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-12T08:40:45.841Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(train_features.shape[1],128),nn.ReLU(),nn.Linear(128,64),nn.ReLU(),nn.Linear(64,32),nn.ReLU(),nn.Linear(32,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,100000,0.0002,5,train_features,train_labels,128,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
