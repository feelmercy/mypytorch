{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:11:48.431337Z",
     "start_time": "2022-04-19T02:11:47.004156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch import optim,nn\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew,kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:11:49.106923Z",
     "start_time": "2022-04-19T02:11:49.039414Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\train.csv',encoding='big5')\n",
    "test_data=pd.read_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\test.csv',encoding='big5',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:11:49.530477Z",
     "start_time": "2022-04-19T02:11:49.522976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (4320, 27)\n",
      "test_data shape:  (4320, 11)\n"
     ]
    }
   ],
   "source": [
    "print('train_data shape: ',train_data.shape)\n",
    "print('test_data shape: ',test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:11:50.047042Z",
     "start_time": "2022-04-19T02:11:50.015038Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data1=train_data.replace('NR',0)\n",
    "train_data1=train_data1.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:16.979962Z",
     "start_time": "2022-04-19T02:12:16.793439Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data={}\n",
    "for m in range(12):\n",
    "    month_data=np.empty((18,20*24))\n",
    "    for d in range(20):\n",
    "        month_data[:,d*24:(d+1)*24]=train_data1.iloc[m*20*18+d*18:m*20*18+(d+1)*18,:]\n",
    "    year_data[m]=month_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:18.144110Z",
     "start_time": "2022-04-19T02:12:18.119607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data1=year_data.copy()\n",
    "month_list=[]\n",
    "for i in range(12):\n",
    "    month_list.append(pd.DataFrame(year_data1[i]))\n",
    "all_train_data1=pd.concat(month_list,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:18.626171Z",
     "start_time": "2022-04-19T02:12:18.614670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.527413194444442"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.iloc[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:19.127735Z",
     "start_time": "2022-04-19T02:12:19.117234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 5760)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:19.644801Z",
     "start_time": "2022-04-19T02:12:19.601295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      "---------- pm2.5 start : \n",
      " -3.1 \n",
      "\n",
      "-8.0\n",
      "-7.2\n",
      "-6.8\n",
      "-6.5\n",
      "-7.1\n",
      "-7.4\n",
      "-8.1\n",
      "-8.3\n",
      "-8.4\n",
      "-9.3\n",
      "-10.6\n",
      "-11.2\n",
      "-12.1\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-12.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 19.0 18.0\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n"
     ]
    }
   ],
   "source": [
    "# temperature always >=0 in Taiwan and change fast when temperature <=0 ,so correct it\n",
    "for idx in [0]:\t\n",
    "\tfor m in range(12):\n",
    "\t\tprint(' month : ',m)\n",
    "\t\ti=0\n",
    "\t\twhile i<480:\n",
    "\t\t\tif year_data1[m][idx,i] <=0:\n",
    "\t\t\t\tprint('---------- pm2.5 start : \\n',year_data1[m][idx,i],'\\n')\n",
    "\t\t\t\tfor k in range(30):\n",
    "\t\t\t\t\tif k+i+1>479:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif year_data1[m][idx,k+i+1] >0:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(year_data1[m][idx,k+i+1])\n",
    "\t\t\t\ti=i+k\n",
    "\t\t\t\tprint('pm2.5 end ------------')\n",
    "\t\t\t\tprint('correct value between  :',year_data1[m][idx,i-1-k],year_data1[m][idx,i+1])\n",
    "\t\t\t\t## add correct to mean value\n",
    "\t\t\t\tyear_data1[m][idx,i-k:i+1]=(year_data1[m][idx,i-1-k]+year_data1[m][idx,i+1])/2\n",
    "\t\t\ti=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:20.377894Z",
     "start_time": "2022-04-19T02:12:20.265879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.8 1.8\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.12 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.34 0.26\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.5 0.3\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.1 1.0\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -1.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 6.6 1.2\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      "---------- pm2.5 start : \n",
      " -0.9 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 17.0 17.0\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 7.4 10.0\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -2.4 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 7.0 6.6\n",
      " month :  11\n",
      " month :  0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 46.0 51.0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 6.0 16.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 13.0 16.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 55.0 48.0\n",
      " month :  4\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 5.0 1.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.0 4.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 5.0 0.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 10.0 9.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 9.0 2.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 4.0\n",
      " month :  5\n",
      " month :  6\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 20.0 27.0\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 18.0 18.0\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 13.0 7.0\n",
      " month :  0\n",
      "---------- pm2.5 start : \n",
      " -0.9 \n",
      "\n",
      "-0.9\n",
      "-0.9\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.6 1.3\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "-0.1\n",
      "-0.2\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.1 1.2\n",
      " month :  1\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.1 0.3\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      "---------- pm2.5 start : \n",
      " -1.5 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.2 2.3\n",
      "---------- pm2.5 start : \n",
      " -0.3 \n",
      "\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 3.8 2.2\n",
      " month :  6\n",
      " month :  7\n",
      "---------- pm2.5 start : \n",
      " -1.6 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 4.3 2.7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 0.9\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.2 0.3\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.4\n",
      "-0.5\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 1.2\n",
      "---------- pm2.5 start : \n",
      " -0.3 \n",
      "\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 1.1\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.8 2.0\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.0 1.9\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2,4,6,9,12,13]:\t\n",
    "\tfor m in range(12):\n",
    "\t\tprint(' month : ',m)\n",
    "\t\ti=0\n",
    "\t\twhile i<480:\n",
    "\t\t\tif year_data1[m][idx,i] <0:\n",
    "\t\t\t\tprint('---------- pm2.5 start : \\n',year_data1[m][idx,i],'\\n')\n",
    "\t\t\t\tfor k in range(30):\n",
    "\t\t\t\t\tif k+i+1>479:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif year_data1[m][idx,k+i+1] >=0:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(year_data1[m][idx,k+i+1])\n",
    "\t\t\t\ti=i+k\n",
    "\t\t\t\tprint('pm2.5 end ------------')\n",
    "\t\t\t\tprint('correct value between  :',year_data1[m][idx,i-1-k],year_data1[m][idx,i+1])\n",
    "\t\t\t\t## add correct to mean value\n",
    "\t\t\t\tyear_data1[m][idx,i-k:i+1]=(year_data1[m][idx,i-1-k]+year_data1[m][idx,i+1])/2\n",
    "\t\t\ti=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:20.896960Z",
     "start_time": "2022-04-19T02:12:20.884458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14.00\n",
       "1     1.80\n",
       "2     0.51\n",
       "3     0.20\n",
       "4     0.90\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.iloc[0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:21.459531Z",
     "start_time": "2022-04-19T02:12:21.407024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_data2=all_train_data1.apply(lambda x : (x-x.mean())/x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:22.174622Z",
     "start_time": "2022-04-19T02:12:22.085110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.527413</td>\n",
       "      <td>1.702396</td>\n",
       "      <td>0.388363</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.135729</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.247726</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.414236</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.763125</td>\n",
       "      <td>1.839653</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.290152</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>0.323573</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.282155</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.577133</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.662537</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.816940</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.300000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.527413     1.702396     0.388363     0.140427     2.135729   \n",
       "std       6.290152     0.125265     0.323573     0.104645     2.282155   \n",
       "min     -12.300000    -0.200000    -0.120000     0.000000    -1.100000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.247726    31.905469    42.709201    21.414236   \n",
       "std       6.187555     7.577133    18.703486    26.222292    16.662537   \n",
       "min       0.000000    -2.400000     0.000000     0.000000    -1.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    29.250000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.763125     1.839653   156.329271   \n",
       "std       2.045443    13.361351     1.816940     0.181839    95.745881   \n",
       "min       0.000000    29.000000    -1.600000    -0.200000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:22.710190Z",
     "start_time": "2022-04-19T02:12:22.701189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.527413194444442"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.iloc[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:23.252259Z",
     "start_time": "2022-04-19T02:12:23.241757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.355677\n",
       "1   -1.355677\n",
       "2   -1.355677\n",
       "3   -1.514655\n",
       "4   -1.673634\n",
       "5   -1.673634\n",
       "6   -1.673634\n",
       "7   -1.673634\n",
       "8   -1.196698\n",
       "9   -0.878741\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.iloc[0:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:23.897841Z",
     "start_time": "2022-04-19T02:12:23.817330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.921351e-15</td>\n",
       "      <td>-4.132630e-13</td>\n",
       "      <td>-1.393800e-14</td>\n",
       "      <td>5.078230e-15</td>\n",
       "      <td>3.474738e-15</td>\n",
       "      <td>-2.338465e-15</td>\n",
       "      <td>-3.438183e-15</td>\n",
       "      <td>-4.431640e-16</td>\n",
       "      <td>2.485088e-16</td>\n",
       "      <td>1.855094e-16</td>\n",
       "      <td>4.130921e-15</td>\n",
       "      <td>-9.199431e-16</td>\n",
       "      <td>5.026265e-16</td>\n",
       "      <td>3.205650e-13</td>\n",
       "      <td>8.574353e-17</td>\n",
       "      <td>5.245418e-16</td>\n",
       "      <td>5.851993e-16</td>\n",
       "      <td>1.040902e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.536816e+00</td>\n",
       "      <td>-1.518692e+01</td>\n",
       "      <td>-1.571093e+00</td>\n",
       "      <td>-1.341940e+00</td>\n",
       "      <td>-1.417839e+00</td>\n",
       "      <td>-1.636509e+00</td>\n",
       "      <td>-1.933149e+00</td>\n",
       "      <td>-1.705857e+00</td>\n",
       "      <td>-1.628736e+00</td>\n",
       "      <td>-1.345187e+00</td>\n",
       "      <td>-9.808389e-02</td>\n",
       "      <td>-3.310232e+00</td>\n",
       "      <td>-2.401358e+00</td>\n",
       "      <td>-1.121682e+01</td>\n",
       "      <td>-1.631707e+00</td>\n",
       "      <td>-1.673570e+00</td>\n",
       "      <td>-2.156207e+00</td>\n",
       "      <td>-1.611732e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.197621e-01</td>\n",
       "      <td>-8.174309e-01</td>\n",
       "      <td>-4.276098e-01</td>\n",
       "      <td>-6.730107e-01</td>\n",
       "      <td>-4.538382e-01</td>\n",
       "      <td>-6.829821e-01</td>\n",
       "      <td>-6.529812e-01</td>\n",
       "      <td>-7.434694e-01</td>\n",
       "      <td>-7.134846e-01</td>\n",
       "      <td>-7.450388e-01</td>\n",
       "      <td>-9.808389e-02</td>\n",
       "      <td>-6.907360e-01</td>\n",
       "      <td>-6.401558e-01</td>\n",
       "      <td>-7.680033e-01</td>\n",
       "      <td>-8.807613e-01</td>\n",
       "      <td>-8.710141e-01</td>\n",
       "      <td>-7.482952e-01</td>\n",
       "      <td>-7.648192e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.513122e-02</td>\n",
       "      <td>-1.912605e-02</td>\n",
       "      <td>-1.494652e-01</td>\n",
       "      <td>-2.907653e-01</td>\n",
       "      <td>-2.347470e-01</td>\n",
       "      <td>-2.466224e-01</td>\n",
       "      <td>-2.966459e-01</td>\n",
       "      <td>-1.553437e-01</td>\n",
       "      <td>-1.795877e-01</td>\n",
       "      <td>-2.049049e-01</td>\n",
       "      <td>-9.808389e-02</td>\n",
       "      <td>1.325340e-01</td>\n",
       "      <td>-2.548928e-01</td>\n",
       "      <td>-2.180656e-01</td>\n",
       "      <td>-3.898786e-01</td>\n",
       "      <td>-3.905364e-01</td>\n",
       "      <td>-1.851306e-01</td>\n",
       "      <td>-2.002106e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.110459e-01</td>\n",
       "      <td>7.791788e-01</td>\n",
       "      <td>1.904894e-01</td>\n",
       "      <td>3.781641e-01</td>\n",
       "      <td>7.198057e-02</td>\n",
       "      <td>4.644824e-01</td>\n",
       "      <td>3.632342e-01</td>\n",
       "      <td>5.397139e-01</td>\n",
       "      <td>5.449866e-01</td>\n",
       "      <td>4.702623e-01</td>\n",
       "      <td>-9.808389e-02</td>\n",
       "      <td>8.061186e-01</td>\n",
       "      <td>3.505206e-01</td>\n",
       "      <td>3.318721e-01</td>\n",
       "      <td>5.918869e-01</td>\n",
       "      <td>6.390586e-01</td>\n",
       "      <td>5.657555e-01</td>\n",
       "      <td>5.526008e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.141854e+00</td>\n",
       "      <td>2.375788e+00</td>\n",
       "      <td>2.219482e+01</td>\n",
       "      <td>1.108104e+01</td>\n",
       "      <td>1.264781e+01</td>\n",
       "      <td>5.797768e+00</td>\n",
       "      <td>7.753892e+00</td>\n",
       "      <td>1.064478e+01</td>\n",
       "      <td>5.273788e+00</td>\n",
       "      <td>5.436493e+00</td>\n",
       "      <td>3.607990e+01</td>\n",
       "      <td>1.928760e+00</td>\n",
       "      <td>1.058751e+01</td>\n",
       "      <td>6.381187e+00</td>\n",
       "      <td>2.127201e+00</td>\n",
       "      <td>2.128011e+00</td>\n",
       "      <td>5.071072e+00</td>\n",
       "      <td>4.975368e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean   2.921351e-15 -4.132630e-13 -1.393800e-14  5.078230e-15  3.474738e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.536816e+00 -1.518692e+01 -1.571093e+00 -1.341940e+00 -1.417839e+00   \n",
       "25%   -7.197621e-01 -8.174309e-01 -4.276098e-01 -6.730107e-01 -4.538382e-01   \n",
       "50%    7.513122e-02 -1.912605e-02 -1.494652e-01 -2.907653e-01 -2.347470e-01   \n",
       "75%    7.110459e-01  7.791788e-01  1.904894e-01  3.781641e-01  7.198057e-02   \n",
       "max    2.141854e+00  2.375788e+00  2.219482e+01  1.108104e+01  1.264781e+01   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean  -2.338465e-15 -3.438183e-15 -4.431640e-16  2.485088e-16  1.855094e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.636509e+00 -1.933149e+00 -1.705857e+00 -1.628736e+00 -1.345187e+00   \n",
       "25%   -6.829821e-01 -6.529812e-01 -7.434694e-01 -7.134846e-01 -7.450388e-01   \n",
       "50%   -2.466224e-01 -2.966459e-01 -1.553437e-01 -1.795877e-01 -2.049049e-01   \n",
       "75%    4.644824e-01  3.632342e-01  5.397139e-01  5.449866e-01  4.702623e-01   \n",
       "max    5.797768e+00  7.753892e+00  1.064478e+01  5.273788e+00  5.436493e+00   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean   4.130921e-15 -9.199431e-16  5.026265e-16  3.205650e-13  8.574353e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -9.808389e-02 -3.310232e+00 -2.401358e+00 -1.121682e+01 -1.631707e+00   \n",
       "25%   -9.808389e-02 -6.907360e-01 -6.401558e-01 -7.680033e-01 -8.807613e-01   \n",
       "50%   -9.808389e-02  1.325340e-01 -2.548928e-01 -2.180656e-01 -3.898786e-01   \n",
       "75%   -9.808389e-02  8.061186e-01  3.505206e-01  3.318721e-01  5.918869e-01   \n",
       "max    3.607990e+01  1.928760e+00  1.058751e+01  6.381187e+00  2.127201e+00   \n",
       "\n",
       "                 15            16            17  \n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  \n",
       "mean   5.245418e-16  5.851993e-16  1.040902e-15  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -1.673570e+00 -2.156207e+00 -1.611732e+00  \n",
       "25%   -8.710141e-01 -7.482952e-01 -7.648192e-01  \n",
       "50%   -3.905364e-01 -1.851306e-01 -2.002106e-01  \n",
       "75%    6.390586e-01  5.657555e-01  5.526008e-01  \n",
       "max    2.128011e+00  5.071072e+00  4.975368e+00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:24.737447Z",
     "start_time": "2022-04-19T02:12:24.623433Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.linear_model import LassoCV,RidgeCV,ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:25.244512Z",
     "start_time": "2022-04-19T02:12:25.237011Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.empty((471*12,18*9))\n",
    "y=np.empty((471*12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:26.898722Z",
     "start_time": "2022-04-19T02:12:25.887093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in range(12):\n",
    "    for g in range(471):\n",
    "        x[m*471+g:m*471+g+1,:]=all_train_data2.iloc[m*480+g:m*480+g+9,:].values.reshape(1,-1)\n",
    "        y[m*471+g:g*471+g+1,:]=all_train_data2.iloc[m*480+g+9:m*480+g+9+1,9].values.reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:27.111749Z",
     "start_time": "2022-04-19T02:12:27.105248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5152735 , -0.09808389])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9,9:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:27.955856Z",
     "start_time": "2022-04-19T02:12:27.942854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5152735 ],\n",
       "       [1.17543706]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:28.844469Z",
     "start_time": "2022-04-19T02:12:28.829967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    1.175437\n",
       "Name: 9, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.iloc[10:11,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:29.919105Z",
     "start_time": "2022-04-19T02:12:29.903603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17958771,  0.5152735 , -0.09808389, -1.28947789,  6.73487971,\n",
       "        0.88180982, -1.15231349, -0.05789803, -1.40532054, -1.32942776])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:30.411668Z",
     "start_time": "2022-04-19T02:12:30.404667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5152735])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:39.641340Z",
     "start_time": "2022-04-19T02:12:39.626338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True,random_state=42)\n",
    "\n",
    "def rmse(y,y_hat):\n",
    "    return np.sqrt(mean_squared_error(y,y_hat))\n",
    "\n",
    "def cv_rmse(model,x=x,y=y):\n",
    "    rmse=np.sqrt( -cross_val_score(model,x,y,scoring='neg_mean_squared_error',cv=kf) )\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:43.255799Z",
     "start_time": "2022-04-19T02:12:43.238797Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:12:44.463952Z",
     "start_time": "2022-04-19T02:12:44.447950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge=make_pipeline(RobustScaler(),RidgeCV(alphas=alphas_alt,cv=kf))\n",
    "lasso=make_pipeline(RobustScaler(),LassoCV(max_iter=1e7,alphas=alphas2,random_state=42,cv=kf))\n",
    "elasticnet=make_pipeline(RobustScaler(),ElasticNetCV(max_iter=1e7,alphas=e_alphas,cv=kf,l1_ratio=e_l1ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:13:12.763546Z",
     "start_time": "2022-04-19T02:12:50.942775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge: 0.3776 (0.0248)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score=cv_rmse(ridge)\n",
    "print(\"Ridge: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:13:39.871488Z",
     "start_time": "2022-04-19T02:13:12.765546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO: 0.3759 (0.0246)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(lasso)\n",
    "print(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:15:29.808948Z",
     "start_time": "2022-04-19T02:13:39.873988Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic net: 0.3760 (0.0247)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:16:07.405222Z",
     "start_time": "2022-04-19T02:16:07.399722Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ linear model with  kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:16:15.195712Z",
     "start_time": "2022-04-19T02:16:15.105700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_k_fold_data(net,num_epochs,lr,train_features,train_labels,test_features,test_labels,batch_size,montum,wd):\n",
    "#     net=nn.Linear(train_features.shape[1],1)\n",
    "#     net=nn.Sequential(nn.Linear(train_features.shape[1],1))\n",
    "    loss=nn.MSELoss()\n",
    "#     optimizer=optim.SGD(net.parameters(),lr=lr,momentum=montum,weight_decay=wd)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=lr,weight_decay=wd)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    train_l,test_l=[],[]\n",
    "    \n",
    "    min_test_loss=1000\n",
    "    early_stop_cnt=0\n",
    "    train_loss,test_loss=0,0\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            l=loss(net(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "#         if (e+1) %1000==0 and test_features is not  None:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss=loss(net(test_features),test_labels).item()\n",
    "            if test_loss<min_test_loss:\n",
    "                min_test_loss=test_loss\n",
    "#                 test_l.append(test_loss)\n",
    "                train_loss=loss(net(train_features),train_labels).item()\n",
    "                test_l.append(test_loss)\n",
    "                train_l.append(train_loss)\n",
    "                print('epoch = %d train_loss : %f , test loss : %f' % (e+1,train_loss,test_loss))\n",
    "                early_stop_cnt=0\n",
    "            else:\n",
    "                early_stop_cnt+=1\n",
    "        if early_stop_cnt > 500:\n",
    "            \n",
    "            break\n",
    "                \n",
    "#             net.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 train_l.append(loss(net(train_features),train_labels).item())\n",
    "#                 test_l.append(loss(net(test_features),test_labels).item())\n",
    "# #                 print('epoch ',(e+1),'train loss : ',train_l[-1],'test loss : ',test_l[-1])\n",
    "\n",
    "    return train_l,test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:16:21.336492Z",
     "start_time": "2022-04-19T02:16:21.289986Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kfold_data(k,j,x,y,random_state=13):\n",
    "    assert k>=1, 'k must >=1'\n",
    "    fold_size = x.shape[0] // k\n",
    "    x_train,y_train=None,None\n",
    "    row_list=list(range(x.shape[0]))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(row_list)\n",
    "    for i in range(k):\n",
    "        idx=slice(fold_size*i,fold_size*(i+1))\n",
    "        x_part,y_part=x[row_list[idx],:],y[row_list[idx],:]\n",
    "        if i==j:\n",
    "            x_val,y_val=x_part,y_part\n",
    "        elif x_train is None:\n",
    "            x_train,y_train=x_part,y_part\n",
    "        else:\n",
    "            x_train=torch.cat((x_train,x_part))\n",
    "            y_train=torch.cat((y_train,y_part))\n",
    "    return x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:16:28.214865Z",
     "start_time": "2022-04-19T02:16:28.177360Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:18:06.835888Z",
     "start_time": "2022-04-19T02:18:06.690870Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x11=torch.Tensor(x)\n",
    "y11=torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:22:34.766911Z",
     "start_time": "2022-04-19T02:18:09.423717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.331083 , test loss : 0.363590\n",
      "epoch = 2 train_loss : 0.259180 , test loss : 0.289458\n",
      "epoch = 3 train_loss : 0.228496 , test loss : 0.255040\n",
      "epoch = 4 train_loss : 0.214618 , test loss : 0.242780\n",
      "epoch = 5 train_loss : 0.197052 , test loss : 0.219407\n",
      "epoch = 6 train_loss : 0.180302 , test loss : 0.199910\n",
      "epoch = 7 train_loss : 0.173092 , test loss : 0.195245\n",
      "epoch = 8 train_loss : 0.170119 , test loss : 0.188078\n",
      "epoch = 9 train_loss : 0.160259 , test loss : 0.178332\n",
      "epoch = 11 train_loss : 0.151470 , test loss : 0.168488\n",
      "epoch = 13 train_loss : 0.148642 , test loss : 0.167612\n",
      "epoch = 14 train_loss : 0.148256 , test loss : 0.167207\n",
      "epoch = 15 train_loss : 0.145817 , test loss : 0.164510\n",
      "epoch = 16 train_loss : 0.141545 , test loss : 0.161405\n",
      "epoch = 24 train_loss : 0.137078 , test loss : 0.158900\n",
      "epoch = 29 train_loss : 0.137055 , test loss : 0.158129\n",
      "epoch = 30 train_loss : 0.133783 , test loss : 0.157588\n",
      "epoch = 38 train_loss : 0.133400 , test loss : 0.154623\n",
      "epoch = 55 train_loss : 0.131890 , test loss : 0.154099\n",
      "epoch = 75 train_loss : 0.131270 , test loss : 0.153535\n",
      "epoch = 109 train_loss : 0.131327 , test loss : 0.153156\n",
      "epoch = 121 train_loss : 0.131106 , test loss : 0.152894\n",
      "epoch = 303 train_loss : 0.130638 , test loss : 0.152254\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.130638,test loss : 0.152254\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.343500 , test loss : 0.375963\n",
      "epoch = 2 train_loss : 0.278084 , test loss : 0.316754\n",
      "epoch = 3 train_loss : 0.241159 , test loss : 0.280722\n",
      "epoch = 4 train_loss : 0.215323 , test loss : 0.250819\n",
      "epoch = 5 train_loss : 0.198296 , test loss : 0.239235\n",
      "epoch = 6 train_loss : 0.185859 , test loss : 0.230956\n",
      "epoch = 7 train_loss : 0.174258 , test loss : 0.213937\n",
      "epoch = 9 train_loss : 0.163734 , test loss : 0.206657\n",
      "epoch = 10 train_loss : 0.160628 , test loss : 0.199069\n",
      "epoch = 12 train_loss : 0.156001 , test loss : 0.198750\n",
      "epoch = 13 train_loss : 0.151851 , test loss : 0.190807\n",
      "epoch = 14 train_loss : 0.146999 , test loss : 0.184208\n",
      "epoch = 15 train_loss : 0.142222 , test loss : 0.181010\n",
      "epoch = 16 train_loss : 0.142989 , test loss : 0.180662\n",
      "epoch = 17 train_loss : 0.142840 , test loss : 0.175650\n",
      "epoch = 21 train_loss : 0.140259 , test loss : 0.173436\n",
      "epoch = 22 train_loss : 0.137195 , test loss : 0.173226\n",
      "epoch = 24 train_loss : 0.135222 , test loss : 0.167638\n",
      "epoch = 28 train_loss : 0.137955 , test loss : 0.167083\n",
      "epoch = 37 train_loss : 0.140423 , test loss : 0.165396\n",
      "epoch = 42 train_loss : 0.132677 , test loss : 0.161537\n",
      "epoch = 55 train_loss : 0.133143 , test loss : 0.161093\n",
      "epoch = 56 train_loss : 0.133072 , test loss : 0.160471\n",
      "epoch = 66 train_loss : 0.132325 , test loss : 0.159826\n",
      "epoch = 91 train_loss : 0.133840 , test loss : 0.159685\n",
      "epoch = 98 train_loss : 0.131619 , test loss : 0.159224\n",
      "epoch = 119 train_loss : 0.131782 , test loss : 0.158648\n",
      "epoch = 156 train_loss : 0.130821 , test loss : 0.158628\n",
      "epoch = 193 train_loss : 0.132485 , test loss : 0.158544\n",
      "epoch = 223 train_loss : 0.131483 , test loss : 0.157568\n",
      "epoch = 471 train_loss : 0.130403 , test loss : 0.157266\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.130403,test loss : 0.157266\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.323270 , test loss : 0.306921\n",
      "epoch = 2 train_loss : 0.257215 , test loss : 0.239006\n",
      "epoch = 3 train_loss : 0.225934 , test loss : 0.206923\n",
      "epoch = 4 train_loss : 0.209732 , test loss : 0.194672\n",
      "epoch = 5 train_loss : 0.194533 , test loss : 0.180936\n",
      "epoch = 6 train_loss : 0.181996 , test loss : 0.171129\n",
      "epoch = 7 train_loss : 0.173315 , test loss : 0.159110\n",
      "epoch = 8 train_loss : 0.165774 , test loss : 0.153089\n",
      "epoch = 9 train_loss : 0.162102 , test loss : 0.151228\n",
      "epoch = 11 train_loss : 0.155966 , test loss : 0.144556\n",
      "epoch = 17 train_loss : 0.151980 , test loss : 0.141782\n",
      "epoch = 18 train_loss : 0.148572 , test loss : 0.139422\n",
      "epoch = 19 train_loss : 0.144837 , test loss : 0.138106\n",
      "epoch = 21 train_loss : 0.143966 , test loss : 0.136254\n",
      "epoch = 23 train_loss : 0.145515 , test loss : 0.134094\n",
      "epoch = 28 train_loss : 0.139585 , test loss : 0.132759\n",
      "epoch = 39 train_loss : 0.139141 , test loss : 0.132690\n",
      "epoch = 42 train_loss : 0.138453 , test loss : 0.130968\n",
      "epoch = 79 train_loss : 0.138248 , test loss : 0.130714\n",
      "epoch = 147 train_loss : 0.136742 , test loss : 0.130693\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.136742,test loss : 0.130693\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.338179 , test loss : 0.351224\n",
      "epoch = 2 train_loss : 0.266653 , test loss : 0.275853\n",
      "epoch = 3 train_loss : 0.230887 , test loss : 0.242592\n",
      "epoch = 4 train_loss : 0.210277 , test loss : 0.222517\n",
      "epoch = 5 train_loss : 0.193971 , test loss : 0.204586\n",
      "epoch = 6 train_loss : 0.189742 , test loss : 0.196114\n",
      "epoch = 7 train_loss : 0.174659 , test loss : 0.181756\n",
      "epoch = 8 train_loss : 0.168393 , test loss : 0.174135\n",
      "epoch = 9 train_loss : 0.163359 , test loss : 0.166167\n",
      "epoch = 10 train_loss : 0.157160 , test loss : 0.161293\n",
      "epoch = 11 train_loss : 0.158330 , test loss : 0.160552\n",
      "epoch = 12 train_loss : 0.152086 , test loss : 0.158229\n",
      "epoch = 15 train_loss : 0.146523 , test loss : 0.153916\n",
      "epoch = 16 train_loss : 0.146248 , test loss : 0.149361\n",
      "epoch = 17 train_loss : 0.143916 , test loss : 0.147884\n",
      "epoch = 22 train_loss : 0.143074 , test loss : 0.147578\n",
      "epoch = 25 train_loss : 0.139814 , test loss : 0.146396\n",
      "epoch = 39 train_loss : 0.136453 , test loss : 0.143523\n",
      "epoch = 46 train_loss : 0.135766 , test loss : 0.142416\n",
      "epoch = 65 train_loss : 0.135114 , test loss : 0.142370\n",
      "epoch = 78 train_loss : 0.135351 , test loss : 0.142314\n",
      "epoch = 89 train_loss : 0.136900 , test loss : 0.142162\n",
      "epoch = 103 train_loss : 0.135325 , test loss : 0.141504\n",
      "epoch = 113 train_loss : 0.134281 , test loss : 0.141490\n",
      "epoch = 138 train_loss : 0.133880 , test loss : 0.140829\n",
      "epoch = 229 train_loss : 0.133989 , test loss : 0.140475\n",
      "epoch = 280 train_loss : 0.134804 , test loss : 0.140418\n",
      "epoch = 299 train_loss : 0.134286 , test loss : 0.140279\n",
      "epoch = 345 train_loss : 0.134416 , test loss : 0.140079\n",
      "epoch = 420 train_loss : 0.133487 , test loss : 0.139969\n",
      "epoch = 582 train_loss : 0.133577 , test loss : 0.139892\n",
      "epoch = 942 train_loss : 0.133531 , test loss : 0.139661\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.133531,test loss : 0.139661\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.353452 , test loss : 0.343146\n",
      "epoch = 2 train_loss : 0.273174 , test loss : 0.269926\n",
      "epoch = 3 train_loss : 0.244630 , test loss : 0.238270\n",
      "epoch = 4 train_loss : 0.216800 , test loss : 0.210163\n",
      "epoch = 5 train_loss : 0.201235 , test loss : 0.199843\n",
      "epoch = 6 train_loss : 0.188724 , test loss : 0.185975\n",
      "epoch = 7 train_loss : 0.178824 , test loss : 0.177477\n",
      "epoch = 8 train_loss : 0.175171 , test loss : 0.172119\n",
      "epoch = 9 train_loss : 0.168979 , test loss : 0.168008\n",
      "epoch = 10 train_loss : 0.162095 , test loss : 0.161643\n",
      "epoch = 11 train_loss : 0.157799 , test loss : 0.156037\n",
      "epoch = 13 train_loss : 0.153774 , test loss : 0.153319\n",
      "epoch = 16 train_loss : 0.148882 , test loss : 0.150617\n",
      "epoch = 19 train_loss : 0.147581 , test loss : 0.144955\n",
      "epoch = 22 train_loss : 0.144129 , test loss : 0.144334\n",
      "epoch = 28 train_loss : 0.145223 , test loss : 0.143882\n",
      "epoch = 29 train_loss : 0.143086 , test loss : 0.143406\n",
      "epoch = 30 train_loss : 0.140713 , test loss : 0.140176\n",
      "epoch = 44 train_loss : 0.138278 , test loss : 0.139899\n",
      "epoch = 53 train_loss : 0.138320 , test loss : 0.138627\n",
      "epoch = 60 train_loss : 0.136829 , test loss : 0.136654\n",
      "epoch = 71 train_loss : 0.137795 , test loss : 0.136487\n",
      "epoch = 83 train_loss : 0.136944 , test loss : 0.136018\n",
      "epoch = 113 train_loss : 0.135684 , test loss : 0.135925\n",
      "epoch = 149 train_loss : 0.135177 , test loss : 0.135767\n",
      "epoch = 164 train_loss : 0.136345 , test loss : 0.135688\n",
      "epoch = 213 train_loss : 0.135868 , test loss : 0.135368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 350 train_loss : 0.135097 , test loss : 0.134879\n",
      "epoch = 484 train_loss : 0.135011 , test loss : 0.134792\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.135011,test loss : 0.134792\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.133265,total test loss mean : 0.142933 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x11.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x11,y11,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:24:04.955364Z",
     "start_time": "2022-04-19T02:24:04.944362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15*16+22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:29:04.667422Z",
     "start_time": "2022-04-19T02:29:04.637919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_Reg(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,layer_size,output_size):\n",
    "        super().__init__()\n",
    "        self.lstm_net=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=layer_size)\n",
    "        self.dense=nn.Linear(hidden_size,output_size)\n",
    "        self.state=None\n",
    "    \n",
    "    def forward(self,x,state):\n",
    "        y,self.state=self.lstm_net(x,state)\n",
    "        output=self.dense(y.view(-1,y.shape[-1]))\n",
    "        return output,self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:52:29.730268Z",
     "start_time": "2022-04-19T05:52:29.551246Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_k_fold_data_lstm(net,num_epochs,lr,train_features,train_labels,test_features,test_labels,batch_size,montum,wd):\n",
    "#     net=nn.Linear(train_features.shape[1],1)\n",
    "#     net=nn.Sequential(nn.Linear(train_features.shape[1],1))\n",
    "    loss=nn.MSELoss()\n",
    "#     optimizer=optim.SGD(net.parameters(),lr=lr,momentum=montum,weight_decay=wd)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=lr,weight_decay=wd)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True,drop_last=True)\n",
    "    train_l,test_l=[],[]\n",
    "    state=None\n",
    "    \n",
    "    min_test_loss=1000\n",
    "    early_stop_cnt=0\n",
    "    train_loss,test_loss=0,0\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        test_loss_list,train_loss_list=[],[]\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            if state is not None:\n",
    "                if isinstance(state,tuple):\n",
    "                    state=(state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state=state.detach()\n",
    "                    \n",
    "            x=x.unsqueeze(dim=0)\n",
    "            (output,state)=net(x,state)\n",
    "            \n",
    "            l=loss(output,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_list.append(l.item())\n",
    "#       if (e+1) %1000==0 and test_features is not  None:\n",
    "        net.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "#             dataset_train=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "#             data_iter_train=torch.utils.data.DataLoader(dataset_train,batch_size,shuffle=True,drop_last=True)\n",
    "            \n",
    "            dataset_test=torch.utils.data.TensorDataset(test_features,test_labels)\n",
    "            data_iter_test=torch.utils.data.DataLoader(dataset_test,batch_size,shuffle=True,drop_last=True)\n",
    "            \n",
    "            for xx_test,yy_test in data_iter_test:\n",
    "                xx_test=xx_test.unsqueeze(dim=0)\n",
    "                (output_test,state)=net(xx_test,state)\n",
    "                test_loss_list.append(loss(output_test,yy_test).item())\n",
    "            test_loss=np.mean(test_loss_list)\n",
    "\n",
    "            if test_loss<min_test_loss:\n",
    "                min_test_loss=test_loss\n",
    "#                 test_l.append(test_loss)\n",
    "#                 for xx_train,yy_train in data_iter_train:\n",
    "#                     xx_train=xx_train.unsqueeze(dim=0)\n",
    "#                     (output_train,state)=net(xx_train,state)\n",
    "#                     train_loss_list.append(loss(output_train,yy_train).item())\n",
    "\n",
    "                train_loss=np.mean(train_loss_list)\n",
    "                \n",
    "                test_l.append(test_loss)\n",
    "                train_l.append(train_loss)\n",
    "                print('epoch = %d train_loss : %f , test loss : %f' % (e+1,train_loss,test_loss))\n",
    "                early_stop_cnt=0\n",
    "            else:\n",
    "                early_stop_cnt+=1\n",
    "        if early_stop_cnt > 500:\n",
    "            \n",
    "            break\n",
    "                \n",
    "#             net.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 train_l.append(loss(net(train_features),train_labels).item())\n",
    "#                 test_l.append(loss(net(test_features),test_labels).item())\n",
    "# #                 print('epoch ',(e+1),'train loss : ',train_l[-1],'test loss : ',test_l[-1])\n",
    "\n",
    "    return train_l,test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:52:30.197328Z",
     "start_time": "2022-04-19T05:52:30.155322Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kfold_data(k,j,x,y,random_state=13):\n",
    "    assert k>=1, 'k must >=1'\n",
    "    fold_size = x.shape[0] // k\n",
    "    x_train,y_train=None,None\n",
    "    row_list=list(range(x.shape[0]))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(row_list)\n",
    "    for i in range(k):\n",
    "        idx=slice(fold_size*i,fold_size*(i+1))\n",
    "        x_part,y_part=x[row_list[idx],:],y[row_list[idx],:]\n",
    "        if i==j:\n",
    "            x_val,y_val=x_part,y_part\n",
    "        elif x_train is None:\n",
    "            x_train,y_train=x_part,y_part\n",
    "        else:\n",
    "            x_train=torch.cat((x_train,x_part))\n",
    "            y_train=torch.cat((y_train,y_part))\n",
    "    return x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:52:30.727895Z",
     "start_time": "2022-04-19T05:52:30.699391Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data_lstm(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-19T05:52:32.034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.657967 , test loss : 0.472880\n",
      "epoch = 2 train_loss : 0.372705 , test loss : 0.378358\n",
      "epoch = 3 train_loss : 0.284610 , test loss : 0.305523\n",
      "epoch = 4 train_loss : 0.236541 , test loss : 0.244333\n",
      "epoch = 5 train_loss : 0.205396 , test loss : 0.215072\n",
      "epoch = 7 train_loss : 0.158358 , test loss : 0.206296\n",
      "epoch = 8 train_loss : 0.143984 , test loss : 0.198946\n",
      "epoch = 9 train_loss : 0.135191 , test loss : 0.191424\n",
      "epoch = 10 train_loss : 0.125332 , test loss : 0.189128\n",
      "epoch = 12 train_loss : 0.110688 , test loss : 0.186612\n",
      "epoch = 13 train_loss : 0.104582 , test loss : 0.157756\n",
      "epoch = 452 train_loss : 0.001220 , test loss : 0.156650\n",
      "epoch = 582 train_loss : 0.000930 , test loss : 0.148020\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.000930,test loss : 0.148020\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.656729 , test loss : 0.459039\n",
      "epoch = 2 train_loss : 0.367449 , test loss : 0.340285\n",
      "epoch = 3 train_loss : 0.279367 , test loss : 0.302749\n",
      "epoch = 4 train_loss : 0.235801 , test loss : 0.254034\n",
      "epoch = 6 train_loss : 0.173529 , test loss : 0.239171\n",
      "epoch = 7 train_loss : 0.154770 , test loss : 0.229220\n",
      "epoch = 8 train_loss : 0.142254 , test loss : 0.227942\n",
      "epoch = 9 train_loss : 0.129893 , test loss : 0.220331\n",
      "epoch = 10 train_loss : 0.118909 , test loss : 0.207635\n",
      "epoch = 11 train_loss : 0.114650 , test loss : 0.184862\n",
      "epoch = 14 train_loss : 0.094948 , test loss : 0.180118\n",
      "epoch = 20 train_loss : 0.072654 , test loss : 0.174700\n",
      "epoch = 26 train_loss : 0.056219 , test loss : 0.172753\n",
      "epoch = 31 train_loss : 0.046213 , test loss : 0.168474\n",
      "epoch = 359 train_loss : 0.001316 , test loss : 0.166828\n",
      "epoch = 584 train_loss : 0.000906 , test loss : 0.166677\n",
      "epoch = 597 train_loss : 0.000909 , test loss : 0.164041\n",
      "epoch = 688 train_loss : 0.000740 , test loss : 0.163908\n",
      "epoch = 791 train_loss : 0.000878 , test loss : 0.160571\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.000878,test loss : 0.160571\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.665590 , test loss : 0.425922\n",
      "epoch = 2 train_loss : 0.377164 , test loss : 0.305521\n",
      "epoch = 3 train_loss : 0.289957 , test loss : 0.248282\n",
      "epoch = 4 train_loss : 0.242816 , test loss : 0.203122\n",
      "epoch = 5 train_loss : 0.207331 , test loss : 0.192995\n",
      "epoch = 6 train_loss : 0.180662 , test loss : 0.170548\n",
      "epoch = 7 train_loss : 0.156502 , test loss : 0.165635\n",
      "epoch = 8 train_loss : 0.149934 , test loss : 0.158629\n",
      "epoch = 9 train_loss : 0.132325 , test loss : 0.155430\n",
      "epoch = 10 train_loss : 0.132948 , test loss : 0.154699\n",
      "epoch = 11 train_loss : 0.117004 , test loss : 0.146343\n",
      "epoch = 22 train_loss : 0.072541 , test loss : 0.143486\n",
      "epoch = 353 train_loss : 0.001568 , test loss : 0.142255\n",
      "epoch = 437 train_loss : 0.001676 , test loss : 0.142222\n",
      "epoch = 500 train_loss : 0.001135 , test loss : 0.141251\n",
      "epoch = 659 train_loss : 0.001137 , test loss : 0.140499\n",
      "epoch = 747 train_loss : 0.000621 , test loss : 0.140436\n",
      "epoch = 801 train_loss : 0.000619 , test loss : 0.134484\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.000619,test loss : 0.134484\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.663423 , test loss : 0.436706\n",
      "epoch = 2 train_loss : 0.365132 , test loss : 0.307885\n",
      "epoch = 3 train_loss : 0.281244 , test loss : 0.258136\n",
      "epoch = 4 train_loss : 0.233735 , test loss : 0.224793\n",
      "epoch = 5 train_loss : 0.202345 , test loss : 0.211975\n",
      "epoch = 6 train_loss : 0.173898 , test loss : 0.185784\n",
      "epoch = 7 train_loss : 0.163371 , test loss : 0.180800\n",
      "epoch = 8 train_loss : 0.148513 , test loss : 0.161562\n",
      "epoch = 10 train_loss : 0.127270 , test loss : 0.159108\n",
      "epoch = 12 train_loss : 0.110776 , test loss : 0.156018\n",
      "epoch = 18 train_loss : 0.083253 , test loss : 0.151777\n",
      "epoch = 20 train_loss : 0.080610 , test loss : 0.148885\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.080610,test loss : 0.148885\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.691454 , test loss : 0.415785\n",
      "epoch = 2 train_loss : 0.374069 , test loss : 0.325631\n",
      "epoch = 3 train_loss : 0.293754 , test loss : 0.246869\n",
      "epoch = 4 train_loss : 0.242870 , test loss : 0.223933\n",
      "epoch = 5 train_loss : 0.210160 , test loss : 0.208029\n",
      "epoch = 6 train_loss : 0.186630 , test loss : 0.196101\n",
      "epoch = 7 train_loss : 0.160481 , test loss : 0.191522\n",
      "epoch = 8 train_loss : 0.148445 , test loss : 0.180246\n",
      "epoch = 9 train_loss : 0.136228 , test loss : 0.168856\n",
      "epoch = 12 train_loss : 0.113248 , test loss : 0.162730\n",
      "epoch = 15 train_loss : 0.098415 , test loss : 0.159553\n",
      "epoch = 21 train_loss : 0.075502 , test loss : 0.153375\n"
     ]
    }
   ],
   "source": [
    "x9=torch.Tensor(x)\n",
    "y9=torch.Tensor(y)\n",
    "def get_net():\n",
    "    return LSTM_Reg(162,256,2,1)\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x9,y9,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T02:09:54.892316Z",
     "start_time": "2022-04-14T02:09:54.886316Z"
    },
    "collapsed": true
   },
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:22:41.046134Z",
     "start_time": "2022-04-19T05:22:41.020131Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_Reg(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,layer_size,output_size):\n",
    "        super().__init__()\n",
    "        self.lstm_net=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=layer_size)\n",
    "        self.dense=nn.Linear(hidden_size,output_size)\n",
    "        self.state=None\n",
    "    \n",
    "    def forward(self,x,state):\n",
    "        y,self.state=self.lstm_net(x,state)\n",
    "        output=self.dense(y.view(-1,y.shape[-1]))\n",
    "        return output,self.state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:22:41.659212Z",
     "start_time": "2022-04-19T05:22:41.640210Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x9=torch.Tensor(x)\n",
    "y9=torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:22:43.175405Z",
     "start_time": "2022-04-19T05:22:43.047889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([32, 162])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([1, 32, 162])\n",
      "torch.Size([20, 162])\n",
      "torch.Size([20, 1])\n",
      "torch.Size([1, 20, 162])\n"
     ]
    }
   ],
   "source": [
    "a=torch.utils.data.TensorDataset(x9,y9)\n",
    "for x2,y2 in  torch.utils.data.DataLoader(a,32,shuffle=True):\n",
    "    print(x2.shape)\n",
    "    print(y2.shape)\n",
    "    print(x2.unsqueeze(dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:22:46.511828Z",
     "start_time": "2022-04-19T05:22:46.447320Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_pytorch(num_epochs,lr,train_features,train_labels,batch_size):\n",
    "    net=LSTM_Reg(162,256,2,1)\n",
    "    loss=nn.MSELoss()\n",
    "    optimizer=optim.Adam(net.parameters(),lr=5e-3)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True,drop_last=True)\n",
    "    state=None\n",
    "    for e in range(num_epochs):\n",
    "        l_sum=[]\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            if state is not None:\n",
    "                if isinstance(state ,tuple):\n",
    "                    state=(state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state=state.detach()\n",
    "                \n",
    "            x=x.unsqueeze(dim=0)\n",
    "            (output,state)=net(x,state)\n",
    "            l=loss(output,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            l_sum.append(l.item())\n",
    "            \n",
    "        if (e+1) % 50 ==0:\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                print('epoch %d , train loss mean : %f,train loss std : %f' % ( e+1,np.mean(l_sum),np.std(l_sum) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T05:45:52.156283Z",
     "start_time": "2022-04-19T05:22:48.880629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 , train loss mean : 0.029320,train loss std : 0.011825\n",
      "epoch 100 , train loss mean : 0.013447,train loss std : 0.005459\n",
      "epoch 150 , train loss mean : 0.009132,train loss std : 0.003357\n",
      "epoch 200 , train loss mean : 0.005775,train loss std : 0.001916\n",
      "epoch 250 , train loss mean : 0.005784,train loss std : 0.002395\n",
      "epoch 300 , train loss mean : 0.004202,train loss std : 0.001604\n",
      "epoch 350 , train loss mean : 0.003526,train loss std : 0.001398\n",
      "epoch 400 , train loss mean : 0.002931,train loss std : 0.001270\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-b815e29b4dec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_pytorch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-335d897f2fa6>\u001b[0m in \u001b[0;36mtrain_pytorch\u001b[1;34m(num_epochs, lr, train_features, train_labels, batch_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_pytorch(1000,0.001,x9,y9,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T07:23:38.962857Z",
     "start_time": "2022-04-18T07:23:38.953355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5652"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "471*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compared with linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T09:52:11.150561Z",
     "start_time": "2022-04-18T09:52:11.093554Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_pytorch_LInear(num_epochs,lr,train_features,train_labels,batch_size):\n",
    "    net=nn.Sequential(nn.Linear(train_features.shape[1],128),nn.ReLU(),nn.Linear(128,1))\n",
    "    loss=nn.MSELoss()\n",
    "    optimizer=optim.Adam(net.parameters(),lr=lr)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    for e in range(num_epochs):\n",
    "        l_sum=[]\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            l=loss(net(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum.append(l.item())\n",
    "        if (e+1) % 50 ==0:\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                print('epoch %d , train loss mean : %f,train loss std : %f' % ( e+1,np.mean(l_sum),np.std(l_sum) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T09:56:00.438177Z",
     "start_time": "2022-04-18T09:52:12.158689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 , train loss mean : 0.038039,train loss std : 0.014225\n",
      "epoch 100 , train loss mean : 0.025197,train loss std : 0.010772\n",
      "epoch 150 , train loss mean : 0.014195,train loss std : 0.006786\n",
      "epoch 200 , train loss mean : 0.010302,train loss std : 0.004486\n",
      "epoch 250 , train loss mean : 0.009503,train loss std : 0.004339\n",
      "epoch 300 , train loss mean : 0.008229,train loss std : 0.003656\n",
      "epoch 350 , train loss mean : 0.007078,train loss std : 0.002974\n",
      "epoch 400 , train loss mean : 0.007720,train loss std : 0.003838\n",
      "epoch 450 , train loss mean : 0.005004,train loss std : 0.002256\n",
      "epoch 500 , train loss mean : 0.005787,train loss std : 0.003748\n",
      "epoch 550 , train loss mean : 0.004788,train loss std : 0.002233\n",
      "epoch 600 , train loss mean : 0.004894,train loss std : 0.002861\n",
      "epoch 650 , train loss mean : 0.004689,train loss std : 0.001956\n",
      "epoch 700 , train loss mean : 0.004684,train loss std : 0.002623\n",
      "epoch 750 , train loss mean : 0.006662,train loss std : 0.004670\n",
      "epoch 800 , train loss mean : 0.005225,train loss std : 0.002757\n",
      "epoch 850 , train loss mean : 0.003030,train loss std : 0.001386\n",
      "epoch 900 , train loss mean : 0.002931,train loss std : 0.001191\n",
      "epoch 950 , train loss mean : 0.004297,train loss std : 0.002032\n",
      "epoch 1000 , train loss mean : 0.003782,train loss std : 0.002016\n"
     ]
    }
   ],
   "source": [
    "train_pytorch_LInear(1000,0.001,x9,y9,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
