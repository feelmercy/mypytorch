{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:19.370878Z",
     "start_time": "2021-12-30T05:35:18.171809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch import optim,nn\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew,kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:20.203926Z",
     "start_time": "2021-12-30T05:35:20.159923Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\train.csv',encoding='big5')\n",
    "test_data=pd.read_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\test.csv',encoding='big5',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:21.194982Z",
     "start_time": "2021-12-30T05:35:21.182982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (4320, 27)\n",
      "test_data shape:  (4320, 11)\n"
     ]
    }
   ],
   "source": [
    "print('train_data shape: ',train_data.shape)\n",
    "print('test_data shape: ',test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:23.465112Z",
     "start_time": "2021-12-30T05:35:23.433110Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data1=train_data.replace('NR',0)\n",
    "train_data1=train_data1.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:25.443225Z",
     "start_time": "2021-12-30T05:35:25.367221Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data={}\n",
    "for m in range(12):\n",
    "    month_data=np.empty((18,20*24))\n",
    "    for d in range(20):\n",
    "        month_data[:,d*24:(d+1)*24]=train_data1.iloc[m*20*18+d*18:m*20*18+(d+1)*18,:]\n",
    "    year_data[m]=month_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:28.246386Z",
     "start_time": "2021-12-30T05:35:28.242385Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.empty((12*471,9*18))\n",
    "y=np.empty((12*471,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:28.862421Z",
     "start_time": "2021-12-30T05:35:28.825419Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in range(12):\n",
    "    for g in range(471):\n",
    "        x[m*471+g:m*471+g+1,:]=year_data[m][:,g:g+9].reshape(1,-1)\n",
    "        y[m*471+g:m*471+g+1,:]=year_data[m][9,g+9]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- just test no normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:30.057489Z",
     "start_time": "2021-12-30T05:35:30.051489Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import optim,nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:31.280559Z",
     "start_time": "2021-12-30T05:35:31.199555Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_k_fold_data(net,num_epochs,lr,train_features,train_labels,test_features,test_labels,batch_size,montum,wd):\n",
    "#     net=nn.Linear(train_features.shape[1],1)\n",
    "#     net=nn.Sequential(nn.Linear(train_features.shape[1],1))\n",
    "    loss=nn.MSELoss()\n",
    "#     optimizer=optim.SGD(net.parameters(),lr=lr,momentum=montum,weight_decay=wd)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=lr,weight_decay=wd)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    train_l,test_l=[],[]\n",
    "    \n",
    "    min_test_loss=1000\n",
    "    early_stop_cnt=0\n",
    "    train_loss,test_loss=0,0\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            l=loss(net(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "#         if (e+1) %1000==0 and test_features is not  None:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss=loss(net(test_features),test_labels).item()\n",
    "            if test_loss<min_test_loss:\n",
    "                min_test_loss=test_loss\n",
    "#                 test_l.append(test_loss)\n",
    "                train_loss=loss(net(train_features),train_labels).item()\n",
    "                test_l.append(test_loss)\n",
    "                train_l.append(train_loss)\n",
    "                print('epoch = %d train_loss : %f , test loss : %f' % (e+1,train_loss,test_loss))\n",
    "                early_stop_cnt=0\n",
    "            else:\n",
    "                early_stop_cnt+=1\n",
    "        if early_stop_cnt > 500:\n",
    "            \n",
    "            break\n",
    "                \n",
    "#             net.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 train_l.append(loss(net(train_features),train_labels).item())\n",
    "#                 test_l.append(loss(net(test_features),test_labels).item())\n",
    "# #                 print('epoch ',(e+1),'train loss : ',train_l[-1],'test loss : ',test_l[-1])\n",
    "\n",
    "    return train_l,test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:31.886594Z",
     "start_time": "2021-12-30T05:35:31.853592Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kfold_data(k,j,x,y,random_state=13):\n",
    "    assert k>=1, 'k must >=1'\n",
    "    fold_size = x.shape[0] // k\n",
    "    x_train,y_train=None,None\n",
    "    row_list=list(range(x.shape[0]))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(row_list)\n",
    "    for i in range(k):\n",
    "        idx=slice(fold_size*i,fold_size*(i+1))\n",
    "        x_part,y_part=x[row_list[idx],:],y[row_list[idx],:]\n",
    "        if i==j:\n",
    "            x_val,y_val=x_part,y_part\n",
    "        elif x_train is None:\n",
    "            x_train,y_train=x_part,y_part\n",
    "        else:\n",
    "            x_train=torch.cat((x_train,x_part))\n",
    "            y_train=torch.cat((y_train,y_part))\n",
    "    return x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:33.495686Z",
     "start_time": "2021-12-30T05:35:33.463684Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:35:34.386737Z",
     "start_time": "2021-12-30T05:35:34.372736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=torch.Tensor(x)\n",
    "y1=torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:39:53.480556Z",
     "start_time": "2021-12-30T05:35:34.945769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 175.724701 , test loss : 178.991638\n",
      "epoch = 2 train_loss : 102.244743 , test loss : 107.463280\n",
      "epoch = 3 train_loss : 83.239082 , test loss : 90.057747\n",
      "epoch = 4 train_loss : 72.302315 , test loss : 79.492081\n",
      "epoch = 5 train_loss : 66.260544 , test loss : 73.624718\n",
      "epoch = 6 train_loss : 60.733200 , test loss : 67.589142\n",
      "epoch = 7 train_loss : 57.711578 , test loss : 64.668472\n",
      "epoch = 8 train_loss : 57.569195 , test loss : 64.308022\n",
      "epoch = 9 train_loss : 53.402813 , test loss : 59.327175\n",
      "epoch = 10 train_loss : 50.617020 , test loss : 56.542198\n",
      "epoch = 11 train_loss : 48.581844 , test loss : 54.509022\n",
      "epoch = 12 train_loss : 46.982491 , test loss : 52.555664\n",
      "epoch = 14 train_loss : 44.473637 , test loss : 50.045460\n",
      "epoch = 15 train_loss : 43.552280 , test loss : 49.049904\n",
      "epoch = 16 train_loss : 42.667728 , test loss : 48.117252\n",
      "epoch = 17 train_loss : 41.701778 , test loss : 47.104408\n",
      "epoch = 18 train_loss : 41.082893 , test loss : 46.466412\n",
      "epoch = 19 train_loss : 40.741463 , test loss : 46.177242\n",
      "epoch = 24 train_loss : 38.762737 , test loss : 44.198833\n",
      "epoch = 28 train_loss : 36.624195 , test loss : 42.577366\n",
      "epoch = 29 train_loss : 36.491699 , test loss : 42.311817\n",
      "epoch = 32 train_loss : 35.793137 , test loss : 42.037601\n",
      "epoch = 34 train_loss : 35.571438 , test loss : 41.718170\n",
      "epoch = 38 train_loss : 34.763515 , test loss : 41.294685\n",
      "epoch = 39 train_loss : 34.607071 , test loss : 40.992298\n",
      "epoch = 43 train_loss : 33.935566 , test loss : 40.396671\n",
      "epoch = 52 train_loss : 33.731506 , test loss : 40.058117\n",
      "epoch = 53 train_loss : 33.223568 , test loss : 39.648579\n",
      "epoch = 55 train_loss : 33.012630 , test loss : 39.494411\n",
      "epoch = 67 train_loss : 32.586819 , test loss : 39.207218\n",
      "epoch = 72 train_loss : 32.692448 , test loss : 38.957672\n",
      "epoch = 76 train_loss : 32.424507 , test loss : 38.891167\n",
      "epoch = 84 train_loss : 32.181610 , test loss : 38.881870\n",
      "epoch = 88 train_loss : 32.273479 , test loss : 38.700512\n",
      "epoch = 94 train_loss : 32.028988 , test loss : 38.645088\n",
      "epoch = 115 train_loss : 31.997507 , test loss : 38.580997\n",
      "epoch = 146 train_loss : 31.798380 , test loss : 38.508053\n",
      "epoch = 150 train_loss : 31.700827 , test loss : 38.468620\n",
      "epoch = 197 train_loss : 31.632473 , test loss : 38.382706\n",
      "epoch = 249 train_loss : 31.546518 , test loss : 38.361065\n",
      "epoch = 472 train_loss : 31.525665 , test loss : 38.352032\n",
      "epoch = 511 train_loss : 31.638840 , test loss : 38.338268\n",
      "epoch = 588 train_loss : 31.500267 , test loss : 38.330746\n",
      "epoch = 607 train_loss : 31.514395 , test loss : 38.318539\n",
      "epoch = 859 train_loss : 31.413345 , test loss : 38.313801\n",
      "epoch = 869 train_loss : 31.361900 , test loss : 38.259415\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.361900,test loss : 38.259415\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 148.663605 , test loss : 171.156204\n",
      "epoch = 2 train_loss : 105.131783 , test loss : 123.500320\n",
      "epoch = 3 train_loss : 85.945335 , test loss : 103.482147\n",
      "epoch = 4 train_loss : 74.408936 , test loss : 89.039726\n",
      "epoch = 5 train_loss : 67.668053 , test loss : 81.955612\n",
      "epoch = 6 train_loss : 62.664528 , test loss : 75.133995\n",
      "epoch = 7 train_loss : 58.145443 , test loss : 70.743561\n",
      "epoch = 8 train_loss : 55.541805 , test loss : 67.503639\n",
      "epoch = 9 train_loss : 53.314331 , test loss : 66.142036\n",
      "epoch = 10 train_loss : 50.638092 , test loss : 63.000301\n",
      "epoch = 12 train_loss : 47.098370 , test loss : 60.067204\n",
      "epoch = 14 train_loss : 45.829285 , test loss : 58.067829\n",
      "epoch = 15 train_loss : 43.710281 , test loss : 56.839333\n",
      "epoch = 17 train_loss : 42.308182 , test loss : 54.612209\n",
      "epoch = 18 train_loss : 41.431858 , test loss : 53.655453\n",
      "epoch = 19 train_loss : 39.911674 , test loss : 52.168385\n",
      "epoch = 22 train_loss : 38.305435 , test loss : 49.934055\n",
      "epoch = 25 train_loss : 36.514870 , test loss : 48.537449\n",
      "epoch = 30 train_loss : 37.364975 , test loss : 48.103859\n",
      "epoch = 31 train_loss : 35.756569 , test loss : 46.483944\n",
      "epoch = 34 train_loss : 35.005726 , test loss : 45.415783\n",
      "epoch = 42 train_loss : 33.793991 , test loss : 43.506115\n",
      "epoch = 46 train_loss : 33.401760 , test loss : 43.346184\n",
      "epoch = 47 train_loss : 33.242107 , test loss : 42.890701\n",
      "epoch = 54 train_loss : 32.822083 , test loss : 42.385700\n",
      "epoch = 55 train_loss : 33.091019 , test loss : 42.016724\n",
      "epoch = 59 train_loss : 32.739094 , test loss : 41.604710\n",
      "epoch = 69 train_loss : 32.325027 , test loss : 41.558754\n",
      "epoch = 70 train_loss : 32.476952 , test loss : 41.354477\n",
      "epoch = 83 train_loss : 32.153599 , test loss : 41.236649\n",
      "epoch = 84 train_loss : 31.917274 , test loss : 40.953217\n",
      "epoch = 86 train_loss : 31.834990 , test loss : 40.878372\n",
      "epoch = 87 train_loss : 31.950628 , test loss : 40.638752\n",
      "epoch = 100 train_loss : 31.672310 , test loss : 40.421913\n",
      "epoch = 104 train_loss : 31.736534 , test loss : 40.400227\n",
      "epoch = 110 train_loss : 31.661943 , test loss : 40.399261\n",
      "epoch = 141 train_loss : 31.767809 , test loss : 40.284187\n",
      "epoch = 157 train_loss : 31.771902 , test loss : 40.047871\n",
      "epoch = 290 train_loss : 31.345976 , test loss : 40.008556\n",
      "epoch = 397 train_loss : 31.382822 , test loss : 39.925980\n",
      "epoch = 528 train_loss : 31.379377 , test loss : 39.641445\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.379377,test loss : 39.641445\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 145.047195 , test loss : 147.257507\n",
      "epoch = 2 train_loss : 104.226006 , test loss : 101.027885\n",
      "epoch = 3 train_loss : 82.646965 , test loss : 78.380493\n",
      "epoch = 4 train_loss : 73.344254 , test loss : 66.614655\n",
      "epoch = 5 train_loss : 66.885429 , test loss : 59.666805\n",
      "epoch = 6 train_loss : 62.600204 , test loss : 56.099422\n",
      "epoch = 7 train_loss : 58.935207 , test loss : 52.746101\n",
      "epoch = 8 train_loss : 59.692051 , test loss : 52.322407\n",
      "epoch = 9 train_loss : 54.649651 , test loss : 48.203419\n",
      "epoch = 10 train_loss : 52.074547 , test loss : 45.598522\n",
      "epoch = 11 train_loss : 51.502449 , test loss : 44.999859\n",
      "epoch = 12 train_loss : 49.244278 , test loss : 43.059891\n",
      "epoch = 14 train_loss : 47.124817 , test loss : 40.893234\n",
      "epoch = 15 train_loss : 45.087929 , test loss : 39.344341\n",
      "epoch = 16 train_loss : 44.134071 , test loss : 37.956383\n",
      "epoch = 18 train_loss : 43.543091 , test loss : 37.649464\n",
      "epoch = 19 train_loss : 41.870327 , test loss : 35.951576\n",
      "epoch = 21 train_loss : 40.620785 , test loss : 34.419239\n",
      "epoch = 22 train_loss : 40.000488 , test loss : 33.939331\n",
      "epoch = 26 train_loss : 38.571102 , test loss : 33.050125\n",
      "epoch = 34 train_loss : 36.643818 , test loss : 31.608330\n",
      "epoch = 35 train_loss : 36.400745 , test loss : 31.460251\n",
      "epoch = 39 train_loss : 35.896385 , test loss : 31.343931\n",
      "epoch = 44 train_loss : 35.355381 , test loss : 30.883333\n",
      "epoch = 69 train_loss : 34.338272 , test loss : 30.643759\n",
      "epoch = 74 train_loss : 34.189323 , test loss : 30.507582\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 34.189323,test loss : 30.507582\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 166.065781 , test loss : 167.355774\n",
      "epoch = 2 train_loss : 104.636688 , test loss : 105.094940\n",
      "epoch = 3 train_loss : 88.933014 , test loss : 88.450142\n",
      "epoch = 4 train_loss : 79.251350 , test loss : 79.016563\n",
      "epoch = 5 train_loss : 71.706581 , test loss : 72.035789\n",
      "epoch = 6 train_loss : 66.535042 , test loss : 67.414146\n",
      "epoch = 7 train_loss : 62.790066 , test loss : 63.526249\n",
      "epoch = 8 train_loss : 61.464294 , test loss : 62.461040\n",
      "epoch = 10 train_loss : 56.975052 , test loss : 58.282032\n",
      "epoch = 12 train_loss : 51.825413 , test loss : 52.508179\n",
      "epoch = 13 train_loss : 48.864780 , test loss : 49.820797\n",
      "epoch = 14 train_loss : 47.143688 , test loss : 47.740723\n",
      "epoch = 16 train_loss : 44.774460 , test loss : 45.408840\n",
      "epoch = 17 train_loss : 43.852730 , test loss : 44.630970\n",
      "epoch = 19 train_loss : 42.109249 , test loss : 42.946930\n",
      "epoch = 21 train_loss : 41.145947 , test loss : 41.363369\n",
      "epoch = 23 train_loss : 40.104191 , test loss : 40.967945\n",
      "epoch = 25 train_loss : 38.766464 , test loss : 39.498692\n",
      "epoch = 26 train_loss : 38.300865 , test loss : 38.970123\n",
      "epoch = 27 train_loss : 38.560257 , test loss : 38.901886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 29 train_loss : 37.808231 , test loss : 38.676689\n",
      "epoch = 33 train_loss : 36.350872 , test loss : 37.381992\n",
      "epoch = 35 train_loss : 36.040718 , test loss : 36.961514\n",
      "epoch = 42 train_loss : 35.530964 , test loss : 36.667282\n",
      "epoch = 45 train_loss : 35.036797 , test loss : 36.367249\n",
      "epoch = 48 train_loss : 34.825905 , test loss : 36.338573\n",
      "epoch = 52 train_loss : 34.419605 , test loss : 35.839447\n",
      "epoch = 53 train_loss : 34.369736 , test loss : 35.646908\n",
      "epoch = 57 train_loss : 34.167000 , test loss : 35.459908\n",
      "epoch = 62 train_loss : 34.003021 , test loss : 35.337692\n",
      "epoch = 66 train_loss : 33.809284 , test loss : 35.246559\n",
      "epoch = 69 train_loss : 33.969215 , test loss : 34.980782\n",
      "epoch = 73 train_loss : 33.570965 , test loss : 34.935570\n",
      "epoch = 75 train_loss : 33.470234 , test loss : 34.862606\n",
      "epoch = 80 train_loss : 33.271416 , test loss : 34.668674\n",
      "epoch = 109 train_loss : 33.189186 , test loss : 34.486366\n",
      "epoch = 117 train_loss : 33.000671 , test loss : 34.331669\n",
      "epoch = 129 train_loss : 32.799221 , test loss : 34.236069\n",
      "epoch = 136 train_loss : 32.872112 , test loss : 34.216984\n",
      "epoch = 141 train_loss : 32.758770 , test loss : 34.136314\n",
      "epoch = 149 train_loss : 32.819969 , test loss : 34.136147\n",
      "epoch = 195 train_loss : 32.657467 , test loss : 34.130463\n",
      "epoch = 259 train_loss : 32.763599 , test loss : 33.998383\n",
      "epoch = 378 train_loss : 32.711746 , test loss : 33.795765\n",
      "epoch = 507 train_loss : 32.652882 , test loss : 33.783466\n",
      "epoch = 855 train_loss : 32.572906 , test loss : 33.751293\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.572906,test loss : 33.751293\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 128.387421 , test loss : 116.594086\n",
      "epoch = 2 train_loss : 109.019630 , test loss : 103.043671\n",
      "epoch = 3 train_loss : 83.408989 , test loss : 77.070000\n",
      "epoch = 4 train_loss : 73.485023 , test loss : 67.559494\n",
      "epoch = 5 train_loss : 67.131172 , test loss : 61.562553\n",
      "epoch = 6 train_loss : 62.662258 , test loss : 57.613144\n",
      "epoch = 7 train_loss : 61.147366 , test loss : 55.988567\n",
      "epoch = 8 train_loss : 56.257183 , test loss : 51.116795\n",
      "epoch = 9 train_loss : 55.861130 , test loss : 51.015602\n",
      "epoch = 11 train_loss : 52.886070 , test loss : 47.938995\n",
      "epoch = 12 train_loss : 51.305584 , test loss : 46.715786\n",
      "epoch = 13 train_loss : 51.397102 , test loss : 46.016869\n",
      "epoch = 14 train_loss : 50.248924 , test loss : 44.934101\n",
      "epoch = 15 train_loss : 45.620560 , test loss : 40.763817\n",
      "epoch = 16 train_loss : 44.990925 , test loss : 39.984730\n",
      "epoch = 18 train_loss : 43.489948 , test loss : 38.392529\n",
      "epoch = 20 train_loss : 42.667004 , test loss : 37.637180\n",
      "epoch = 22 train_loss : 42.024364 , test loss : 36.819706\n",
      "epoch = 23 train_loss : 41.758980 , test loss : 36.510242\n",
      "epoch = 27 train_loss : 39.189774 , test loss : 34.909695\n",
      "epoch = 29 train_loss : 39.339420 , test loss : 34.336666\n",
      "epoch = 31 train_loss : 37.896904 , test loss : 33.341614\n",
      "epoch = 36 train_loss : 37.226501 , test loss : 33.054005\n",
      "epoch = 38 train_loss : 36.771107 , test loss : 32.308548\n",
      "epoch = 41 train_loss : 36.900272 , test loss : 32.264107\n",
      "epoch = 43 train_loss : 36.029610 , test loss : 31.541960\n",
      "epoch = 51 train_loss : 35.598675 , test loss : 31.292637\n",
      "epoch = 52 train_loss : 35.543022 , test loss : 31.014940\n",
      "epoch = 68 train_loss : 34.647846 , test loss : 30.500360\n",
      "epoch = 82 train_loss : 34.419342 , test loss : 30.454767\n",
      "epoch = 93 train_loss : 34.235794 , test loss : 30.112862\n",
      "epoch = 97 train_loss : 34.265915 , test loss : 30.018547\n",
      "epoch = 102 train_loss : 34.152649 , test loss : 29.816231\n",
      "epoch = 116 train_loss : 34.101513 , test loss : 29.733183\n",
      "epoch = 190 train_loss : 34.162048 , test loss : 29.703394\n",
      "epoch = 226 train_loss : 33.913708 , test loss : 29.624790\n",
      "epoch = 243 train_loss : 33.872051 , test loss : 29.624138\n",
      "epoch = 265 train_loss : 33.838715 , test loss : 29.576694\n",
      "epoch = 283 train_loss : 33.958344 , test loss : 29.571487\n",
      "epoch = 291 train_loss : 33.717369 , test loss : 29.539276\n",
      "epoch = 394 train_loss : 33.813080 , test loss : 29.464100\n",
      "epoch = 567 train_loss : 33.728447 , test loss : 29.460594\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.728447,test loss : 29.460594\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.646391,total test loss mean : 34.324066 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T02:24:50.698522Z",
     "start_time": "2021-12-28T02:17:21.373822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 290.766388 , test loss : 269.512115\n",
      "epoch = 2 train_loss : 103.084366 , test loss : 134.009445\n",
      "epoch = 3 train_loss : 79.996941 , test loss : 101.958191\n",
      "epoch = 4 train_loss : 70.435394 , test loss : 84.803787\n",
      "epoch = 5 train_loss : 64.179726 , test loss : 74.874535\n",
      "epoch = 6 train_loss : 59.422081 , test loss : 70.178734\n",
      "epoch = 7 train_loss : 56.428925 , test loss : 67.311516\n",
      "epoch = 8 train_loss : 54.308441 , test loss : 60.004467\n",
      "epoch = 9 train_loss : 51.060757 , test loss : 57.502617\n",
      "epoch = 10 train_loss : 50.022552 , test loss : 55.552086\n",
      "epoch = 11 train_loss : 47.512028 , test loss : 53.037868\n",
      "epoch = 12 train_loss : 46.209293 , test loss : 51.636555\n",
      "epoch = 13 train_loss : 44.205700 , test loss : 51.578796\n",
      "epoch = 15 train_loss : 45.089931 , test loss : 48.935425\n",
      "epoch = 16 train_loss : 41.220982 , test loss : 47.141804\n",
      "epoch = 20 train_loss : 38.471390 , test loss : 46.138603\n",
      "epoch = 22 train_loss : 39.110271 , test loss : 44.030369\n",
      "epoch = 24 train_loss : 36.903030 , test loss : 43.335476\n",
      "epoch = 26 train_loss : 36.534931 , test loss : 42.058006\n",
      "epoch = 38 train_loss : 34.008827 , test loss : 41.306564\n",
      "epoch = 43 train_loss : 34.276772 , test loss : 40.211624\n",
      "epoch = 76 train_loss : 32.621796 , test loss : 39.394806\n",
      "epoch = 80 train_loss : 32.170753 , test loss : 39.274220\n",
      "epoch = 88 train_loss : 33.075703 , test loss : 39.157803\n",
      "epoch = 274 train_loss : 32.268150 , test loss : 39.044209\n",
      "epoch = 589 train_loss : 31.994390 , test loss : 38.944489\n",
      "epoch = 599 train_loss : 31.550230 , test loss : 38.846043\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.550230,test loss : 38.846043\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 275.036987 , test loss : 402.659393\n",
      "epoch = 2 train_loss : 114.712807 , test loss : 167.458221\n",
      "epoch = 3 train_loss : 81.981705 , test loss : 121.469376\n",
      "epoch = 4 train_loss : 68.923409 , test loss : 98.154694\n",
      "epoch = 5 train_loss : 64.048538 , test loss : 92.143738\n",
      "epoch = 6 train_loss : 59.652012 , test loss : 84.900047\n",
      "epoch = 7 train_loss : 57.034042 , test loss : 78.888657\n",
      "epoch = 8 train_loss : 52.427448 , test loss : 71.992302\n",
      "epoch = 9 train_loss : 50.332047 , test loss : 68.905090\n",
      "epoch = 10 train_loss : 48.032677 , test loss : 65.338242\n",
      "epoch = 12 train_loss : 45.443630 , test loss : 60.436218\n",
      "epoch = 13 train_loss : 43.757626 , test loss : 58.598961\n",
      "epoch = 14 train_loss : 42.526455 , test loss : 56.018871\n",
      "epoch = 15 train_loss : 41.537239 , test loss : 54.611076\n",
      "epoch = 17 train_loss : 42.191341 , test loss : 54.218914\n",
      "epoch = 18 train_loss : 40.650654 , test loss : 53.151836\n",
      "epoch = 19 train_loss : 38.510506 , test loss : 49.883240\n",
      "epoch = 23 train_loss : 36.884483 , test loss : 46.895962\n",
      "epoch = 25 train_loss : 36.290504 , test loss : 46.410480\n",
      "epoch = 26 train_loss : 35.988335 , test loss : 45.628731\n",
      "epoch = 28 train_loss : 35.724854 , test loss : 45.321850\n",
      "epoch = 31 train_loss : 35.001968 , test loss : 43.985962\n",
      "epoch = 34 train_loss : 34.521172 , test loss : 43.650959\n",
      "epoch = 35 train_loss : 34.480122 , test loss : 43.155491\n",
      "epoch = 36 train_loss : 33.967091 , test loss : 42.682800\n",
      "epoch = 39 train_loss : 33.814510 , test loss : 42.138500\n",
      "epoch = 45 train_loss : 33.388424 , test loss : 41.999451\n",
      "epoch = 49 train_loss : 32.963131 , test loss : 41.638714\n",
      "epoch = 53 train_loss : 32.799736 , test loss : 41.219830\n",
      "epoch = 54 train_loss : 32.808556 , test loss : 41.161785\n",
      "epoch = 69 train_loss : 32.610756 , test loss : 40.988708\n",
      "epoch = 76 train_loss : 32.282063 , test loss : 40.781052\n",
      "epoch = 77 train_loss : 32.021572 , test loss : 40.336727\n",
      "epoch = 83 train_loss : 31.775738 , test loss : 40.177670\n",
      "epoch = 127 train_loss : 31.731323 , test loss : 40.044788\n",
      "epoch = 166 train_loss : 31.706999 , test loss : 39.806553\n",
      "epoch = 665 train_loss : 31.345417 , test loss : 39.623024\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.345417,test loss : 39.623024\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 273.269928 , test loss : 278.072693\n",
      "epoch = 2 train_loss : 112.476158 , test loss : 129.571060\n",
      "epoch = 3 train_loss : 83.898918 , test loss : 90.439644\n",
      "epoch = 4 train_loss : 73.486961 , test loss : 82.637794\n",
      "epoch = 5 train_loss : 71.933075 , test loss : 74.722702\n",
      "epoch = 6 train_loss : 62.276295 , test loss : 72.001579\n",
      "epoch = 7 train_loss : 62.711960 , test loss : 67.987213\n",
      "epoch = 8 train_loss : 55.519489 , test loss : 65.565590\n",
      "epoch = 9 train_loss : 53.052498 , test loss : 64.971313\n",
      "epoch = 10 train_loss : 50.416122 , test loss : 60.781780\n",
      "epoch = 11 train_loss : 50.181816 , test loss : 58.537495\n",
      "epoch = 12 train_loss : 46.912918 , test loss : 56.975491\n",
      "epoch = 14 train_loss : 43.921577 , test loss : 54.454292\n",
      "epoch = 16 train_loss : 44.049515 , test loss : 53.178017\n",
      "epoch = 17 train_loss : 40.841759 , test loss : 52.682053\n",
      "epoch = 19 train_loss : 39.759308 , test loss : 52.342587\n",
      "epoch = 21 train_loss : 38.166252 , test loss : 49.853607\n",
      "epoch = 22 train_loss : 37.862492 , test loss : 49.250290\n",
      "epoch = 23 train_loss : 37.255810 , test loss : 49.070866\n",
      "epoch = 24 train_loss : 36.698624 , test loss : 48.331593\n",
      "epoch = 26 train_loss : 36.314102 , test loss : 47.616547\n",
      "epoch = 27 train_loss : 36.075367 , test loss : 47.218731\n",
      "epoch = 36 train_loss : 34.342014 , test loss : 45.339657\n",
      "epoch = 39 train_loss : 33.496170 , test loss : 44.977818\n",
      "epoch = 44 train_loss : 33.225239 , test loss : 44.783150\n",
      "epoch = 52 train_loss : 33.192333 , test loss : 44.274445\n",
      "epoch = 56 train_loss : 32.713646 , test loss : 43.684170\n",
      "epoch = 69 train_loss : 33.482357 , test loss : 43.606770\n",
      "epoch = 70 train_loss : 32.176861 , test loss : 43.184105\n",
      "epoch = 74 train_loss : 31.978352 , test loss : 43.055668\n",
      "epoch = 81 train_loss : 32.637985 , test loss : 42.898956\n",
      "epoch = 82 train_loss : 32.334892 , test loss : 42.429996\n",
      "epoch = 96 train_loss : 32.153698 , test loss : 42.223404\n",
      "epoch = 106 train_loss : 31.711838 , test loss : 42.051662\n",
      "epoch = 123 train_loss : 31.330624 , test loss : 41.915104\n",
      "epoch = 149 train_loss : 31.650097 , test loss : 41.586948\n",
      "epoch = 159 train_loss : 31.084080 , test loss : 41.565536\n",
      "epoch = 208 train_loss : 31.446091 , test loss : 41.439465\n",
      "epoch = 345 train_loss : 31.864357 , test loss : 41.388424\n",
      "epoch = 358 train_loss : 31.664141 , test loss : 41.112900\n",
      "epoch = 671 train_loss : 31.034340 , test loss : 41.030445\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 31.034340,test loss : 41.030445\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 206.390793 , test loss : 173.152069\n",
      "epoch = 2 train_loss : 100.856606 , test loss : 53.294033\n",
      "epoch = 3 train_loss : 86.365433 , test loss : 47.067734\n",
      "epoch = 4 train_loss : 74.286636 , test loss : 37.724834\n",
      "epoch = 5 train_loss : 67.932068 , test loss : 34.704048\n",
      "epoch = 6 train_loss : 64.522141 , test loss : 31.689579\n",
      "epoch = 7 train_loss : 60.787716 , test loss : 30.396940\n",
      "epoch = 8 train_loss : 60.033348 , test loss : 29.896271\n",
      "epoch = 9 train_loss : 54.696312 , test loss : 28.210423\n",
      "epoch = 11 train_loss : 50.597626 , test loss : 27.872971\n",
      "epoch = 12 train_loss : 49.781097 , test loss : 25.787857\n",
      "epoch = 14 train_loss : 46.292522 , test loss : 25.135153\n",
      "epoch = 16 train_loss : 44.362637 , test loss : 24.173910\n",
      "epoch = 21 train_loss : 41.644966 , test loss : 22.780361\n",
      "epoch = 40 train_loss : 38.994682 , test loss : 22.667007\n",
      "epoch = 46 train_loss : 38.290993 , test loss : 22.259886\n",
      "epoch = 48 train_loss : 37.632141 , test loss : 22.220030\n",
      "epoch = 57 train_loss : 36.991009 , test loss : 22.026943\n",
      "epoch = 69 train_loss : 36.967388 , test loss : 21.880627\n",
      "epoch = 90 train_loss : 36.657700 , test loss : 21.873016\n",
      "epoch = 110 train_loss : 36.498367 , test loss : 21.759315\n",
      "epoch = 142 train_loss : 36.779636 , test loss : 21.738342\n",
      "epoch = 157 train_loss : 35.975906 , test loss : 21.738251\n",
      "epoch = 186 train_loss : 36.167614 , test loss : 21.664112\n",
      "epoch = 187 train_loss : 36.337997 , test loss : 21.501553\n",
      "epoch = 452 train_loss : 36.531586 , test loss : 21.373186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 579 train_loss : 36.938469 , test loss : 21.137606\n",
      "epoch = 842 train_loss : 36.743961 , test loss : 21.071686\n",
      "epoch = 875 train_loss : 37.535267 , test loss : 20.861010\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 37.535267,test loss : 20.861010\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 344.158264 , test loss : 364.149841\n",
      "epoch = 2 train_loss : 98.619385 , test loss : 119.195351\n",
      "epoch = 3 train_loss : 84.213676 , test loss : 94.371712\n",
      "epoch = 4 train_loss : 73.286697 , test loss : 87.182747\n",
      "epoch = 5 train_loss : 68.329010 , test loss : 76.775963\n",
      "epoch = 6 train_loss : 62.501350 , test loss : 72.582199\n",
      "epoch = 8 train_loss : 55.265423 , test loss : 63.680378\n",
      "epoch = 9 train_loss : 56.973656 , test loss : 58.588451\n",
      "epoch = 10 train_loss : 50.257824 , test loss : 55.361938\n",
      "epoch = 12 train_loss : 46.380188 , test loss : 52.420948\n",
      "epoch = 14 train_loss : 44.755901 , test loss : 47.015038\n",
      "epoch = 17 train_loss : 41.119034 , test loss : 44.248890\n",
      "epoch = 18 train_loss : 43.689724 , test loss : 43.210331\n",
      "epoch = 19 train_loss : 40.027187 , test loss : 42.510307\n",
      "epoch = 20 train_loss : 42.220261 , test loss : 41.062622\n",
      "epoch = 21 train_loss : 39.189140 , test loss : 39.918602\n",
      "epoch = 22 train_loss : 38.967770 , test loss : 38.976677\n",
      "epoch = 27 train_loss : 37.400150 , test loss : 38.731709\n",
      "epoch = 28 train_loss : 42.445393 , test loss : 38.414001\n",
      "epoch = 29 train_loss : 37.256992 , test loss : 36.774338\n",
      "epoch = 31 train_loss : 36.328762 , test loss : 35.890224\n",
      "epoch = 34 train_loss : 36.424881 , test loss : 35.536354\n",
      "epoch = 37 train_loss : 35.472530 , test loss : 35.225716\n",
      "epoch = 41 train_loss : 36.389984 , test loss : 34.105217\n",
      "epoch = 48 train_loss : 35.042812 , test loss : 33.864624\n",
      "epoch = 58 train_loss : 35.438004 , test loss : 33.149296\n",
      "epoch = 75 train_loss : 33.910820 , test loss : 32.783298\n",
      "epoch = 121 train_loss : 33.890854 , test loss : 32.678581\n",
      "epoch = 125 train_loss : 34.313152 , test loss : 32.557747\n",
      "epoch = 149 train_loss : 33.912701 , test loss : 32.534119\n",
      "epoch = 159 train_loss : 33.606091 , test loss : 32.473255\n",
      "epoch = 162 train_loss : 34.087986 , test loss : 32.354126\n",
      "epoch = 164 train_loss : 33.765511 , test loss : 32.060993\n",
      "epoch = 196 train_loss : 34.081886 , test loss : 32.022171\n",
      "epoch = 259 train_loss : 33.654373 , test loss : 31.827070\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.654373,test loss : 31.827070\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 33.023925,total test loss mean : 34.437518 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],512),nn.Linear(512,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### just test data col normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:53:20.211066Z",
     "start_time": "2021-12-30T01:53:20.196065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5652, 162)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:40:42.699371Z",
     "start_time": "2021-12-30T05:40:42.589365Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2=pd.DataFrame(x)\n",
    "x2=x2.apply(lambda x:((x-x.mean())/x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:40:43.888439Z",
     "start_time": "2021-12-30T05:40:43.863438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x22=torch.Tensor(x2.values)\n",
    "y22=torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T02:36:45.573410Z",
     "start_time": "2021-12-28T02:33:36.734609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 563.576843 , test loss : 832.734558\n",
      "epoch = 11 train_loss : 244.796875 , test loss : 767.408997\n",
      "epoch = 12 train_loss : 214.190063 , test loss : 677.944275\n",
      "epoch = 13 train_loss : 185.046494 , test loss : 552.179260\n",
      "epoch = 14 train_loss : 155.866241 , test loss : 491.534088\n",
      "epoch = 15 train_loss : 132.594147 , test loss : 383.075348\n",
      "epoch = 16 train_loss : 107.768951 , test loss : 328.814972\n",
      "epoch = 17 train_loss : 87.841248 , test loss : 224.141357\n",
      "epoch = 18 train_loss : 71.900284 , test loss : 181.749496\n",
      "epoch = 19 train_loss : 59.911762 , test loss : 129.574921\n",
      "epoch = 20 train_loss : 51.394901 , test loss : 110.958374\n",
      "epoch = 21 train_loss : 45.188522 , test loss : 86.687241\n",
      "epoch = 22 train_loss : 41.066101 , test loss : 67.410683\n",
      "epoch = 23 train_loss : 38.290638 , test loss : 59.066189\n",
      "epoch = 24 train_loss : 37.328880 , test loss : 50.510220\n",
      "epoch = 25 train_loss : 36.293625 , test loss : 48.489433\n",
      "epoch = 26 train_loss : 35.523125 , test loss : 48.297016\n",
      "epoch = 27 train_loss : 34.782928 , test loss : 42.942310\n",
      "epoch = 28 train_loss : 34.318516 , test loss : 42.253948\n",
      "epoch = 31 train_loss : 33.406914 , test loss : 41.029079\n",
      "epoch = 36 train_loss : 33.337044 , test loss : 40.826561\n",
      "epoch = 42 train_loss : 32.442478 , test loss : 40.682938\n",
      "epoch = 48 train_loss : 31.916767 , test loss : 39.526470\n",
      "epoch = 53 train_loss : 31.795626 , test loss : 39.509388\n",
      "epoch = 105 train_loss : 31.804226 , test loss : 39.301285\n",
      "epoch = 206 train_loss : 31.933037 , test loss : 39.287006\n",
      "epoch = 238 train_loss : 31.214611 , test loss : 38.884525\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.214611,test loss : 38.884525\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 580.120544 , test loss : 839.246582\n",
      "epoch = 2 train_loss : 541.647034 , test loss : 702.120789\n",
      "epoch = 5 train_loss : 464.544861 , test loss : 691.266235\n",
      "epoch = 6 train_loss : 437.128571 , test loss : 660.577942\n",
      "epoch = 7 train_loss : 406.016296 , test loss : 627.048828\n",
      "epoch = 8 train_loss : 372.587006 , test loss : 609.201233\n",
      "epoch = 9 train_loss : 337.919312 , test loss : 513.657104\n",
      "epoch = 10 train_loss : 299.709137 , test loss : 500.993164\n",
      "epoch = 11 train_loss : 264.801270 , test loss : 498.492584\n",
      "epoch = 12 train_loss : 225.073853 , test loss : 382.171814\n",
      "epoch = 13 train_loss : 188.391052 , test loss : 306.713928\n",
      "epoch = 14 train_loss : 154.392105 , test loss : 264.226562\n",
      "epoch = 15 train_loss : 125.254051 , test loss : 218.612900\n",
      "epoch = 16 train_loss : 100.089012 , test loss : 154.432129\n",
      "epoch = 17 train_loss : 79.594040 , test loss : 132.653397\n",
      "epoch = 18 train_loss : 63.983635 , test loss : 95.762024\n",
      "epoch = 19 train_loss : 53.230156 , test loss : 77.959778\n",
      "epoch = 20 train_loss : 45.995663 , test loss : 69.179420\n",
      "epoch = 21 train_loss : 41.216908 , test loss : 57.629215\n",
      "epoch = 22 train_loss : 38.555996 , test loss : 50.386948\n",
      "epoch = 23 train_loss : 36.277119 , test loss : 48.435837\n",
      "epoch = 24 train_loss : 35.095123 , test loss : 46.820515\n",
      "epoch = 25 train_loss : 34.610939 , test loss : 45.763767\n",
      "epoch = 26 train_loss : 34.638271 , test loss : 45.617630\n",
      "epoch = 28 train_loss : 34.205379 , test loss : 44.292709\n",
      "epoch = 29 train_loss : 33.254894 , test loss : 43.429771\n",
      "epoch = 32 train_loss : 32.734089 , test loss : 42.797882\n",
      "epoch = 33 train_loss : 32.762527 , test loss : 42.557858\n",
      "epoch = 36 train_loss : 32.404881 , test loss : 42.104549\n",
      "epoch = 39 train_loss : 32.215469 , test loss : 41.817692\n",
      "epoch = 43 train_loss : 31.907740 , test loss : 41.532536\n",
      "epoch = 49 train_loss : 31.610710 , test loss : 40.823696\n",
      "epoch = 59 train_loss : 31.492588 , test loss : 40.636311\n",
      "epoch = 72 train_loss : 31.323383 , test loss : 40.527603\n",
      "epoch = 81 train_loss : 31.706974 , test loss : 40.485645\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.706974,test loss : 40.485645\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 604.350647 , test loss : 649.065674\n",
      "epoch = 13 train_loss : 236.083969 , test loss : 634.641907\n",
      "epoch = 14 train_loss : 206.713470 , test loss : 543.402283\n",
      "epoch = 15 train_loss : 177.505814 , test loss : 465.643585\n",
      "epoch = 16 train_loss : 150.621307 , test loss : 397.371094\n",
      "epoch = 17 train_loss : 125.577965 , test loss : 322.213470\n",
      "epoch = 18 train_loss : 104.612732 , test loss : 233.851471\n",
      "epoch = 19 train_loss : 85.818581 , test loss : 204.363617\n",
      "epoch = 20 train_loss : 71.391304 , test loss : 147.257401\n",
      "epoch = 21 train_loss : 59.838661 , test loss : 127.255760\n",
      "epoch = 22 train_loss : 51.558060 , test loss : 92.183578\n",
      "epoch = 23 train_loss : 46.170952 , test loss : 73.201836\n",
      "epoch = 24 train_loss : 42.437962 , test loss : 61.358707\n",
      "epoch = 25 train_loss : 39.821007 , test loss : 59.918633\n",
      "epoch = 26 train_loss : 37.640831 , test loss : 54.741367\n",
      "epoch = 27 train_loss : 35.736046 , test loss : 52.955593\n",
      "epoch = 28 train_loss : 35.081192 , test loss : 51.527225\n",
      "epoch = 29 train_loss : 34.643684 , test loss : 48.845676\n",
      "epoch = 30 train_loss : 34.238079 , test loss : 47.715290\n",
      "epoch = 32 train_loss : 33.605953 , test loss : 46.448246\n",
      "epoch = 33 train_loss : 33.214096 , test loss : 46.118279\n",
      "epoch = 34 train_loss : 33.130829 , test loss : 45.947430\n",
      "epoch = 35 train_loss : 32.877647 , test loss : 45.770916\n",
      "epoch = 36 train_loss : 33.118504 , test loss : 45.734013\n",
      "epoch = 37 train_loss : 33.160469 , test loss : 45.685020\n",
      "epoch = 38 train_loss : 32.982010 , test loss : 45.058605\n",
      "epoch = 41 train_loss : 32.173340 , test loss : 45.002304\n",
      "epoch = 42 train_loss : 32.730305 , test loss : 44.522022\n",
      "epoch = 45 train_loss : 32.199455 , test loss : 43.954529\n",
      "epoch = 51 train_loss : 31.486975 , test loss : 43.623581\n",
      "epoch = 56 train_loss : 31.880379 , test loss : 43.444782\n",
      "epoch = 68 train_loss : 31.486359 , test loss : 43.126488\n",
      "epoch = 73 train_loss : 31.307232 , test loss : 43.109222\n",
      "epoch = 76 train_loss : 31.281849 , test loss : 42.734905\n",
      "epoch = 85 train_loss : 31.139263 , test loss : 42.613018\n",
      "epoch = 96 train_loss : 30.664150 , test loss : 42.558392\n",
      "epoch = 99 train_loss : 30.754995 , test loss : 42.427299\n",
      "epoch = 100 train_loss : 30.807468 , test loss : 42.288273\n",
      "epoch = 102 train_loss : 30.905748 , test loss : 42.233940\n",
      "epoch = 107 train_loss : 30.754047 , test loss : 42.079941\n",
      "epoch = 129 train_loss : 30.692411 , test loss : 41.899483\n",
      "epoch = 175 train_loss : 30.568306 , test loss : 41.834751\n",
      "epoch = 186 train_loss : 30.717096 , test loss : 41.680943\n",
      "epoch = 223 train_loss : 30.950483 , test loss : 41.678265\n",
      "epoch = 320 train_loss : 30.961567 , test loss : 41.643208\n",
      "epoch = 398 train_loss : 30.500710 , test loss : 41.631847\n",
      "epoch = 551 train_loss : 30.556591 , test loss : 41.630310\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 30.556591,test loss : 41.630310\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 645.571472 , test loss : 487.138428\n",
      "epoch = 10 train_loss : 352.990173 , test loss : 483.980957\n",
      "epoch = 11 train_loss : 318.743713 , test loss : 452.703125\n",
      "epoch = 12 train_loss : 283.928986 , test loss : 413.594604\n",
      "epoch = 13 train_loss : 249.978226 , test loss : 366.470795\n",
      "epoch = 14 train_loss : 214.552460 , test loss : 305.641113\n",
      "epoch = 15 train_loss : 182.070709 , test loss : 235.738678\n",
      "epoch = 16 train_loss : 151.367752 , test loss : 192.028931\n",
      "epoch = 17 train_loss : 124.773125 , test loss : 151.339905\n",
      "epoch = 18 train_loss : 101.967903 , test loss : 115.842705\n",
      "epoch = 19 train_loss : 85.286240 , test loss : 95.753174\n",
      "epoch = 20 train_loss : 70.829010 , test loss : 72.867714\n",
      "epoch = 21 train_loss : 61.016457 , test loss : 49.242172\n",
      "epoch = 22 train_loss : 52.633823 , test loss : 39.778316\n",
      "epoch = 23 train_loss : 48.857956 , test loss : 37.344040\n",
      "epoch = 24 train_loss : 44.584583 , test loss : 27.380148\n",
      "epoch = 25 train_loss : 42.682339 , test loss : 25.806246\n",
      "epoch = 27 train_loss : 40.189766 , test loss : 24.122923\n",
      "epoch = 28 train_loss : 39.725845 , test loss : 23.936655\n",
      "epoch = 29 train_loss : 39.286049 , test loss : 23.635416\n",
      "epoch = 31 train_loss : 38.659355 , test loss : 23.399364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 35 train_loss : 37.688641 , test loss : 23.398241\n",
      "epoch = 39 train_loss : 37.174675 , test loss : 23.071039\n",
      "epoch = 42 train_loss : 37.052330 , test loss : 22.730919\n",
      "epoch = 47 train_loss : 36.647984 , test loss : 22.539539\n",
      "epoch = 51 train_loss : 36.479469 , test loss : 22.492062\n",
      "epoch = 72 train_loss : 35.717010 , test loss : 22.463718\n",
      "epoch = 94 train_loss : 35.570087 , test loss : 22.332874\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 35.570087,test loss : 22.332874\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 627.315674 , test loss : 616.007874\n",
      "epoch = 2 train_loss : 572.924744 , test loss : 612.647827\n",
      "epoch = 3 train_loss : 543.352234 , test loss : 608.106201\n",
      "epoch = 4 train_loss : 514.450195 , test loss : 601.866272\n",
      "epoch = 9 train_loss : 361.626282 , test loss : 592.471252\n",
      "epoch = 10 train_loss : 326.927460 , test loss : 554.085449\n",
      "epoch = 11 train_loss : 291.853973 , test loss : 506.943024\n",
      "epoch = 12 train_loss : 257.447235 , test loss : 451.700073\n",
      "epoch = 13 train_loss : 222.597382 , test loss : 409.848999\n",
      "epoch = 14 train_loss : 189.318863 , test loss : 349.360596\n",
      "epoch = 15 train_loss : 158.543854 , test loss : 284.825043\n",
      "epoch = 16 train_loss : 131.158325 , test loss : 227.189346\n",
      "epoch = 17 train_loss : 110.201859 , test loss : 197.308884\n",
      "epoch = 18 train_loss : 89.362579 , test loss : 138.553589\n",
      "epoch = 19 train_loss : 72.763916 , test loss : 102.659241\n",
      "epoch = 20 train_loss : 61.380680 , test loss : 81.684814\n",
      "epoch = 21 train_loss : 52.649002 , test loss : 63.381031\n",
      "epoch = 22 train_loss : 47.357235 , test loss : 55.323509\n",
      "epoch = 23 train_loss : 43.360584 , test loss : 47.990246\n",
      "epoch = 24 train_loss : 40.403881 , test loss : 42.505135\n",
      "epoch = 25 train_loss : 38.815662 , test loss : 39.645885\n",
      "epoch = 26 train_loss : 37.962791 , test loss : 38.404636\n",
      "epoch = 27 train_loss : 37.690659 , test loss : 38.081493\n",
      "epoch = 28 train_loss : 36.760098 , test loss : 37.026222\n",
      "epoch = 29 train_loss : 37.097988 , test loss : 36.438713\n",
      "epoch = 31 train_loss : 36.162861 , test loss : 36.258965\n",
      "epoch = 32 train_loss : 35.421696 , test loss : 35.688953\n",
      "epoch = 33 train_loss : 35.807220 , test loss : 35.301201\n",
      "epoch = 34 train_loss : 35.765636 , test loss : 35.000462\n",
      "epoch = 37 train_loss : 34.945553 , test loss : 34.925785\n",
      "epoch = 41 train_loss : 35.398029 , test loss : 34.170414\n",
      "epoch = 44 train_loss : 34.485954 , test loss : 34.077431\n",
      "epoch = 46 train_loss : 34.026199 , test loss : 33.838223\n",
      "epoch = 47 train_loss : 34.123745 , test loss : 33.734062\n",
      "epoch = 48 train_loss : 34.211300 , test loss : 33.452511\n",
      "epoch = 51 train_loss : 34.451736 , test loss : 33.142181\n",
      "epoch = 55 train_loss : 33.567101 , test loss : 32.884506\n",
      "epoch = 60 train_loss : 33.442955 , test loss : 32.600689\n",
      "epoch = 62 train_loss : 33.577324 , test loss : 32.534790\n",
      "epoch = 70 train_loss : 33.489388 , test loss : 32.422459\n",
      "epoch = 72 train_loss : 33.364532 , test loss : 32.116581\n",
      "epoch = 85 train_loss : 33.202888 , test loss : 32.054352\n",
      "epoch = 96 train_loss : 33.352314 , test loss : 31.983181\n",
      "epoch = 135 train_loss : 33.751221 , test loss : 31.730675\n",
      "epoch = 150 train_loss : 33.193142 , test loss : 31.640821\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.193142,test loss : 31.640821\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.448281,total test loss mean : 34.994835 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x22.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x22,y22,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:16:45.502570Z",
     "start_time": "2021-12-29T06:09:26.908484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 572.718445 , test loss : 584.010437\n",
      "epoch = 2 train_loss : 522.648865 , test loss : 538.788757\n",
      "epoch = 3 train_loss : 479.260925 , test loss : 500.751770\n",
      "epoch = 4 train_loss : 431.364075 , test loss : 453.181488\n",
      "epoch = 5 train_loss : 373.274139 , test loss : 394.611633\n",
      "epoch = 6 train_loss : 308.810272 , test loss : 328.901825\n",
      "epoch = 7 train_loss : 240.460709 , test loss : 254.985916\n",
      "epoch = 8 train_loss : 176.963196 , test loss : 191.133621\n",
      "epoch = 9 train_loss : 119.721054 , test loss : 129.870667\n",
      "epoch = 10 train_loss : 78.511131 , test loss : 86.935173\n",
      "epoch = 11 train_loss : 54.415157 , test loss : 61.995895\n",
      "epoch = 12 train_loss : 43.039936 , test loss : 49.880802\n",
      "epoch = 13 train_loss : 38.245274 , test loss : 44.676754\n",
      "epoch = 14 train_loss : 37.054710 , test loss : 43.680313\n",
      "epoch = 17 train_loss : 35.117310 , test loss : 42.466881\n",
      "epoch = 18 train_loss : 34.847382 , test loss : 41.714108\n",
      "epoch = 20 train_loss : 33.589920 , test loss : 40.671570\n",
      "epoch = 28 train_loss : 32.676655 , test loss : 40.012390\n",
      "epoch = 31 train_loss : 32.621048 , test loss : 39.378891\n",
      "epoch = 36 train_loss : 31.783453 , test loss : 39.074406\n",
      "epoch = 109 train_loss : 31.415457 , test loss : 38.783646\n",
      "epoch = 479 train_loss : 31.225880 , test loss : 38.780869\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.225880,test loss : 38.780869\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 576.192932 , test loss : 563.626160\n",
      "epoch = 2 train_loss : 521.887085 , test loss : 524.657471\n",
      "epoch = 3 train_loss : 478.075562 , test loss : 488.315491\n",
      "epoch = 4 train_loss : 428.294312 , test loss : 442.616730\n",
      "epoch = 5 train_loss : 369.718811 , test loss : 392.868347\n",
      "epoch = 6 train_loss : 303.410736 , test loss : 330.995941\n",
      "epoch = 7 train_loss : 236.286606 , test loss : 264.985901\n",
      "epoch = 8 train_loss : 170.423172 , test loss : 197.772751\n",
      "epoch = 9 train_loss : 116.174706 , test loss : 138.346542\n",
      "epoch = 10 train_loss : 76.880730 , test loss : 92.992577\n",
      "epoch = 11 train_loss : 53.057377 , test loss : 68.107033\n",
      "epoch = 12 train_loss : 42.146824 , test loss : 55.255127\n",
      "epoch = 13 train_loss : 37.243565 , test loss : 49.361702\n",
      "epoch = 14 train_loss : 35.948742 , test loss : 46.331310\n",
      "epoch = 15 train_loss : 36.106743 , test loss : 46.067909\n",
      "epoch = 17 train_loss : 34.382725 , test loss : 45.052475\n",
      "epoch = 18 train_loss : 33.568691 , test loss : 43.879875\n",
      "epoch = 21 train_loss : 32.674042 , test loss : 43.227173\n",
      "epoch = 22 train_loss : 33.228512 , test loss : 42.898140\n",
      "epoch = 23 train_loss : 32.446789 , test loss : 42.427250\n",
      "epoch = 27 train_loss : 32.470009 , test loss : 41.769665\n",
      "epoch = 35 train_loss : 31.897499 , test loss : 41.343899\n",
      "epoch = 38 train_loss : 31.803549 , test loss : 41.060753\n",
      "epoch = 42 train_loss : 31.920727 , test loss : 40.888340\n",
      "epoch = 61 train_loss : 32.012688 , test loss : 40.344646\n",
      "epoch = 78 train_loss : 31.431530 , test loss : 40.200893\n",
      "epoch = 123 train_loss : 31.158346 , test loss : 40.098377\n",
      "epoch = 255 train_loss : 31.671913 , test loss : 40.064800\n",
      "epoch = 582 train_loss : 31.131283 , test loss : 40.045872\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.131283,test loss : 40.045872\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 572.503723 , test loss : 596.078247\n",
      "epoch = 2 train_loss : 525.387146 , test loss : 534.820801\n",
      "epoch = 3 train_loss : 480.406921 , test loss : 486.917969\n",
      "epoch = 4 train_loss : 433.322693 , test loss : 440.343903\n",
      "epoch = 5 train_loss : 374.115417 , test loss : 387.430847\n",
      "epoch = 6 train_loss : 308.969818 , test loss : 318.363098\n",
      "epoch = 7 train_loss : 242.016098 , test loss : 250.199219\n",
      "epoch = 8 train_loss : 177.320786 , test loss : 181.775391\n",
      "epoch = 9 train_loss : 121.523788 , test loss : 126.150688\n",
      "epoch = 10 train_loss : 82.204498 , test loss : 80.916298\n",
      "epoch = 11 train_loss : 57.841553 , test loss : 55.093914\n",
      "epoch = 12 train_loss : 46.161514 , test loss : 43.198826\n",
      "epoch = 13 train_loss : 41.754944 , test loss : 38.408066\n",
      "epoch = 14 train_loss : 39.486130 , test loss : 35.630180\n",
      "epoch = 15 train_loss : 37.876114 , test loss : 33.912140\n",
      "epoch = 16 train_loss : 37.579937 , test loss : 33.253757\n",
      "epoch = 17 train_loss : 36.360573 , test loss : 32.630905\n",
      "epoch = 19 train_loss : 36.133007 , test loss : 32.298512\n",
      "epoch = 21 train_loss : 35.203983 , test loss : 31.776337\n",
      "epoch = 37 train_loss : 34.581608 , test loss : 31.601492\n",
      "epoch = 42 train_loss : 34.162922 , test loss : 31.561659\n",
      "epoch = 54 train_loss : 33.535755 , test loss : 31.517864\n",
      "epoch = 58 train_loss : 33.568527 , test loss : 31.353479\n",
      "epoch = 62 train_loss : 34.068607 , test loss : 31.260468\n",
      "epoch = 340 train_loss : 33.150471 , test loss : 31.165726\n",
      "epoch = 828 train_loss : 33.192722 , test loss : 31.098724\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 33.192722,test loss : 31.098724\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 575.453491 , test loss : 563.956421\n",
      "epoch = 2 train_loss : 522.856567 , test loss : 521.945312\n",
      "epoch = 3 train_loss : 477.709076 , test loss : 481.084259\n",
      "epoch = 4 train_loss : 428.253540 , test loss : 438.801849\n",
      "epoch = 5 train_loss : 369.938354 , test loss : 383.793701\n",
      "epoch = 6 train_loss : 304.766693 , test loss : 322.254456\n",
      "epoch = 7 train_loss : 236.525757 , test loss : 252.176590\n",
      "epoch = 8 train_loss : 172.105499 , test loss : 185.402283\n",
      "epoch = 9 train_loss : 120.252632 , test loss : 127.455200\n",
      "epoch = 10 train_loss : 78.124992 , test loss : 83.768860\n",
      "epoch = 11 train_loss : 54.709991 , test loss : 59.047115\n",
      "epoch = 12 train_loss : 44.273602 , test loss : 47.773861\n",
      "epoch = 13 train_loss : 39.536171 , test loss : 41.251545\n",
      "epoch = 14 train_loss : 37.514881 , test loss : 39.042847\n",
      "epoch = 16 train_loss : 36.147644 , test loss : 37.270473\n",
      "epoch = 21 train_loss : 35.421192 , test loss : 36.526997\n",
      "epoch = 23 train_loss : 35.548023 , test loss : 36.364220\n",
      "epoch = 26 train_loss : 35.048195 , test loss : 35.843914\n",
      "epoch = 33 train_loss : 33.378139 , test loss : 35.635429\n",
      "epoch = 36 train_loss : 34.077667 , test loss : 35.608013\n",
      "epoch = 38 train_loss : 33.201874 , test loss : 34.888203\n",
      "epoch = 44 train_loss : 32.809452 , test loss : 34.653965\n",
      "epoch = 63 train_loss : 33.143982 , test loss : 34.644764\n",
      "epoch = 64 train_loss : 32.547787 , test loss : 34.612106\n",
      "epoch = 107 train_loss : 32.845821 , test loss : 34.471992\n",
      "epoch = 196 train_loss : 32.632557 , test loss : 34.432323\n",
      "epoch = 256 train_loss : 32.486942 , test loss : 34.367252\n",
      "epoch = 350 train_loss : 32.542271 , test loss : 34.305431\n",
      "epoch = 587 train_loss : 32.402088 , test loss : 34.249123\n",
      "epoch = 953 train_loss : 32.402527 , test loss : 34.229546\n",
      "epoch = 992 train_loss : 32.216408 , test loss : 34.205376\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.216408,test loss : 34.205376\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 574.274414 , test loss : 575.877197\n",
      "epoch = 2 train_loss : 522.518738 , test loss : 526.939514\n",
      "epoch = 3 train_loss : 480.846161 , test loss : 484.407928\n",
      "epoch = 4 train_loss : 433.333496 , test loss : 433.691315\n",
      "epoch = 5 train_loss : 377.552429 , test loss : 383.603577\n",
      "epoch = 6 train_loss : 311.139465 , test loss : 312.559326\n",
      "epoch = 7 train_loss : 241.666550 , test loss : 244.129349\n",
      "epoch = 8 train_loss : 175.254684 , test loss : 177.509552\n",
      "epoch = 9 train_loss : 120.241859 , test loss : 122.463722\n",
      "epoch = 10 train_loss : 80.795357 , test loss : 82.694046\n",
      "epoch = 11 train_loss : 56.167511 , test loss : 55.491913\n",
      "epoch = 12 train_loss : 45.847805 , test loss : 42.551025\n",
      "epoch = 13 train_loss : 40.515240 , test loss : 37.586117\n",
      "epoch = 16 train_loss : 37.285477 , test loss : 34.742336\n",
      "epoch = 17 train_loss : 36.346359 , test loss : 32.948879\n",
      "epoch = 21 train_loss : 36.000652 , test loss : 32.625721\n",
      "epoch = 23 train_loss : 35.470131 , test loss : 32.544693\n",
      "epoch = 26 train_loss : 34.723763 , test loss : 31.504349\n",
      "epoch = 27 train_loss : 34.668064 , test loss : 31.271341\n",
      "epoch = 28 train_loss : 34.735180 , test loss : 31.166920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 31 train_loss : 35.138771 , test loss : 31.126564\n",
      "epoch = 36 train_loss : 34.116096 , test loss : 31.032524\n",
      "epoch = 40 train_loss : 34.017723 , test loss : 30.509760\n",
      "epoch = 42 train_loss : 33.864189 , test loss : 30.366016\n",
      "epoch = 44 train_loss : 33.771214 , test loss : 30.251110\n",
      "epoch = 57 train_loss : 33.601959 , test loss : 30.230684\n",
      "epoch = 90 train_loss : 33.839481 , test loss : 30.217751\n",
      "epoch = 121 train_loss : 33.607899 , test loss : 29.801674\n",
      "epoch = 177 train_loss : 33.617168 , test loss : 29.759855\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.617168,test loss : 29.759855\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.276692,total test loss mean : 34.778139 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x22.shape[1],512),nn.Linear(512,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x22,y22,256,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- just test linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:40:52.580936Z",
     "start_time": "2021-12-30T05:40:51.183857Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso,ElasticNet,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:41:05.508676Z",
     "start_time": "2021-12-30T05:41:05.493675Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "\n",
    "def rmlse_cv(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x)\n",
    "    rmse=np.sqrt(-cross_val_score(model,x,y,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:41:09.930929Z",
     "start_time": "2021-12-30T05:41:06.349724Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 5.9364 (0.6516)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.0005,random_state=1))\n",
    "score=rmlse_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:41:14.775206Z",
     "start_time": "2021-12-30T05:41:14.758205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8588435719005165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(34.326048 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:41:19.010448Z",
     "start_time": "2021-12-30T05:41:15.343238Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " enet score: 5.9364 (0.6516)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "enet=make_pipeline(RobustScaler(),ElasticNet(alpha=0.0005,l1_ratio=0.9))\n",
    "scoreo=rmlse_cv(enet)\n",
    "print(\"\\n enet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:41:21.293579Z",
     "start_time": "2021-12-30T05:41:20.968560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ridge score: 5.9404 (0.6500)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge=make_pipeline(RobustScaler(),Ridge(alpha=0.5))\n",
    "score=rmlse_cv(ridge)\n",
    "print(\"\\n ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:42:39.630059Z",
     "start_time": "2021-12-30T05:41:22.062623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 6.9629 (1.0416)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000,\n",
    "                                   learning_rate=0.05,\n",
    "                                   max_depth=4,\n",
    "                                   max_features='sqrt',\n",
    "                                   min_samples_leaf=15,\n",
    "                                   min_samples_split=10,\n",
    "                                   loss='huber',\n",
    "                                   random_state=5)\n",
    "score = rmlse_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:43:31.793043Z",
     "start_time": "2021-12-30T05:42:44.039312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:42:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:43:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:43:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:43:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Xgboost score: 6.5696 (0.8384)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "score = rmlse_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:43:39.086460Z",
     "start_time": "2021-12-30T05:43:37.591375Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 6.6617 (0.9785)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "score = rmlse_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:08.906166Z",
     "start_time": "2021-12-30T05:44:08.883164Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_list=[]\n",
    "for i in range(12):\n",
    "    month_list.append(pd.DataFrame(year_data[i]))\n",
    "all_train_data=pd.concat(month_list,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:09.394194Z",
     "start_time": "2021-12-30T05:44:09.390193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 480)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_list[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:10.558260Z",
     "start_time": "2021-12-30T05:44:10.550260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check reshape data is right ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:12.120349Z",
     "start_time": "2021-12-30T05:44:12.088348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>109.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>108.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>114.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       9    10    11   12   13     14     15   16   17\n",
       "475  37.0  0.0  76.0  2.6  1.9  109.0   97.0  1.0  1.4\n",
       "476  28.0  0.0  80.0  2.2  1.9  108.0  107.0  1.7  1.3\n",
       "477  17.0  0.0  82.0  2.3  1.9  114.0  118.0  1.5  1.6\n",
       "478  24.0  0.0  84.0  2.3  2.0  108.0  100.0  2.0  1.8\n",
       "479  29.0  0.0  84.0  2.3  2.0  109.0  105.0  2.0  2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.iloc[-5:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:12.938396Z",
     "start_time": "2021-12-30T05:44:12.886393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.527413</td>\n",
       "      <td>1.702396</td>\n",
       "      <td>0.388363</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.135729</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.247726</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.414236</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.763125</td>\n",
       "      <td>1.839653</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.290152</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>0.323573</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.282155</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.577133</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.662537</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.816940</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.300000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.527413     1.702396     0.388363     0.140427     2.135729   \n",
       "std       6.290152     0.125265     0.323573     0.104645     2.282155   \n",
       "min     -12.300000    -0.200000    -0.120000     0.000000    -1.100000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.247726    31.905469    42.709201    21.414236   \n",
       "std       6.187555     7.577133    18.703486    26.222292    16.662537   \n",
       "min       0.000000    -2.400000     0.000000     0.000000    -1.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    29.250000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.763125     1.839653   156.329271   \n",
       "std       2.045443    13.361351     1.816940     0.181839    95.745881   \n",
       "min       0.000000    29.000000    -1.600000    -0.200000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T03:08:39.600886Z",
     "start_time": "2021-12-28T03:08:39.594886Z"
    },
    "collapsed": true
   },
   "source": [
    "### correct outlier value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:31.070433Z",
     "start_time": "2021-12-30T05:44:31.062433Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data1=year_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:33.154553Z",
     "start_time": "2021-12-30T05:44:33.115550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      "---------- pm2.5 start : \n",
      " -3.1 \n",
      "\n",
      "-8.0\n",
      "-7.2\n",
      "-6.8\n",
      "-6.5\n",
      "-7.1\n",
      "-7.4\n",
      "-8.1\n",
      "-8.3\n",
      "-8.4\n",
      "-9.3\n",
      "-10.6\n",
      "-11.2\n",
      "-12.1\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-12.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 19.0 18.0\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n"
     ]
    }
   ],
   "source": [
    "# temperature always >=0 in Taiwan and change fast when temperature <=0 ,so correct it\n",
    "for idx in [0]:\t\n",
    "\tfor m in range(12):\n",
    "\t\tprint(' month : ',m)\n",
    "\t\ti=0\n",
    "\t\twhile i<480:\n",
    "\t\t\tif year_data1[m][idx,i] <=0:\n",
    "\t\t\t\tprint('---------- pm2.5 start : \\n',year_data1[m][idx,i],'\\n')\n",
    "\t\t\t\tfor k in range(30):\n",
    "\t\t\t\t\tif k+i+1>479:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif year_data1[m][idx,k+i+1] >0:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(year_data1[m][idx,k+i+1])\n",
    "\t\t\t\ti=i+k\n",
    "\t\t\t\tprint('pm2.5 end ------------')\n",
    "\t\t\t\tprint('correct value between  :',year_data1[m][idx,i-1-k],year_data1[m][idx,i+1])\n",
    "\t\t\t\t## add correct to mean value\n",
    "\t\t\t\tyear_data1[m][idx,i-k:i+1]=(year_data1[m][idx,i-1-k]+year_data1[m][idx,i+1])/2\n",
    "\t\t\ti=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:39.320905Z",
     "start_time": "2021-12-30T05:44:39.293904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_list=[]\n",
    "for i in range(12):\n",
    "    month_list.append(pd.DataFrame(year_data1[i]))\n",
    "all_train_data1=pd.concat(month_list,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:40.484972Z",
     "start_time": "2021-12-30T05:44:40.409968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.610382</td>\n",
       "      <td>1.702396</td>\n",
       "      <td>0.388363</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.135729</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.247726</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.414236</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.763125</td>\n",
       "      <td>1.839653</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.062216</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>0.323573</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.282155</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.577133</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.662537</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.816940</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.700000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.610382     1.702396     0.388363     0.140427     2.135729   \n",
       "std       6.062216     0.125265     0.323573     0.104645     2.282155   \n",
       "min       6.700000    -0.200000    -0.120000     0.000000    -1.100000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.247726    31.905469    42.709201    21.414236   \n",
       "std       6.187555     7.577133    18.703486    26.222292    16.662537   \n",
       "min       0.000000    -2.400000     0.000000     0.000000    -1.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    29.250000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.763125     1.839653   156.329271   \n",
       "std       2.045443    13.361351     1.816940     0.181839    95.745881   \n",
       "min       0.000000    29.000000    -1.600000    -0.200000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:54.038747Z",
     "start_time": "2021-12-30T05:44:53.919740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.8 1.8\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.12 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.34 0.26\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.5 0.3\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.1 1.0\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -1.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 6.6 1.2\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      "---------- pm2.5 start : \n",
      " -0.9 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 17.0 17.0\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 7.4 10.0\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -2.4 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 7.0 6.6\n",
      " month :  11\n",
      " month :  0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 46.0 51.0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 6.0 16.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 13.0 16.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 55.0 48.0\n",
      " month :  4\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 5.0 1.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.0 4.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 5.0 0.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 10.0 9.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 9.0 2.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 4.0\n",
      " month :  5\n",
      " month :  6\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 20.0 27.0\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 18.0 18.0\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 13.0 7.0\n",
      " month :  0\n",
      "---------- pm2.5 start : \n",
      " -0.9 \n",
      "\n",
      "-0.9\n",
      "-0.9\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.6 1.3\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "-0.1\n",
      "-0.2\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.1 1.2\n",
      " month :  1\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.1 0.3\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      "---------- pm2.5 start : \n",
      " -1.5 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.2 2.3\n",
      "---------- pm2.5 start : \n",
      " -0.3 \n",
      "\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 3.8 2.2\n",
      " month :  6\n",
      " month :  7\n",
      "---------- pm2.5 start : \n",
      " -1.6 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 4.3 2.7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 0.9\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.2 0.3\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.4\n",
      "-0.5\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 1.2\n",
      "---------- pm2.5 start : \n",
      " -0.3 \n",
      "\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 1.1\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.8 2.0\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.0 1.9\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2,4,6,9,12,13]:\t\n",
    "\tfor m in range(12):\n",
    "\t\tprint(' month : ',m)\n",
    "\t\ti=0\n",
    "\t\twhile i<480:\n",
    "\t\t\tif year_data1[m][idx,i] <0:\n",
    "\t\t\t\tprint('---------- pm2.5 start : \\n',year_data1[m][idx,i],'\\n')\n",
    "\t\t\t\tfor k in range(30):\n",
    "\t\t\t\t\tif k+i+1>479:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif year_data1[m][idx,k+i+1] >=0:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(year_data1[m][idx,k+i+1])\n",
    "\t\t\t\ti=i+k\n",
    "\t\t\t\tprint('pm2.5 end ------------')\n",
    "\t\t\t\tprint('correct value between  :',year_data1[m][idx,i-1-k],year_data1[m][idx,i+1])\n",
    "\t\t\t\t## add correct to mean value\n",
    "\t\t\t\tyear_data1[m][idx,i-k:i+1]=(year_data1[m][idx,i-1-k]+year_data1[m][idx,i+1])/2\n",
    "\t\t\ti=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:55.555834Z",
     "start_time": "2021-12-30T05:44:55.533833Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_list=[]\n",
    "for i in range(12):\n",
    "    month_list.append(pd.DataFrame(year_data1[i]))\n",
    "all_train_data1=pd.concat(month_list,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:56.459886Z",
     "start_time": "2021-12-30T05:44:56.397882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.610382</td>\n",
       "      <td>1.705521</td>\n",
       "      <td>0.388436</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.136970</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.254115</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.534201</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.769089</td>\n",
       "      <td>1.843012</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.062216</td>\n",
       "      <td>0.100203</td>\n",
       "      <td>0.323505</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.281611</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.571422</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.576035</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.809743</td>\n",
       "      <td>0.163008</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.610382     1.705521     0.388436     0.140427     2.136970   \n",
       "std       6.062216     0.100203     0.323505     0.104645     2.281611   \n",
       "min       6.700000     0.000000     0.080000     0.000000     0.000000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.254115    31.905469    42.709201    21.534201   \n",
       "std       6.187555     7.571422    18.703486    26.222292    16.576035   \n",
       "min       0.000000     1.300000     0.000000     0.000000     0.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    30.000000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.769089     1.843012   156.329271   \n",
       "std       2.045443    13.361351     1.809743     0.163008    95.745881   \n",
       "min       0.000000    29.000000     0.000000     0.000000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:56.918912Z",
     "start_time": "2021-12-30T05:44:56.911911Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x3=np.empty((12*471,18*9))\n",
    "y3=np.empty((12*471,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:57.588950Z",
     "start_time": "2021-12-30T05:44:57.549948Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in range(12):\n",
    "    for g in range(471):\n",
    "        x3[m*471+g:m*471+g+1,:]=year_data1[m][:,g:g+9].reshape(1,-1)\n",
    "        y3[m*471+g:m*471+g+1,:]=year_data1[m][9,g+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:58.123981Z",
     "start_time": "2021-12-30T05:44:58.116980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7, 1.7, 1.7, 1.7, 1.8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data[11][-5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:58.767018Z",
     "start_time": "2021-12-30T05:44:58.760017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7, 1.7, 1.7, 1.7, 1.8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data1[11][-5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:44:59.343050Z",
     "start_time": "2021-12-30T05:44:59.337050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3, 1.7, 0.7, 0.4, 1.1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-5,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:00.063092Z",
     "start_time": "2021-12-30T05:45:00.057091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3, 1.7, 0.7, 0.4, 1.1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3[-5,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:00.617123Z",
     "start_time": "2021-12-30T05:45:00.605123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [28.],\n",
       "       [17.],\n",
       "       [24.],\n",
       "       [29.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:01.228158Z",
     "start_time": "2021-12-30T05:45:01.222158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [28.],\n",
       "       [17.],\n",
       "       [24.],\n",
       "       [29.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:01.851194Z",
     "start_time": "2021-12-30T05:45:01.838193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:02.481230Z",
     "start_time": "2021-12-30T05:45:02.469229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3[y3<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:03.000260Z",
     "start_time": "2021-12-30T05:45:02.992259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3[x3<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:03.611295Z",
     "start_time": "2021-12-30T05:45:03.524290Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x33=pd.DataFrame(x3)\n",
    "x33=x33.apply(lambda x: (x-x.mean())/x.std())\n",
    "x33=x33.values\n",
    "y33=y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:04.805363Z",
     "start_time": "2021-12-30T05:45:04.781362Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x333=torch.Tensor(x33)\n",
    "y333=torch.Tensor(y33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T02:16:28.216948Z",
     "start_time": "2021-12-29T02:12:18.918689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 150.251907 , test loss : 155.604050\n",
      "epoch = 2 train_loss : 99.558205 , test loss : 104.195030\n",
      "epoch = 3 train_loss : 80.369507 , test loss : 87.102425\n",
      "epoch = 4 train_loss : 69.669907 , test loss : 75.825897\n",
      "epoch = 5 train_loss : 64.667076 , test loss : 70.746811\n",
      "epoch = 6 train_loss : 61.921131 , test loss : 67.884300\n",
      "epoch = 7 train_loss : 56.259201 , test loss : 62.566200\n",
      "epoch = 8 train_loss : 52.487587 , test loss : 58.312618\n",
      "epoch = 9 train_loss : 50.237362 , test loss : 55.953819\n",
      "epoch = 10 train_loss : 48.078827 , test loss : 53.591438\n",
      "epoch = 12 train_loss : 45.296902 , test loss : 50.552940\n",
      "epoch = 13 train_loss : 43.835632 , test loss : 48.931911\n",
      "epoch = 14 train_loss : 43.257683 , test loss : 48.668621\n",
      "epoch = 15 train_loss : 43.066242 , test loss : 48.321022\n",
      "epoch = 16 train_loss : 41.003517 , test loss : 46.407482\n",
      "epoch = 18 train_loss : 40.249680 , test loss : 45.904747\n",
      "epoch = 19 train_loss : 38.598541 , test loss : 44.173035\n",
      "epoch = 20 train_loss : 38.547020 , test loss : 44.082150\n",
      "epoch = 22 train_loss : 37.248482 , test loss : 42.881256\n",
      "epoch = 23 train_loss : 37.011169 , test loss : 42.585403\n",
      "epoch = 26 train_loss : 36.006237 , test loss : 42.196953\n",
      "epoch = 27 train_loss : 36.063396 , test loss : 41.977585\n",
      "epoch = 32 train_loss : 35.185047 , test loss : 41.576931\n",
      "epoch = 33 train_loss : 35.144768 , test loss : 40.977394\n",
      "epoch = 34 train_loss : 34.678127 , test loss : 40.857880\n",
      "epoch = 37 train_loss : 34.473026 , test loss : 40.780830\n",
      "epoch = 38 train_loss : 34.395901 , test loss : 40.455273\n",
      "epoch = 47 train_loss : 33.358772 , test loss : 39.841576\n",
      "epoch = 50 train_loss : 33.210590 , test loss : 39.612091\n",
      "epoch = 61 train_loss : 32.744186 , test loss : 39.266121\n",
      "epoch = 65 train_loss : 32.891804 , test loss : 39.043297\n",
      "epoch = 69 train_loss : 32.580742 , test loss : 39.013527\n",
      "epoch = 76 train_loss : 32.249630 , test loss : 38.681110\n",
      "epoch = 102 train_loss : 32.055527 , test loss : 38.664467\n",
      "epoch = 108 train_loss : 31.887192 , test loss : 38.646629\n",
      "epoch = 110 train_loss : 31.938704 , test loss : 38.565674\n",
      "epoch = 113 train_loss : 31.797230 , test loss : 38.562164\n",
      "epoch = 130 train_loss : 31.782171 , test loss : 38.475536\n",
      "epoch = 167 train_loss : 31.622107 , test loss : 38.448021\n",
      "epoch = 232 train_loss : 31.607468 , test loss : 38.441761\n",
      "epoch = 307 train_loss : 31.533176 , test loss : 38.386894\n",
      "epoch = 360 train_loss : 31.507948 , test loss : 38.383743\n",
      "epoch = 388 train_loss : 31.486395 , test loss : 38.380219\n",
      "epoch = 468 train_loss : 31.524921 , test loss : 38.329308\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.524921,test loss : 38.329308\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 143.725555 , test loss : 154.987457\n",
      "epoch = 2 train_loss : 100.910851 , test loss : 113.883461\n",
      "epoch = 3 train_loss : 83.219131 , test loss : 95.803833\n",
      "epoch = 4 train_loss : 72.540367 , test loss : 84.528183\n",
      "epoch = 5 train_loss : 66.115387 , test loss : 77.704483\n",
      "epoch = 6 train_loss : 65.482933 , test loss : 75.550949\n",
      "epoch = 7 train_loss : 57.813988 , test loss : 68.540169\n",
      "epoch = 8 train_loss : 54.613674 , test loss : 65.679649\n",
      "epoch = 9 train_loss : 52.527237 , test loss : 64.081070\n",
      "epoch = 11 train_loss : 48.902870 , test loss : 60.918900\n",
      "epoch = 12 train_loss : 46.654434 , test loss : 57.656437\n",
      "epoch = 13 train_loss : 44.123055 , test loss : 56.219910\n",
      "epoch = 14 train_loss : 43.174698 , test loss : 54.817467\n",
      "epoch = 15 train_loss : 41.921715 , test loss : 53.645023\n",
      "epoch = 16 train_loss : 40.889576 , test loss : 52.606224\n",
      "epoch = 18 train_loss : 40.200459 , test loss : 51.252213\n",
      "epoch = 25 train_loss : 36.500397 , test loss : 48.231174\n",
      "epoch = 27 train_loss : 36.285896 , test loss : 47.165508\n",
      "epoch = 31 train_loss : 35.126976 , test loss : 45.532291\n",
      "epoch = 38 train_loss : 34.985157 , test loss : 44.890324\n",
      "epoch = 39 train_loss : 33.863876 , test loss : 44.277374\n",
      "epoch = 44 train_loss : 33.594116 , test loss : 43.653275\n",
      "epoch = 49 train_loss : 33.022732 , test loss : 42.533009\n",
      "epoch = 66 train_loss : 32.898987 , test loss : 41.859562\n",
      "epoch = 67 train_loss : 32.332130 , test loss : 41.832455\n",
      "epoch = 70 train_loss : 32.160141 , test loss : 41.358372\n",
      "epoch = 74 train_loss : 32.483154 , test loss : 41.176147\n",
      "epoch = 84 train_loss : 32.174908 , test loss : 40.907177\n",
      "epoch = 93 train_loss : 31.883329 , test loss : 40.875656\n",
      "epoch = 95 train_loss : 31.801115 , test loss : 40.688587\n",
      "epoch = 105 train_loss : 31.625254 , test loss : 40.409760\n",
      "epoch = 114 train_loss : 31.569515 , test loss : 40.341904\n",
      "epoch = 116 train_loss : 31.833282 , test loss : 40.203236\n",
      "epoch = 128 train_loss : 31.569878 , test loss : 40.164585\n",
      "epoch = 150 train_loss : 31.563631 , test loss : 40.151329\n",
      "epoch = 170 train_loss : 31.539246 , test loss : 39.784611\n",
      "epoch = 410 train_loss : 31.426306 , test loss : 39.765163\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.426306,test loss : 39.765163\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 145.884232 , test loss : 140.887878\n",
      "epoch = 2 train_loss : 120.065048 , test loss : 116.224304\n",
      "epoch = 3 train_loss : 98.570274 , test loss : 94.186981\n",
      "epoch = 4 train_loss : 81.681030 , test loss : 73.767868\n",
      "epoch = 5 train_loss : 75.400017 , test loss : 69.698990\n",
      "epoch = 6 train_loss : 64.741722 , test loss : 57.722424\n",
      "epoch = 7 train_loss : 60.742702 , test loss : 53.652279\n",
      "epoch = 8 train_loss : 58.748707 , test loss : 52.589188\n",
      "epoch = 9 train_loss : 55.252384 , test loss : 48.977894\n",
      "epoch = 11 train_loss : 53.850754 , test loss : 48.374622\n",
      "epoch = 12 train_loss : 50.319855 , test loss : 43.622704\n",
      "epoch = 13 train_loss : 50.156013 , test loss : 43.097050\n",
      "epoch = 14 train_loss : 47.216991 , test loss : 40.599445\n",
      "epoch = 15 train_loss : 45.989624 , test loss : 39.233509\n",
      "epoch = 16 train_loss : 45.114216 , test loss : 38.344410\n",
      "epoch = 18 train_loss : 43.299843 , test loss : 36.700054\n",
      "epoch = 22 train_loss : 41.115692 , test loss : 34.517052\n",
      "epoch = 27 train_loss : 39.084946 , test loss : 33.301525\n",
      "epoch = 29 train_loss : 39.071964 , test loss : 33.191559\n",
      "epoch = 35 train_loss : 37.630730 , test loss : 32.264652\n",
      "epoch = 37 train_loss : 37.642590 , test loss : 31.549349\n",
      "epoch = 41 train_loss : 36.586323 , test loss : 31.301083\n",
      "epoch = 44 train_loss : 36.068253 , test loss : 31.177195\n",
      "epoch = 49 train_loss : 35.864624 , test loss : 30.882711\n",
      "epoch = 50 train_loss : 35.517689 , test loss : 30.831886\n",
      "epoch = 54 train_loss : 35.153355 , test loss : 30.668146\n",
      "epoch = 102 train_loss : 33.920467 , test loss : 30.383089\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 33.920467,test loss : 30.383089\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 142.874252 , test loss : 142.546906\n",
      "epoch = 2 train_loss : 119.191261 , test loss : 116.087776\n",
      "epoch = 3 train_loss : 88.238503 , test loss : 86.509819\n",
      "epoch = 4 train_loss : 78.222191 , test loss : 77.165604\n",
      "epoch = 5 train_loss : 71.658936 , test loss : 71.025558\n",
      "epoch = 6 train_loss : 66.289833 , test loss : 66.185440\n",
      "epoch = 7 train_loss : 61.963337 , test loss : 62.200985\n",
      "epoch = 8 train_loss : 58.489521 , test loss : 59.226700\n",
      "epoch = 9 train_loss : 56.484394 , test loss : 57.165253\n",
      "epoch = 11 train_loss : 51.688873 , test loss : 52.250797\n",
      "epoch = 12 train_loss : 49.865849 , test loss : 50.368149\n",
      "epoch = 13 train_loss : 47.525772 , test loss : 47.625549\n",
      "epoch = 14 train_loss : 46.856441 , test loss : 47.474556\n",
      "epoch = 16 train_loss : 43.777718 , test loss : 43.869785\n",
      "epoch = 19 train_loss : 41.434441 , test loss : 41.466133\n",
      "epoch = 22 train_loss : 39.722618 , test loss : 40.094814\n",
      "epoch = 23 train_loss : 39.498554 , test loss : 39.797440\n",
      "epoch = 26 train_loss : 38.299229 , test loss : 39.027855\n",
      "epoch = 28 train_loss : 38.559696 , test loss : 38.656879\n",
      "epoch = 30 train_loss : 36.811920 , test loss : 37.361240\n",
      "epoch = 32 train_loss : 36.628784 , test loss : 36.882042\n",
      "epoch = 34 train_loss : 35.838390 , test loss : 36.666584\n",
      "epoch = 42 train_loss : 35.663643 , test loss : 36.283394\n",
      "epoch = 44 train_loss : 34.760086 , test loss : 35.802444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 47 train_loss : 34.565628 , test loss : 35.519215\n",
      "epoch = 52 train_loss : 34.032391 , test loss : 35.292900\n",
      "epoch = 55 train_loss : 34.050674 , test loss : 35.128277\n",
      "epoch = 58 train_loss : 33.804146 , test loss : 34.602654\n",
      "epoch = 87 train_loss : 33.378014 , test loss : 34.423214\n",
      "epoch = 92 train_loss : 33.236534 , test loss : 34.405964\n",
      "epoch = 114 train_loss : 32.970219 , test loss : 34.267426\n",
      "epoch = 125 train_loss : 32.875366 , test loss : 34.185539\n",
      "epoch = 126 train_loss : 32.862984 , test loss : 34.093227\n",
      "epoch = 155 train_loss : 33.150898 , test loss : 33.923546\n",
      "epoch = 206 train_loss : 32.652462 , test loss : 33.831314\n",
      "epoch = 599 train_loss : 32.596390 , test loss : 33.752548\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.596390,test loss : 33.752548\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 217.226624 , test loss : 210.688721\n",
      "epoch = 2 train_loss : 124.173622 , test loss : 113.696732\n",
      "epoch = 3 train_loss : 96.885925 , test loss : 88.073257\n",
      "epoch = 4 train_loss : 83.384079 , test loss : 75.425491\n",
      "epoch = 5 train_loss : 74.445267 , test loss : 67.556084\n",
      "epoch = 6 train_loss : 69.508949 , test loss : 62.718414\n",
      "epoch = 7 train_loss : 65.273666 , test loss : 58.496239\n",
      "epoch = 8 train_loss : 58.464451 , test loss : 51.935070\n",
      "epoch = 9 train_loss : 57.514267 , test loss : 51.249962\n",
      "epoch = 10 train_loss : 54.963215 , test loss : 48.700630\n",
      "epoch = 11 train_loss : 53.136543 , test loss : 47.158134\n",
      "epoch = 12 train_loss : 49.328178 , test loss : 43.412411\n",
      "epoch = 15 train_loss : 45.439144 , test loss : 39.797569\n",
      "epoch = 16 train_loss : 44.844486 , test loss : 39.342064\n",
      "epoch = 19 train_loss : 42.372627 , test loss : 36.976665\n",
      "epoch = 20 train_loss : 41.550728 , test loss : 36.130901\n",
      "epoch = 25 train_loss : 40.350388 , test loss : 35.325302\n",
      "epoch = 26 train_loss : 38.908703 , test loss : 33.888447\n",
      "epoch = 27 train_loss : 38.565826 , test loss : 33.491726\n",
      "epoch = 29 train_loss : 38.134262 , test loss : 33.042660\n",
      "epoch = 32 train_loss : 37.749619 , test loss : 33.005898\n",
      "epoch = 33 train_loss : 37.158371 , test loss : 32.269398\n",
      "epoch = 34 train_loss : 37.011303 , test loss : 32.167774\n",
      "epoch = 44 train_loss : 36.297901 , test loss : 31.830486\n",
      "epoch = 51 train_loss : 35.566666 , test loss : 31.281530\n",
      "epoch = 53 train_loss : 35.568539 , test loss : 30.834728\n",
      "epoch = 55 train_loss : 35.325760 , test loss : 30.576435\n",
      "epoch = 59 train_loss : 35.022369 , test loss : 30.527760\n",
      "epoch = 70 train_loss : 34.647186 , test loss : 30.500654\n",
      "epoch = 73 train_loss : 34.607864 , test loss : 30.309664\n",
      "epoch = 79 train_loss : 34.431690 , test loss : 30.185942\n",
      "epoch = 81 train_loss : 34.482990 , test loss : 30.057896\n",
      "epoch = 97 train_loss : 34.496082 , test loss : 30.051306\n",
      "epoch = 103 train_loss : 34.525021 , test loss : 29.985331\n",
      "epoch = 108 train_loss : 34.300770 , test loss : 29.784212\n",
      "epoch = 127 train_loss : 34.087532 , test loss : 29.729136\n",
      "epoch = 137 train_loss : 33.921806 , test loss : 29.676088\n",
      "epoch = 167 train_loss : 33.912956 , test loss : 29.598385\n",
      "epoch = 206 train_loss : 33.988064 , test loss : 29.575928\n",
      "epoch = 292 train_loss : 33.757290 , test loss : 29.474783\n",
      "epoch = 503 train_loss : 33.724987 , test loss : 29.448877\n",
      "epoch = 537 train_loss : 33.708096 , test loss : 29.430435\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.708096,test loss : 29.430435\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.635236,total test loss mean : 34.332109 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T08:03:25.478134Z",
     "start_time": "2021-12-30T08:03:15.837583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4 train_loss : 923.535461 , test loss : 907.922485\n",
      "epoch = 5 train_loss : 720.332886 , test loss : 709.085083\n",
      "epoch = 6 train_loss : 574.788879 , test loss : 566.616333\n",
      "epoch = 7 train_loss : 472.148865 , test loss : 466.090485\n",
      "epoch = 8 train_loss : 402.220886 , test loss : 397.568909\n",
      "epoch = 9 train_loss : 355.551514 , test loss : 351.816681\n",
      "epoch = 10 train_loss : 325.272675 , test loss : 322.134613\n",
      "epoch = 11 train_loss : 305.305817 , test loss : 302.573792\n",
      "epoch = 12 train_loss : 293.044128 , test loss : 290.594116\n",
      "epoch = 13 train_loss : 284.710693 , test loss : 282.493988\n",
      "epoch = 14 train_loss : 278.727264 , test loss : 276.728210\n",
      "epoch = 15 train_loss : 274.145966 , test loss : 272.357483\n",
      "epoch = 16 train_loss : 270.334930 , test loss : 268.769501\n",
      "epoch = 17 train_loss : 266.733276 , test loss : 265.388947\n",
      "epoch = 18 train_loss : 263.397949 , test loss : 262.282654\n",
      "epoch = 19 train_loss : 260.100281 , test loss : 259.233978\n",
      "epoch = 20 train_loss : 256.866425 , test loss : 256.245941\n",
      "epoch = 21 train_loss : 253.685532 , test loss : 253.319183\n",
      "epoch = 22 train_loss : 250.388046 , test loss : 250.271027\n",
      "epoch = 23 train_loss : 247.180099 , test loss : 247.313904\n",
      "epoch = 24 train_loss : 243.973022 , test loss : 244.365372\n",
      "epoch = 25 train_loss : 240.820801 , test loss : 241.459137\n",
      "epoch = 26 train_loss : 237.628433 , test loss : 238.516296\n",
      "epoch = 27 train_loss : 234.493774 , test loss : 235.630737\n",
      "epoch = 28 train_loss : 231.400986 , test loss : 232.787689\n",
      "epoch = 29 train_loss : 228.279572 , test loss : 229.907928\n",
      "epoch = 30 train_loss : 225.253403 , test loss : 227.114548\n",
      "epoch = 31 train_loss : 222.240448 , test loss : 224.330750\n",
      "epoch = 32 train_loss : 219.316010 , test loss : 221.641800\n",
      "epoch = 33 train_loss : 216.376602 , test loss : 218.932037\n",
      "epoch = 34 train_loss : 213.459976 , test loss : 216.243912\n",
      "epoch = 35 train_loss : 210.623993 , test loss : 213.626480\n",
      "epoch = 36 train_loss : 207.787048 , test loss : 211.001434\n",
      "epoch = 37 train_loss : 205.043549 , test loss : 208.468903\n",
      "epoch = 38 train_loss : 202.370911 , test loss : 206.002151\n",
      "epoch = 39 train_loss : 199.682770 , test loss : 203.515854\n",
      "epoch = 40 train_loss : 197.070648 , test loss : 201.102539\n",
      "epoch = 41 train_loss : 194.510986 , test loss : 198.733643\n",
      "epoch = 42 train_loss : 192.013321 , test loss : 196.420288\n",
      "epoch = 43 train_loss : 189.526352 , test loss : 194.118835\n",
      "epoch = 44 train_loss : 187.124756 , test loss : 191.891586\n",
      "epoch = 45 train_loss : 184.775940 , test loss : 189.710327\n",
      "epoch = 46 train_loss : 182.457047 , test loss : 187.561813\n",
      "epoch = 47 train_loss : 180.254852 , test loss : 185.517410\n",
      "epoch = 48 train_loss : 178.058289 , test loss : 183.481873\n",
      "epoch = 49 train_loss : 175.923233 , test loss : 181.496033\n",
      "epoch = 50 train_loss : 173.824677 , test loss : 179.549118\n",
      "epoch = 51 train_loss : 171.793900 , test loss : 177.660797\n",
      "epoch = 52 train_loss : 169.786850 , test loss : 175.785599\n",
      "epoch = 53 train_loss : 167.826584 , test loss : 173.961487\n",
      "epoch = 54 train_loss : 165.955597 , test loss : 172.218796\n",
      "epoch = 55 train_loss : 164.108871 , test loss : 170.495529\n",
      "epoch = 56 train_loss : 162.318024 , test loss : 168.820190\n",
      "epoch = 57 train_loss : 160.565155 , test loss : 167.181656\n",
      "epoch = 58 train_loss : 158.886520 , test loss : 165.615005\n",
      "epoch = 59 train_loss : 157.241531 , test loss : 164.072006\n",
      "epoch = 60 train_loss : 155.640747 , test loss : 162.564407\n",
      "epoch = 61 train_loss : 154.061462 , test loss : 161.088394\n",
      "epoch = 62 train_loss : 152.532806 , test loss : 159.653458\n",
      "epoch = 63 train_loss : 151.064392 , test loss : 158.270081\n",
      "epoch = 64 train_loss : 149.638245 , test loss : 156.925293\n",
      "epoch = 65 train_loss : 148.233170 , test loss : 155.600357\n",
      "epoch = 66 train_loss : 146.876770 , test loss : 154.322250\n",
      "epoch = 67 train_loss : 145.554428 , test loss : 153.079208\n",
      "epoch = 68 train_loss : 144.266129 , test loss : 151.853821\n",
      "epoch = 69 train_loss : 143.059128 , test loss : 150.703964\n",
      "epoch = 70 train_loss : 141.838852 , test loss : 149.557434\n",
      "epoch = 71 train_loss : 140.649979 , test loss : 148.425247\n",
      "epoch = 72 train_loss : 139.504044 , test loss : 147.338120\n",
      "epoch = 73 train_loss : 138.410431 , test loss : 146.295609\n",
      "epoch = 74 train_loss : 137.337234 , test loss : 145.279358\n",
      "epoch = 75 train_loss : 136.272461 , test loss : 144.256638\n",
      "epoch = 76 train_loss : 135.249664 , test loss : 143.276230\n",
      "epoch = 77 train_loss : 134.264938 , test loss : 142.327271\n",
      "epoch = 78 train_loss : 133.286758 , test loss : 141.396362\n",
      "epoch = 79 train_loss : 132.353607 , test loss : 140.501144\n",
      "epoch = 80 train_loss : 131.425552 , test loss : 139.614243\n",
      "epoch = 81 train_loss : 130.563065 , test loss : 138.775024\n",
      "epoch = 82 train_loss : 129.696808 , test loss : 137.939514\n",
      "epoch = 83 train_loss : 128.829956 , test loss : 137.099930\n",
      "epoch = 84 train_loss : 128.017166 , test loss : 136.318741\n",
      "epoch = 85 train_loss : 127.215469 , test loss : 135.543625\n",
      "epoch = 86 train_loss : 126.418243 , test loss : 134.766495\n",
      "epoch = 87 train_loss : 125.658447 , test loss : 134.026352\n",
      "epoch = 88 train_loss : 124.917053 , test loss : 133.302292\n",
      "epoch = 89 train_loss : 124.186684 , test loss : 132.588806\n",
      "epoch = 90 train_loss : 123.482086 , test loss : 131.901627\n",
      "epoch = 91 train_loss : 122.773880 , test loss : 131.209869\n",
      "epoch = 92 train_loss : 122.106392 , test loss : 130.564880\n",
      "epoch = 93 train_loss : 121.454834 , test loss : 129.922150\n",
      "epoch = 94 train_loss : 120.798363 , test loss : 129.287582\n",
      "epoch = 95 train_loss : 120.168175 , test loss : 128.649506\n",
      "epoch = 96 train_loss : 119.539726 , test loss : 128.018066\n",
      "epoch = 97 train_loss : 118.920197 , test loss : 127.422325\n",
      "epoch = 98 train_loss : 118.334602 , test loss : 126.865814\n",
      "epoch = 99 train_loss : 117.752663 , test loss : 126.259697\n",
      "epoch = 100 train_loss : 117.155724 , test loss : 125.682648\n",
      "epoch = 101 train_loss : 116.595062 , test loss : 125.137344\n",
      "epoch = 102 train_loss : 116.037521 , test loss : 124.571083\n",
      "epoch = 103 train_loss : 115.482811 , test loss : 124.028465\n",
      "epoch = 104 train_loss : 114.949493 , test loss : 123.503395\n",
      "epoch = 105 train_loss : 114.415436 , test loss : 122.946075\n",
      "epoch = 106 train_loss : 113.885124 , test loss : 122.429207\n",
      "epoch = 107 train_loss : 113.364304 , test loss : 121.922005\n",
      "epoch = 108 train_loss : 112.858337 , test loss : 121.412476\n",
      "epoch = 109 train_loss : 112.364594 , test loss : 120.906586\n",
      "epoch = 110 train_loss : 111.865829 , test loss : 120.435188\n",
      "epoch = 111 train_loss : 111.368370 , test loss : 119.920403\n",
      "epoch = 112 train_loss : 110.901825 , test loss : 119.439262\n",
      "epoch = 113 train_loss : 110.403091 , test loss : 118.951416\n",
      "epoch = 114 train_loss : 109.923546 , test loss : 118.478111\n",
      "epoch = 115 train_loss : 109.456047 , test loss : 118.024590\n",
      "epoch = 116 train_loss : 109.010117 , test loss : 117.557800\n",
      "epoch = 117 train_loss : 108.557755 , test loss : 117.101395\n",
      "epoch = 118 train_loss : 108.094391 , test loss : 116.650230\n",
      "epoch = 119 train_loss : 107.656784 , test loss : 116.222755\n",
      "epoch = 120 train_loss : 107.207970 , test loss : 115.754608\n",
      "epoch = 121 train_loss : 106.768303 , test loss : 115.306320\n",
      "epoch = 122 train_loss : 106.336685 , test loss : 114.887009\n",
      "epoch = 123 train_loss : 105.914177 , test loss : 114.473099\n",
      "epoch = 124 train_loss : 105.471649 , test loss : 114.006073\n",
      "epoch = 125 train_loss : 105.043053 , test loss : 113.577667\n",
      "epoch = 126 train_loss : 104.638023 , test loss : 113.196686\n",
      "epoch = 127 train_loss : 104.213348 , test loss : 112.745560\n",
      "epoch = 128 train_loss : 103.806915 , test loss : 112.339737\n",
      "epoch = 129 train_loss : 103.398438 , test loss : 111.931076\n",
      "epoch = 130 train_loss : 102.992447 , test loss : 111.526520\n",
      "epoch = 131 train_loss : 102.591446 , test loss : 111.103455\n",
      "epoch = 132 train_loss : 102.199059 , test loss : 110.744705\n",
      "epoch = 133 train_loss : 101.798409 , test loss : 110.318573\n",
      "epoch = 134 train_loss : 101.399857 , test loss : 109.921829\n",
      "epoch = 135 train_loss : 101.009003 , test loss : 109.552017\n",
      "epoch = 136 train_loss : 100.619522 , test loss : 109.140541\n",
      "epoch = 137 train_loss : 100.234390 , test loss : 108.751152\n",
      "epoch = 138 train_loss : 99.852615 , test loss : 108.367157\n",
      "epoch = 139 train_loss : 99.470474 , test loss : 108.003967\n",
      "epoch = 140 train_loss : 99.097855 , test loss : 107.593918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 141 train_loss : 98.721169 , test loss : 107.217644\n",
      "epoch = 142 train_loss : 98.342079 , test loss : 106.853676\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-44eb03fda169>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnet1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-7b2ccab40de2>\u001b[0m in \u001b[0;36mtrain_kfold\u001b[1;34m(net1, num_epochs, lr, k, x_data, y_data, batch_size, montum, wd)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_kfold_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtrain_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_k_fold_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmontum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtrain_sum_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtest_sum_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-df4102941ca8>\u001b[0m in \u001b[0;36mtrain_k_fold_data\u001b[1;34m(net, num_epochs, lr, train_features, train_labels, test_features, test_labels, batch_size, montum, wd)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#         if (e+1) %1000==0 and test_features is not  None:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,10000,0.00001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T05:51:27.381571Z",
     "start_time": "2021-12-28T05:38:58.692749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 242.862030 , test loss : 430.585968\n",
      "epoch = 2 train_loss : 119.124214 , test loss : 118.581306\n",
      "epoch = 3 train_loss : 92.216858 , test loss : 113.473755\n",
      "epoch = 4 train_loss : 79.558067 , test loss : 93.636253\n",
      "epoch = 5 train_loss : 68.957764 , test loss : 77.322014\n",
      "epoch = 6 train_loss : 62.653736 , test loss : 67.041039\n",
      "epoch = 7 train_loss : 55.060841 , test loss : 60.360199\n",
      "epoch = 8 train_loss : 51.390102 , test loss : 59.180382\n",
      "epoch = 9 train_loss : 50.936089 , test loss : 54.854618\n",
      "epoch = 10 train_loss : 43.929916 , test loss : 50.223682\n",
      "epoch = 12 train_loss : 41.247108 , test loss : 49.901432\n",
      "epoch = 13 train_loss : 39.674068 , test loss : 46.727482\n",
      "epoch = 16 train_loss : 40.105263 , test loss : 46.483082\n",
      "epoch = 17 train_loss : 38.295731 , test loss : 44.586624\n",
      "epoch = 19 train_loss : 40.744301 , test loss : 44.009396\n",
      "epoch = 26 train_loss : 34.560661 , test loss : 41.944489\n",
      "epoch = 28 train_loss : 34.315250 , test loss : 41.782665\n",
      "epoch = 35 train_loss : 34.449360 , test loss : 41.747913\n",
      "epoch = 38 train_loss : 33.810379 , test loss : 41.590111\n",
      "epoch = 42 train_loss : 34.711914 , test loss : 40.877445\n",
      "epoch = 44 train_loss : 33.038746 , test loss : 40.100815\n",
      "epoch = 60 train_loss : 32.789215 , test loss : 40.058155\n",
      "epoch = 68 train_loss : 32.600666 , test loss : 38.928970\n",
      "epoch = 233 train_loss : 32.028053 , test loss : 38.828194\n",
      "epoch = 417 train_loss : 31.511808 , test loss : 38.819115\n",
      "epoch = 488 train_loss : 31.813438 , test loss : 38.777073\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.813438,test loss : 38.777073\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 253.703796 , test loss : 440.871918\n",
      "epoch = 2 train_loss : 104.174599 , test loss : 149.008163\n",
      "epoch = 3 train_loss : 94.792305 , test loss : 135.465988\n",
      "epoch = 4 train_loss : 78.804909 , test loss : 111.314926\n",
      "epoch = 5 train_loss : 69.498032 , test loss : 98.251556\n",
      "epoch = 6 train_loss : 61.887409 , test loss : 85.660118\n",
      "epoch = 7 train_loss : 57.378086 , test loss : 79.908150\n",
      "epoch = 8 train_loss : 51.841846 , test loss : 70.944679\n",
      "epoch = 9 train_loss : 47.992577 , test loss : 64.512093\n",
      "epoch = 10 train_loss : 45.789753 , test loss : 60.871986\n",
      "epoch = 11 train_loss : 42.871513 , test loss : 56.334328\n",
      "epoch = 12 train_loss : 41.698345 , test loss : 54.440136\n",
      "epoch = 13 train_loss : 40.573380 , test loss : 52.262966\n",
      "epoch = 15 train_loss : 39.052319 , test loss : 51.004421\n",
      "epoch = 17 train_loss : 37.073654 , test loss : 47.347801\n",
      "epoch = 18 train_loss : 37.212677 , test loss : 47.180450\n",
      "epoch = 23 train_loss : 35.805759 , test loss : 44.462952\n",
      "epoch = 36 train_loss : 34.388588 , test loss : 43.084526\n",
      "epoch = 40 train_loss : 33.564358 , test loss : 42.065128\n",
      "epoch = 53 train_loss : 32.905937 , test loss : 41.927387\n",
      "epoch = 54 train_loss : 32.895794 , test loss : 41.400433\n",
      "epoch = 55 train_loss : 33.018860 , test loss : 41.259201\n",
      "epoch = 72 train_loss : 32.545242 , test loss : 40.690968\n",
      "epoch = 98 train_loss : 32.738194 , test loss : 40.556381\n",
      "epoch = 116 train_loss : 32.054626 , test loss : 40.210392\n",
      "epoch = 211 train_loss : 31.799917 , test loss : 39.939659\n",
      "epoch = 220 train_loss : 31.837509 , test loss : 39.402359\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.837509,test loss : 39.402359\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 270.867645 , test loss : 163.364166\n",
      "epoch = 2 train_loss : 117.495750 , test loss : 110.353653\n",
      "epoch = 3 train_loss : 94.724281 , test loss : 94.813744\n",
      "epoch = 4 train_loss : 82.552658 , test loss : 83.261574\n",
      "epoch = 5 train_loss : 68.976898 , test loss : 77.428528\n",
      "epoch = 6 train_loss : 62.561283 , test loss : 69.858719\n",
      "epoch = 7 train_loss : 55.846210 , test loss : 64.834953\n",
      "epoch = 9 train_loss : 49.139481 , test loss : 61.530731\n",
      "epoch = 10 train_loss : 46.571369 , test loss : 59.675236\n",
      "epoch = 11 train_loss : 44.382282 , test loss : 55.448380\n",
      "epoch = 14 train_loss : 41.920422 , test loss : 52.926861\n",
      "epoch = 15 train_loss : 38.992741 , test loss : 49.967983\n",
      "epoch = 16 train_loss : 39.305904 , test loss : 49.337700\n",
      "epoch = 19 train_loss : 40.317932 , test loss : 49.005825\n",
      "epoch = 20 train_loss : 36.268410 , test loss : 47.788101\n",
      "epoch = 21 train_loss : 37.650093 , test loss : 47.368855\n",
      "epoch = 23 train_loss : 35.732601 , test loss : 46.190586\n",
      "epoch = 24 train_loss : 35.424816 , test loss : 46.125187\n",
      "epoch = 26 train_loss : 34.736931 , test loss : 46.062012\n",
      "epoch = 27 train_loss : 33.997177 , test loss : 45.894722\n",
      "epoch = 31 train_loss : 33.875698 , test loss : 45.329277\n",
      "epoch = 35 train_loss : 33.110207 , test loss : 44.081505\n",
      "epoch = 49 train_loss : 32.805611 , test loss : 43.952251\n",
      "epoch = 54 train_loss : 31.969185 , test loss : 43.326141\n",
      "epoch = 76 train_loss : 33.096554 , test loss : 42.641216\n",
      "epoch = 77 train_loss : 32.498779 , test loss : 42.602821\n",
      "epoch = 79 train_loss : 32.031094 , test loss : 42.247803\n",
      "epoch = 94 train_loss : 32.646935 , test loss : 41.956024\n",
      "epoch = 133 train_loss : 31.590672 , test loss : 41.768368\n",
      "epoch = 200 train_loss : 31.313713 , test loss : 41.676247\n",
      "epoch = 228 train_loss : 31.474735 , test loss : 41.439980\n",
      "epoch = 253 train_loss : 31.458986 , test loss : 41.217033\n",
      "epoch = 364 train_loss : 31.221523 , test loss : 41.202030\n",
      "epoch = 461 train_loss : 31.155672 , test loss : 41.180252\n",
      "epoch = 523 train_loss : 31.092924 , test loss : 41.135956\n",
      "epoch = 643 train_loss : 31.079573 , test loss : 41.066849\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 31.079573,test loss : 41.066849\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 379.128387 , test loss : 151.578537\n",
      "epoch = 2 train_loss : 126.353790 , test loss : 52.539356\n",
      "epoch = 4 train_loss : 96.758987 , test loss : 43.711193\n",
      "epoch = 5 train_loss : 85.197861 , test loss : 39.515598\n",
      "epoch = 6 train_loss : 78.825142 , test loss : 36.877522\n",
      "epoch = 7 train_loss : 68.417595 , test loss : 33.936707\n",
      "epoch = 9 train_loss : 57.829910 , test loss : 30.182486\n",
      "epoch = 13 train_loss : 50.946491 , test loss : 26.472439\n",
      "epoch = 17 train_loss : 43.144169 , test loss : 23.874323\n",
      "epoch = 19 train_loss : 42.897598 , test loss : 23.736223\n",
      "epoch = 22 train_loss : 41.821518 , test loss : 22.071968\n",
      "epoch = 40 train_loss : 38.422337 , test loss : 21.727371\n",
      "epoch = 43 train_loss : 39.473049 , test loss : 21.671101\n",
      "epoch = 65 train_loss : 37.723583 , test loss : 21.551376\n",
      "epoch = 70 train_loss : 37.728294 , test loss : 21.505310\n",
      "epoch = 76 train_loss : 36.851471 , test loss : 21.490700\n",
      "epoch = 106 train_loss : 37.714268 , test loss : 21.099810\n",
      "epoch = 124 train_loss : 37.353622 , test loss : 20.952677\n",
      "epoch = 251 train_loss : 37.325062 , test loss : 20.905018\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 37.325062,test loss : 20.905018\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 243.779495 , test loss : 225.714340\n",
      "epoch = 2 train_loss : 125.996101 , test loss : 167.298065\n",
      "epoch = 3 train_loss : 94.713829 , test loss : 104.134155\n",
      "epoch = 4 train_loss : 77.539474 , test loss : 91.158653\n",
      "epoch = 5 train_loss : 68.915871 , test loss : 75.734833\n",
      "epoch = 6 train_loss : 59.858738 , test loss : 73.648758\n",
      "epoch = 7 train_loss : 54.621819 , test loss : 62.527672\n",
      "epoch = 9 train_loss : 48.565594 , test loss : 54.083157\n",
      "epoch = 11 train_loss : 45.894913 , test loss : 50.538513\n",
      "epoch = 13 train_loss : 43.483994 , test loss : 45.703239\n",
      "epoch = 14 train_loss : 44.058201 , test loss : 44.136383\n",
      "epoch = 15 train_loss : 42.265835 , test loss : 42.654675\n",
      "epoch = 18 train_loss : 39.509907 , test loss : 42.124271\n",
      "epoch = 20 train_loss : 38.539719 , test loss : 39.985474\n",
      "epoch = 21 train_loss : 37.813538 , test loss : 38.976456\n",
      "epoch = 22 train_loss : 37.827145 , test loss : 38.188316\n",
      "epoch = 26 train_loss : 37.022041 , test loss : 36.775948\n",
      "epoch = 35 train_loss : 35.974651 , test loss : 35.392849\n",
      "epoch = 42 train_loss : 35.610878 , test loss : 35.058311\n",
      "epoch = 43 train_loss : 36.030460 , test loss : 34.184673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 49 train_loss : 34.928020 , test loss : 33.869534\n",
      "epoch = 51 train_loss : 36.700760 , test loss : 33.787556\n",
      "epoch = 63 train_loss : 35.367897 , test loss : 33.556740\n",
      "epoch = 64 train_loss : 34.876911 , test loss : 32.767750\n",
      "epoch = 76 train_loss : 34.153156 , test loss : 32.471138\n",
      "epoch = 137 train_loss : 33.618958 , test loss : 32.308193\n",
      "epoch = 166 train_loss : 34.511906 , test loss : 32.157074\n",
      "epoch = 198 train_loss : 33.693707 , test loss : 31.952950\n",
      "epoch = 460 train_loss : 33.335690 , test loss : 31.911142\n",
      "epoch = 670 train_loss : 33.825115 , test loss : 31.892073\n",
      "epoch = 784 train_loss : 33.554974 , test loss : 31.700590\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.554974,test loss : 31.700590\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 33.122111,total test loss mean : 34.370378 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],512),nn.Linear(512,256),nn.Linear(256,64),nn.Linear(64,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T08:49:30.635619Z",
     "start_time": "2021-12-28T08:41:07.260827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 288.760529 , test loss : 299.105316\n",
      "epoch = 2 train_loss : 234.510315 , test loss : 249.888062\n",
      "epoch = 3 train_loss : 229.500900 , test loss : 245.100098\n",
      "epoch = 4 train_loss : 221.382858 , test loss : 236.312546\n",
      "epoch = 5 train_loss : 214.687164 , test loss : 229.509644\n",
      "epoch = 6 train_loss : 208.009369 , test loss : 222.841476\n",
      "epoch = 7 train_loss : 201.419632 , test loss : 216.145477\n",
      "epoch = 8 train_loss : 195.092239 , test loss : 209.845413\n",
      "epoch = 9 train_loss : 188.901154 , test loss : 203.525360\n",
      "epoch = 10 train_loss : 183.050842 , test loss : 197.447571\n",
      "epoch = 11 train_loss : 177.628250 , test loss : 191.980637\n",
      "epoch = 12 train_loss : 172.545654 , test loss : 186.748230\n",
      "epoch = 13 train_loss : 167.733047 , test loss : 181.838089\n",
      "epoch = 14 train_loss : 163.276962 , test loss : 177.231750\n",
      "epoch = 15 train_loss : 159.083923 , test loss : 172.846954\n",
      "epoch = 16 train_loss : 155.173172 , test loss : 168.875824\n",
      "epoch = 17 train_loss : 151.477036 , test loss : 165.003204\n",
      "epoch = 18 train_loss : 147.988449 , test loss : 161.379242\n",
      "epoch = 19 train_loss : 144.766418 , test loss : 157.974915\n",
      "epoch = 20 train_loss : 141.702652 , test loss : 154.786331\n",
      "epoch = 21 train_loss : 138.850693 , test loss : 151.810074\n",
      "epoch = 22 train_loss : 136.153442 , test loss : 148.956390\n",
      "epoch = 23 train_loss : 133.528610 , test loss : 146.234451\n",
      "epoch = 24 train_loss : 131.135101 , test loss : 143.687973\n",
      "epoch = 25 train_loss : 128.772476 , test loss : 141.266464\n",
      "epoch = 26 train_loss : 126.515480 , test loss : 138.836212\n",
      "epoch = 27 train_loss : 124.349731 , test loss : 136.594040\n",
      "epoch = 28 train_loss : 122.293922 , test loss : 134.343323\n",
      "epoch = 29 train_loss : 120.304153 , test loss : 132.371521\n",
      "epoch = 30 train_loss : 118.363808 , test loss : 130.188141\n",
      "epoch = 31 train_loss : 116.467323 , test loss : 128.262619\n",
      "epoch = 32 train_loss : 114.686279 , test loss : 126.483391\n",
      "epoch = 33 train_loss : 112.885040 , test loss : 124.455025\n",
      "epoch = 34 train_loss : 111.236076 , test loss : 122.857300\n",
      "epoch = 35 train_loss : 109.572433 , test loss : 120.952904\n",
      "epoch = 36 train_loss : 107.920898 , test loss : 119.355888\n",
      "epoch = 37 train_loss : 106.424294 , test loss : 117.621040\n",
      "epoch = 38 train_loss : 104.923332 , test loss : 116.232704\n",
      "epoch = 39 train_loss : 103.423866 , test loss : 114.628540\n",
      "epoch = 40 train_loss : 102.008629 , test loss : 113.074272\n",
      "epoch = 41 train_loss : 100.636841 , test loss : 111.639954\n",
      "epoch = 42 train_loss : 99.297279 , test loss : 110.284302\n",
      "epoch = 43 train_loss : 97.988602 , test loss : 108.812714\n",
      "epoch = 44 train_loss : 96.728951 , test loss : 107.535088\n",
      "epoch = 45 train_loss : 95.500641 , test loss : 106.223793\n",
      "epoch = 46 train_loss : 94.307854 , test loss : 104.948433\n",
      "epoch = 47 train_loss : 93.210068 , test loss : 103.856277\n",
      "epoch = 48 train_loss : 92.108650 , test loss : 102.705917\n",
      "epoch = 49 train_loss : 91.024406 , test loss : 101.445145\n",
      "epoch = 50 train_loss : 89.987640 , test loss : 100.340401\n",
      "epoch = 51 train_loss : 88.950722 , test loss : 99.264282\n",
      "epoch = 52 train_loss : 88.182724 , test loss : 98.617790\n",
      "epoch = 53 train_loss : 87.138771 , test loss : 97.226166\n",
      "epoch = 54 train_loss : 86.397858 , test loss : 96.728958\n",
      "epoch = 55 train_loss : 85.282005 , test loss : 95.349655\n",
      "epoch = 56 train_loss : 84.455536 , test loss : 94.420959\n",
      "epoch = 57 train_loss : 83.767792 , test loss : 93.880882\n",
      "epoch = 58 train_loss : 82.858002 , test loss : 92.677269\n",
      "epoch = 59 train_loss : 82.076759 , test loss : 91.957504\n",
      "epoch = 60 train_loss : 81.311081 , test loss : 91.064102\n",
      "epoch = 61 train_loss : 80.754791 , test loss : 90.306976\n",
      "epoch = 62 train_loss : 79.956329 , test loss : 89.518929\n",
      "epoch = 63 train_loss : 79.386887 , test loss : 89.093857\n",
      "epoch = 64 train_loss : 78.648232 , test loss : 88.081123\n",
      "epoch = 65 train_loss : 77.991249 , test loss : 87.510361\n",
      "epoch = 66 train_loss : 77.351219 , test loss : 86.767235\n",
      "epoch = 67 train_loss : 76.831711 , test loss : 86.088974\n",
      "epoch = 68 train_loss : 76.203064 , test loss : 85.464645\n",
      "epoch = 69 train_loss : 75.698303 , test loss : 84.997925\n",
      "epoch = 70 train_loss : 75.260162 , test loss : 84.285110\n",
      "epoch = 71 train_loss : 74.639923 , test loss : 83.673752\n",
      "epoch = 72 train_loss : 74.428444 , test loss : 83.666756\n",
      "epoch = 73 train_loss : 73.613968 , test loss : 82.640038\n",
      "epoch = 74 train_loss : 73.165230 , test loss : 82.038895\n",
      "epoch = 75 train_loss : 72.699684 , test loss : 81.646072\n",
      "epoch = 76 train_loss : 72.234894 , test loss : 81.122063\n",
      "epoch = 77 train_loss : 71.776962 , test loss : 80.505302\n",
      "epoch = 78 train_loss : 71.352257 , test loss : 80.091446\n",
      "epoch = 79 train_loss : 71.041595 , test loss : 79.804893\n",
      "epoch = 80 train_loss : 70.529564 , test loss : 79.111160\n",
      "epoch = 81 train_loss : 70.144524 , test loss : 78.649292\n",
      "epoch = 82 train_loss : 70.112083 , test loss : 78.397865\n",
      "epoch = 83 train_loss : 69.430016 , test loss : 77.921043\n",
      "epoch = 84 train_loss : 69.016006 , test loss : 77.347778\n",
      "epoch = 85 train_loss : 68.648308 , test loss : 76.937698\n",
      "epoch = 86 train_loss : 68.294350 , test loss : 76.589760\n",
      "epoch = 87 train_loss : 68.218178 , test loss : 76.589188\n",
      "epoch = 88 train_loss : 67.625450 , test loss : 75.840775\n",
      "epoch = 89 train_loss : 67.483406 , test loss : 75.463608\n",
      "epoch = 90 train_loss : 67.054008 , test loss : 75.229622\n",
      "epoch = 91 train_loss : 66.670029 , test loss : 74.621559\n",
      "epoch = 92 train_loss : 66.341141 , test loss : 74.251900\n",
      "epoch = 93 train_loss : 66.000626 , test loss : 73.890121\n",
      "epoch = 94 train_loss : 65.869453 , test loss : 73.843895\n",
      "epoch = 95 train_loss : 65.403923 , test loss : 73.194656\n",
      "epoch = 96 train_loss : 65.100822 , test loss : 72.880051\n",
      "epoch = 97 train_loss : 64.983093 , test loss : 72.598877\n",
      "epoch = 98 train_loss : 64.553284 , test loss : 72.271156\n",
      "epoch = 99 train_loss : 64.273972 , test loss : 71.967529\n",
      "epoch = 100 train_loss : 64.106407 , test loss : 71.592201\n",
      "epoch = 101 train_loss : 63.872005 , test loss : 71.309395\n",
      "epoch = 102 train_loss : 63.536289 , test loss : 71.126495\n",
      "epoch = 103 train_loss : 63.276413 , test loss : 70.824310\n",
      "epoch = 104 train_loss : 62.896847 , test loss : 70.306473\n",
      "epoch = 105 train_loss : 62.709263 , test loss : 70.019897\n",
      "epoch = 106 train_loss : 62.518417 , test loss : 69.975327\n",
      "epoch = 107 train_loss : 62.130379 , test loss : 69.428925\n",
      "epoch = 108 train_loss : 61.879772 , test loss : 69.160278\n",
      "epoch = 109 train_loss : 61.640450 , test loss : 68.842010\n",
      "epoch = 110 train_loss : 61.599636 , test loss : 68.671997\n",
      "epoch = 111 train_loss : 61.594654 , test loss : 68.581909\n",
      "epoch = 112 train_loss : 60.901993 , test loss : 68.004410\n",
      "epoch = 113 train_loss : 60.727131 , test loss : 67.891418\n",
      "epoch = 114 train_loss : 60.445679 , test loss : 67.531525\n",
      "epoch = 115 train_loss : 60.201042 , test loss : 67.190147\n",
      "epoch = 116 train_loss : 60.000683 , test loss : 66.939629\n",
      "epoch = 117 train_loss : 59.750950 , test loss : 66.725319\n",
      "epoch = 118 train_loss : 59.522835 , test loss : 66.470299\n",
      "epoch = 119 train_loss : 59.276936 , test loss : 66.125946\n",
      "epoch = 120 train_loss : 59.067291 , test loss : 65.886070\n",
      "epoch = 121 train_loss : 59.110157 , test loss : 65.803581\n",
      "epoch = 122 train_loss : 58.887188 , test loss : 65.789360\n",
      "epoch = 123 train_loss : 58.459980 , test loss : 65.132004\n",
      "epoch = 124 train_loss : 58.234371 , test loss : 64.893433\n",
      "epoch = 125 train_loss : 57.952618 , test loss : 64.669197\n",
      "epoch = 127 train_loss : 57.761402 , test loss : 64.285843\n",
      "epoch = 129 train_loss : 57.233688 , test loss : 63.742580\n",
      "epoch = 130 train_loss : 56.905216 , test loss : 63.428410\n",
      "epoch = 131 train_loss : 56.704453 , test loss : 63.194378\n",
      "epoch = 132 train_loss : 56.508152 , test loss : 63.050411\n",
      "epoch = 133 train_loss : 56.338768 , test loss : 62.755875\n",
      "epoch = 135 train_loss : 56.100174 , test loss : 62.426037\n",
      "epoch = 136 train_loss : 55.661030 , test loss : 62.076000\n",
      "epoch = 138 train_loss : 55.481068 , test loss : 61.934654\n",
      "epoch = 139 train_loss : 55.096684 , test loss : 61.392857\n",
      "epoch = 140 train_loss : 54.883949 , test loss : 61.193428\n",
      "epoch = 141 train_loss : 54.687359 , test loss : 61.006596\n",
      "epoch = 142 train_loss : 54.487957 , test loss : 60.771271\n",
      "epoch = 143 train_loss : 54.355160 , test loss : 60.551670\n",
      "epoch = 145 train_loss : 53.913155 , test loss : 60.093819\n",
      "epoch = 147 train_loss : 53.564137 , test loss : 59.777321\n",
      "epoch = 148 train_loss : 53.354549 , test loss : 59.526760\n",
      "epoch = 149 train_loss : 53.368587 , test loss : 59.386086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 150 train_loss : 53.291855 , test loss : 59.281574\n",
      "epoch = 151 train_loss : 53.142475 , test loss : 59.100426\n",
      "epoch = 152 train_loss : 52.649277 , test loss : 58.768467\n",
      "epoch = 154 train_loss : 52.350552 , test loss : 58.456951\n",
      "epoch = 155 train_loss : 52.252956 , test loss : 58.362350\n",
      "epoch = 156 train_loss : 52.162903 , test loss : 58.284046\n",
      "epoch = 157 train_loss : 51.896244 , test loss : 57.977318\n",
      "epoch = 158 train_loss : 51.652313 , test loss : 57.675774\n",
      "epoch = 159 train_loss : 51.408676 , test loss : 57.392944\n",
      "epoch = 160 train_loss : 51.537674 , test loss : 57.357029\n",
      "epoch = 161 train_loss : 51.573090 , test loss : 57.348331\n",
      "epoch = 162 train_loss : 51.365749 , test loss : 57.123726\n",
      "epoch = 163 train_loss : 50.794296 , test loss : 56.622768\n",
      "epoch = 164 train_loss : 50.613033 , test loss : 56.541996\n",
      "epoch = 165 train_loss : 50.449718 , test loss : 56.373264\n",
      "epoch = 167 train_loss : 50.368111 , test loss : 56.317455\n",
      "epoch = 168 train_loss : 50.050758 , test loss : 55.969307\n",
      "epoch = 169 train_loss : 49.781536 , test loss : 55.597729\n",
      "epoch = 171 train_loss : 49.498165 , test loss : 55.316315\n",
      "epoch = 172 train_loss : 49.316025 , test loss : 55.108837\n",
      "epoch = 173 train_loss : 49.241848 , test loss : 55.072220\n",
      "epoch = 174 train_loss : 49.059830 , test loss : 54.864544\n",
      "epoch = 175 train_loss : 48.939548 , test loss : 54.613750\n",
      "epoch = 176 train_loss : 48.722439 , test loss : 54.467346\n",
      "epoch = 178 train_loss : 48.464180 , test loss : 54.194176\n",
      "epoch = 179 train_loss : 48.288677 , test loss : 53.994808\n",
      "epoch = 180 train_loss : 48.128998 , test loss : 53.806400\n",
      "epoch = 181 train_loss : 48.004166 , test loss : 53.648750\n",
      "epoch = 183 train_loss : 47.842567 , test loss : 53.567627\n",
      "epoch = 184 train_loss : 47.696594 , test loss : 53.256283\n",
      "epoch = 186 train_loss : 47.549889 , test loss : 53.057301\n",
      "epoch = 187 train_loss : 47.299530 , test loss : 52.828266\n",
      "epoch = 188 train_loss : 47.104649 , test loss : 52.772568\n",
      "epoch = 189 train_loss : 46.901634 , test loss : 52.469524\n",
      "epoch = 190 train_loss : 46.869118 , test loss : 52.391342\n",
      "epoch = 191 train_loss : 46.675575 , test loss : 52.200191\n",
      "epoch = 193 train_loss : 46.451027 , test loss : 52.079449\n",
      "epoch = 194 train_loss : 46.338879 , test loss : 51.960934\n",
      "epoch = 195 train_loss : 46.146877 , test loss : 51.710468\n",
      "epoch = 196 train_loss : 46.005421 , test loss : 51.542969\n",
      "epoch = 197 train_loss : 45.889534 , test loss : 51.442890\n",
      "epoch = 199 train_loss : 45.638615 , test loss : 51.138325\n",
      "epoch = 200 train_loss : 45.517025 , test loss : 51.017502\n",
      "epoch = 201 train_loss : 45.442699 , test loss : 50.882694\n",
      "epoch = 202 train_loss : 45.278622 , test loss : 50.786034\n",
      "epoch = 203 train_loss : 45.172337 , test loss : 50.655640\n",
      "epoch = 204 train_loss : 45.051552 , test loss : 50.511333\n",
      "epoch = 205 train_loss : 44.933590 , test loss : 50.429802\n",
      "epoch = 206 train_loss : 44.868614 , test loss : 50.388802\n",
      "epoch = 207 train_loss : 44.762993 , test loss : 50.276749\n",
      "epoch = 208 train_loss : 44.593452 , test loss : 50.055614\n",
      "epoch = 210 train_loss : 44.398830 , test loss : 49.883980\n",
      "epoch = 212 train_loss : 44.301834 , test loss : 49.648174\n",
      "epoch = 213 train_loss : 44.056870 , test loss : 49.516712\n",
      "epoch = 215 train_loss : 43.855644 , test loss : 49.334282\n",
      "epoch = 216 train_loss : 43.939545 , test loss : 49.275276\n",
      "epoch = 217 train_loss : 43.688377 , test loss : 49.047710\n",
      "epoch = 219 train_loss : 43.428959 , test loss : 48.857807\n",
      "epoch = 220 train_loss : 43.474953 , test loss : 48.794704\n",
      "epoch = 221 train_loss : 43.377491 , test loss : 48.679871\n",
      "epoch = 222 train_loss : 43.187984 , test loss : 48.529572\n",
      "epoch = 225 train_loss : 42.841991 , test loss : 48.254131\n",
      "epoch = 227 train_loss : 42.654018 , test loss : 48.062416\n",
      "epoch = 230 train_loss : 42.690948 , test loss : 47.931896\n",
      "epoch = 231 train_loss : 42.363670 , test loss : 47.820694\n",
      "epoch = 232 train_loss : 42.230732 , test loss : 47.580921\n",
      "epoch = 233 train_loss : 42.182606 , test loss : 47.480766\n",
      "epoch = 235 train_loss : 42.034081 , test loss : 47.377762\n",
      "epoch = 237 train_loss : 41.797623 , test loss : 47.141453\n",
      "epoch = 238 train_loss : 41.800377 , test loss : 47.072880\n",
      "epoch = 239 train_loss : 41.620323 , test loss : 46.981583\n",
      "epoch = 240 train_loss : 41.542976 , test loss : 46.964165\n",
      "epoch = 241 train_loss : 41.467583 , test loss : 46.879509\n",
      "epoch = 242 train_loss : 41.392387 , test loss : 46.808601\n",
      "epoch = 243 train_loss : 41.280045 , test loss : 46.677120\n",
      "epoch = 244 train_loss : 41.201355 , test loss : 46.564693\n",
      "epoch = 246 train_loss : 41.051914 , test loss : 46.452675\n",
      "epoch = 248 train_loss : 40.930954 , test loss : 46.252533\n",
      "epoch = 252 train_loss : 40.593533 , test loss : 46.013653\n",
      "epoch = 254 train_loss : 40.447708 , test loss : 45.807270\n",
      "epoch = 257 train_loss : 40.521507 , test loss : 45.778969\n",
      "epoch = 258 train_loss : 40.267822 , test loss : 45.746990\n",
      "epoch = 259 train_loss : 40.120705 , test loss : 45.571686\n",
      "epoch = 261 train_loss : 40.004745 , test loss : 45.443916\n",
      "epoch = 262 train_loss : 39.945721 , test loss : 45.383652\n",
      "epoch = 264 train_loss : 39.906380 , test loss : 45.205498\n",
      "epoch = 265 train_loss : 39.779671 , test loss : 45.108589\n",
      "epoch = 266 train_loss : 39.632198 , test loss : 45.008575\n",
      "epoch = 272 train_loss : 39.276890 , test loss : 44.653454\n",
      "epoch = 275 train_loss : 39.102303 , test loss : 44.481773\n",
      "epoch = 276 train_loss : 39.018917 , test loss : 44.441376\n",
      "epoch = 279 train_loss : 39.039909 , test loss : 44.357166\n",
      "epoch = 281 train_loss : 38.976524 , test loss : 44.263985\n",
      "epoch = 284 train_loss : 38.596043 , test loss : 43.984245\n",
      "epoch = 285 train_loss : 38.526188 , test loss : 43.942978\n",
      "epoch = 286 train_loss : 38.523766 , test loss : 43.881695\n",
      "epoch = 288 train_loss : 38.425156 , test loss : 43.804741\n",
      "epoch = 291 train_loss : 38.209854 , test loss : 43.644337\n",
      "epoch = 294 train_loss : 38.065620 , test loss : 43.551888\n",
      "epoch = 295 train_loss : 38.135056 , test loss : 43.508297\n",
      "epoch = 296 train_loss : 37.958786 , test loss : 43.420517\n",
      "epoch = 298 train_loss : 37.881268 , test loss : 43.415432\n",
      "epoch = 299 train_loss : 37.852680 , test loss : 43.392807\n",
      "epoch = 301 train_loss : 37.751282 , test loss : 43.198093\n",
      "epoch = 303 train_loss : 37.639622 , test loss : 43.124435\n",
      "epoch = 305 train_loss : 37.559814 , test loss : 43.079418\n",
      "epoch = 307 train_loss : 37.454121 , test loss : 42.972549\n",
      "epoch = 312 train_loss : 37.289425 , test loss : 42.914661\n",
      "epoch = 314 train_loss : 37.207302 , test loss : 42.820385\n",
      "epoch = 316 train_loss : 37.120506 , test loss : 42.608761\n",
      "epoch = 318 train_loss : 37.008801 , test loss : 42.575180\n",
      "epoch = 321 train_loss : 36.913334 , test loss : 42.552692\n",
      "epoch = 322 train_loss : 36.848591 , test loss : 42.418659\n",
      "epoch = 325 train_loss : 36.736034 , test loss : 42.350250\n",
      "epoch = 326 train_loss : 36.733932 , test loss : 42.283195\n",
      "epoch = 329 train_loss : 36.593952 , test loss : 42.244526\n",
      "epoch = 332 train_loss : 36.482628 , test loss : 42.099785\n",
      "epoch = 333 train_loss : 36.499409 , test loss : 42.059757\n",
      "epoch = 334 train_loss : 36.420589 , test loss : 42.041828\n",
      "epoch = 336 train_loss : 36.352757 , test loss : 42.024551\n",
      "epoch = 338 train_loss : 36.285275 , test loss : 41.936432\n",
      "epoch = 339 train_loss : 36.254028 , test loss : 41.903351\n",
      "epoch = 340 train_loss : 36.312714 , test loss : 41.883625\n",
      "epoch = 341 train_loss : 36.262600 , test loss : 41.822624\n",
      "epoch = 343 train_loss : 36.123753 , test loss : 41.800354\n",
      "epoch = 344 train_loss : 36.143623 , test loss : 41.758568\n",
      "epoch = 346 train_loss : 36.034309 , test loss : 41.735634\n",
      "epoch = 347 train_loss : 35.998768 , test loss : 41.666954\n",
      "epoch = 348 train_loss : 35.970356 , test loss : 41.635635\n",
      "epoch = 352 train_loss : 35.872074 , test loss : 41.533302\n",
      "epoch = 353 train_loss : 35.817833 , test loss : 41.531082\n",
      "epoch = 354 train_loss : 35.793358 , test loss : 41.479099\n",
      "epoch = 356 train_loss : 35.763832 , test loss : 41.432091\n",
      "epoch = 357 train_loss : 35.769318 , test loss : 41.421791\n",
      "epoch = 360 train_loss : 35.660473 , test loss : 41.344402\n",
      "epoch = 363 train_loss : 35.548634 , test loss : 41.305389\n",
      "epoch = 367 train_loss : 35.511528 , test loss : 41.212566\n",
      "epoch = 368 train_loss : 35.417206 , test loss : 41.191505\n",
      "epoch = 369 train_loss : 35.416573 , test loss : 41.134983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 372 train_loss : 35.313892 , test loss : 41.124584\n",
      "epoch = 374 train_loss : 35.264469 , test loss : 41.046535\n",
      "epoch = 378 train_loss : 35.344063 , test loss : 41.030548\n",
      "epoch = 380 train_loss : 35.121494 , test loss : 40.943882\n",
      "epoch = 381 train_loss : 35.099327 , test loss : 40.893944\n",
      "epoch = 384 train_loss : 35.084538 , test loss : 40.880508\n",
      "epoch = 385 train_loss : 35.015724 , test loss : 40.830517\n",
      "epoch = 390 train_loss : 34.911461 , test loss : 40.754025\n",
      "epoch = 393 train_loss : 34.921089 , test loss : 40.717049\n",
      "epoch = 394 train_loss : 34.929749 , test loss : 40.702599\n",
      "epoch = 398 train_loss : 34.828613 , test loss : 40.648743\n",
      "epoch = 399 train_loss : 34.788113 , test loss : 40.614304\n",
      "epoch = 402 train_loss : 34.666615 , test loss : 40.573494\n",
      "epoch = 403 train_loss : 34.759628 , test loss : 40.570953\n",
      "epoch = 407 train_loss : 34.578041 , test loss : 40.525467\n",
      "epoch = 410 train_loss : 34.514271 , test loss : 40.450233\n",
      "epoch = 412 train_loss : 34.477901 , test loss : 40.423401\n",
      "epoch = 415 train_loss : 34.450367 , test loss : 40.337147\n",
      "epoch = 418 train_loss : 34.426830 , test loss : 40.333698\n",
      "epoch = 421 train_loss : 34.331177 , test loss : 40.318069\n",
      "epoch = 423 train_loss : 34.301029 , test loss : 40.311951\n",
      "epoch = 424 train_loss : 34.324112 , test loss : 40.243488\n",
      "epoch = 425 train_loss : 34.259239 , test loss : 40.234516\n",
      "epoch = 427 train_loss : 34.269321 , test loss : 40.203938\n",
      "epoch = 430 train_loss : 34.233646 , test loss : 40.170521\n",
      "epoch = 436 train_loss : 34.125462 , test loss : 40.106968\n",
      "epoch = 443 train_loss : 34.024227 , test loss : 40.023251\n",
      "epoch = 445 train_loss : 33.964142 , test loss : 40.011875\n",
      "epoch = 446 train_loss : 34.061115 , test loss : 39.983013\n",
      "epoch = 447 train_loss : 33.964886 , test loss : 39.973232\n",
      "epoch = 452 train_loss : 33.869343 , test loss : 39.968086\n",
      "epoch = 453 train_loss : 33.865440 , test loss : 39.930378\n",
      "epoch = 457 train_loss : 33.913731 , test loss : 39.919617\n",
      "epoch = 458 train_loss : 33.784359 , test loss : 39.889046\n",
      "epoch = 461 train_loss : 33.857807 , test loss : 39.859985\n",
      "epoch = 464 train_loss : 33.719139 , test loss : 39.821014\n",
      "epoch = 473 train_loss : 33.692833 , test loss : 39.767990\n",
      "epoch = 474 train_loss : 33.700039 , test loss : 39.758156\n",
      "epoch = 477 train_loss : 33.590202 , test loss : 39.737026\n",
      "epoch = 479 train_loss : 33.541508 , test loss : 39.733093\n",
      "epoch = 485 train_loss : 33.549717 , test loss : 39.661488\n",
      "epoch = 487 train_loss : 33.515694 , test loss : 39.638515\n",
      "epoch = 495 train_loss : 33.492729 , test loss : 39.605721\n",
      "epoch = 498 train_loss : 33.368992 , test loss : 39.521080\n",
      "epoch = 506 train_loss : 33.285004 , test loss : 39.502956\n",
      "epoch = 507 train_loss : 33.275040 , test loss : 39.490925\n",
      "epoch = 511 train_loss : 33.272182 , test loss : 39.478237\n",
      "epoch = 515 train_loss : 33.184509 , test loss : 39.476898\n",
      "epoch = 517 train_loss : 33.262558 , test loss : 39.463757\n",
      "epoch = 518 train_loss : 33.228291 , test loss : 39.424809\n",
      "epoch = 524 train_loss : 33.110172 , test loss : 39.393810\n",
      "epoch = 525 train_loss : 33.151558 , test loss : 39.379612\n",
      "epoch = 528 train_loss : 33.133389 , test loss : 39.338577\n",
      "epoch = 540 train_loss : 32.983814 , test loss : 39.321507\n",
      "epoch = 545 train_loss : 33.006660 , test loss : 39.280357\n",
      "epoch = 552 train_loss : 32.949043 , test loss : 39.239708\n",
      "epoch = 556 train_loss : 32.885071 , test loss : 39.225716\n",
      "epoch = 559 train_loss : 32.896130 , test loss : 39.196774\n",
      "epoch = 566 train_loss : 32.796104 , test loss : 39.185745\n",
      "epoch = 567 train_loss : 32.807926 , test loss : 39.168156\n",
      "epoch = 574 train_loss : 32.764359 , test loss : 39.156559\n",
      "epoch = 577 train_loss : 32.726719 , test loss : 39.142715\n",
      "epoch = 581 train_loss : 32.727985 , test loss : 39.131844\n",
      "epoch = 590 train_loss : 32.716442 , test loss : 39.114944\n",
      "epoch = 591 train_loss : 32.679272 , test loss : 39.083580\n",
      "epoch = 593 train_loss : 32.640148 , test loss : 39.075050\n",
      "epoch = 597 train_loss : 32.739738 , test loss : 39.065277\n",
      "epoch = 605 train_loss : 32.569912 , test loss : 39.022964\n",
      "epoch = 611 train_loss : 32.640148 , test loss : 39.007713\n",
      "epoch = 615 train_loss : 32.582127 , test loss : 38.998978\n",
      "epoch = 617 train_loss : 32.530693 , test loss : 38.955280\n",
      "epoch = 634 train_loss : 32.450359 , test loss : 38.933655\n",
      "epoch = 637 train_loss : 32.410255 , test loss : 38.924191\n",
      "epoch = 648 train_loss : 32.443001 , test loss : 38.910015\n",
      "epoch = 649 train_loss : 32.365730 , test loss : 38.889988\n",
      "epoch = 653 train_loss : 32.350479 , test loss : 38.864590\n",
      "epoch = 660 train_loss : 32.335869 , test loss : 38.849773\n",
      "epoch = 671 train_loss : 32.373554 , test loss : 38.848663\n",
      "epoch = 674 train_loss : 32.289555 , test loss : 38.802456\n",
      "epoch = 691 train_loss : 32.196354 , test loss : 38.770210\n",
      "epoch = 705 train_loss : 32.153126 , test loss : 38.756336\n",
      "epoch = 714 train_loss : 32.154034 , test loss : 38.738022\n",
      "epoch = 719 train_loss : 32.097519 , test loss : 38.724701\n",
      "epoch = 726 train_loss : 32.143978 , test loss : 38.713486\n",
      "epoch = 735 train_loss : 32.095081 , test loss : 38.708359\n",
      "epoch = 741 train_loss : 32.150021 , test loss : 38.707439\n",
      "epoch = 743 train_loss : 32.092636 , test loss : 38.701794\n",
      "epoch = 747 train_loss : 32.040493 , test loss : 38.678875\n",
      "epoch = 750 train_loss : 32.012089 , test loss : 38.656448\n",
      "epoch = 755 train_loss : 32.008675 , test loss : 38.646320\n",
      "epoch = 773 train_loss : 31.981619 , test loss : 38.589417\n",
      "epoch = 818 train_loss : 31.855583 , test loss : 38.568264\n",
      "epoch = 838 train_loss : 31.870829 , test loss : 38.560863\n",
      "epoch = 845 train_loss : 31.850653 , test loss : 38.531616\n",
      "epoch = 882 train_loss : 31.816465 , test loss : 38.524441\n",
      "epoch = 886 train_loss : 31.752953 , test loss : 38.519581\n",
      "epoch = 897 train_loss : 31.738382 , test loss : 38.510960\n",
      "epoch = 907 train_loss : 31.735823 , test loss : 38.496552\n",
      "epoch = 929 train_loss : 31.722500 , test loss : 38.461803\n",
      "epoch = 999 train_loss : 31.615479 , test loss : 38.434673\n",
      "epoch = 1075 train_loss : 31.575268 , test loss : 38.434391\n",
      "epoch = 1106 train_loss : 31.600471 , test loss : 38.407646\n",
      "epoch = 1197 train_loss : 31.527287 , test loss : 38.403160\n",
      "epoch = 1295 train_loss : 31.433979 , test loss : 38.399971\n",
      "epoch = 1329 train_loss : 31.422678 , test loss : 38.393585\n",
      "epoch = 1467 train_loss : 31.406178 , test loss : 38.388405\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.406178,test loss : 38.388405\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 516.044189 , test loss : 498.930359\n",
      "epoch = 2 train_loss : 349.910217 , test loss : 353.481293\n",
      "epoch = 3 train_loss : 336.089203 , test loss : 346.770538\n",
      "epoch = 4 train_loss : 322.383484 , test loss : 331.964417\n",
      "epoch = 5 train_loss : 309.450592 , test loss : 318.207764\n",
      "epoch = 6 train_loss : 297.041046 , test loss : 305.976959\n",
      "epoch = 7 train_loss : 284.771851 , test loss : 294.211456\n",
      "epoch = 8 train_loss : 272.732452 , test loss : 283.155853\n",
      "epoch = 9 train_loss : 261.470245 , test loss : 272.232025\n",
      "epoch = 10 train_loss : 250.852325 , test loss : 261.283417\n",
      "epoch = 11 train_loss : 240.643295 , test loss : 252.299271\n",
      "epoch = 12 train_loss : 231.226089 , test loss : 243.121826\n",
      "epoch = 13 train_loss : 222.241806 , test loss : 235.045883\n",
      "epoch = 14 train_loss : 213.982758 , test loss : 226.628250\n",
      "epoch = 15 train_loss : 206.157440 , test loss : 219.398102\n",
      "epoch = 16 train_loss : 199.047485 , test loss : 213.018753\n",
      "epoch = 17 train_loss : 192.419724 , test loss : 206.367172\n",
      "epoch = 18 train_loss : 186.260910 , test loss : 201.054199\n",
      "epoch = 19 train_loss : 180.554886 , test loss : 195.272354\n",
      "epoch = 20 train_loss : 175.189789 , test loss : 190.518143\n",
      "epoch = 21 train_loss : 170.388474 , test loss : 186.158951\n",
      "epoch = 22 train_loss : 165.784210 , test loss : 181.863159\n",
      "epoch = 23 train_loss : 161.561508 , test loss : 177.760223\n",
      "epoch = 24 train_loss : 157.750092 , test loss : 174.343613\n",
      "epoch = 25 train_loss : 154.168808 , test loss : 171.222336\n",
      "epoch = 26 train_loss : 150.767044 , test loss : 167.849670\n",
      "epoch = 27 train_loss : 147.617462 , test loss : 164.937454\n",
      "epoch = 28 train_loss : 144.663025 , test loss : 162.145096\n",
      "epoch = 29 train_loss : 142.007278 , test loss : 159.511978\n",
      "epoch = 30 train_loss : 139.499130 , test loss : 157.042236\n",
      "epoch = 31 train_loss : 137.074448 , test loss : 155.163483\n",
      "epoch = 32 train_loss : 134.788498 , test loss : 152.767502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 33 train_loss : 132.719315 , test loss : 150.769745\n",
      "epoch = 34 train_loss : 130.729111 , test loss : 148.753815\n",
      "epoch = 35 train_loss : 128.893021 , test loss : 146.882385\n",
      "epoch = 36 train_loss : 127.122955 , test loss : 145.417603\n",
      "epoch = 37 train_loss : 125.385361 , test loss : 143.578232\n",
      "epoch = 38 train_loss : 123.784668 , test loss : 141.973450\n",
      "epoch = 39 train_loss : 122.241714 , test loss : 140.430420\n",
      "epoch = 40 train_loss : 120.738068 , test loss : 138.911957\n",
      "epoch = 41 train_loss : 119.343369 , test loss : 137.266495\n",
      "epoch = 42 train_loss : 117.946274 , test loss : 135.876160\n",
      "epoch = 43 train_loss : 116.632790 , test loss : 134.478088\n",
      "epoch = 44 train_loss : 115.374565 , test loss : 133.228760\n",
      "epoch = 45 train_loss : 114.149895 , test loss : 132.010483\n",
      "epoch = 46 train_loss : 112.949539 , test loss : 130.518661\n",
      "epoch = 47 train_loss : 111.775475 , test loss : 129.395218\n",
      "epoch = 48 train_loss : 110.656464 , test loss : 128.275238\n",
      "epoch = 49 train_loss : 109.603485 , test loss : 126.754547\n",
      "epoch = 50 train_loss : 108.486725 , test loss : 125.741524\n",
      "epoch = 51 train_loss : 107.437416 , test loss : 124.568947\n",
      "epoch = 52 train_loss : 106.410210 , test loss : 123.485550\n",
      "epoch = 53 train_loss : 105.431160 , test loss : 122.425453\n",
      "epoch = 54 train_loss : 104.485199 , test loss : 121.062988\n",
      "epoch = 55 train_loss : 103.504974 , test loss : 120.138069\n",
      "epoch = 56 train_loss : 102.604523 , test loss : 119.150604\n",
      "epoch = 57 train_loss : 101.696449 , test loss : 118.145149\n",
      "epoch = 58 train_loss : 100.817802 , test loss : 116.926765\n",
      "epoch = 59 train_loss : 99.928864 , test loss : 116.128288\n",
      "epoch = 60 train_loss : 99.064690 , test loss : 114.951752\n",
      "epoch = 61 train_loss : 98.225784 , test loss : 114.108055\n",
      "epoch = 62 train_loss : 97.403999 , test loss : 113.050934\n",
      "epoch = 63 train_loss : 96.587212 , test loss : 112.094009\n",
      "epoch = 64 train_loss : 95.804016 , test loss : 111.240616\n",
      "epoch = 65 train_loss : 95.099655 , test loss : 110.611328\n",
      "epoch = 66 train_loss : 94.280785 , test loss : 109.471504\n",
      "epoch = 67 train_loss : 93.556046 , test loss : 108.455498\n",
      "epoch = 68 train_loss : 92.890030 , test loss : 107.485588\n",
      "epoch = 69 train_loss : 92.230278 , test loss : 107.315590\n",
      "epoch = 70 train_loss : 91.372330 , test loss : 106.019531\n",
      "epoch = 71 train_loss : 91.031181 , test loss : 105.028358\n",
      "epoch = 73 train_loss : 89.506569 , test loss : 103.448349\n",
      "epoch = 74 train_loss : 88.829918 , test loss : 103.294212\n",
      "epoch = 75 train_loss : 88.136421 , test loss : 101.912140\n",
      "epoch = 76 train_loss : 87.432785 , test loss : 101.512291\n",
      "epoch = 77 train_loss : 86.824806 , test loss : 100.507942\n",
      "epoch = 78 train_loss : 86.310524 , test loss : 100.302063\n",
      "epoch = 79 train_loss : 85.716568 , test loss : 99.042229\n",
      "epoch = 80 train_loss : 85.071022 , test loss : 98.760605\n",
      "epoch = 81 train_loss : 84.458244 , test loss : 97.833534\n",
      "epoch = 82 train_loss : 83.910309 , test loss : 97.361153\n",
      "epoch = 83 train_loss : 83.316345 , test loss : 96.518387\n",
      "epoch = 84 train_loss : 82.772820 , test loss : 95.963600\n",
      "epoch = 85 train_loss : 82.256073 , test loss : 95.372231\n",
      "epoch = 86 train_loss : 81.719269 , test loss : 94.713570\n",
      "epoch = 87 train_loss : 81.214653 , test loss : 94.141800\n",
      "epoch = 88 train_loss : 80.806992 , test loss : 93.376495\n",
      "epoch = 89 train_loss : 80.323303 , test loss : 93.281715\n",
      "epoch = 90 train_loss : 79.722939 , test loss : 92.302788\n",
      "epoch = 91 train_loss : 79.225548 , test loss : 91.748169\n",
      "epoch = 92 train_loss : 78.823639 , test loss : 91.149254\n",
      "epoch = 93 train_loss : 78.432106 , test loss : 91.082436\n",
      "epoch = 94 train_loss : 77.845749 , test loss : 90.085686\n",
      "epoch = 95 train_loss : 77.448738 , test loss : 89.871674\n",
      "epoch = 96 train_loss : 77.082077 , test loss : 89.061806\n",
      "epoch = 97 train_loss : 76.639420 , test loss : 89.032417\n",
      "epoch = 98 train_loss : 76.129570 , test loss : 88.086655\n",
      "epoch = 99 train_loss : 75.707230 , test loss : 87.901917\n",
      "epoch = 100 train_loss : 75.367676 , test loss : 87.152313\n",
      "epoch = 101 train_loss : 74.852798 , test loss : 86.877785\n",
      "epoch = 102 train_loss : 74.434532 , test loss : 86.262138\n",
      "epoch = 103 train_loss : 74.053337 , test loss : 85.946503\n",
      "epoch = 104 train_loss : 73.682442 , test loss : 85.376602\n",
      "epoch = 105 train_loss : 73.282341 , test loss : 84.961815\n",
      "epoch = 106 train_loss : 72.922966 , test loss : 84.772591\n",
      "epoch = 107 train_loss : 72.677757 , test loss : 84.139526\n",
      "epoch = 108 train_loss : 72.189156 , test loss : 83.916176\n",
      "epoch = 109 train_loss : 71.900673 , test loss : 83.331779\n",
      "epoch = 110 train_loss : 71.470573 , test loss : 83.116486\n",
      "epoch = 111 train_loss : 71.187599 , test loss : 82.543121\n",
      "epoch = 112 train_loss : 70.846260 , test loss : 82.496117\n",
      "epoch = 113 train_loss : 70.429832 , test loss : 81.772377\n",
      "epoch = 114 train_loss : 70.367378 , test loss : 81.496803\n",
      "epoch = 116 train_loss : 69.437904 , test loss : 80.904655\n",
      "epoch = 117 train_loss : 69.281273 , test loss : 80.423454\n",
      "epoch = 118 train_loss : 68.860275 , test loss : 80.338028\n",
      "epoch = 119 train_loss : 68.484055 , test loss : 79.752495\n",
      "epoch = 120 train_loss : 68.724541 , test loss : 79.670746\n",
      "epoch = 122 train_loss : 67.567719 , test loss : 78.895744\n",
      "epoch = 123 train_loss : 67.336472 , test loss : 78.457420\n",
      "epoch = 125 train_loss : 66.704201 , test loss : 77.882942\n",
      "epoch = 126 train_loss : 66.561775 , test loss : 77.583389\n",
      "epoch = 127 train_loss : 66.116585 , test loss : 77.361938\n",
      "epoch = 128 train_loss : 66.008507 , test loss : 76.995178\n",
      "epoch = 129 train_loss : 65.678505 , test loss : 76.662277\n",
      "epoch = 130 train_loss : 65.280876 , test loss : 76.376427\n",
      "epoch = 132 train_loss : 64.799316 , test loss : 75.837410\n",
      "epoch = 134 train_loss : 64.220039 , test loss : 75.274467\n",
      "epoch = 136 train_loss : 63.687664 , test loss : 74.766464\n",
      "epoch = 138 train_loss : 63.187443 , test loss : 74.375465\n",
      "epoch = 139 train_loss : 62.918270 , test loss : 74.075394\n",
      "epoch = 140 train_loss : 62.770744 , test loss : 73.740723\n",
      "epoch = 141 train_loss : 62.480637 , test loss : 73.454803\n",
      "epoch = 142 train_loss : 62.169991 , test loss : 73.305328\n",
      "epoch = 143 train_loss : 61.937618 , test loss : 73.004936\n",
      "epoch = 144 train_loss : 61.777912 , test loss : 72.796143\n",
      "epoch = 145 train_loss : 61.438942 , test loss : 72.554428\n",
      "epoch = 146 train_loss : 61.216625 , test loss : 72.267204\n",
      "epoch = 147 train_loss : 61.130424 , test loss : 72.080299\n",
      "epoch = 149 train_loss : 60.516930 , test loss : 71.604164\n",
      "epoch = 150 train_loss : 60.300091 , test loss : 71.526466\n",
      "epoch = 151 train_loss : 60.045280 , test loss : 71.195099\n",
      "epoch = 153 train_loss : 59.657570 , test loss : 70.698715\n",
      "epoch = 155 train_loss : 59.172276 , test loss : 70.281548\n",
      "epoch = 157 train_loss : 58.696705 , test loss : 69.940079\n",
      "epoch = 159 train_loss : 58.262325 , test loss : 69.453316\n",
      "epoch = 160 train_loss : 58.041096 , test loss : 69.243469\n",
      "epoch = 161 train_loss : 57.919518 , test loss : 68.992096\n",
      "epoch = 162 train_loss : 57.707466 , test loss : 68.819824\n",
      "epoch = 164 train_loss : 57.197441 , test loss : 68.487061\n",
      "epoch = 165 train_loss : 57.092453 , test loss : 68.225349\n",
      "epoch = 167 train_loss : 56.607597 , test loss : 67.998703\n",
      "epoch = 168 train_loss : 56.376133 , test loss : 67.725502\n",
      "epoch = 170 train_loss : 56.068413 , test loss : 67.606598\n",
      "epoch = 171 train_loss : 55.895420 , test loss : 67.063271\n",
      "epoch = 172 train_loss : 55.570431 , test loss : 66.851707\n",
      "epoch = 173 train_loss : 55.349758 , test loss : 66.774734\n",
      "epoch = 174 train_loss : 55.158409 , test loss : 66.636871\n",
      "epoch = 175 train_loss : 55.012917 , test loss : 66.538429\n",
      "epoch = 176 train_loss : 54.765587 , test loss : 66.138527\n",
      "epoch = 177 train_loss : 54.572189 , test loss : 66.075287\n",
      "epoch = 178 train_loss : 54.361431 , test loss : 65.827995\n",
      "epoch = 179 train_loss : 54.202530 , test loss : 65.752037\n",
      "epoch = 181 train_loss : 53.806744 , test loss : 65.363945\n",
      "epoch = 182 train_loss : 53.700024 , test loss : 65.050453\n",
      "epoch = 183 train_loss : 53.421482 , test loss : 64.895889\n",
      "epoch = 184 train_loss : 53.218437 , test loss : 64.776451\n",
      "epoch = 185 train_loss : 53.033680 , test loss : 64.567230\n",
      "epoch = 186 train_loss : 52.896992 , test loss : 64.331055\n",
      "epoch = 187 train_loss : 52.688244 , test loss : 64.184326\n",
      "epoch = 188 train_loss : 52.476162 , test loss : 64.071022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 190 train_loss : 52.563210 , test loss : 63.858692\n",
      "epoch = 191 train_loss : 52.012016 , test loss : 63.544781\n",
      "epoch = 192 train_loss : 51.908978 , test loss : 63.377678\n",
      "epoch = 193 train_loss : 51.687553 , test loss : 63.199482\n",
      "epoch = 194 train_loss : 51.647705 , test loss : 63.124939\n",
      "epoch = 195 train_loss : 51.241505 , test loss : 62.935001\n",
      "epoch = 196 train_loss : 51.204723 , test loss : 62.718201\n",
      "epoch = 200 train_loss : 50.391014 , test loss : 62.119194\n",
      "epoch = 202 train_loss : 50.053406 , test loss : 61.835754\n",
      "epoch = 203 train_loss : 49.898346 , test loss : 61.615543\n",
      "epoch = 204 train_loss : 49.752811 , test loss : 61.579170\n",
      "epoch = 205 train_loss : 49.604626 , test loss : 61.341122\n",
      "epoch = 206 train_loss : 49.455776 , test loss : 61.180130\n",
      "epoch = 207 train_loss : 49.252289 , test loss : 61.040607\n",
      "epoch = 209 train_loss : 48.973236 , test loss : 60.742294\n",
      "epoch = 212 train_loss : 48.471134 , test loss : 60.406094\n",
      "epoch = 213 train_loss : 48.356258 , test loss : 60.175144\n",
      "epoch = 214 train_loss : 48.181389 , test loss : 60.159519\n",
      "epoch = 215 train_loss : 48.034019 , test loss : 60.054855\n",
      "epoch = 216 train_loss : 47.875034 , test loss : 59.887230\n",
      "epoch = 217 train_loss : 47.742096 , test loss : 59.790848\n",
      "epoch = 218 train_loss : 47.617901 , test loss : 59.522194\n",
      "epoch = 219 train_loss : 47.426228 , test loss : 59.441658\n",
      "epoch = 220 train_loss : 47.281380 , test loss : 59.225468\n",
      "epoch = 221 train_loss : 47.262852 , test loss : 59.104752\n",
      "epoch = 222 train_loss : 47.074287 , test loss : 58.971161\n",
      "epoch = 223 train_loss : 47.138111 , test loss : 58.914101\n",
      "epoch = 224 train_loss : 46.706383 , test loss : 58.734589\n",
      "epoch = 225 train_loss : 46.657669 , test loss : 58.584564\n",
      "epoch = 227 train_loss : 46.618687 , test loss : 58.453358\n",
      "epoch = 228 train_loss : 46.157959 , test loss : 58.238010\n",
      "epoch = 230 train_loss : 45.889633 , test loss : 57.968163\n",
      "epoch = 231 train_loss : 45.759113 , test loss : 57.881123\n",
      "epoch = 233 train_loss : 45.527256 , test loss : 57.718590\n",
      "epoch = 234 train_loss : 45.370335 , test loss : 57.438442\n",
      "epoch = 237 train_loss : 45.010380 , test loss : 57.103008\n",
      "epoch = 238 train_loss : 44.933163 , test loss : 56.972866\n",
      "epoch = 241 train_loss : 44.498199 , test loss : 56.752914\n",
      "epoch = 242 train_loss : 44.516994 , test loss : 56.526695\n",
      "epoch = 243 train_loss : 44.260399 , test loss : 56.425270\n",
      "epoch = 245 train_loss : 44.032547 , test loss : 56.155296\n",
      "epoch = 248 train_loss : 43.664787 , test loss : 55.878654\n",
      "epoch = 249 train_loss : 43.553741 , test loss : 55.873486\n",
      "epoch = 251 train_loss : 43.440811 , test loss : 55.539333\n",
      "epoch = 252 train_loss : 43.249111 , test loss : 55.418243\n",
      "epoch = 255 train_loss : 42.898579 , test loss : 55.092442\n",
      "epoch = 256 train_loss : 42.783264 , test loss : 55.047546\n",
      "epoch = 257 train_loss : 42.753048 , test loss : 54.906281\n",
      "epoch = 258 train_loss : 42.599331 , test loss : 54.797173\n",
      "epoch = 261 train_loss : 42.734123 , test loss : 54.707642\n",
      "epoch = 262 train_loss : 42.172623 , test loss : 54.475143\n",
      "epoch = 264 train_loss : 41.983524 , test loss : 54.197445\n",
      "epoch = 266 train_loss : 41.783554 , test loss : 54.083023\n",
      "epoch = 267 train_loss : 41.867069 , test loss : 53.957504\n",
      "epoch = 269 train_loss : 41.665504 , test loss : 53.739788\n",
      "epoch = 270 train_loss : 41.452091 , test loss : 53.647297\n",
      "epoch = 273 train_loss : 41.140121 , test loss : 53.358040\n",
      "epoch = 274 train_loss : 41.116447 , test loss : 53.279270\n",
      "epoch = 276 train_loss : 40.875099 , test loss : 53.163620\n",
      "epoch = 277 train_loss : 40.825901 , test loss : 53.016232\n",
      "epoch = 279 train_loss : 40.633617 , test loss : 52.825848\n",
      "epoch = 280 train_loss : 40.540989 , test loss : 52.765316\n",
      "epoch = 282 train_loss : 40.369316 , test loss : 52.635136\n",
      "epoch = 283 train_loss : 40.288635 , test loss : 52.524914\n",
      "epoch = 285 train_loss : 40.256340 , test loss : 52.407890\n",
      "epoch = 286 train_loss : 40.080139 , test loss : 52.265972\n",
      "epoch = 287 train_loss : 40.086231 , test loss : 52.156590\n",
      "epoch = 290 train_loss : 39.751934 , test loss : 52.049946\n",
      "epoch = 291 train_loss : 39.690025 , test loss : 51.841045\n",
      "epoch = 294 train_loss : 39.521229 , test loss : 51.604374\n",
      "epoch = 295 train_loss : 39.436386 , test loss : 51.529079\n",
      "epoch = 298 train_loss : 39.176182 , test loss : 51.440834\n",
      "epoch = 299 train_loss : 39.271576 , test loss : 51.264336\n",
      "epoch = 301 train_loss : 39.175240 , test loss : 51.087807\n",
      "epoch = 302 train_loss : 38.918015 , test loss : 51.019814\n",
      "epoch = 303 train_loss : 38.838993 , test loss : 51.003651\n",
      "epoch = 304 train_loss : 38.890690 , test loss : 50.872124\n",
      "epoch = 305 train_loss : 38.799904 , test loss : 50.799126\n",
      "epoch = 306 train_loss : 38.687786 , test loss : 50.719303\n",
      "epoch = 307 train_loss : 38.645306 , test loss : 50.678375\n",
      "epoch = 310 train_loss : 38.619320 , test loss : 50.554768\n",
      "epoch = 311 train_loss : 38.342567 , test loss : 50.446682\n",
      "epoch = 312 train_loss : 38.367897 , test loss : 50.327106\n",
      "epoch = 313 train_loss : 38.265663 , test loss : 50.283394\n",
      "epoch = 316 train_loss : 38.421494 , test loss : 50.143703\n",
      "epoch = 317 train_loss : 38.367752 , test loss : 50.135944\n",
      "epoch = 318 train_loss : 38.080692 , test loss : 49.919132\n",
      "epoch = 321 train_loss : 37.939007 , test loss : 49.744099\n",
      "epoch = 324 train_loss : 37.633575 , test loss : 49.628418\n",
      "epoch = 326 train_loss : 37.777660 , test loss : 49.478882\n",
      "epoch = 329 train_loss : 37.399868 , test loss : 49.278954\n",
      "epoch = 332 train_loss : 37.259731 , test loss : 49.233906\n",
      "epoch = 334 train_loss : 37.151707 , test loss : 49.013496\n",
      "epoch = 335 train_loss : 37.113316 , test loss : 49.000263\n",
      "epoch = 337 train_loss : 37.114368 , test loss : 48.803951\n",
      "epoch = 339 train_loss : 36.939571 , test loss : 48.688526\n",
      "epoch = 340 train_loss : 36.976837 , test loss : 48.615036\n",
      "epoch = 343 train_loss : 36.775455 , test loss : 48.510662\n",
      "epoch = 344 train_loss : 36.729004 , test loss : 48.427265\n",
      "epoch = 345 train_loss : 36.823196 , test loss : 48.412300\n",
      "epoch = 348 train_loss : 36.721226 , test loss : 48.206108\n",
      "epoch = 350 train_loss : 36.515877 , test loss : 48.141354\n",
      "epoch = 351 train_loss : 36.445896 , test loss : 48.081703\n",
      "epoch = 353 train_loss : 36.367016 , test loss : 47.994019\n",
      "epoch = 354 train_loss : 36.402992 , test loss : 47.940758\n",
      "epoch = 355 train_loss : 36.408566 , test loss : 47.840721\n",
      "epoch = 357 train_loss : 36.221340 , test loss : 47.819878\n",
      "epoch = 358 train_loss : 36.193504 , test loss : 47.693726\n",
      "epoch = 361 train_loss : 36.080105 , test loss : 47.611591\n",
      "epoch = 363 train_loss : 36.004433 , test loss : 47.495705\n",
      "epoch = 364 train_loss : 36.015087 , test loss : 47.437054\n",
      "epoch = 365 train_loss : 35.935081 , test loss : 47.396832\n",
      "epoch = 368 train_loss : 36.121929 , test loss : 47.314316\n",
      "epoch = 369 train_loss : 36.177425 , test loss : 47.283657\n",
      "epoch = 371 train_loss : 35.999718 , test loss : 47.126778\n",
      "epoch = 372 train_loss : 35.848965 , test loss : 47.031418\n",
      "epoch = 374 train_loss : 35.833019 , test loss : 46.979614\n",
      "epoch = 376 train_loss : 35.588581 , test loss : 46.934391\n",
      "epoch = 377 train_loss : 35.629951 , test loss : 46.837570\n",
      "epoch = 380 train_loss : 35.708664 , test loss : 46.790363\n",
      "epoch = 382 train_loss : 35.488483 , test loss : 46.598148\n",
      "epoch = 383 train_loss : 35.399651 , test loss : 46.583862\n",
      "epoch = 389 train_loss : 35.238392 , test loss : 46.457336\n",
      "epoch = 391 train_loss : 35.191704 , test loss : 46.343769\n",
      "epoch = 393 train_loss : 35.188534 , test loss : 46.170002\n",
      "epoch = 396 train_loss : 35.285725 , test loss : 46.080101\n",
      "epoch = 400 train_loss : 34.961906 , test loss : 46.072094\n",
      "epoch = 401 train_loss : 35.193352 , test loss : 45.979733\n",
      "epoch = 403 train_loss : 34.896084 , test loss : 45.903721\n",
      "epoch = 405 train_loss : 34.846111 , test loss : 45.781189\n",
      "epoch = 408 train_loss : 34.806725 , test loss : 45.648003\n",
      "epoch = 412 train_loss : 34.821144 , test loss : 45.555481\n",
      "epoch = 414 train_loss : 34.668720 , test loss : 45.467983\n",
      "epoch = 415 train_loss : 34.641029 , test loss : 45.445675\n",
      "epoch = 418 train_loss : 34.614334 , test loss : 45.322777\n",
      "epoch = 419 train_loss : 34.645161 , test loss : 45.322773\n",
      "epoch = 420 train_loss : 34.543663 , test loss : 45.281662\n",
      "epoch = 421 train_loss : 34.550159 , test loss : 45.264095\n",
      "epoch = 423 train_loss : 34.485096 , test loss : 45.234386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 425 train_loss : 34.477524 , test loss : 45.098793\n",
      "epoch = 427 train_loss : 34.470139 , test loss : 45.079391\n",
      "epoch = 431 train_loss : 34.368095 , test loss : 45.062523\n",
      "epoch = 432 train_loss : 34.326771 , test loss : 44.978745\n",
      "epoch = 433 train_loss : 34.304470 , test loss : 44.943569\n",
      "epoch = 434 train_loss : 34.397263 , test loss : 44.880672\n",
      "epoch = 438 train_loss : 34.235573 , test loss : 44.738621\n",
      "epoch = 442 train_loss : 34.178860 , test loss : 44.680847\n",
      "epoch = 444 train_loss : 34.124130 , test loss : 44.651627\n",
      "epoch = 446 train_loss : 34.103294 , test loss : 44.549393\n",
      "epoch = 448 train_loss : 34.098133 , test loss : 44.524082\n",
      "epoch = 452 train_loss : 34.006470 , test loss : 44.423637\n",
      "epoch = 453 train_loss : 34.008717 , test loss : 44.401405\n",
      "epoch = 456 train_loss : 33.958122 , test loss : 44.274021\n",
      "epoch = 462 train_loss : 33.873318 , test loss : 44.226921\n",
      "epoch = 463 train_loss : 33.850018 , test loss : 44.120773\n",
      "epoch = 467 train_loss : 33.834549 , test loss : 44.071552\n",
      "epoch = 471 train_loss : 33.788895 , test loss : 43.985035\n",
      "epoch = 475 train_loss : 33.896164 , test loss : 43.902054\n",
      "epoch = 479 train_loss : 33.792397 , test loss : 43.815639\n",
      "epoch = 480 train_loss : 33.709190 , test loss : 43.747604\n",
      "epoch = 482 train_loss : 33.832653 , test loss : 43.742855\n",
      "epoch = 487 train_loss : 33.545082 , test loss : 43.665176\n",
      "epoch = 488 train_loss : 33.531094 , test loss : 43.610630\n",
      "epoch = 489 train_loss : 33.614086 , test loss : 43.598431\n",
      "epoch = 490 train_loss : 33.542927 , test loss : 43.567932\n",
      "epoch = 495 train_loss : 33.519409 , test loss : 43.461773\n",
      "epoch = 496 train_loss : 33.440212 , test loss : 43.460972\n",
      "epoch = 498 train_loss : 33.423340 , test loss : 43.382710\n",
      "epoch = 502 train_loss : 33.420876 , test loss : 43.284168\n",
      "epoch = 505 train_loss : 33.371124 , test loss : 43.216713\n",
      "epoch = 508 train_loss : 33.311253 , test loss : 43.202164\n",
      "epoch = 512 train_loss : 33.278439 , test loss : 43.144215\n",
      "epoch = 514 train_loss : 33.246777 , test loss : 43.110142\n",
      "epoch = 515 train_loss : 33.375084 , test loss : 43.106998\n",
      "epoch = 518 train_loss : 33.220440 , test loss : 43.031761\n",
      "epoch = 525 train_loss : 33.239605 , test loss : 42.913174\n",
      "epoch = 526 train_loss : 33.203449 , test loss : 42.902218\n",
      "epoch = 529 train_loss : 33.118317 , test loss : 42.822201\n",
      "epoch = 534 train_loss : 33.094952 , test loss : 42.783340\n",
      "epoch = 537 train_loss : 33.035942 , test loss : 42.747234\n",
      "epoch = 542 train_loss : 33.086388 , test loss : 42.663639\n",
      "epoch = 544 train_loss : 33.008320 , test loss : 42.616013\n",
      "epoch = 546 train_loss : 33.019566 , test loss : 42.548004\n",
      "epoch = 552 train_loss : 32.911179 , test loss : 42.507866\n",
      "epoch = 553 train_loss : 32.895657 , test loss : 42.494110\n",
      "epoch = 558 train_loss : 32.854507 , test loss : 42.437393\n",
      "epoch = 559 train_loss : 32.851151 , test loss : 42.378105\n",
      "epoch = 560 train_loss : 32.843121 , test loss : 42.363327\n",
      "epoch = 562 train_loss : 32.902397 , test loss : 42.344852\n",
      "epoch = 564 train_loss : 32.814110 , test loss : 42.298393\n",
      "epoch = 568 train_loss : 32.784790 , test loss : 42.278877\n",
      "epoch = 569 train_loss : 32.856289 , test loss : 42.270550\n",
      "epoch = 579 train_loss : 32.735493 , test loss : 42.084736\n",
      "epoch = 587 train_loss : 32.647903 , test loss : 42.083752\n",
      "epoch = 589 train_loss : 32.643360 , test loss : 42.029503\n",
      "epoch = 592 train_loss : 32.626957 , test loss : 42.029121\n",
      "epoch = 595 train_loss : 32.590565 , test loss : 41.942970\n",
      "epoch = 599 train_loss : 32.570545 , test loss : 41.929409\n",
      "epoch = 605 train_loss : 32.664391 , test loss : 41.833046\n",
      "epoch = 615 train_loss : 32.475346 , test loss : 41.734146\n",
      "epoch = 625 train_loss : 32.421497 , test loss : 41.689186\n",
      "epoch = 628 train_loss : 32.420860 , test loss : 41.625130\n",
      "epoch = 632 train_loss : 32.543533 , test loss : 41.617588\n",
      "epoch = 636 train_loss : 32.360619 , test loss : 41.572472\n",
      "epoch = 638 train_loss : 32.348942 , test loss : 41.537674\n",
      "epoch = 640 train_loss : 32.339931 , test loss : 41.496490\n",
      "epoch = 646 train_loss : 32.354572 , test loss : 41.460361\n",
      "epoch = 654 train_loss : 32.290024 , test loss : 41.416561\n",
      "epoch = 655 train_loss : 32.271011 , test loss : 41.412174\n",
      "epoch = 659 train_loss : 32.254574 , test loss : 41.403736\n",
      "epoch = 660 train_loss : 32.258575 , test loss : 41.343521\n",
      "epoch = 664 train_loss : 32.251438 , test loss : 41.330723\n",
      "epoch = 674 train_loss : 32.186146 , test loss : 41.289391\n",
      "epoch = 678 train_loss : 32.300800 , test loss : 41.288467\n",
      "epoch = 679 train_loss : 32.202190 , test loss : 41.213150\n",
      "epoch = 680 train_loss : 32.173737 , test loss : 41.187817\n",
      "epoch = 692 train_loss : 32.142086 , test loss : 41.134628\n",
      "epoch = 693 train_loss : 32.188183 , test loss : 41.127964\n",
      "epoch = 699 train_loss : 32.089058 , test loss : 41.124828\n",
      "epoch = 700 train_loss : 32.083942 , test loss : 41.100651\n",
      "epoch = 704 train_loss : 32.101246 , test loss : 41.100452\n",
      "epoch = 707 train_loss : 32.187172 , test loss : 41.079273\n",
      "epoch = 712 train_loss : 32.048317 , test loss : 41.074860\n",
      "epoch = 713 train_loss : 32.040558 , test loss : 41.007259\n",
      "epoch = 716 train_loss : 32.040581 , test loss : 41.006069\n",
      "epoch = 721 train_loss : 32.012951 , test loss : 40.979881\n",
      "epoch = 723 train_loss : 32.006588 , test loss : 40.962135\n",
      "epoch = 727 train_loss : 32.033142 , test loss : 40.934280\n",
      "epoch = 730 train_loss : 32.028782 , test loss : 40.906536\n",
      "epoch = 741 train_loss : 31.955418 , test loss : 40.868050\n",
      "epoch = 748 train_loss : 31.973284 , test loss : 40.822197\n",
      "epoch = 754 train_loss : 32.083340 , test loss : 40.820927\n",
      "epoch = 759 train_loss : 31.931984 , test loss : 40.726715\n",
      "epoch = 766 train_loss : 31.886391 , test loss : 40.716892\n",
      "epoch = 768 train_loss : 31.919075 , test loss : 40.708706\n",
      "epoch = 778 train_loss : 31.854445 , test loss : 40.629559\n",
      "epoch = 792 train_loss : 31.856741 , test loss : 40.598957\n",
      "epoch = 806 train_loss : 31.778448 , test loss : 40.546803\n",
      "epoch = 821 train_loss : 31.794291 , test loss : 40.531837\n",
      "epoch = 828 train_loss : 31.727699 , test loss : 40.498810\n",
      "epoch = 831 train_loss : 31.733063 , test loss : 40.461098\n",
      "epoch = 835 train_loss : 31.725950 , test loss : 40.419495\n",
      "epoch = 850 train_loss : 31.689516 , test loss : 40.419266\n",
      "epoch = 853 train_loss : 31.680382 , test loss : 40.384796\n",
      "epoch = 872 train_loss : 31.638231 , test loss : 40.348347\n",
      "epoch = 889 train_loss : 31.705292 , test loss : 40.303734\n",
      "epoch = 898 train_loss : 31.596561 , test loss : 40.291943\n",
      "epoch = 901 train_loss : 31.598595 , test loss : 40.288670\n",
      "epoch = 910 train_loss : 31.594753 , test loss : 40.274483\n",
      "epoch = 916 train_loss : 31.613859 , test loss : 40.273285\n",
      "epoch = 921 train_loss : 31.566505 , test loss : 40.268784\n",
      "epoch = 925 train_loss : 31.623198 , test loss : 40.185696\n",
      "epoch = 934 train_loss : 31.576382 , test loss : 40.177353\n",
      "epoch = 958 train_loss : 31.554440 , test loss : 40.150181\n",
      "epoch = 976 train_loss : 31.494064 , test loss : 40.146622\n",
      "epoch = 978 train_loss : 31.527218 , test loss : 40.105328\n",
      "epoch = 993 train_loss : 31.502493 , test loss : 40.047016\n",
      "epoch = 1034 train_loss : 31.450184 , test loss : 40.027401\n",
      "epoch = 1051 train_loss : 31.462425 , test loss : 40.004627\n",
      "epoch = 1071 train_loss : 31.424206 , test loss : 39.954636\n",
      "epoch = 1104 train_loss : 31.440245 , test loss : 39.948483\n",
      "epoch = 1115 train_loss : 31.379192 , test loss : 39.915192\n",
      "epoch = 1126 train_loss : 31.414583 , test loss : 39.914806\n",
      "epoch = 1179 train_loss : 31.486942 , test loss : 39.904587\n",
      "epoch = 1181 train_loss : 31.371555 , test loss : 39.900860\n",
      "epoch = 1187 train_loss : 31.324863 , test loss : 39.899055\n",
      "epoch = 1189 train_loss : 31.345282 , test loss : 39.864666\n",
      "epoch = 1205 train_loss : 31.324215 , test loss : 39.845005\n",
      "epoch = 1242 train_loss : 31.356976 , test loss : 39.844563\n",
      "epoch = 1263 train_loss : 31.281851 , test loss : 39.825943\n",
      "epoch = 1283 train_loss : 31.280285 , test loss : 39.805447\n",
      "epoch = 1365 train_loss : 31.281284 , test loss : 39.750656\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.281284,test loss : 39.750656\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 332.193848 , test loss : 338.501648\n",
      "epoch = 2 train_loss : 305.683929 , test loss : 310.486359\n",
      "epoch = 3 train_loss : 281.393616 , test loss : 284.643250\n",
      "epoch = 4 train_loss : 259.733429 , test loss : 262.202850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5 train_loss : 240.952545 , test loss : 243.256042\n",
      "epoch = 6 train_loss : 223.997131 , test loss : 225.277786\n",
      "epoch = 7 train_loss : 209.691376 , test loss : 210.648575\n",
      "epoch = 8 train_loss : 197.018417 , test loss : 197.378098\n",
      "epoch = 9 train_loss : 186.425308 , test loss : 186.132126\n",
      "epoch = 10 train_loss : 177.018311 , test loss : 176.552277\n",
      "epoch = 11 train_loss : 168.936020 , test loss : 168.113495\n",
      "epoch = 12 train_loss : 161.902451 , test loss : 160.741379\n",
      "epoch = 13 train_loss : 155.839401 , test loss : 154.347977\n",
      "epoch = 14 train_loss : 150.472946 , test loss : 148.696518\n",
      "epoch = 15 train_loss : 145.586807 , test loss : 143.663025\n",
      "epoch = 16 train_loss : 141.261688 , test loss : 139.150726\n",
      "epoch = 17 train_loss : 137.420761 , test loss : 135.138901\n",
      "epoch = 18 train_loss : 133.950714 , test loss : 131.534836\n",
      "epoch = 19 train_loss : 130.719727 , test loss : 128.169006\n",
      "epoch = 20 train_loss : 127.680626 , test loss : 124.960640\n",
      "epoch = 21 train_loss : 124.935585 , test loss : 122.032463\n",
      "epoch = 22 train_loss : 122.332245 , test loss : 119.456238\n",
      "epoch = 23 train_loss : 119.929184 , test loss : 116.806435\n",
      "epoch = 24 train_loss : 117.630020 , test loss : 114.526581\n",
      "epoch = 25 train_loss : 115.493065 , test loss : 112.370232\n",
      "epoch = 26 train_loss : 113.530594 , test loss : 110.321175\n",
      "epoch = 27 train_loss : 111.732483 , test loss : 108.142242\n",
      "epoch = 28 train_loss : 109.835602 , test loss : 106.347603\n",
      "epoch = 29 train_loss : 108.464149 , test loss : 105.201195\n",
      "epoch = 30 train_loss : 106.821335 , test loss : 102.924667\n",
      "epoch = 31 train_loss : 104.882896 , test loss : 101.181892\n",
      "epoch = 32 train_loss : 103.668678 , test loss : 99.678726\n",
      "epoch = 33 train_loss : 102.120346 , test loss : 98.444977\n",
      "epoch = 34 train_loss : 100.828453 , test loss : 97.067764\n",
      "epoch = 35 train_loss : 99.783958 , test loss : 96.079178\n",
      "epoch = 36 train_loss : 98.800743 , test loss : 94.323387\n",
      "epoch = 37 train_loss : 97.093567 , test loss : 92.984070\n",
      "epoch = 38 train_loss : 96.001007 , test loss : 91.763199\n",
      "epoch = 39 train_loss : 94.950653 , test loss : 90.647255\n",
      "epoch = 40 train_loss : 93.941460 , test loss : 89.573776\n",
      "epoch = 41 train_loss : 92.962227 , test loss : 88.262123\n",
      "epoch = 42 train_loss : 92.204659 , test loss : 87.779640\n",
      "epoch = 43 train_loss : 91.215523 , test loss : 86.202812\n",
      "epoch = 44 train_loss : 90.241196 , test loss : 85.346260\n",
      "epoch = 45 train_loss : 89.464333 , test loss : 84.428978\n",
      "epoch = 46 train_loss : 88.634956 , test loss : 83.508972\n",
      "epoch = 47 train_loss : 88.097519 , test loss : 82.690369\n",
      "epoch = 48 train_loss : 87.207123 , test loss : 82.219055\n",
      "epoch = 49 train_loss : 86.406380 , test loss : 81.151703\n",
      "epoch = 50 train_loss : 85.876717 , test loss : 80.306755\n",
      "epoch = 51 train_loss : 85.180702 , test loss : 79.953400\n",
      "epoch = 52 train_loss : 84.813477 , test loss : 79.659630\n",
      "epoch = 53 train_loss : 83.780090 , test loss : 78.132431\n",
      "epoch = 54 train_loss : 83.340034 , test loss : 77.884476\n",
      "epoch = 55 train_loss : 82.611687 , test loss : 76.863304\n",
      "epoch = 56 train_loss : 82.298813 , test loss : 76.271675\n",
      "epoch = 57 train_loss : 81.580490 , test loss : 75.613617\n",
      "epoch = 58 train_loss : 80.974792 , test loss : 75.005470\n",
      "epoch = 59 train_loss : 80.601891 , test loss : 74.834000\n",
      "epoch = 60 train_loss : 80.049355 , test loss : 73.874626\n",
      "epoch = 61 train_loss : 79.535126 , test loss : 73.333000\n",
      "epoch = 62 train_loss : 79.065559 , test loss : 72.773048\n",
      "epoch = 63 train_loss : 78.560127 , test loss : 72.523430\n",
      "epoch = 64 train_loss : 78.311165 , test loss : 72.374168\n",
      "epoch = 65 train_loss : 77.641907 , test loss : 71.369286\n",
      "epoch = 66 train_loss : 77.288673 , test loss : 70.923843\n",
      "epoch = 67 train_loss : 77.279053 , test loss : 70.580872\n",
      "epoch = 68 train_loss : 76.421906 , test loss : 69.994781\n",
      "epoch = 69 train_loss : 76.055817 , test loss : 69.828224\n",
      "epoch = 70 train_loss : 75.660355 , test loss : 69.159142\n",
      "epoch = 71 train_loss : 75.235390 , test loss : 68.901833\n",
      "epoch = 72 train_loss : 74.885307 , test loss : 68.517754\n",
      "epoch = 73 train_loss : 74.500542 , test loss : 68.058411\n",
      "epoch = 74 train_loss : 74.334816 , test loss : 67.597939\n",
      "epoch = 75 train_loss : 73.790733 , test loss : 67.213554\n",
      "epoch = 77 train_loss : 73.362114 , test loss : 67.125351\n",
      "epoch = 78 train_loss : 73.152466 , test loss : 66.235153\n",
      "epoch = 79 train_loss : 72.458504 , test loss : 65.793434\n",
      "epoch = 80 train_loss : 72.376694 , test loss : 65.486687\n",
      "epoch = 81 train_loss : 71.818588 , test loss : 65.303947\n",
      "epoch = 82 train_loss : 71.615036 , test loss : 65.260330\n",
      "epoch = 84 train_loss : 70.873215 , test loss : 64.244415\n",
      "epoch = 85 train_loss : 70.681236 , test loss : 63.872993\n",
      "epoch = 86 train_loss : 70.287102 , test loss : 63.612732\n",
      "epoch = 87 train_loss : 70.073715 , test loss : 63.356472\n",
      "epoch = 89 train_loss : 69.576523 , test loss : 62.728092\n",
      "epoch = 90 train_loss : 69.432251 , test loss : 62.480984\n",
      "epoch = 91 train_loss : 68.862038 , test loss : 62.187847\n",
      "epoch = 92 train_loss : 68.620285 , test loss : 61.847786\n",
      "epoch = 94 train_loss : 68.070160 , test loss : 61.355488\n",
      "epoch = 95 train_loss : 67.927032 , test loss : 61.124031\n",
      "epoch = 96 train_loss : 67.550148 , test loss : 60.945198\n",
      "epoch = 97 train_loss : 67.277367 , test loss : 60.682026\n",
      "epoch = 98 train_loss : 67.025406 , test loss : 60.292072\n",
      "epoch = 99 train_loss : 66.797180 , test loss : 60.043892\n",
      "epoch = 101 train_loss : 66.393997 , test loss : 59.938271\n",
      "epoch = 102 train_loss : 66.104126 , test loss : 59.620155\n",
      "epoch = 105 train_loss : 65.740524 , test loss : 59.502804\n",
      "epoch = 106 train_loss : 65.102531 , test loss : 58.468113\n",
      "epoch = 107 train_loss : 64.884285 , test loss : 58.214729\n",
      "epoch = 109 train_loss : 64.424797 , test loss : 57.726620\n",
      "epoch = 110 train_loss : 64.516884 , test loss : 57.679649\n",
      "epoch = 111 train_loss : 63.986870 , test loss : 57.400181\n",
      "epoch = 112 train_loss : 64.118744 , test loss : 57.201153\n",
      "epoch = 113 train_loss : 63.989464 , test loss : 57.064800\n",
      "epoch = 114 train_loss : 63.362682 , test loss : 56.849949\n",
      "epoch = 115 train_loss : 63.132637 , test loss : 56.599911\n",
      "epoch = 116 train_loss : 62.930794 , test loss : 56.243332\n",
      "epoch = 117 train_loss : 63.134796 , test loss : 56.221832\n",
      "epoch = 118 train_loss : 62.638908 , test loss : 56.209694\n",
      "epoch = 119 train_loss : 62.327423 , test loss : 55.830238\n",
      "epoch = 120 train_loss : 62.093185 , test loss : 55.493912\n",
      "epoch = 121 train_loss : 61.915581 , test loss : 55.219139\n",
      "epoch = 123 train_loss : 61.480061 , test loss : 54.858406\n",
      "epoch = 124 train_loss : 61.300358 , test loss : 54.659603\n",
      "epoch = 126 train_loss : 60.965652 , test loss : 54.530743\n",
      "epoch = 127 train_loss : 60.705196 , test loss : 54.079613\n",
      "epoch = 128 train_loss : 60.503696 , test loss : 53.922592\n",
      "epoch = 130 train_loss : 60.428009 , test loss : 53.613216\n",
      "epoch = 132 train_loss : 59.765835 , test loss : 53.190907\n",
      "epoch = 133 train_loss : 59.701088 , test loss : 52.960415\n",
      "epoch = 134 train_loss : 59.390018 , test loss : 52.800373\n",
      "epoch = 137 train_loss : 58.869823 , test loss : 52.375828\n",
      "epoch = 138 train_loss : 59.244019 , test loss : 52.373096\n",
      "epoch = 139 train_loss : 58.510876 , test loss : 51.966404\n",
      "epoch = 141 train_loss : 58.189182 , test loss : 51.755707\n",
      "epoch = 142 train_loss : 58.489929 , test loss : 51.689869\n",
      "epoch = 143 train_loss : 57.899101 , test loss : 51.174755\n",
      "epoch = 145 train_loss : 57.476639 , test loss : 50.962620\n",
      "epoch = 146 train_loss : 57.312023 , test loss : 50.846092\n",
      "epoch = 147 train_loss : 57.247627 , test loss : 50.608978\n",
      "epoch = 148 train_loss : 57.030197 , test loss : 50.441582\n",
      "epoch = 149 train_loss : 56.909111 , test loss : 50.262794\n",
      "epoch = 150 train_loss : 56.719139 , test loss : 50.102367\n",
      "epoch = 153 train_loss : 56.248623 , test loss : 49.872879\n",
      "epoch = 154 train_loss : 56.028423 , test loss : 49.542706\n",
      "epoch = 155 train_loss : 55.995796 , test loss : 49.350998\n",
      "epoch = 156 train_loss : 55.741158 , test loss : 49.126194\n",
      "epoch = 157 train_loss : 55.566322 , test loss : 49.090370\n",
      "epoch = 158 train_loss : 55.442135 , test loss : 48.837620\n",
      "epoch = 160 train_loss : 55.414398 , test loss : 48.650810\n",
      "epoch = 161 train_loss : 55.356735 , test loss : 48.576702\n",
      "epoch = 162 train_loss : 54.800945 , test loss : 48.246769\n",
      "epoch = 163 train_loss : 54.654480 , test loss : 48.089352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 165 train_loss : 54.453983 , test loss : 47.858162\n",
      "epoch = 166 train_loss : 54.223244 , test loss : 47.684052\n",
      "epoch = 167 train_loss : 54.100456 , test loss : 47.668617\n",
      "epoch = 168 train_loss : 54.038837 , test loss : 47.641777\n",
      "epoch = 170 train_loss : 53.760220 , test loss : 47.396904\n",
      "epoch = 171 train_loss : 53.512100 , test loss : 47.045654\n",
      "epoch = 172 train_loss : 53.387371 , test loss : 46.768997\n",
      "epoch = 173 train_loss : 53.237846 , test loss : 46.737171\n",
      "epoch = 175 train_loss : 53.043716 , test loss : 46.632816\n",
      "epoch = 178 train_loss : 52.575161 , test loss : 46.075638\n",
      "epoch = 179 train_loss : 52.507435 , test loss : 45.951611\n",
      "epoch = 180 train_loss : 52.310680 , test loss : 45.799812\n",
      "epoch = 181 train_loss : 52.193951 , test loss : 45.730988\n",
      "epoch = 183 train_loss : 51.971073 , test loss : 45.530800\n",
      "epoch = 184 train_loss : 51.820778 , test loss : 45.388973\n",
      "epoch = 186 train_loss : 51.571327 , test loss : 45.064728\n",
      "epoch = 187 train_loss : 51.475334 , test loss : 44.879753\n",
      "epoch = 188 train_loss : 51.315125 , test loss : 44.817368\n",
      "epoch = 190 train_loss : 51.185814 , test loss : 44.794289\n",
      "epoch = 191 train_loss : 51.019566 , test loss : 44.654037\n",
      "epoch = 192 train_loss : 50.834732 , test loss : 44.331921\n",
      "epoch = 193 train_loss : 51.006306 , test loss : 44.250343\n",
      "epoch = 194 train_loss : 50.594570 , test loss : 44.154839\n",
      "epoch = 195 train_loss : 50.506821 , test loss : 44.019997\n",
      "epoch = 196 train_loss : 50.358536 , test loss : 43.880367\n",
      "epoch = 197 train_loss : 50.426991 , test loss : 43.834614\n",
      "epoch = 199 train_loss : 50.021793 , test loss : 43.524525\n",
      "epoch = 200 train_loss : 50.030903 , test loss : 43.452427\n",
      "epoch = 201 train_loss : 49.871983 , test loss : 43.262409\n",
      "epoch = 202 train_loss : 49.679325 , test loss : 43.178532\n",
      "epoch = 203 train_loss : 49.571228 , test loss : 43.080830\n",
      "epoch = 205 train_loss : 49.359440 , test loss : 42.830029\n",
      "epoch = 207 train_loss : 49.140537 , test loss : 42.671516\n",
      "epoch = 208 train_loss : 49.035812 , test loss : 42.584801\n",
      "epoch = 209 train_loss : 48.920544 , test loss : 42.485394\n",
      "epoch = 210 train_loss : 48.837326 , test loss : 42.333984\n",
      "epoch = 212 train_loss : 48.604656 , test loss : 42.136539\n",
      "epoch = 213 train_loss : 48.592968 , test loss : 42.005661\n",
      "epoch = 214 train_loss : 48.482342 , test loss : 41.911617\n",
      "epoch = 215 train_loss : 48.467129 , test loss : 41.836994\n",
      "epoch = 216 train_loss : 48.221203 , test loss : 41.785019\n",
      "epoch = 220 train_loss : 47.826397 , test loss : 41.335575\n",
      "epoch = 222 train_loss : 47.953697 , test loss : 41.332985\n",
      "epoch = 223 train_loss : 47.570423 , test loss : 41.015800\n",
      "epoch = 224 train_loss : 47.411449 , test loss : 40.856865\n",
      "epoch = 228 train_loss : 47.151577 , test loss : 40.808445\n",
      "epoch = 229 train_loss : 47.132675 , test loss : 40.596588\n",
      "epoch = 231 train_loss : 46.891018 , test loss : 40.327339\n",
      "epoch = 232 train_loss : 46.806072 , test loss : 40.256977\n",
      "epoch = 233 train_loss : 46.656139 , test loss : 40.128819\n",
      "epoch = 234 train_loss : 46.493050 , test loss : 40.021957\n",
      "epoch = 235 train_loss : 46.406548 , test loss : 39.973251\n",
      "epoch = 236 train_loss : 46.321407 , test loss : 39.896202\n",
      "epoch = 238 train_loss : 46.178612 , test loss : 39.663918\n",
      "epoch = 239 train_loss : 46.065144 , test loss : 39.657394\n",
      "epoch = 241 train_loss : 46.154095 , test loss : 39.574684\n",
      "epoch = 243 train_loss : 45.846958 , test loss : 39.523140\n",
      "epoch = 244 train_loss : 45.680355 , test loss : 39.171524\n",
      "epoch = 247 train_loss : 45.443573 , test loss : 39.050236\n",
      "epoch = 248 train_loss : 45.457508 , test loss : 38.955391\n",
      "epoch = 249 train_loss : 45.252060 , test loss : 38.818962\n",
      "epoch = 250 train_loss : 45.174885 , test loss : 38.782169\n",
      "epoch = 251 train_loss : 45.091301 , test loss : 38.661030\n",
      "epoch = 252 train_loss : 45.022499 , test loss : 38.588524\n",
      "epoch = 253 train_loss : 44.937763 , test loss : 38.511890\n",
      "epoch = 255 train_loss : 44.808285 , test loss : 38.371590\n",
      "epoch = 259 train_loss : 44.504623 , test loss : 38.187176\n",
      "epoch = 260 train_loss : 44.525242 , test loss : 38.103153\n",
      "epoch = 262 train_loss : 44.289028 , test loss : 37.986652\n",
      "epoch = 266 train_loss : 44.150867 , test loss : 37.705032\n",
      "epoch = 268 train_loss : 44.047459 , test loss : 37.661346\n",
      "epoch = 269 train_loss : 43.801785 , test loss : 37.448292\n",
      "epoch = 270 train_loss : 43.753559 , test loss : 37.372467\n",
      "epoch = 273 train_loss : 43.515537 , test loss : 37.211773\n",
      "epoch = 274 train_loss : 43.460743 , test loss : 37.138180\n",
      "epoch = 275 train_loss : 43.447758 , test loss : 37.131298\n",
      "epoch = 276 train_loss : 43.322788 , test loss : 36.975906\n",
      "epoch = 277 train_loss : 43.246693 , test loss : 36.945847\n",
      "epoch = 278 train_loss : 43.230251 , test loss : 36.888538\n",
      "epoch = 279 train_loss : 43.167789 , test loss : 36.850090\n",
      "epoch = 280 train_loss : 43.065144 , test loss : 36.741383\n",
      "epoch = 281 train_loss : 43.011650 , test loss : 36.676903\n",
      "epoch = 282 train_loss : 42.987331 , test loss : 36.661011\n",
      "epoch = 283 train_loss : 42.876453 , test loss : 36.594311\n",
      "epoch = 286 train_loss : 42.689960 , test loss : 36.408485\n",
      "epoch = 289 train_loss : 42.513481 , test loss : 36.239315\n",
      "epoch = 292 train_loss : 42.530190 , test loss : 36.233120\n",
      "epoch = 293 train_loss : 42.344433 , test loss : 36.056427\n",
      "epoch = 296 train_loss : 42.116539 , test loss : 35.869686\n",
      "epoch = 299 train_loss : 41.961018 , test loss : 35.760086\n",
      "epoch = 301 train_loss : 41.880959 , test loss : 35.681606\n",
      "epoch = 303 train_loss : 41.732635 , test loss : 35.576641\n",
      "epoch = 307 train_loss : 41.547112 , test loss : 35.441406\n",
      "epoch = 308 train_loss : 41.480103 , test loss : 35.350914\n",
      "epoch = 311 train_loss : 41.319241 , test loss : 35.205654\n",
      "epoch = 313 train_loss : 41.273796 , test loss : 35.128067\n",
      "epoch = 314 train_loss : 41.195744 , test loss : 35.062305\n",
      "epoch = 316 train_loss : 41.075630 , test loss : 34.947563\n",
      "epoch = 319 train_loss : 41.014828 , test loss : 34.924728\n",
      "epoch = 322 train_loss : 40.801144 , test loss : 34.770039\n",
      "epoch = 323 train_loss : 40.791569 , test loss : 34.743782\n",
      "epoch = 324 train_loss : 40.741108 , test loss : 34.727142\n",
      "epoch = 325 train_loss : 40.736736 , test loss : 34.641727\n",
      "epoch = 326 train_loss : 40.668468 , test loss : 34.601574\n",
      "epoch = 331 train_loss : 40.384289 , test loss : 34.413616\n",
      "epoch = 332 train_loss : 40.357056 , test loss : 34.347687\n",
      "epoch = 334 train_loss : 40.256809 , test loss : 34.274185\n",
      "epoch = 335 train_loss : 40.214283 , test loss : 34.252785\n",
      "epoch = 336 train_loss : 40.186062 , test loss : 34.236900\n",
      "epoch = 339 train_loss : 40.187565 , test loss : 34.180344\n",
      "epoch = 342 train_loss : 39.959522 , test loss : 34.064789\n",
      "epoch = 343 train_loss : 39.919971 , test loss : 34.013100\n",
      "epoch = 348 train_loss : 39.695049 , test loss : 33.836418\n",
      "epoch = 350 train_loss : 39.705944 , test loss : 33.832157\n",
      "epoch = 351 train_loss : 39.588383 , test loss : 33.725159\n",
      "epoch = 353 train_loss : 39.523014 , test loss : 33.624775\n",
      "epoch = 358 train_loss : 39.395611 , test loss : 33.570126\n",
      "epoch = 360 train_loss : 39.276134 , test loss : 33.511524\n",
      "epoch = 361 train_loss : 39.225956 , test loss : 33.490623\n",
      "epoch = 363 train_loss : 39.252872 , test loss : 33.428474\n",
      "epoch = 365 train_loss : 39.089417 , test loss : 33.352341\n",
      "epoch = 367 train_loss : 39.106083 , test loss : 33.340492\n",
      "epoch = 368 train_loss : 39.033333 , test loss : 33.280991\n",
      "epoch = 370 train_loss : 38.926128 , test loss : 33.252678\n",
      "epoch = 374 train_loss : 38.838558 , test loss : 33.195728\n",
      "epoch = 375 train_loss : 38.767441 , test loss : 33.093914\n",
      "epoch = 376 train_loss : 38.749500 , test loss : 33.069805\n",
      "epoch = 379 train_loss : 38.666130 , test loss : 32.989273\n",
      "epoch = 380 train_loss : 38.615498 , test loss : 32.943264\n",
      "epoch = 385 train_loss : 38.537395 , test loss : 32.940819\n",
      "epoch = 387 train_loss : 38.422054 , test loss : 32.845005\n",
      "epoch = 391 train_loss : 38.312908 , test loss : 32.794785\n",
      "epoch = 394 train_loss : 38.218166 , test loss : 32.735146\n",
      "epoch = 397 train_loss : 38.148540 , test loss : 32.644466\n",
      "epoch = 399 train_loss : 38.098862 , test loss : 32.569492\n",
      "epoch = 403 train_loss : 38.021439 , test loss : 32.531998\n",
      "epoch = 407 train_loss : 37.882633 , test loss : 32.457863\n",
      "epoch = 408 train_loss : 37.875710 , test loss : 32.435944\n",
      "epoch = 410 train_loss : 37.808296 , test loss : 32.402428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 413 train_loss : 37.768707 , test loss : 32.371902\n",
      "epoch = 416 train_loss : 37.675529 , test loss : 32.332447\n",
      "epoch = 418 train_loss : 37.667397 , test loss : 32.253925\n",
      "epoch = 422 train_loss : 37.518578 , test loss : 32.243980\n",
      "epoch = 423 train_loss : 37.492943 , test loss : 32.190365\n",
      "epoch = 425 train_loss : 37.477615 , test loss : 32.167675\n",
      "epoch = 427 train_loss : 37.445274 , test loss : 32.155334\n",
      "epoch = 428 train_loss : 37.383724 , test loss : 32.094330\n",
      "epoch = 431 train_loss : 37.348137 , test loss : 32.073524\n",
      "epoch = 436 train_loss : 37.236633 , test loss : 32.049778\n",
      "epoch = 437 train_loss : 37.211369 , test loss : 32.015785\n",
      "epoch = 440 train_loss : 37.135494 , test loss : 31.945898\n",
      "epoch = 447 train_loss : 37.006859 , test loss : 31.883465\n",
      "epoch = 450 train_loss : 36.945911 , test loss : 31.874651\n",
      "epoch = 451 train_loss : 36.963726 , test loss : 31.846531\n",
      "epoch = 452 train_loss : 36.985653 , test loss : 31.844479\n",
      "epoch = 455 train_loss : 36.888817 , test loss : 31.820919\n",
      "epoch = 457 train_loss : 36.867413 , test loss : 31.797506\n",
      "epoch = 460 train_loss : 36.769142 , test loss : 31.742369\n",
      "epoch = 463 train_loss : 36.721649 , test loss : 31.676962\n",
      "epoch = 466 train_loss : 36.663181 , test loss : 31.641808\n",
      "epoch = 470 train_loss : 36.598309 , test loss : 31.627239\n",
      "epoch = 474 train_loss : 36.531044 , test loss : 31.583767\n",
      "epoch = 476 train_loss : 36.503780 , test loss : 31.572073\n",
      "epoch = 480 train_loss : 36.439926 , test loss : 31.509474\n",
      "epoch = 489 train_loss : 36.303234 , test loss : 31.446304\n",
      "epoch = 496 train_loss : 36.203457 , test loss : 31.411480\n",
      "epoch = 498 train_loss : 36.178345 , test loss : 31.365669\n",
      "epoch = 506 train_loss : 36.070271 , test loss : 31.360584\n",
      "epoch = 507 train_loss : 36.058838 , test loss : 31.289793\n",
      "epoch = 514 train_loss : 35.962971 , test loss : 31.281139\n",
      "epoch = 517 train_loss : 35.941284 , test loss : 31.241720\n",
      "epoch = 521 train_loss : 35.884361 , test loss : 31.204615\n",
      "epoch = 531 train_loss : 35.790562 , test loss : 31.171944\n",
      "epoch = 536 train_loss : 35.711456 , test loss : 31.131670\n",
      "epoch = 546 train_loss : 35.592407 , test loss : 31.110632\n",
      "epoch = 548 train_loss : 35.575241 , test loss : 31.097570\n",
      "epoch = 556 train_loss : 35.495335 , test loss : 31.096191\n",
      "epoch = 560 train_loss : 35.473190 , test loss : 31.081814\n",
      "epoch = 563 train_loss : 35.460957 , test loss : 31.069502\n",
      "epoch = 566 train_loss : 35.397877 , test loss : 30.992365\n",
      "epoch = 587 train_loss : 35.229912 , test loss : 30.938564\n",
      "epoch = 593 train_loss : 35.164787 , test loss : 30.906624\n",
      "epoch = 606 train_loss : 35.085636 , test loss : 30.899111\n",
      "epoch = 619 train_loss : 34.962700 , test loss : 30.847380\n",
      "epoch = 633 train_loss : 34.865490 , test loss : 30.835350\n",
      "epoch = 641 train_loss : 34.814758 , test loss : 30.782936\n",
      "epoch = 655 train_loss : 34.737495 , test loss : 30.772469\n",
      "epoch = 663 train_loss : 34.696747 , test loss : 30.768328\n",
      "epoch = 669 train_loss : 34.638577 , test loss : 30.724392\n",
      "epoch = 670 train_loss : 34.635529 , test loss : 30.707563\n",
      "epoch = 708 train_loss : 34.440975 , test loss : 30.651665\n",
      "epoch = 773 train_loss : 34.145145 , test loss : 30.632637\n",
      "epoch = 861 train_loss : 33.847057 , test loss : 30.614561\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 33.847057,test loss : 30.614561\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 2 train_loss : 613.084351 , test loss : 629.898254\n",
      "epoch = 3 train_loss : 359.208557 , test loss : 367.877594\n",
      "epoch = 4 train_loss : 269.047729 , test loss : 273.192078\n",
      "epoch = 5 train_loss : 245.098618 , test loss : 247.018265\n",
      "epoch = 6 train_loss : 239.182281 , test loss : 240.211258\n",
      "epoch = 7 train_loss : 235.844681 , test loss : 236.616699\n",
      "epoch = 8 train_loss : 232.420502 , test loss : 233.126343\n",
      "epoch = 9 train_loss : 228.936707 , test loss : 229.638657\n",
      "epoch = 10 train_loss : 225.462494 , test loss : 226.214279\n",
      "epoch = 11 train_loss : 221.819977 , test loss : 222.500259\n",
      "epoch = 12 train_loss : 218.242050 , test loss : 218.883469\n",
      "epoch = 13 train_loss : 214.674530 , test loss : 215.341095\n",
      "epoch = 14 train_loss : 211.142212 , test loss : 211.818405\n",
      "epoch = 15 train_loss : 207.560364 , test loss : 208.178268\n",
      "epoch = 16 train_loss : 204.035461 , test loss : 204.688400\n",
      "epoch = 17 train_loss : 200.669403 , test loss : 201.346344\n",
      "epoch = 18 train_loss : 197.210556 , test loss : 197.856644\n",
      "epoch = 19 train_loss : 193.867477 , test loss : 194.537979\n",
      "epoch = 20 train_loss : 190.585052 , test loss : 191.273788\n",
      "epoch = 21 train_loss : 187.433395 , test loss : 188.116745\n",
      "epoch = 22 train_loss : 184.316269 , test loss : 185.061600\n",
      "epoch = 23 train_loss : 181.313492 , test loss : 182.044556\n",
      "epoch = 24 train_loss : 178.341660 , test loss : 179.116699\n",
      "epoch = 25 train_loss : 175.489426 , test loss : 176.272751\n",
      "epoch = 26 train_loss : 172.672195 , test loss : 173.491486\n",
      "epoch = 27 train_loss : 169.965256 , test loss : 170.824036\n",
      "epoch = 28 train_loss : 167.325943 , test loss : 168.202393\n",
      "epoch = 29 train_loss : 164.797272 , test loss : 165.694382\n",
      "epoch = 30 train_loss : 162.338959 , test loss : 163.270462\n",
      "epoch = 31 train_loss : 159.965698 , test loss : 160.927322\n",
      "epoch = 32 train_loss : 157.640549 , test loss : 158.621002\n",
      "epoch = 33 train_loss : 155.410675 , test loss : 156.428604\n",
      "epoch = 34 train_loss : 153.220749 , test loss : 154.268219\n",
      "epoch = 35 train_loss : 151.112503 , test loss : 152.180771\n",
      "epoch = 36 train_loss : 149.125473 , test loss : 150.228348\n",
      "epoch = 37 train_loss : 147.165009 , test loss : 148.287491\n",
      "epoch = 38 train_loss : 145.253403 , test loss : 146.400421\n",
      "epoch = 39 train_loss : 143.417725 , test loss : 144.599518\n",
      "epoch = 40 train_loss : 141.645645 , test loss : 142.842331\n",
      "epoch = 41 train_loss : 139.919769 , test loss : 141.143585\n",
      "epoch = 42 train_loss : 138.255386 , test loss : 139.497940\n",
      "epoch = 43 train_loss : 136.632294 , test loss : 137.888702\n",
      "epoch = 44 train_loss : 135.076920 , test loss : 136.363419\n",
      "epoch = 45 train_loss : 133.582626 , test loss : 134.863785\n",
      "epoch = 46 train_loss : 132.125046 , test loss : 133.437332\n",
      "epoch = 47 train_loss : 130.707703 , test loss : 132.011383\n",
      "epoch = 48 train_loss : 129.342789 , test loss : 130.666260\n",
      "epoch = 49 train_loss : 127.976341 , test loss : 129.323547\n",
      "epoch = 50 train_loss : 126.645699 , test loss : 127.996475\n",
      "epoch = 51 train_loss : 125.391037 , test loss : 126.754654\n",
      "epoch = 52 train_loss : 124.174522 , test loss : 125.521378\n",
      "epoch = 53 train_loss : 122.963974 , test loss : 124.327141\n",
      "epoch = 54 train_loss : 121.806778 , test loss : 123.147163\n",
      "epoch = 55 train_loss : 120.630600 , test loss : 121.990013\n",
      "epoch = 56 train_loss : 119.511284 , test loss : 120.857780\n",
      "epoch = 57 train_loss : 118.410530 , test loss : 119.763756\n",
      "epoch = 58 train_loss : 117.326363 , test loss : 118.698181\n",
      "epoch = 59 train_loss : 116.260201 , test loss : 117.609894\n",
      "epoch = 60 train_loss : 115.223854 , test loss : 116.568130\n",
      "epoch = 61 train_loss : 114.204590 , test loss : 115.550896\n",
      "epoch = 62 train_loss : 113.241028 , test loss : 114.553291\n",
      "epoch = 63 train_loss : 112.241264 , test loss : 113.573227\n",
      "epoch = 64 train_loss : 111.291687 , test loss : 112.601608\n",
      "epoch = 65 train_loss : 110.362320 , test loss : 111.675232\n",
      "epoch = 66 train_loss : 109.452164 , test loss : 110.732956\n",
      "epoch = 67 train_loss : 108.547882 , test loss : 109.847427\n",
      "epoch = 68 train_loss : 107.673470 , test loss : 108.927643\n",
      "epoch = 69 train_loss : 106.813950 , test loss : 108.068710\n",
      "epoch = 70 train_loss : 105.936516 , test loss : 107.192749\n",
      "epoch = 71 train_loss : 105.096855 , test loss : 106.336624\n",
      "epoch = 72 train_loss : 104.281006 , test loss : 105.497116\n",
      "epoch = 73 train_loss : 103.454063 , test loss : 104.665321\n",
      "epoch = 74 train_loss : 102.649239 , test loss : 103.831100\n",
      "epoch = 75 train_loss : 101.875137 , test loss : 103.058121\n",
      "epoch = 76 train_loss : 101.091461 , test loss : 102.267159\n",
      "epoch = 77 train_loss : 100.350075 , test loss : 101.475449\n",
      "epoch = 78 train_loss : 99.586273 , test loss : 100.717461\n",
      "epoch = 79 train_loss : 98.840088 , test loss : 99.980698\n",
      "epoch = 80 train_loss : 98.104630 , test loss : 99.237732\n",
      "epoch = 81 train_loss : 97.401390 , test loss : 98.473083\n",
      "epoch = 82 train_loss : 96.686874 , test loss : 97.802979\n",
      "epoch = 83 train_loss : 95.974373 , test loss : 97.042030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 84 train_loss : 95.285278 , test loss : 96.372261\n",
      "epoch = 85 train_loss : 94.591576 , test loss : 95.652771\n",
      "epoch = 86 train_loss : 93.928490 , test loss : 94.966133\n",
      "epoch = 87 train_loss : 93.273605 , test loss : 94.324844\n",
      "epoch = 88 train_loss : 92.616913 , test loss : 93.637329\n",
      "epoch = 89 train_loss : 91.966057 , test loss : 93.008377\n",
      "epoch = 90 train_loss : 91.330894 , test loss : 92.345490\n",
      "epoch = 91 train_loss : 90.720558 , test loss : 91.742783\n",
      "epoch = 92 train_loss : 90.087669 , test loss : 91.069878\n",
      "epoch = 93 train_loss : 89.485466 , test loss : 90.491997\n",
      "epoch = 94 train_loss : 88.885635 , test loss : 89.870773\n",
      "epoch = 95 train_loss : 88.300285 , test loss : 89.303337\n",
      "epoch = 96 train_loss : 87.716545 , test loss : 88.699867\n",
      "epoch = 97 train_loss : 87.150116 , test loss : 88.110107\n",
      "epoch = 98 train_loss : 86.616882 , test loss : 87.615181\n",
      "epoch = 99 train_loss : 86.037567 , test loss : 87.023384\n",
      "epoch = 100 train_loss : 85.495041 , test loss : 86.452118\n",
      "epoch = 101 train_loss : 84.953522 , test loss : 85.947350\n",
      "epoch = 102 train_loss : 84.430939 , test loss : 85.387817\n",
      "epoch = 103 train_loss : 83.903679 , test loss : 84.898369\n",
      "epoch = 104 train_loss : 83.394104 , test loss : 84.348198\n",
      "epoch = 105 train_loss : 82.863991 , test loss : 83.830048\n",
      "epoch = 106 train_loss : 82.368965 , test loss : 83.338417\n",
      "epoch = 107 train_loss : 81.878716 , test loss : 82.841728\n",
      "epoch = 108 train_loss : 81.395699 , test loss : 82.362961\n",
      "epoch = 109 train_loss : 80.915443 , test loss : 81.906937\n",
      "epoch = 110 train_loss : 80.445274 , test loss : 81.439934\n",
      "epoch = 111 train_loss : 79.963783 , test loss : 80.967865\n",
      "epoch = 112 train_loss : 79.523430 , test loss : 80.520279\n",
      "epoch = 113 train_loss : 79.070030 , test loss : 80.075111\n",
      "epoch = 114 train_loss : 78.612045 , test loss : 79.611732\n",
      "epoch = 115 train_loss : 78.177567 , test loss : 79.202766\n",
      "epoch = 116 train_loss : 77.780594 , test loss : 78.782013\n",
      "epoch = 117 train_loss : 77.337433 , test loss : 78.381340\n",
      "epoch = 118 train_loss : 76.912666 , test loss : 77.942558\n",
      "epoch = 119 train_loss : 76.497475 , test loss : 77.534576\n",
      "epoch = 120 train_loss : 76.093040 , test loss : 77.160004\n",
      "epoch = 121 train_loss : 75.694633 , test loss : 76.773140\n",
      "epoch = 122 train_loss : 75.298195 , test loss : 76.369431\n",
      "epoch = 123 train_loss : 74.913879 , test loss : 76.003098\n",
      "epoch = 124 train_loss : 74.540756 , test loss : 75.635101\n",
      "epoch = 125 train_loss : 74.156631 , test loss : 75.265015\n",
      "epoch = 126 train_loss : 73.780495 , test loss : 74.896225\n",
      "epoch = 127 train_loss : 73.436378 , test loss : 74.555771\n",
      "epoch = 128 train_loss : 73.068726 , test loss : 74.222427\n",
      "epoch = 129 train_loss : 72.691689 , test loss : 73.840599\n",
      "epoch = 130 train_loss : 72.356216 , test loss : 73.523552\n",
      "epoch = 131 train_loss : 72.009048 , test loss : 73.196495\n",
      "epoch = 132 train_loss : 71.665054 , test loss : 72.848930\n",
      "epoch = 133 train_loss : 71.332161 , test loss : 72.527031\n",
      "epoch = 134 train_loss : 71.017479 , test loss : 72.247231\n",
      "epoch = 135 train_loss : 70.683510 , test loss : 71.913536\n",
      "epoch = 136 train_loss : 70.360817 , test loss : 71.586021\n",
      "epoch = 137 train_loss : 70.074234 , test loss : 71.316574\n",
      "epoch = 138 train_loss : 69.755592 , test loss : 71.028481\n",
      "epoch = 139 train_loss : 69.439072 , test loss : 70.704407\n",
      "epoch = 141 train_loss : 69.040482 , test loss : 70.333046\n",
      "epoch = 142 train_loss : 68.558823 , test loss : 69.883209\n",
      "epoch = 143 train_loss : 68.278481 , test loss : 69.630318\n",
      "epoch = 144 train_loss : 68.110962 , test loss : 69.480576\n",
      "epoch = 145 train_loss : 67.703476 , test loss : 69.088478\n",
      "epoch = 146 train_loss : 67.411629 , test loss : 68.811691\n",
      "epoch = 147 train_loss : 67.184250 , test loss : 68.597687\n",
      "epoch = 148 train_loss : 67.025513 , test loss : 68.448418\n",
      "epoch = 149 train_loss : 66.604721 , test loss : 68.043152\n",
      "epoch = 150 train_loss : 66.357094 , test loss : 67.797882\n",
      "epoch = 151 train_loss : 66.130608 , test loss : 67.608322\n",
      "epoch = 152 train_loss : 65.913071 , test loss : 67.382469\n",
      "epoch = 153 train_loss : 65.570976 , test loss : 67.067154\n",
      "epoch = 154 train_loss : 65.351845 , test loss : 66.864304\n",
      "epoch = 155 train_loss : 65.091377 , test loss : 66.622963\n",
      "epoch = 156 train_loss : 64.846504 , test loss : 66.384209\n",
      "epoch = 157 train_loss : 64.630318 , test loss : 66.204163\n",
      "epoch = 158 train_loss : 64.360443 , test loss : 65.937401\n",
      "epoch = 159 train_loss : 64.171898 , test loss : 65.744919\n",
      "epoch = 160 train_loss : 63.919899 , test loss : 65.514359\n",
      "epoch = 161 train_loss : 63.811958 , test loss : 65.444000\n",
      "epoch = 162 train_loss : 63.473923 , test loss : 65.087631\n",
      "epoch = 163 train_loss : 63.228477 , test loss : 64.874496\n",
      "epoch = 164 train_loss : 63.145477 , test loss : 64.818336\n",
      "epoch = 165 train_loss : 63.088802 , test loss : 64.720314\n",
      "epoch = 166 train_loss : 62.594147 , test loss : 64.276047\n",
      "epoch = 167 train_loss : 62.604965 , test loss : 64.250999\n",
      "epoch = 168 train_loss : 62.166683 , test loss : 63.880398\n",
      "epoch = 169 train_loss : 61.875778 , test loss : 63.586922\n",
      "epoch = 171 train_loss : 61.598320 , test loss : 63.353371\n",
      "epoch = 172 train_loss : 61.374153 , test loss : 63.137234\n",
      "epoch = 173 train_loss : 61.044487 , test loss : 62.772964\n",
      "epoch = 174 train_loss : 60.833168 , test loss : 62.576004\n",
      "epoch = 175 train_loss : 60.727856 , test loss : 62.455452\n",
      "epoch = 176 train_loss : 60.507622 , test loss : 62.293362\n",
      "epoch = 177 train_loss : 60.239697 , test loss : 61.987133\n",
      "epoch = 178 train_loss : 60.156868 , test loss : 61.959064\n",
      "epoch = 179 train_loss : 59.957302 , test loss : 61.785034\n",
      "epoch = 180 train_loss : 59.816872 , test loss : 61.566483\n",
      "epoch = 181 train_loss : 59.517162 , test loss : 61.329079\n",
      "epoch = 182 train_loss : 59.374126 , test loss : 61.232082\n",
      "epoch = 183 train_loss : 59.161030 , test loss : 60.940361\n",
      "epoch = 185 train_loss : 58.713276 , test loss : 60.533012\n",
      "epoch = 186 train_loss : 58.610020 , test loss : 60.480839\n",
      "epoch = 187 train_loss : 58.377045 , test loss : 60.226284\n",
      "epoch = 188 train_loss : 58.159851 , test loss : 60.013145\n",
      "epoch = 189 train_loss : 57.977375 , test loss : 59.808243\n",
      "epoch = 190 train_loss : 57.991165 , test loss : 59.766304\n",
      "epoch = 191 train_loss : 57.897984 , test loss : 59.678257\n",
      "epoch = 192 train_loss : 57.624760 , test loss : 59.541252\n",
      "epoch = 193 train_loss : 57.282585 , test loss : 59.156956\n",
      "epoch = 195 train_loss : 56.922398 , test loss : 58.759964\n",
      "epoch = 196 train_loss : 56.819653 , test loss : 58.724384\n",
      "epoch = 197 train_loss : 56.872112 , test loss : 58.635876\n",
      "epoch = 198 train_loss : 56.403549 , test loss : 58.251884\n",
      "epoch = 200 train_loss : 56.222408 , test loss : 58.026485\n",
      "epoch = 201 train_loss : 56.033619 , test loss : 57.820229\n",
      "epoch = 202 train_loss : 55.742004 , test loss : 57.647785\n",
      "epoch = 203 train_loss : 55.601223 , test loss : 57.499268\n",
      "epoch = 204 train_loss : 55.403030 , test loss : 57.231262\n",
      "epoch = 205 train_loss : 55.411926 , test loss : 57.184361\n",
      "epoch = 206 train_loss : 55.080723 , test loss : 56.962048\n",
      "epoch = 207 train_loss : 54.957733 , test loss : 56.867844\n",
      "epoch = 208 train_loss : 54.845425 , test loss : 56.752331\n",
      "epoch = 209 train_loss : 54.577129 , test loss : 56.433884\n",
      "epoch = 210 train_loss : 54.442337 , test loss : 56.307812\n",
      "epoch = 211 train_loss : 54.263458 , test loss : 56.124538\n",
      "epoch = 212 train_loss : 54.096115 , test loss : 55.920689\n",
      "epoch = 213 train_loss : 53.935722 , test loss : 55.796909\n",
      "epoch = 214 train_loss : 53.822880 , test loss : 55.704720\n",
      "epoch = 216 train_loss : 53.498341 , test loss : 55.370136\n",
      "epoch = 218 train_loss : 53.229572 , test loss : 54.998020\n",
      "epoch = 219 train_loss : 53.007011 , test loss : 54.835617\n",
      "epoch = 220 train_loss : 53.041164 , test loss : 54.756348\n",
      "epoch = 221 train_loss : 52.790230 , test loss : 54.536995\n",
      "epoch = 222 train_loss : 52.598415 , test loss : 54.355335\n",
      "epoch = 224 train_loss : 52.271248 , test loss : 54.034706\n",
      "epoch = 225 train_loss : 52.164761 , test loss : 54.000916\n",
      "epoch = 227 train_loss : 51.832588 , test loss : 53.598545\n",
      "epoch = 228 train_loss : 51.773018 , test loss : 53.470669\n",
      "epoch = 230 train_loss : 51.461960 , test loss : 53.173008\n",
      "epoch = 231 train_loss : 51.364464 , test loss : 53.049904\n",
      "epoch = 232 train_loss : 51.204498 , test loss : 52.882565\n",
      "epoch = 233 train_loss : 50.986530 , test loss : 52.722401\n",
      "epoch = 235 train_loss : 50.795738 , test loss : 52.597214\n",
      "epoch = 236 train_loss : 50.693157 , test loss : 52.285225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 237 train_loss : 50.436321 , test loss : 52.140759\n",
      "epoch = 238 train_loss : 50.341408 , test loss : 52.113979\n",
      "epoch = 239 train_loss : 50.170025 , test loss : 51.863731\n",
      "epoch = 240 train_loss : 50.037457 , test loss : 51.741302\n",
      "epoch = 241 train_loss : 49.986244 , test loss : 51.610367\n",
      "epoch = 242 train_loss : 49.803936 , test loss : 51.515427\n",
      "epoch = 244 train_loss : 49.684376 , test loss : 51.452461\n",
      "epoch = 245 train_loss : 49.483829 , test loss : 51.201023\n",
      "epoch = 246 train_loss : 49.313789 , test loss : 51.032127\n",
      "epoch = 248 train_loss : 49.036823 , test loss : 50.595047\n",
      "epoch = 250 train_loss : 48.748806 , test loss : 50.367844\n",
      "epoch = 251 train_loss : 48.726093 , test loss : 50.250957\n",
      "epoch = 252 train_loss : 48.507885 , test loss : 50.055794\n",
      "epoch = 253 train_loss : 48.406265 , test loss : 49.954277\n",
      "epoch = 255 train_loss : 48.149364 , test loss : 49.696484\n",
      "epoch = 256 train_loss : 48.039185 , test loss : 49.644318\n",
      "epoch = 257 train_loss : 47.909809 , test loss : 49.490448\n",
      "epoch = 258 train_loss : 47.909279 , test loss : 49.348404\n",
      "epoch = 260 train_loss : 47.578838 , test loss : 49.145359\n",
      "epoch = 262 train_loss : 47.322510 , test loss : 48.783909\n",
      "epoch = 264 train_loss : 47.179798 , test loss : 48.780613\n",
      "epoch = 265 train_loss : 46.982098 , test loss : 48.483116\n",
      "epoch = 266 train_loss : 46.882343 , test loss : 48.328194\n",
      "epoch = 268 train_loss : 46.699081 , test loss : 48.069260\n",
      "epoch = 269 train_loss : 46.619617 , test loss : 47.996059\n",
      "epoch = 270 train_loss : 46.431404 , test loss : 47.891556\n",
      "epoch = 271 train_loss : 46.390102 , test loss : 47.757057\n",
      "epoch = 272 train_loss : 46.275585 , test loss : 47.638874\n",
      "epoch = 275 train_loss : 45.907047 , test loss : 47.344807\n",
      "epoch = 277 train_loss : 45.766617 , test loss : 47.095295\n",
      "epoch = 279 train_loss : 45.616802 , test loss : 46.888111\n",
      "epoch = 281 train_loss : 45.299973 , test loss : 46.664352\n",
      "epoch = 283 train_loss : 45.296249 , test loss : 46.533268\n",
      "epoch = 284 train_loss : 45.071976 , test loss : 46.359375\n",
      "epoch = 286 train_loss : 44.813137 , test loss : 46.131481\n",
      "epoch = 287 train_loss : 44.808002 , test loss : 46.012638\n",
      "epoch = 288 train_loss : 44.613918 , test loss : 45.970974\n",
      "epoch = 290 train_loss : 44.423275 , test loss : 45.778042\n",
      "epoch = 291 train_loss : 44.333199 , test loss : 45.657269\n",
      "epoch = 293 train_loss : 44.353817 , test loss : 45.539845\n",
      "epoch = 295 train_loss : 44.052822 , test loss : 45.265507\n",
      "epoch = 296 train_loss : 43.882301 , test loss : 45.128235\n",
      "epoch = 297 train_loss : 43.821884 , test loss : 45.052948\n",
      "epoch = 298 train_loss : 43.701210 , test loss : 44.999161\n",
      "epoch = 299 train_loss : 43.640522 , test loss : 44.835159\n",
      "epoch = 302 train_loss : 43.358208 , test loss : 44.633980\n",
      "epoch = 303 train_loss : 43.308502 , test loss : 44.628685\n",
      "epoch = 305 train_loss : 43.116402 , test loss : 44.351673\n",
      "epoch = 307 train_loss : 42.955070 , test loss : 44.209663\n",
      "epoch = 308 train_loss : 42.883572 , test loss : 44.076653\n",
      "epoch = 309 train_loss : 42.891285 , test loss : 44.030170\n",
      "epoch = 310 train_loss : 42.724899 , test loss : 43.889111\n",
      "epoch = 312 train_loss : 42.568058 , test loss : 43.747849\n",
      "epoch = 314 train_loss : 42.400410 , test loss : 43.611206\n",
      "epoch = 316 train_loss : 42.374020 , test loss : 43.447666\n",
      "epoch = 318 train_loss : 42.095955 , test loss : 43.265076\n",
      "epoch = 320 train_loss : 41.991699 , test loss : 43.143169\n",
      "epoch = 323 train_loss : 41.774750 , test loss : 43.026669\n",
      "epoch = 324 train_loss : 41.725044 , test loss : 42.813171\n",
      "epoch = 326 train_loss : 41.528103 , test loss : 42.702747\n",
      "epoch = 330 train_loss : 41.273174 , test loss : 42.480846\n",
      "epoch = 331 train_loss : 41.186615 , test loss : 42.355747\n",
      "epoch = 333 train_loss : 41.058247 , test loss : 42.227020\n",
      "epoch = 334 train_loss : 40.999157 , test loss : 42.157139\n",
      "epoch = 335 train_loss : 41.018219 , test loss : 42.057434\n",
      "epoch = 336 train_loss : 40.875977 , test loss : 42.050930\n",
      "epoch = 337 train_loss : 41.048820 , test loss : 42.024010\n",
      "epoch = 338 train_loss : 40.844204 , test loss : 41.870480\n",
      "epoch = 340 train_loss : 40.617943 , test loss : 41.795528\n",
      "epoch = 341 train_loss : 40.734066 , test loss : 41.772438\n",
      "epoch = 343 train_loss : 40.522793 , test loss : 41.551437\n",
      "epoch = 345 train_loss : 40.325806 , test loss : 41.493221\n",
      "epoch = 347 train_loss : 40.220409 , test loss : 41.430759\n",
      "epoch = 348 train_loss : 40.153873 , test loss : 41.323174\n",
      "epoch = 349 train_loss : 40.177727 , test loss : 41.217743\n",
      "epoch = 350 train_loss : 40.204033 , test loss : 41.189991\n",
      "epoch = 351 train_loss : 40.212013 , test loss : 41.135921\n",
      "epoch = 353 train_loss : 39.878792 , test loss : 40.956615\n",
      "epoch = 355 train_loss : 39.765282 , test loss : 40.923191\n",
      "epoch = 357 train_loss : 39.712910 , test loss : 40.760033\n",
      "epoch = 359 train_loss : 39.550457 , test loss : 40.699596\n",
      "epoch = 362 train_loss : 39.399044 , test loss : 40.527370\n",
      "epoch = 363 train_loss : 39.390392 , test loss : 40.443565\n",
      "epoch = 364 train_loss : 39.366978 , test loss : 40.392826\n",
      "epoch = 367 train_loss : 39.153084 , test loss : 40.272541\n",
      "epoch = 369 train_loss : 39.079998 , test loss : 40.166809\n",
      "epoch = 372 train_loss : 38.947628 , test loss : 40.010319\n",
      "epoch = 374 train_loss : 38.825802 , test loss : 39.964554\n",
      "epoch = 375 train_loss : 38.778194 , test loss : 39.892082\n",
      "epoch = 376 train_loss : 38.845058 , test loss : 39.838573\n",
      "epoch = 377 train_loss : 38.688839 , test loss : 39.828972\n",
      "epoch = 378 train_loss : 38.645966 , test loss : 39.805603\n",
      "epoch = 379 train_loss : 38.603592 , test loss : 39.723576\n",
      "epoch = 380 train_loss : 38.557426 , test loss : 39.705639\n",
      "epoch = 381 train_loss : 38.588879 , test loss : 39.622593\n",
      "epoch = 384 train_loss : 38.397209 , test loss : 39.481445\n",
      "epoch = 388 train_loss : 38.242851 , test loss : 39.421402\n",
      "epoch = 390 train_loss : 38.349842 , test loss : 39.355431\n",
      "epoch = 391 train_loss : 38.326309 , test loss : 39.311886\n",
      "epoch = 396 train_loss : 38.089050 , test loss : 39.087555\n",
      "epoch = 397 train_loss : 37.898106 , test loss : 38.964523\n",
      "epoch = 401 train_loss : 37.754040 , test loss : 38.953098\n",
      "epoch = 402 train_loss : 37.714703 , test loss : 38.805626\n",
      "epoch = 405 train_loss : 37.605804 , test loss : 38.802582\n",
      "epoch = 407 train_loss : 37.567516 , test loss : 38.775509\n",
      "epoch = 408 train_loss : 37.513878 , test loss : 38.642040\n",
      "epoch = 409 train_loss : 37.585903 , test loss : 38.601791\n",
      "epoch = 414 train_loss : 37.322083 , test loss : 38.466515\n",
      "epoch = 417 train_loss : 37.322926 , test loss : 38.405529\n",
      "epoch = 418 train_loss : 37.340790 , test loss : 38.379326\n",
      "epoch = 420 train_loss : 37.130680 , test loss : 38.289192\n",
      "epoch = 421 train_loss : 37.128914 , test loss : 38.251068\n",
      "epoch = 423 train_loss : 37.044888 , test loss : 38.239143\n",
      "epoch = 425 train_loss : 37.217659 , test loss : 38.225384\n",
      "epoch = 426 train_loss : 37.000969 , test loss : 38.113461\n",
      "epoch = 431 train_loss : 36.821766 , test loss : 38.075748\n",
      "epoch = 432 train_loss : 36.971424 , test loss : 38.043571\n",
      "epoch = 433 train_loss : 36.775066 , test loss : 37.933651\n",
      "epoch = 435 train_loss : 36.737930 , test loss : 37.899864\n",
      "epoch = 436 train_loss : 36.691002 , test loss : 37.878567\n",
      "epoch = 437 train_loss : 36.709236 , test loss : 37.867474\n",
      "epoch = 438 train_loss : 36.644051 , test loss : 37.843872\n",
      "epoch = 443 train_loss : 36.535557 , test loss : 37.827469\n",
      "epoch = 445 train_loss : 36.533585 , test loss : 37.685272\n",
      "epoch = 447 train_loss : 36.418766 , test loss : 37.656063\n",
      "epoch = 448 train_loss : 36.391365 , test loss : 37.627731\n",
      "epoch = 449 train_loss : 36.367554 , test loss : 37.617615\n",
      "epoch = 452 train_loss : 36.329643 , test loss : 37.521248\n",
      "epoch = 454 train_loss : 36.266369 , test loss : 37.465111\n",
      "epoch = 457 train_loss : 36.230698 , test loss : 37.417309\n",
      "epoch = 460 train_loss : 36.205372 , test loss : 37.386009\n",
      "epoch = 461 train_loss : 36.123760 , test loss : 37.299397\n",
      "epoch = 462 train_loss : 36.083794 , test loss : 37.295670\n",
      "epoch = 465 train_loss : 36.023052 , test loss : 37.269363\n",
      "epoch = 469 train_loss : 36.026108 , test loss : 37.237949\n",
      "epoch = 472 train_loss : 35.913200 , test loss : 37.218075\n",
      "epoch = 474 train_loss : 35.903702 , test loss : 37.081444\n",
      "epoch = 475 train_loss : 35.878204 , test loss : 37.048309\n",
      "epoch = 479 train_loss : 35.738354 , test loss : 37.034973\n",
      "epoch = 480 train_loss : 35.748051 , test loss : 36.999386\n",
      "epoch = 483 train_loss : 35.695724 , test loss : 36.933708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 487 train_loss : 35.597206 , test loss : 36.901684\n",
      "epoch = 490 train_loss : 35.576408 , test loss : 36.825768\n",
      "epoch = 497 train_loss : 35.461536 , test loss : 36.748646\n",
      "epoch = 502 train_loss : 35.384346 , test loss : 36.659729\n",
      "epoch = 505 train_loss : 35.301750 , test loss : 36.654308\n",
      "epoch = 510 train_loss : 35.232712 , test loss : 36.568283\n",
      "epoch = 516 train_loss : 35.179352 , test loss : 36.493225\n",
      "epoch = 518 train_loss : 35.110737 , test loss : 36.465855\n",
      "epoch = 520 train_loss : 35.109180 , test loss : 36.414772\n",
      "epoch = 527 train_loss : 34.985950 , test loss : 36.382778\n",
      "epoch = 530 train_loss : 35.096497 , test loss : 36.330425\n",
      "epoch = 535 train_loss : 34.882980 , test loss : 36.274750\n",
      "epoch = 539 train_loss : 34.835377 , test loss : 36.255936\n",
      "epoch = 540 train_loss : 34.821186 , test loss : 36.238926\n",
      "epoch = 541 train_loss : 34.932709 , test loss : 36.196182\n",
      "epoch = 543 train_loss : 34.821442 , test loss : 36.136360\n",
      "epoch = 548 train_loss : 34.744690 , test loss : 36.130894\n",
      "epoch = 549 train_loss : 34.714386 , test loss : 36.115345\n",
      "epoch = 553 train_loss : 34.670574 , test loss : 36.113449\n",
      "epoch = 556 train_loss : 34.656116 , test loss : 36.047394\n",
      "epoch = 558 train_loss : 34.615685 , test loss : 36.033112\n",
      "epoch = 561 train_loss : 34.641014 , test loss : 35.990982\n",
      "epoch = 565 train_loss : 34.543240 , test loss : 35.968014\n",
      "epoch = 571 train_loss : 34.520668 , test loss : 35.957333\n",
      "epoch = 574 train_loss : 34.454464 , test loss : 35.916058\n",
      "epoch = 576 train_loss : 34.430954 , test loss : 35.899624\n",
      "epoch = 577 train_loss : 34.422710 , test loss : 35.881191\n",
      "epoch = 582 train_loss : 34.457493 , test loss : 35.854668\n",
      "epoch = 585 train_loss : 34.342709 , test loss : 35.827770\n",
      "epoch = 587 train_loss : 34.394482 , test loss : 35.776573\n",
      "epoch = 593 train_loss : 34.291126 , test loss : 35.717159\n",
      "epoch = 601 train_loss : 34.283306 , test loss : 35.704166\n",
      "epoch = 603 train_loss : 34.201118 , test loss : 35.672333\n",
      "epoch = 611 train_loss : 34.249657 , test loss : 35.654884\n",
      "epoch = 615 train_loss : 34.099274 , test loss : 35.615433\n",
      "epoch = 617 train_loss : 34.104004 , test loss : 35.606842\n",
      "epoch = 619 train_loss : 34.068634 , test loss : 35.588787\n",
      "epoch = 621 train_loss : 34.065502 , test loss : 35.574299\n",
      "epoch = 624 train_loss : 34.063725 , test loss : 35.570385\n",
      "epoch = 625 train_loss : 34.065361 , test loss : 35.559696\n",
      "epoch = 627 train_loss : 34.012920 , test loss : 35.544003\n",
      "epoch = 630 train_loss : 34.012501 , test loss : 35.473259\n",
      "epoch = 636 train_loss : 33.956799 , test loss : 35.448524\n",
      "epoch = 640 train_loss : 33.932232 , test loss : 35.446060\n",
      "epoch = 641 train_loss : 33.921379 , test loss : 35.432838\n",
      "epoch = 644 train_loss : 33.907955 , test loss : 35.423214\n",
      "epoch = 652 train_loss : 33.941967 , test loss : 35.401001\n",
      "epoch = 656 train_loss : 33.844803 , test loss : 35.371517\n",
      "epoch = 659 train_loss : 33.893051 , test loss : 35.370079\n",
      "epoch = 660 train_loss : 33.879295 , test loss : 35.331566\n",
      "epoch = 663 train_loss : 33.804321 , test loss : 35.327755\n",
      "epoch = 664 train_loss : 33.818714 , test loss : 35.312717\n",
      "epoch = 668 train_loss : 33.822483 , test loss : 35.289726\n",
      "epoch = 671 train_loss : 33.745033 , test loss : 35.283268\n",
      "epoch = 673 train_loss : 33.781628 , test loss : 35.261826\n",
      "epoch = 678 train_loss : 33.762939 , test loss : 35.258972\n",
      "epoch = 679 train_loss : 33.775822 , test loss : 35.243351\n",
      "epoch = 688 train_loss : 33.648190 , test loss : 35.242039\n",
      "epoch = 692 train_loss : 33.740509 , test loss : 35.222160\n",
      "epoch = 694 train_loss : 33.621357 , test loss : 35.172989\n",
      "epoch = 705 train_loss : 33.563320 , test loss : 35.152176\n",
      "epoch = 706 train_loss : 33.558304 , test loss : 35.132027\n",
      "epoch = 710 train_loss : 33.539471 , test loss : 35.120728\n",
      "epoch = 711 train_loss : 33.596382 , test loss : 35.075775\n",
      "epoch = 717 train_loss : 33.526352 , test loss : 35.030071\n",
      "epoch = 732 train_loss : 33.471813 , test loss : 35.004292\n",
      "epoch = 741 train_loss : 33.440830 , test loss : 34.981312\n",
      "epoch = 747 train_loss : 33.434608 , test loss : 34.953392\n",
      "epoch = 754 train_loss : 33.375259 , test loss : 34.904869\n",
      "epoch = 767 train_loss : 33.319729 , test loss : 34.884991\n",
      "epoch = 772 train_loss : 33.378704 , test loss : 34.880013\n",
      "epoch = 774 train_loss : 33.303726 , test loss : 34.873108\n",
      "epoch = 784 train_loss : 33.254707 , test loss : 34.870850\n",
      "epoch = 788 train_loss : 33.304253 , test loss : 34.847809\n",
      "epoch = 792 train_loss : 33.258915 , test loss : 34.821053\n",
      "epoch = 806 train_loss : 33.232224 , test loss : 34.785816\n",
      "epoch = 807 train_loss : 33.223549 , test loss : 34.782139\n",
      "epoch = 810 train_loss : 33.196468 , test loss : 34.765396\n",
      "epoch = 815 train_loss : 33.174984 , test loss : 34.758438\n",
      "epoch = 827 train_loss : 33.127308 , test loss : 34.755669\n",
      "epoch = 829 train_loss : 33.161728 , test loss : 34.742710\n",
      "epoch = 837 train_loss : 33.223667 , test loss : 34.705601\n",
      "epoch = 846 train_loss : 33.144241 , test loss : 34.698429\n",
      "epoch = 848 train_loss : 33.192101 , test loss : 34.679199\n",
      "epoch = 857 train_loss : 33.080147 , test loss : 34.650646\n",
      "epoch = 862 train_loss : 33.046341 , test loss : 34.647610\n",
      "epoch = 865 train_loss : 33.058487 , test loss : 34.626980\n",
      "epoch = 866 train_loss : 33.083122 , test loss : 34.624718\n",
      "epoch = 872 train_loss : 33.057201 , test loss : 34.607605\n",
      "epoch = 876 train_loss : 33.031799 , test loss : 34.605572\n",
      "epoch = 884 train_loss : 33.058506 , test loss : 34.591099\n",
      "epoch = 888 train_loss : 33.000889 , test loss : 34.586075\n",
      "epoch = 895 train_loss : 32.984001 , test loss : 34.553101\n",
      "epoch = 928 train_loss : 32.943993 , test loss : 34.539803\n",
      "epoch = 934 train_loss : 32.969910 , test loss : 34.515812\n",
      "epoch = 936 train_loss : 32.904739 , test loss : 34.513836\n",
      "epoch = 941 train_loss : 33.015869 , test loss : 34.512623\n",
      "epoch = 948 train_loss : 32.897236 , test loss : 34.512169\n",
      "epoch = 953 train_loss : 32.872826 , test loss : 34.503826\n",
      "epoch = 963 train_loss : 32.864731 , test loss : 34.441006\n",
      "epoch = 1000 train_loss : 32.879692 , test loss : 34.439110\n",
      "epoch = 1014 train_loss : 32.779785 , test loss : 34.416550\n",
      "epoch = 1018 train_loss : 32.783707 , test loss : 34.411022\n",
      "epoch = 1021 train_loss : 32.775555 , test loss : 34.405632\n",
      "epoch = 1022 train_loss : 32.805119 , test loss : 34.397655\n",
      "epoch = 1023 train_loss : 32.820728 , test loss : 34.370804\n",
      "epoch = 1032 train_loss : 32.846226 , test loss : 34.368439\n",
      "epoch = 1062 train_loss : 32.737423 , test loss : 34.359127\n",
      "epoch = 1071 train_loss : 32.823498 , test loss : 34.332386\n",
      "epoch = 1080 train_loss : 32.709679 , test loss : 34.331718\n",
      "epoch = 1093 train_loss : 32.698994 , test loss : 34.303524\n",
      "epoch = 1095 train_loss : 32.724407 , test loss : 34.300282\n",
      "epoch = 1108 train_loss : 32.726955 , test loss : 34.294861\n",
      "epoch = 1126 train_loss : 32.669964 , test loss : 34.286495\n",
      "epoch = 1127 train_loss : 32.679199 , test loss : 34.275532\n",
      "epoch = 1135 train_loss : 32.687111 , test loss : 34.274681\n",
      "epoch = 1147 train_loss : 32.654747 , test loss : 34.271297\n",
      "epoch = 1174 train_loss : 32.695805 , test loss : 34.267532\n",
      "epoch = 1206 train_loss : 32.625214 , test loss : 34.247169\n",
      "epoch = 1233 train_loss : 32.672272 , test loss : 34.245380\n",
      "epoch = 1241 train_loss : 32.610458 , test loss : 34.226753\n",
      "epoch = 1245 train_loss : 32.611801 , test loss : 34.199722\n",
      "epoch = 1257 train_loss : 32.639496 , test loss : 34.192417\n",
      "epoch = 1306 train_loss : 32.598499 , test loss : 34.184280\n",
      "epoch = 1340 train_loss : 32.563969 , test loss : 34.182335\n",
      "epoch = 1359 train_loss : 32.567284 , test loss : 34.176250\n",
      "epoch = 1430 train_loss : 32.549416 , test loss : 34.170246\n",
      "epoch = 1446 train_loss : 32.542023 , test loss : 34.148136\n",
      "epoch = 1550 train_loss : 32.527615 , test loss : 34.143673\n",
      "epoch = 1556 train_loss : 32.511589 , test loss : 34.130951\n",
      "epoch = 1604 train_loss : 32.510899 , test loss : 34.116550\n",
      "epoch = 1654 train_loss : 32.474808 , test loss : 34.107426\n",
      "epoch = 1955 train_loss : 32.454372 , test loss : 34.105221\n",
      "epoch = 1960 train_loss : 32.502110 , test loss : 34.073753\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.502110,test loss : 34.073753\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 572.781189 , test loss : 575.513367\n",
      "epoch = 2 train_loss : 454.580688 , test loss : 467.618103\n",
      "epoch = 3 train_loss : 437.184692 , test loss : 451.156921\n",
      "epoch = 4 train_loss : 415.837372 , test loss : 426.793152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5 train_loss : 396.441620 , test loss : 404.982910\n",
      "epoch = 6 train_loss : 376.913208 , test loss : 383.944366\n",
      "epoch = 7 train_loss : 358.417664 , test loss : 363.824524\n",
      "epoch = 8 train_loss : 340.220520 , test loss : 344.203705\n",
      "epoch = 9 train_loss : 323.078064 , test loss : 325.789948\n",
      "epoch = 10 train_loss : 306.856445 , test loss : 308.005585\n",
      "epoch = 11 train_loss : 291.486450 , test loss : 291.461334\n",
      "epoch = 12 train_loss : 276.987213 , test loss : 275.986847\n",
      "epoch = 13 train_loss : 263.574585 , test loss : 261.539612\n",
      "epoch = 14 train_loss : 251.216446 , test loss : 248.182434\n",
      "epoch = 15 train_loss : 239.573395 , test loss : 235.837234\n",
      "epoch = 16 train_loss : 228.946091 , test loss : 224.446442\n",
      "epoch = 17 train_loss : 218.886887 , test loss : 213.751282\n",
      "epoch = 18 train_loss : 209.740936 , test loss : 204.051254\n",
      "epoch = 19 train_loss : 201.189774 , test loss : 194.963959\n",
      "epoch = 20 train_loss : 193.402969 , test loss : 186.712082\n",
      "epoch = 21 train_loss : 186.186508 , test loss : 179.099182\n",
      "epoch = 22 train_loss : 179.602783 , test loss : 172.169693\n",
      "epoch = 23 train_loss : 173.509903 , test loss : 165.808334\n",
      "epoch = 24 train_loss : 167.896774 , test loss : 159.937057\n",
      "epoch = 25 train_loss : 162.717865 , test loss : 154.523041\n",
      "epoch = 26 train_loss : 157.945999 , test loss : 149.563538\n",
      "epoch = 27 train_loss : 153.751160 , test loss : 145.315872\n",
      "epoch = 28 train_loss : 149.560318 , test loss : 140.950089\n",
      "epoch = 29 train_loss : 145.841187 , test loss : 137.132919\n",
      "epoch = 30 train_loss : 142.316528 , test loss : 133.482971\n",
      "epoch = 31 train_loss : 139.062256 , test loss : 130.248581\n",
      "epoch = 32 train_loss : 136.018616 , test loss : 127.146431\n",
      "epoch = 33 train_loss : 133.206573 , test loss : 124.302467\n",
      "epoch = 34 train_loss : 130.565262 , test loss : 121.666260\n",
      "epoch = 35 train_loss : 128.018295 , test loss : 119.138443\n",
      "epoch = 36 train_loss : 125.665337 , test loss : 116.761803\n",
      "epoch = 37 train_loss : 123.458771 , test loss : 114.606842\n",
      "epoch = 38 train_loss : 121.338234 , test loss : 112.479721\n",
      "epoch = 39 train_loss : 119.362808 , test loss : 110.589058\n",
      "epoch = 40 train_loss : 117.458740 , test loss : 108.720322\n",
      "epoch = 41 train_loss : 115.645813 , test loss : 106.919388\n",
      "epoch = 42 train_loss : 113.910973 , test loss : 105.272171\n",
      "epoch = 43 train_loss : 112.236977 , test loss : 103.643532\n",
      "epoch = 44 train_loss : 110.637138 , test loss : 102.139252\n",
      "epoch = 45 train_loss : 109.080269 , test loss : 100.600395\n",
      "epoch = 46 train_loss : 107.621735 , test loss : 99.160469\n",
      "epoch = 47 train_loss : 106.200455 , test loss : 97.866852\n",
      "epoch = 48 train_loss : 104.820869 , test loss : 96.551697\n",
      "epoch = 49 train_loss : 103.493835 , test loss : 95.219437\n",
      "epoch = 50 train_loss : 102.213165 , test loss : 93.968826\n",
      "epoch = 51 train_loss : 100.977608 , test loss : 92.850639\n",
      "epoch = 52 train_loss : 99.791222 , test loss : 91.763779\n",
      "epoch = 53 train_loss : 98.661171 , test loss : 90.598846\n",
      "epoch = 54 train_loss : 97.537682 , test loss : 89.552544\n",
      "epoch = 55 train_loss : 96.479813 , test loss : 88.663368\n",
      "epoch = 56 train_loss : 95.612846 , test loss : 87.574532\n",
      "epoch = 57 train_loss : 94.450073 , test loss : 86.778732\n",
      "epoch = 58 train_loss : 93.438797 , test loss : 85.697044\n",
      "epoch = 59 train_loss : 92.502052 , test loss : 84.788857\n",
      "epoch = 60 train_loss : 91.551682 , test loss : 84.028946\n",
      "epoch = 61 train_loss : 90.662476 , test loss : 83.117661\n",
      "epoch = 62 train_loss : 89.822472 , test loss : 82.370300\n",
      "epoch = 63 train_loss : 88.957565 , test loss : 81.565720\n",
      "epoch = 64 train_loss : 88.350082 , test loss : 80.825294\n",
      "epoch = 65 train_loss : 87.663528 , test loss : 80.600426\n",
      "epoch = 66 train_loss : 86.629257 , test loss : 79.396156\n",
      "epoch = 67 train_loss : 85.902496 , test loss : 78.668701\n",
      "epoch = 68 train_loss : 85.241219 , test loss : 78.229668\n",
      "epoch = 69 train_loss : 84.510994 , test loss : 77.388542\n",
      "epoch = 70 train_loss : 83.828491 , test loss : 76.898743\n",
      "epoch = 71 train_loss : 83.162056 , test loss : 76.239021\n",
      "epoch = 72 train_loss : 82.528130 , test loss : 75.642479\n",
      "epoch = 73 train_loss : 81.946106 , test loss : 75.043358\n",
      "epoch = 74 train_loss : 81.376045 , test loss : 74.686447\n",
      "epoch = 75 train_loss : 80.814598 , test loss : 73.988853\n",
      "epoch = 76 train_loss : 80.317253 , test loss : 73.508682\n",
      "epoch = 77 train_loss : 79.650513 , test loss : 73.039978\n",
      "epoch = 78 train_loss : 79.121315 , test loss : 72.507118\n",
      "epoch = 79 train_loss : 78.622643 , test loss : 72.136574\n",
      "epoch = 80 train_loss : 78.098457 , test loss : 71.590492\n",
      "epoch = 81 train_loss : 77.632759 , test loss : 71.141090\n",
      "epoch = 83 train_loss : 76.755630 , test loss : 70.316788\n",
      "epoch = 84 train_loss : 76.220528 , test loss : 69.920029\n",
      "epoch = 85 train_loss : 75.792580 , test loss : 69.543800\n",
      "epoch = 86 train_loss : 75.510994 , test loss : 69.169212\n",
      "epoch = 87 train_loss : 75.115005 , test loss : 69.028976\n",
      "epoch = 88 train_loss : 74.936539 , test loss : 68.627533\n",
      "epoch = 89 train_loss : 74.219376 , test loss : 68.174072\n",
      "epoch = 90 train_loss : 73.750648 , test loss : 67.675903\n",
      "epoch = 91 train_loss : 73.407303 , test loss : 67.326973\n",
      "epoch = 92 train_loss : 73.126862 , test loss : 67.192528\n",
      "epoch = 93 train_loss : 72.817703 , test loss : 66.749870\n",
      "epoch = 94 train_loss : 72.347977 , test loss : 66.434280\n",
      "epoch = 95 train_loss : 72.088188 , test loss : 66.227730\n",
      "epoch = 96 train_loss : 71.637428 , test loss : 65.708344\n",
      "epoch = 97 train_loss : 71.384941 , test loss : 65.448021\n",
      "epoch = 98 train_loss : 71.077454 , test loss : 65.303673\n",
      "epoch = 99 train_loss : 70.664444 , test loss : 64.888771\n",
      "epoch = 100 train_loss : 70.356972 , test loss : 64.543770\n",
      "epoch = 101 train_loss : 70.193329 , test loss : 64.364311\n",
      "epoch = 102 train_loss : 69.780342 , test loss : 64.092972\n",
      "epoch = 104 train_loss : 69.143425 , test loss : 63.423199\n",
      "epoch = 105 train_loss : 68.851967 , test loss : 63.201580\n",
      "epoch = 106 train_loss : 68.749878 , test loss : 63.161293\n",
      "epoch = 107 train_loss : 68.257942 , test loss : 62.641697\n",
      "epoch = 108 train_loss : 68.027328 , test loss : 62.392792\n",
      "epoch = 109 train_loss : 67.886620 , test loss : 62.351906\n",
      "epoch = 110 train_loss : 67.449265 , test loss : 61.855568\n",
      "epoch = 111 train_loss : 67.250778 , test loss : 61.659298\n",
      "epoch = 112 train_loss : 66.910583 , test loss : 61.383076\n",
      "epoch = 113 train_loss : 66.651810 , test loss : 61.142662\n",
      "epoch = 114 train_loss : 66.412552 , test loss : 60.904575\n",
      "epoch = 115 train_loss : 66.180634 , test loss : 60.662750\n",
      "epoch = 116 train_loss : 65.946770 , test loss : 60.514954\n",
      "epoch = 117 train_loss : 65.681770 , test loss : 60.251709\n",
      "epoch = 118 train_loss : 65.401253 , test loss : 59.970695\n",
      "epoch = 119 train_loss : 65.156242 , test loss : 59.737957\n",
      "epoch = 121 train_loss : 64.764465 , test loss : 59.330593\n",
      "epoch = 122 train_loss : 64.511703 , test loss : 59.093311\n",
      "epoch = 123 train_loss : 64.231392 , test loss : 58.854507\n",
      "epoch = 125 train_loss : 63.787746 , test loss : 58.421841\n",
      "epoch = 126 train_loss : 63.591873 , test loss : 58.285259\n",
      "epoch = 127 train_loss : 63.302635 , test loss : 57.972019\n",
      "epoch = 128 train_loss : 63.080494 , test loss : 57.774799\n",
      "epoch = 129 train_loss : 62.880318 , test loss : 57.596306\n",
      "epoch = 130 train_loss : 62.680943 , test loss : 57.399673\n",
      "epoch = 131 train_loss : 62.445908 , test loss : 57.166950\n",
      "epoch = 132 train_loss : 62.279663 , test loss : 57.000832\n",
      "epoch = 133 train_loss : 62.074528 , test loss : 56.800255\n",
      "epoch = 135 train_loss : 61.619667 , test loss : 56.426537\n",
      "epoch = 136 train_loss : 61.387058 , test loss : 56.197865\n",
      "epoch = 137 train_loss : 61.143826 , test loss : 55.943993\n",
      "epoch = 139 train_loss : 60.883045 , test loss : 55.723778\n",
      "epoch = 140 train_loss : 60.523853 , test loss : 55.333267\n",
      "epoch = 141 train_loss : 60.508682 , test loss : 55.306171\n",
      "epoch = 142 train_loss : 60.117962 , test loss : 54.983505\n",
      "epoch = 143 train_loss : 59.940781 , test loss : 54.819454\n",
      "epoch = 144 train_loss : 59.839218 , test loss : 54.724216\n",
      "epoch = 145 train_loss : 59.558502 , test loss : 54.445518\n",
      "epoch = 146 train_loss : 59.361343 , test loss : 54.264130\n",
      "epoch = 147 train_loss : 59.139896 , test loss : 54.022961\n",
      "epoch = 148 train_loss : 58.945705 , test loss : 53.842262\n",
      "epoch = 150 train_loss : 58.633541 , test loss : 53.505142\n",
      "epoch = 152 train_loss : 58.211330 , test loss : 53.137821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 154 train_loss : 57.896088 , test loss : 52.823601\n",
      "epoch = 155 train_loss : 57.765366 , test loss : 52.701195\n",
      "epoch = 156 train_loss : 57.627930 , test loss : 52.567177\n",
      "epoch = 157 train_loss : 57.258923 , test loss : 52.236595\n",
      "epoch = 158 train_loss : 57.063034 , test loss : 52.029739\n",
      "epoch = 160 train_loss : 56.713505 , test loss : 51.714340\n",
      "epoch = 161 train_loss : 56.550419 , test loss : 51.585358\n",
      "epoch = 162 train_loss : 56.344017 , test loss : 51.347023\n",
      "epoch = 163 train_loss : 56.203003 , test loss : 51.241497\n",
      "epoch = 164 train_loss : 55.990208 , test loss : 51.014557\n",
      "epoch = 165 train_loss : 55.882462 , test loss : 50.916065\n",
      "epoch = 166 train_loss : 55.645386 , test loss : 50.672001\n",
      "epoch = 167 train_loss : 55.465515 , test loss : 50.508686\n",
      "epoch = 169 train_loss : 55.153076 , test loss : 50.194958\n",
      "epoch = 170 train_loss : 54.980690 , test loss : 50.051109\n",
      "epoch = 171 train_loss : 54.810341 , test loss : 49.901672\n",
      "epoch = 172 train_loss : 54.632904 , test loss : 49.686962\n",
      "epoch = 175 train_loss : 54.143402 , test loss : 49.234211\n",
      "epoch = 176 train_loss : 53.950203 , test loss : 49.061249\n",
      "epoch = 177 train_loss : 53.795815 , test loss : 48.911964\n",
      "epoch = 178 train_loss : 53.655434 , test loss : 48.781338\n",
      "epoch = 179 train_loss : 53.608959 , test loss : 48.717506\n",
      "epoch = 180 train_loss : 53.310104 , test loss : 48.463741\n",
      "epoch = 181 train_loss : 53.232704 , test loss : 48.341202\n",
      "epoch = 182 train_loss : 52.993687 , test loss : 48.134705\n",
      "epoch = 183 train_loss : 52.848690 , test loss : 48.010952\n",
      "epoch = 185 train_loss : 52.535995 , test loss : 47.731396\n",
      "epoch = 186 train_loss : 52.433575 , test loss : 47.600327\n",
      "epoch = 187 train_loss : 52.233955 , test loss : 47.406391\n",
      "epoch = 188 train_loss : 52.100719 , test loss : 47.317848\n",
      "epoch = 189 train_loss : 51.982437 , test loss : 47.212074\n",
      "epoch = 190 train_loss : 51.796654 , test loss : 47.055214\n",
      "epoch = 191 train_loss : 51.723900 , test loss : 46.947498\n",
      "epoch = 192 train_loss : 51.656399 , test loss : 46.917183\n",
      "epoch = 193 train_loss : 51.361691 , test loss : 46.615612\n",
      "epoch = 194 train_loss : 51.193127 , test loss : 46.436237\n",
      "epoch = 196 train_loss : 51.052116 , test loss : 46.241989\n",
      "epoch = 197 train_loss : 50.770470 , test loss : 46.024647\n",
      "epoch = 199 train_loss : 50.495235 , test loss : 45.754467\n",
      "epoch = 201 train_loss : 50.347435 , test loss : 45.570477\n",
      "epoch = 202 train_loss : 50.081947 , test loss : 45.372295\n",
      "epoch = 203 train_loss : 50.058624 , test loss : 45.371487\n",
      "epoch = 206 train_loss : 49.919903 , test loss : 45.293499\n",
      "epoch = 207 train_loss : 49.422688 , test loss : 44.699707\n",
      "epoch = 210 train_loss : 49.040733 , test loss : 44.343742\n",
      "epoch = 211 train_loss : 48.953510 , test loss : 44.242321\n",
      "epoch = 212 train_loss : 48.899506 , test loss : 44.170189\n",
      "epoch = 213 train_loss : 48.765488 , test loss : 44.055077\n",
      "epoch = 214 train_loss : 48.593628 , test loss : 43.949406\n",
      "epoch = 215 train_loss : 48.499775 , test loss : 43.854137\n",
      "epoch = 217 train_loss : 48.346687 , test loss : 43.728012\n",
      "epoch = 218 train_loss : 48.360664 , test loss : 43.602066\n",
      "epoch = 219 train_loss : 48.257759 , test loss : 43.521061\n",
      "epoch = 220 train_loss : 47.916897 , test loss : 43.257839\n",
      "epoch = 221 train_loss : 47.722267 , test loss : 43.118732\n",
      "epoch = 222 train_loss : 47.614727 , test loss : 42.980679\n",
      "epoch = 224 train_loss : 47.379143 , test loss : 42.717224\n",
      "epoch = 227 train_loss : 47.065720 , test loss : 42.436954\n",
      "epoch = 228 train_loss : 46.939827 , test loss : 42.328476\n",
      "epoch = 231 train_loss : 46.621147 , test loss : 42.041737\n",
      "epoch = 232 train_loss : 46.621258 , test loss : 41.981846\n",
      "epoch = 233 train_loss : 46.593201 , test loss : 41.941628\n",
      "epoch = 234 train_loss : 46.310909 , test loss : 41.708397\n",
      "epoch = 235 train_loss : 46.299259 , test loss : 41.665752\n",
      "epoch = 236 train_loss : 46.120293 , test loss : 41.531994\n",
      "epoch = 237 train_loss : 46.016407 , test loss : 41.440056\n",
      "epoch = 239 train_loss : 45.889957 , test loss : 41.247063\n",
      "epoch = 241 train_loss : 45.642136 , test loss : 41.012001\n",
      "epoch = 243 train_loss : 45.631893 , test loss : 40.993835\n",
      "epoch = 244 train_loss : 45.547714 , test loss : 40.885227\n",
      "epoch = 245 train_loss : 45.324741 , test loss : 40.687443\n",
      "epoch = 246 train_loss : 45.169033 , test loss : 40.648766\n",
      "epoch = 247 train_loss : 45.118721 , test loss : 40.619343\n",
      "epoch = 249 train_loss : 44.969898 , test loss : 40.467159\n",
      "epoch = 250 train_loss : 44.914845 , test loss : 40.304462\n",
      "epoch = 252 train_loss : 44.627613 , test loss : 40.120441\n",
      "epoch = 253 train_loss : 44.585003 , test loss : 39.994686\n",
      "epoch = 254 train_loss : 44.446327 , test loss : 39.918850\n",
      "epoch = 255 train_loss : 44.368866 , test loss : 39.838657\n",
      "epoch = 256 train_loss : 44.320450 , test loss : 39.738789\n",
      "epoch = 257 train_loss : 44.242359 , test loss : 39.667496\n",
      "epoch = 258 train_loss : 44.113644 , test loss : 39.553051\n",
      "epoch = 261 train_loss : 43.865955 , test loss : 39.358711\n",
      "epoch = 263 train_loss : 43.705280 , test loss : 39.185406\n",
      "epoch = 266 train_loss : 43.785210 , test loss : 39.183395\n",
      "epoch = 267 train_loss : 43.449738 , test loss : 38.989208\n",
      "epoch = 268 train_loss : 43.344856 , test loss : 38.826618\n",
      "epoch = 269 train_loss : 43.323437 , test loss : 38.774719\n",
      "epoch = 273 train_loss : 43.016571 , test loss : 38.566994\n",
      "epoch = 274 train_loss : 43.011112 , test loss : 38.453072\n",
      "epoch = 275 train_loss : 42.867176 , test loss : 38.430580\n",
      "epoch = 277 train_loss : 42.710213 , test loss : 38.191586\n",
      "epoch = 280 train_loss : 42.529293 , test loss : 37.978989\n",
      "epoch = 283 train_loss : 42.332214 , test loss : 37.796463\n",
      "epoch = 284 train_loss : 42.322163 , test loss : 37.724461\n",
      "epoch = 286 train_loss : 42.124447 , test loss : 37.619740\n",
      "epoch = 289 train_loss : 41.977573 , test loss : 37.585842\n",
      "epoch = 290 train_loss : 41.897453 , test loss : 37.510067\n",
      "epoch = 291 train_loss : 41.984711 , test loss : 37.412697\n",
      "epoch = 292 train_loss : 41.749409 , test loss : 37.276096\n",
      "epoch = 293 train_loss : 41.680710 , test loss : 37.206078\n",
      "epoch = 295 train_loss : 41.594685 , test loss : 37.085434\n",
      "epoch = 298 train_loss : 41.394825 , test loss : 36.965038\n",
      "epoch = 299 train_loss : 41.425194 , test loss : 36.889080\n",
      "epoch = 301 train_loss : 41.238941 , test loss : 36.858822\n",
      "epoch = 302 train_loss : 41.204033 , test loss : 36.800541\n",
      "epoch = 303 train_loss : 41.151554 , test loss : 36.763885\n",
      "epoch = 306 train_loss : 40.953278 , test loss : 36.505043\n",
      "epoch = 309 train_loss : 40.801716 , test loss : 36.396374\n",
      "epoch = 310 train_loss : 40.919727 , test loss : 36.375919\n",
      "epoch = 311 train_loss : 40.707615 , test loss : 36.288536\n",
      "epoch = 313 train_loss : 40.608944 , test loss : 36.230152\n",
      "epoch = 315 train_loss : 40.661526 , test loss : 36.133297\n",
      "epoch = 316 train_loss : 40.469387 , test loss : 36.074581\n",
      "epoch = 318 train_loss : 40.475506 , test loss : 35.972557\n",
      "epoch = 321 train_loss : 40.267906 , test loss : 35.928040\n",
      "epoch = 322 train_loss : 40.351051 , test loss : 35.830475\n",
      "epoch = 323 train_loss : 40.152119 , test loss : 35.758610\n",
      "epoch = 326 train_loss : 40.084160 , test loss : 35.658325\n",
      "epoch = 327 train_loss : 40.013611 , test loss : 35.581497\n",
      "epoch = 329 train_loss : 39.883659 , test loss : 35.508091\n",
      "epoch = 330 train_loss : 39.846504 , test loss : 35.447170\n",
      "epoch = 333 train_loss : 39.723515 , test loss : 35.344654\n",
      "epoch = 336 train_loss : 39.602688 , test loss : 35.244553\n",
      "epoch = 338 train_loss : 39.756519 , test loss : 35.229050\n",
      "epoch = 339 train_loss : 39.483112 , test loss : 35.116703\n",
      "epoch = 340 train_loss : 39.507885 , test loss : 35.102001\n",
      "epoch = 341 train_loss : 39.413471 , test loss : 35.024967\n",
      "epoch = 343 train_loss : 39.356731 , test loss : 34.958393\n",
      "epoch = 345 train_loss : 39.258495 , test loss : 34.931190\n",
      "epoch = 347 train_loss : 39.184551 , test loss : 34.831158\n",
      "epoch = 348 train_loss : 39.159195 , test loss : 34.803802\n",
      "epoch = 350 train_loss : 39.085602 , test loss : 34.775448\n",
      "epoch = 351 train_loss : 39.060444 , test loss : 34.739761\n",
      "epoch = 352 train_loss : 39.019966 , test loss : 34.670517\n",
      "epoch = 353 train_loss : 38.980030 , test loss : 34.627457\n",
      "epoch = 355 train_loss : 38.927181 , test loss : 34.576309\n",
      "epoch = 356 train_loss : 39.048851 , test loss : 34.554989\n",
      "epoch = 357 train_loss : 38.872734 , test loss : 34.493538\n",
      "epoch = 358 train_loss : 38.808270 , test loss : 34.475147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 360 train_loss : 38.758865 , test loss : 34.370003\n",
      "epoch = 362 train_loss : 38.718620 , test loss : 34.329189\n",
      "epoch = 367 train_loss : 38.554642 , test loss : 34.290344\n",
      "epoch = 368 train_loss : 38.502808 , test loss : 34.209679\n",
      "epoch = 369 train_loss : 38.466888 , test loss : 34.142532\n",
      "epoch = 370 train_loss : 38.544647 , test loss : 34.124893\n",
      "epoch = 374 train_loss : 38.326870 , test loss : 34.001205\n",
      "epoch = 377 train_loss : 38.343723 , test loss : 33.930786\n",
      "epoch = 378 train_loss : 38.280632 , test loss : 33.901962\n",
      "epoch = 381 train_loss : 38.141670 , test loss : 33.873417\n",
      "epoch = 382 train_loss : 38.161694 , test loss : 33.793835\n",
      "epoch = 383 train_loss : 38.176174 , test loss : 33.756092\n",
      "epoch = 387 train_loss : 38.038662 , test loss : 33.658596\n",
      "epoch = 389 train_loss : 37.925968 , test loss : 33.607292\n",
      "epoch = 392 train_loss : 37.840664 , test loss : 33.583981\n",
      "epoch = 393 train_loss : 37.848736 , test loss : 33.490124\n",
      "epoch = 395 train_loss : 37.777935 , test loss : 33.467365\n",
      "epoch = 399 train_loss : 37.677273 , test loss : 33.395119\n",
      "epoch = 400 train_loss : 37.680733 , test loss : 33.351864\n",
      "epoch = 404 train_loss : 37.561741 , test loss : 33.301407\n",
      "epoch = 408 train_loss : 37.489803 , test loss : 33.184677\n",
      "epoch = 410 train_loss : 37.446003 , test loss : 33.168022\n",
      "epoch = 411 train_loss : 37.413975 , test loss : 33.140953\n",
      "epoch = 414 train_loss : 37.359974 , test loss : 33.082096\n",
      "epoch = 415 train_loss : 37.385551 , test loss : 33.037426\n",
      "epoch = 418 train_loss : 37.272259 , test loss : 33.007206\n",
      "epoch = 419 train_loss : 37.250629 , test loss : 33.001106\n",
      "epoch = 420 train_loss : 37.241852 , test loss : 32.941105\n",
      "epoch = 422 train_loss : 37.196030 , test loss : 32.923641\n",
      "epoch = 425 train_loss : 37.140530 , test loss : 32.907433\n",
      "epoch = 427 train_loss : 37.129528 , test loss : 32.838493\n",
      "epoch = 430 train_loss : 37.147469 , test loss : 32.772434\n",
      "epoch = 435 train_loss : 36.961956 , test loss : 32.725704\n",
      "epoch = 436 train_loss : 36.947731 , test loss : 32.694916\n",
      "epoch = 439 train_loss : 36.988960 , test loss : 32.665878\n",
      "epoch = 440 train_loss : 36.878998 , test loss : 32.634716\n",
      "epoch = 444 train_loss : 36.868160 , test loss : 32.555218\n",
      "epoch = 445 train_loss : 36.807072 , test loss : 32.542034\n",
      "epoch = 446 train_loss : 36.807774 , test loss : 32.518322\n",
      "epoch = 448 train_loss : 36.747860 , test loss : 32.509014\n",
      "epoch = 450 train_loss : 36.717312 , test loss : 32.445210\n",
      "epoch = 451 train_loss : 36.725632 , test loss : 32.438053\n",
      "epoch = 455 train_loss : 36.670681 , test loss : 32.402821\n",
      "epoch = 456 train_loss : 36.729816 , test loss : 32.389191\n",
      "epoch = 458 train_loss : 36.591499 , test loss : 32.368046\n",
      "epoch = 461 train_loss : 36.559525 , test loss : 32.332924\n",
      "epoch = 465 train_loss : 36.558414 , test loss : 32.256813\n",
      "epoch = 468 train_loss : 36.450581 , test loss : 32.255630\n",
      "epoch = 470 train_loss : 36.427052 , test loss : 32.170818\n",
      "epoch = 477 train_loss : 36.337368 , test loss : 32.111595\n",
      "epoch = 481 train_loss : 36.349510 , test loss : 32.079037\n",
      "epoch = 485 train_loss : 36.299133 , test loss : 32.014614\n",
      "epoch = 491 train_loss : 36.173485 , test loss : 31.967810\n",
      "epoch = 492 train_loss : 36.197720 , test loss : 31.945858\n",
      "epoch = 494 train_loss : 36.131485 , test loss : 31.926527\n",
      "epoch = 497 train_loss : 36.101341 , test loss : 31.910347\n",
      "epoch = 500 train_loss : 36.072250 , test loss : 31.881678\n",
      "epoch = 504 train_loss : 36.017536 , test loss : 31.852760\n",
      "epoch = 506 train_loss : 36.001896 , test loss : 31.836092\n",
      "epoch = 512 train_loss : 35.937660 , test loss : 31.754126\n",
      "epoch = 515 train_loss : 35.938301 , test loss : 31.705532\n",
      "epoch = 522 train_loss : 35.912613 , test loss : 31.674568\n",
      "epoch = 523 train_loss : 35.842419 , test loss : 31.623512\n",
      "epoch = 527 train_loss : 35.861565 , test loss : 31.620955\n",
      "epoch = 529 train_loss : 35.769722 , test loss : 31.611040\n",
      "epoch = 533 train_loss : 35.780632 , test loss : 31.546814\n",
      "epoch = 538 train_loss : 35.706520 , test loss : 31.516537\n",
      "epoch = 547 train_loss : 35.608246 , test loss : 31.460697\n",
      "epoch = 550 train_loss : 35.605404 , test loss : 31.435875\n",
      "epoch = 552 train_loss : 35.648800 , test loss : 31.417582\n",
      "epoch = 553 train_loss : 35.631603 , test loss : 31.410254\n",
      "epoch = 558 train_loss : 35.545460 , test loss : 31.369423\n",
      "epoch = 561 train_loss : 35.514988 , test loss : 31.348854\n",
      "epoch = 568 train_loss : 35.478706 , test loss : 31.277245\n",
      "epoch = 576 train_loss : 35.389755 , test loss : 31.241674\n",
      "epoch = 584 train_loss : 35.369091 , test loss : 31.208372\n",
      "epoch = 585 train_loss : 35.357265 , test loss : 31.193874\n",
      "epoch = 588 train_loss : 35.298607 , test loss : 31.131916\n",
      "epoch = 594 train_loss : 35.282730 , test loss : 31.127979\n",
      "epoch = 595 train_loss : 35.246925 , test loss : 31.109852\n",
      "epoch = 600 train_loss : 35.274788 , test loss : 31.106476\n",
      "epoch = 603 train_loss : 35.194595 , test loss : 31.064751\n",
      "epoch = 604 train_loss : 35.188095 , test loss : 31.062975\n",
      "epoch = 606 train_loss : 35.185223 , test loss : 31.020164\n",
      "epoch = 615 train_loss : 35.177502 , test loss : 31.000607\n",
      "epoch = 620 train_loss : 35.106110 , test loss : 30.968983\n",
      "epoch = 627 train_loss : 35.105934 , test loss : 30.949186\n",
      "epoch = 629 train_loss : 35.046707 , test loss : 30.926647\n",
      "epoch = 636 train_loss : 34.995163 , test loss : 30.895365\n",
      "epoch = 652 train_loss : 34.912663 , test loss : 30.887245\n",
      "epoch = 656 train_loss : 35.090481 , test loss : 30.865898\n",
      "epoch = 657 train_loss : 34.889568 , test loss : 30.798544\n",
      "epoch = 673 train_loss : 34.909389 , test loss : 30.745855\n",
      "epoch = 685 train_loss : 34.766308 , test loss : 30.634241\n",
      "epoch = 700 train_loss : 34.692501 , test loss : 30.613352\n",
      "epoch = 707 train_loss : 34.668030 , test loss : 30.611403\n",
      "epoch = 710 train_loss : 34.662537 , test loss : 30.611141\n",
      "epoch = 711 train_loss : 34.642872 , test loss : 30.598288\n",
      "epoch = 716 train_loss : 34.623226 , test loss : 30.580807\n",
      "epoch = 722 train_loss : 34.678944 , test loss : 30.553774\n",
      "epoch = 728 train_loss : 34.583782 , test loss : 30.538799\n",
      "epoch = 730 train_loss : 34.591190 , test loss : 30.532368\n",
      "epoch = 735 train_loss : 34.560181 , test loss : 30.513668\n",
      "epoch = 737 train_loss : 34.555325 , test loss : 30.494596\n",
      "epoch = 746 train_loss : 34.575859 , test loss : 30.461473\n",
      "epoch = 750 train_loss : 34.502728 , test loss : 30.460072\n",
      "epoch = 753 train_loss : 34.560173 , test loss : 30.457451\n",
      "epoch = 758 train_loss : 34.471985 , test loss : 30.423565\n",
      "epoch = 765 train_loss : 34.456879 , test loss : 30.404812\n",
      "epoch = 768 train_loss : 34.440609 , test loss : 30.387892\n",
      "epoch = 775 train_loss : 34.417831 , test loss : 30.384552\n",
      "epoch = 777 train_loss : 34.412708 , test loss : 30.381254\n",
      "epoch = 784 train_loss : 34.457047 , test loss : 30.341663\n",
      "epoch = 796 train_loss : 34.404564 , test loss : 30.338503\n",
      "epoch = 805 train_loss : 34.327076 , test loss : 30.300314\n",
      "epoch = 814 train_loss : 34.302727 , test loss : 30.289616\n",
      "epoch = 824 train_loss : 34.356014 , test loss : 30.272005\n",
      "epoch = 828 train_loss : 34.267612 , test loss : 30.239826\n",
      "epoch = 832 train_loss : 34.271069 , test loss : 30.213053\n",
      "epoch = 836 train_loss : 34.252541 , test loss : 30.187996\n",
      "epoch = 867 train_loss : 34.185490 , test loss : 30.152925\n",
      "epoch = 874 train_loss : 34.193802 , test loss : 30.144583\n",
      "epoch = 879 train_loss : 34.149059 , test loss : 30.142323\n",
      "epoch = 881 train_loss : 34.224232 , test loss : 30.132481\n",
      "epoch = 899 train_loss : 34.150387 , test loss : 30.103790\n",
      "epoch = 905 train_loss : 34.098915 , test loss : 30.099463\n",
      "epoch = 911 train_loss : 34.161274 , test loss : 30.093824\n",
      "epoch = 915 train_loss : 34.134750 , test loss : 30.048414\n",
      "epoch = 931 train_loss : 34.104206 , test loss : 30.026573\n",
      "epoch = 939 train_loss : 34.081356 , test loss : 30.022493\n",
      "epoch = 943 train_loss : 34.106152 , test loss : 30.020193\n",
      "epoch = 946 train_loss : 34.077198 , test loss : 30.002764\n",
      "epoch = 961 train_loss : 34.023052 , test loss : 29.953682\n",
      "epoch = 974 train_loss : 34.014820 , test loss : 29.951094\n",
      "epoch = 979 train_loss : 33.982315 , test loss : 29.949488\n",
      "epoch = 987 train_loss : 34.015862 , test loss : 29.937176\n",
      "epoch = 1011 train_loss : 33.960991 , test loss : 29.923380\n",
      "epoch = 1034 train_loss : 33.918274 , test loss : 29.907251\n",
      "epoch = 1037 train_loss : 33.911083 , test loss : 29.884193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1053 train_loss : 33.906631 , test loss : 29.837877\n",
      "epoch = 1105 train_loss : 33.858658 , test loss : 29.825220\n",
      "epoch = 1109 train_loss : 33.825672 , test loss : 29.814447\n",
      "epoch = 1114 train_loss : 33.879551 , test loss : 29.804144\n",
      "epoch = 1129 train_loss : 33.852291 , test loss : 29.797880\n",
      "epoch = 1138 train_loss : 33.803692 , test loss : 29.797783\n",
      "epoch = 1148 train_loss : 33.808681 , test loss : 29.787867\n",
      "epoch = 1160 train_loss : 33.797993 , test loss : 29.775429\n",
      "epoch = 1166 train_loss : 33.788143 , test loss : 29.753630\n",
      "epoch = 1207 train_loss : 33.749950 , test loss : 29.733604\n",
      "epoch = 1224 train_loss : 33.772785 , test loss : 29.706675\n",
      "epoch = 1256 train_loss : 33.734791 , test loss : 29.686760\n",
      "epoch = 1315 train_loss : 33.775188 , test loss : 29.678291\n",
      "epoch = 1354 train_loss : 33.750854 , test loss : 29.672173\n",
      "epoch = 1376 train_loss : 33.668762 , test loss : 29.658360\n",
      "epoch = 1390 train_loss : 33.677979 , test loss : 29.647678\n",
      "epoch = 1418 train_loss : 33.658054 , test loss : 29.618979\n",
      "epoch = 1522 train_loss : 33.623943 , test loss : 29.601501\n",
      "epoch = 1548 train_loss : 33.627659 , test loss : 29.596369\n",
      "epoch = 1613 train_loss : 33.603893 , test loss : 29.589954\n",
      "epoch = 1647 train_loss : 33.602272 , test loss : 29.582092\n",
      "epoch = 1714 train_loss : 33.596828 , test loss : 29.575005\n",
      "epoch = 1746 train_loss : 33.576355 , test loss : 29.568577\n",
      "epoch = 1934 train_loss : 33.581554 , test loss : 29.556837\n",
      "epoch = 1986 train_loss : 33.614727 , test loss : 29.554363\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.614727,test loss : 29.554363\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.530271,total test loss mean : 34.476348 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],8),nn.Linear(8,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,5000,0.0001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:11.065721Z",
     "start_time": "2021-12-30T05:45:11.053720Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "\n",
    "def rmlse_cv2(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x33)\n",
    "    rmse=np.sqrt(-cross_val_score(model,x33,y33,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:14.419913Z",
     "start_time": "2021-12-30T05:45:11.734759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 5.6020 (0.5464)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.005,random_state=1))\n",
    "score=rmlse_cv2(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use boxcox transformer to gaussian dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:45.379684Z",
     "start_time": "2021-12-30T05:45:45.371683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox,boxcox_normmax\n",
    "from scipy.special import boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:46.111725Z",
     "start_time": "2021-12-30T05:45:46.101725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:45:58.552437Z",
     "start_time": "2021-12-30T05:45:58.542436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:01.433310Z",
     "start_time": "2021-12-30T02:03:01.388307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --skew :  -0.2834134242907861 --kurt :  -0.7968009844193018\n",
      "1 --skew :  -5.095255676523535 --kurt :  85.70760213466164\n",
      "2 --skew :  9.165303973318487 --kurt :  132.25692190213024\n",
      "3 --skew :  2.172048918138678 --kurt :  8.458548044518952\n",
      "4 --skew :  5.378836580918865 --kurt :  41.25921290333162\n",
      "5 --skew :  1.6391191931961593 --kurt :  3.8457481859587697\n",
      "6 --skew :  2.071649558193799 --kurt :  6.419180514549189\n",
      "7 --skew :  1.3121217461933794 --kurt :  5.2975502420733696\n",
      "8 --skew :  1.103678593463204 --kurt :  1.7728459308764268\n",
      "9 --skew :  1.2763236528649795 --kurt :  2.115391100082106\n",
      "10 --skew :  21.7839204262489 --kurt :  623.8917732792679\n",
      "11 --skew :  -0.6050425772235472 --kurt :  -0.1979575284081454\n",
      "12 --skew :  2.1806637991938813 --kurt :  8.332926208370576\n",
      "13 --skew :  -0.7973228533500623 --kurt :  21.5544747714386\n",
      "14 --skew :  0.5569055078560654 --kurt :  -0.9777533530993172\n",
      "15 --skew :  0.5166061431100419 --kurt :  -1.0455161114586577\n",
      "16 --skew :  0.9251663396039612 --kurt :  1.023738040336486\n",
      "17 --skew :  1.0990996760341267 --kurt :  1.2102189438217152\n"
     ]
    }
   ],
   "source": [
    "for i in range(all_train_data1.shape[1]):\n",
    "    print(all_train_data1.index[i],'--skew : ',all_train_data1[i].skew(),'--kurt : ',all_train_data1[i].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:06.273742Z",
     "start_time": "2021-12-30T05:48:06.014727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --skew :  -0.2834134242907861 --kurt :  -0.7968009844193018\n",
      "lambda :  1.461645538288768\n",
      "0 --skew :  -0.07414275326700835 --kurt :  -0.9258821506244836\n",
      "--------------------------------------------------------------------\n",
      "1 --skew :  -5.095255676523535 --kurt :  85.70760213466164\n",
      "lambda :  5.990940784090655\n",
      "1 --skew :  0.2052435896115669 --kurt :  0.583625236412292\n",
      "--------------------------------------------------------------------\n",
      "2 --skew :  9.165303973318487 --kurt :  132.25692190213024\n",
      "lambda :  -3.259330902857795\n",
      "2 --skew :  -0.003907562716963148 --kurt :  -0.06972890461562153\n",
      "--------------------------------------------------------------------\n",
      "3 --skew :  2.172048918138678 --kurt :  8.458548044518952\n",
      "lambda :  -6.182620739009405\n",
      "3 --skew :  0.05859262861967747 --kurt :  -0.5568735662256521\n",
      "--------------------------------------------------------------------\n",
      "4 --skew :  5.378836580918865 --kurt :  41.25921290333162\n",
      "lambda :  -0.7826645126628972\n",
      "4 --skew :  -0.03484059806052529 --kurt :  0.5414188516389893\n",
      "--------------------------------------------------------------------\n",
      "5 --skew :  1.6391191931961593 --kurt :  3.8457481859587697\n",
      "lambda :  0.003516830957090046\n",
      "5 --skew :  0.013408365980071172 --kurt :  0.19498206467320722\n",
      "--------------------------------------------------------------------\n",
      "6 --skew :  2.071649558193799 --kurt :  6.419180514549189\n",
      "lambda :  -0.1942146862014387\n",
      "6 --skew :  -0.002404565434079636 --kurt :  0.0440333018723158\n",
      "--------------------------------------------------------------------\n",
      "7 --skew :  1.3121217461933794 --kurt :  5.2975502420733696\n",
      "lambda :  0.41482616104608666\n",
      "7 --skew :  0.006751929748339162 --kurt :  0.28627689522357613\n",
      "--------------------------------------------------------------------\n",
      "8 --skew :  1.103678593463204 --kurt :  1.7728459308764268\n",
      "lambda :  0.4477248234931694\n",
      "8 --skew :  0.02201672862987185 --kurt :  0.1603650294853538\n",
      "--------------------------------------------------------------------\n",
      "9 --skew :  1.2763236528649795 --kurt :  2.115391100082106\n",
      "lambda :  0.4145678510523434\n",
      "9 --skew :  0.03317866068741833 --kurt :  -0.18174471082602928\n",
      "--------------------------------------------------------------------\n",
      "10 --skew :  21.7839204262489 --kurt :  623.8917732792679\n",
      "lambda :  -6.186399577904084\n",
      "10 --skew :  3.759158275003242 --kurt :  12.400036693306454\n",
      "--------------------------------------------------------------------\n",
      "11 --skew :  -0.6050425772235472 --kurt :  -0.1979575284081454\n",
      "lambda :  2.4338353657960474\n",
      "11 --skew :  -0.07298225942919347 --kurt :  -0.8136949843530794\n",
      "--------------------------------------------------------------------\n",
      "12 --skew :  2.1806637991938813 --kurt :  8.332926208370576\n",
      "lambda :  -0.24358108144432533\n",
      "12 --skew :  0.021947686457242925 --kurt :  0.5477017915641502\n",
      "--------------------------------------------------------------------\n",
      "13 --skew :  -0.7973228533500623 --kurt :  21.5544747714386\n",
      "lambda :  2.0482410553537025\n",
      "13 --skew :  0.8584013280369255 --kurt :  8.48135294318179\n",
      "--------------------------------------------------------------------\n",
      "14 --skew :  0.5569055078560654 --kurt :  -0.9777533530993172\n",
      "lambda :  0.3417183305204095\n",
      "14 --skew :  -0.11116266544173034 --kurt :  -0.5747813166565554\n",
      "--------------------------------------------------------------------\n",
      "15 --skew :  0.5166061431100419 --kurt :  -1.0455161114586577\n",
      "lambda :  0.31039132586722773\n",
      "15 --skew :  -0.12154909027070926 --kurt :  -0.6493410942779887\n",
      "--------------------------------------------------------------------\n",
      "16 --skew :  0.9251663396039612 --kurt :  1.023738040336486\n",
      "lambda :  -0.14707046206981406\n",
      "16 --skew :  0.016664314785999827 --kurt :  -0.4468770575550054\n",
      "--------------------------------------------------------------------\n",
      "17 --skew :  1.0990996760341267 --kurt :  1.2102189438217152\n",
      "lambda :  -0.2521218322454977\n",
      "17 --skew :  0.012020490427854405 --kurt :  -0.5440498606314681\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_train_data2=pd.DataFrame()\n",
    "for i in range(all_train_data1.shape[1]):\n",
    "    lm=boxcox_normmax(all_train_data1[i]+1)\n",
    "    all_train_data2[i]=boxcox1p(all_train_data1[i],lm)\n",
    "    print(all_train_data1.index[i],'--skew : ',all_train_data1[i].skew(),'--kurt : ',all_train_data1[i].kurt())\n",
    "    print('lambda : ',lm)\n",
    "    print(all_train_data2.index[i],'--skew : ',all_train_data2[i].skew(),'--kurt : ',all_train_data2[i].kurt())\n",
    "    print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:13.434152Z",
     "start_time": "2021-12-30T05:48:13.424151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:13.927180Z",
     "start_time": "2021-12-30T05:48:13.905179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data2={}\n",
    "for m in range(12):\n",
    "    month_data2=np.empty((18,480))\n",
    "    month_data2[:,:]=all_train_data2.T.iloc[:,m*480:(m+1)*480]\n",
    "    year_data2[m]=month_data2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:14.423208Z",
     "start_time": "2021-12-30T05:48:14.412208Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data3={}\n",
    "for m in range(12):\n",
    "    month_data3=np.empty((18,480))\n",
    "    month_data3[:,:]=all_train_data1.T.iloc[:,m*480:(m+1)*480]\n",
    "    year_data3[m]=month_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:15.138249Z",
     "start_time": "2021-12-30T05:48:15.126249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6, 2.2, 2.3, 2.3, 2.3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data[11][-6,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:15.878292Z",
     "start_time": "2021-12-30T05:48:15.868291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6, 2.2, 2.3, 2.3, 2.3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data3[11][-6,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:16.560331Z",
     "start_time": "2021-12-30T05:48:16.554330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1003593 , 1.01289662, 1.03598957, 1.03598957, 1.03598957])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data2[11][-6,-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare all_train_data1 and all_train_data2\n",
    "- all_train_data1 : just correct outlier value\n",
    "- all_train_data2 : just boxcox after all_train_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:35.843434Z",
     "start_time": "2021-12-30T05:48:35.777430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.610382</td>\n",
       "      <td>1.705521</td>\n",
       "      <td>0.388436</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.136970</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.254115</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.534201</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.769089</td>\n",
       "      <td>1.843012</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.062216</td>\n",
       "      <td>0.100203</td>\n",
       "      <td>0.323505</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.281611</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.571422</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.576035</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.809743</td>\n",
       "      <td>0.163008</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.610382     1.705521     0.388436     0.140427     2.136970   \n",
       "std       6.062216     0.100203     0.323505     0.104645     2.281611   \n",
       "min       6.700000     0.000000     0.080000     0.000000     0.000000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.254115    31.905469    42.709201    21.534201   \n",
       "std       6.187555     7.571422    18.703486    26.222292    16.576035   \n",
       "min       0.000000     1.300000     0.000000     0.000000     0.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    30.000000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.769089     1.843012   156.329271   \n",
       "std       2.045443    13.361351     1.809743     0.163008    95.745881   \n",
       "min       0.000000    29.000000     0.000000     0.000000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:48:37.214512Z",
     "start_time": "2021-12-30T05:48:37.137508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.426493</td>\n",
       "      <td>65.832202</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>0.079806</td>\n",
       "      <td>0.672361</td>\n",
       "      <td>2.283694</td>\n",
       "      <td>1.937404</td>\n",
       "      <td>7.449352</td>\n",
       "      <td>9.327724</td>\n",
       "      <td>5.756380</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>15482.226219</td>\n",
       "      <td>1.051691</td>\n",
       "      <td>3.676586</td>\n",
       "      <td>12.803597</td>\n",
       "      <td>11.687312</td>\n",
       "      <td>1.046624</td>\n",
       "      <td>0.813470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.536335</td>\n",
       "      <td>12.405338</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.176061</td>\n",
       "      <td>0.523410</td>\n",
       "      <td>0.306804</td>\n",
       "      <td>2.431622</td>\n",
       "      <td>3.291614</td>\n",
       "      <td>2.725299</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>6063.422584</td>\n",
       "      <td>0.303361</td>\n",
       "      <td>0.481140</td>\n",
       "      <td>3.602422</td>\n",
       "      <td>3.020925</td>\n",
       "      <td>0.263948</td>\n",
       "      <td>0.292340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.833239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1616.845054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.926550</td>\n",
       "      <td>50.952479</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>0.055291</td>\n",
       "      <td>0.562804</td>\n",
       "      <td>1.938097</td>\n",
       "      <td>1.735287</td>\n",
       "      <td>5.766358</td>\n",
       "      <td>7.204513</td>\n",
       "      <td>3.853588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10617.557930</td>\n",
       "      <td>0.852464</td>\n",
       "      <td>3.245618</td>\n",
       "      <td>9.751980</td>\n",
       "      <td>9.184518</td>\n",
       "      <td>0.857234</td>\n",
       "      <td>0.592611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.525274</td>\n",
       "      <td>63.921527</td>\n",
       "      <td>0.188618</td>\n",
       "      <td>0.076901</td>\n",
       "      <td>0.672848</td>\n",
       "      <td>2.270782</td>\n",
       "      <td>1.916995</td>\n",
       "      <td>7.472206</td>\n",
       "      <td>9.283713</td>\n",
       "      <td>5.763730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15534.166404</td>\n",
       "      <td>1.035990</td>\n",
       "      <td>3.534372</td>\n",
       "      <td>12.099014</td>\n",
       "      <td>11.107693</td>\n",
       "      <td>1.042283</td>\n",
       "      <td>0.818152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>88.521007</td>\n",
       "      <td>79.522794</td>\n",
       "      <td>0.215417</td>\n",
       "      <td>0.103613</td>\n",
       "      <td>0.775804</td>\n",
       "      <td>2.651342</td>\n",
       "      <td>2.143833</td>\n",
       "      <td>9.063998</td>\n",
       "      <td>11.523345</td>\n",
       "      <td>7.603404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20398.022735</td>\n",
       "      <td>1.243713</td>\n",
       "      <td>3.834142</td>\n",
       "      <td>15.383128</td>\n",
       "      <td>13.963600</td>\n",
       "      <td>1.233421</td>\n",
       "      <td>1.030980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.380091</td>\n",
       "      <td>120.311749</td>\n",
       "      <td>0.306532</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>1.192886</td>\n",
       "      <td>3.876332</td>\n",
       "      <td>2.905076</td>\n",
       "      <td>20.678088</td>\n",
       "      <td>20.721569</td>\n",
       "      <td>14.709463</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>30295.187454</td>\n",
       "      <td>2.192628</td>\n",
       "      <td>7.863631</td>\n",
       "      <td>18.965279</td>\n",
       "      <td>16.819218</td>\n",
       "      <td>1.852950</td>\n",
       "      <td>1.618322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     70.426493    65.832202     0.186377     0.079806     0.672361   \n",
       "std      25.536335    12.405338     0.041562     0.032614     0.176061   \n",
       "min      12.833239     0.000000     0.068067     0.000000     0.000000   \n",
       "25%      49.926550    50.952479     0.158556     0.055291     0.562804   \n",
       "50%      70.525274    63.921527     0.188618     0.076901     0.672848   \n",
       "75%      88.521007    79.522794     0.215417     0.103613     0.775804   \n",
       "max     133.380091   120.311749     0.306532     0.160805     1.192886   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      2.283694     1.937404     7.449352     9.327724     5.756380   \n",
       "std       0.523410     0.306804     2.431622     3.291614     2.725299   \n",
       "min       0.000000     0.769032     0.000000     0.000000     0.000000   \n",
       "25%       1.938097     1.735287     5.766358     7.204513     3.853588   \n",
       "50%       2.270782     1.916995     7.472206     9.283713     5.763730   \n",
       "75%       2.651342     2.143833     9.063998    11.523345     7.603404   \n",
       "max       3.876332     2.905076    20.678088    20.721569    14.709463   \n",
       "\n",
       "                10            11           12           13           14  \\\n",
       "count  5760.000000   5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.008977  15482.226219     1.051691     3.676586    12.803597   \n",
       "std       0.035324   6063.422584     0.303361     0.481140     3.602422   \n",
       "min       0.000000   1616.845054     0.000000     0.000000     0.096879   \n",
       "25%       0.000000  10617.557930     0.852464     3.245618     9.751980   \n",
       "50%       0.000000  15534.166404     1.035990     3.534372    12.099014   \n",
       "75%       0.000000  20398.022735     1.243713     3.834142    15.383128   \n",
       "max       0.161645  30295.187454     2.192628     7.863631    18.965279   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean     11.687312     1.046624     0.813470  \n",
       "std       3.020925     0.263948     0.292340  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       9.184518     0.857234     0.592611  \n",
       "50%      11.107693     1.042283     0.818152  \n",
       "75%      13.963600     1.233421     1.030980  \n",
       "max      16.819218     1.852950     1.618322  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:30:30.106735Z",
     "start_time": "2021-12-29T06:30:30.100734Z"
    }
   },
   "source": [
    "## diff with hw_test81 begin\n",
    "- all_train_data3 : normalized\n",
    "- all_train_data2 : no normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:59:02.849296Z",
     "start_time": "2021-12-30T05:59:02.845296Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (all_train_data2[0] - all_train_data2[0].mean()) / all_train_data2[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:58:29.309378Z",
     "start_time": "2021-12-30T05:58:29.264375Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_data3=pd.DataFrame()\n",
    "for i in range(all_train_data2.shape[1]):\n",
    "    if i!=9:\n",
    "        all_train_data3[i]=(all_train_data2[i] - all_train_data2[i].mean()) / all_train_data2[i].std()\n",
    "    else:\n",
    "        all_train_data3[i]=all_train_data2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:58:42.422128Z",
     "start_time": "2021-12-30T05:58:42.415127Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# all_train_data3=all_train_data3.apply(lambda x : (x-x.mean())/x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:58:43.990218Z",
     "start_time": "2021-12-30T05:58:43.928214Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.019875e-13</td>\n",
       "      <td>-5.144712e-14</td>\n",
       "      <td>6.653925e-14</td>\n",
       "      <td>2.549689e-14</td>\n",
       "      <td>2.334629e-15</td>\n",
       "      <td>-6.727368e-14</td>\n",
       "      <td>-4.221841e-14</td>\n",
       "      <td>2.062856e-15</td>\n",
       "      <td>5.215490e-14</td>\n",
       "      <td>5.756380</td>\n",
       "      <td>-1.659610e-15</td>\n",
       "      <td>6.245795e-14</td>\n",
       "      <td>-9.682569e-15</td>\n",
       "      <td>-1.537578e-14</td>\n",
       "      <td>1.616595e-14</td>\n",
       "      <td>-8.086471e-15</td>\n",
       "      <td>3.354384e-14</td>\n",
       "      <td>3.181464e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.725299</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.255345e+00</td>\n",
       "      <td>-5.306764e+00</td>\n",
       "      <td>-2.846587e+00</td>\n",
       "      <td>-2.447008e+00</td>\n",
       "      <td>-3.818917e+00</td>\n",
       "      <td>-4.363104e+00</td>\n",
       "      <td>-3.808196e+00</td>\n",
       "      <td>-3.063532e+00</td>\n",
       "      <td>-2.833784e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-2.286725e+00</td>\n",
       "      <td>-3.466795e+00</td>\n",
       "      <td>-7.641412e+00</td>\n",
       "      <td>-3.527271e+00</td>\n",
       "      <td>-3.868786e+00</td>\n",
       "      <td>-3.965265e+00</td>\n",
       "      <td>-2.782619e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.027755e-01</td>\n",
       "      <td>-1.199461e+00</td>\n",
       "      <td>-6.693840e-01</td>\n",
       "      <td>-7.516859e-01</td>\n",
       "      <td>-6.222681e-01</td>\n",
       "      <td>-6.602794e-01</td>\n",
       "      <td>-6.587790e-01</td>\n",
       "      <td>-6.921282e-01</td>\n",
       "      <td>-6.450364e-01</td>\n",
       "      <td>3.853588</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-8.022974e-01</td>\n",
       "      <td>-6.567335e-01</td>\n",
       "      <td>-8.957229e-01</td>\n",
       "      <td>-8.471015e-01</td>\n",
       "      <td>-8.284860e-01</td>\n",
       "      <td>-7.175293e-01</td>\n",
       "      <td>-7.554874e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.868283e-03</td>\n",
       "      <td>-1.540203e-01</td>\n",
       "      <td>5.390355e-02</td>\n",
       "      <td>-8.905258e-02</td>\n",
       "      <td>2.767230e-03</td>\n",
       "      <td>-2.466757e-02</td>\n",
       "      <td>-6.652185e-02</td>\n",
       "      <td>9.398760e-03</td>\n",
       "      <td>-1.337080e-02</td>\n",
       "      <td>5.763730</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.566150e-03</td>\n",
       "      <td>-5.175865e-02</td>\n",
       "      <td>-2.955772e-01</td>\n",
       "      <td>-1.955858e-01</td>\n",
       "      <td>-1.918681e-01</td>\n",
       "      <td>-1.644871e-02</td>\n",
       "      <td>1.601343e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.085792e-01</td>\n",
       "      <td>1.103605e+00</td>\n",
       "      <td>6.987095e-01</td>\n",
       "      <td>7.299705e-01</td>\n",
       "      <td>5.875442e-01</td>\n",
       "      <td>7.024097e-01</td>\n",
       "      <td>6.728357e-01</td>\n",
       "      <td>6.640201e-01</td>\n",
       "      <td>6.670347e-01</td>\n",
       "      <td>7.603404</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.107297e-01</td>\n",
       "      <td>6.329803e-01</td>\n",
       "      <td>3.274645e-01</td>\n",
       "      <td>7.160547e-01</td>\n",
       "      <td>7.535070e-01</td>\n",
       "      <td>7.077023e-01</td>\n",
       "      <td>7.440291e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.465256e+00</td>\n",
       "      <td>4.391621e+00</td>\n",
       "      <td>2.890982e+00</td>\n",
       "      <td>2.483615e+00</td>\n",
       "      <td>2.956513e+00</td>\n",
       "      <td>3.042810e+00</td>\n",
       "      <td>3.154037e+00</td>\n",
       "      <td>5.440292e+00</td>\n",
       "      <td>3.461476e+00</td>\n",
       "      <td>14.709463</td>\n",
       "      <td>4.321989e+00</td>\n",
       "      <td>2.443003e+00</td>\n",
       "      <td>3.760984e+00</td>\n",
       "      <td>8.702351e+00</td>\n",
       "      <td>1.710428e+00</td>\n",
       "      <td>1.698787e+00</td>\n",
       "      <td>3.054866e+00</td>\n",
       "      <td>2.753135e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean   1.019875e-13 -5.144712e-14  6.653925e-14  2.549689e-14  2.334629e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.255345e+00 -5.306764e+00 -2.846587e+00 -2.447008e+00 -3.818917e+00   \n",
       "25%   -8.027755e-01 -1.199461e+00 -6.693840e-01 -7.516859e-01 -6.222681e-01   \n",
       "50%    3.868283e-03 -1.540203e-01  5.390355e-02 -8.905258e-02  2.767230e-03   \n",
       "75%    7.085792e-01  1.103605e+00  6.987095e-01  7.299705e-01  5.875442e-01   \n",
       "max    2.465256e+00  4.391621e+00  2.890982e+00  2.483615e+00  2.956513e+00   \n",
       "\n",
       "                 5             6             7             8            9   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5760.000000   \n",
       "mean  -6.727368e-14 -4.221841e-14  2.062856e-15  5.215490e-14     5.756380   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00     2.725299   \n",
       "min   -4.363104e+00 -3.808196e+00 -3.063532e+00 -2.833784e+00     0.000000   \n",
       "25%   -6.602794e-01 -6.587790e-01 -6.921282e-01 -6.450364e-01     3.853588   \n",
       "50%   -2.466757e-02 -6.652185e-02  9.398760e-03 -1.337080e-02     5.763730   \n",
       "75%    7.024097e-01  6.728357e-01  6.640201e-01  6.670347e-01     7.603404   \n",
       "max    3.042810e+00  3.154037e+00  5.440292e+00  3.461476e+00    14.709463   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean  -1.659610e-15  6.245795e-14 -9.682569e-15 -1.537578e-14  1.616595e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.541260e-01 -2.286725e+00 -3.466795e+00 -7.641412e+00 -3.527271e+00   \n",
       "25%   -2.541260e-01 -8.022974e-01 -6.567335e-01 -8.957229e-01 -8.471015e-01   \n",
       "50%   -2.541260e-01  8.566150e-03 -5.175865e-02 -2.955772e-01 -1.955858e-01   \n",
       "75%   -2.541260e-01  8.107297e-01  6.329803e-01  3.274645e-01  7.160547e-01   \n",
       "max    4.321989e+00  2.443003e+00  3.760984e+00  8.702351e+00  1.710428e+00   \n",
       "\n",
       "                 15            16            17  \n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  \n",
       "mean  -8.086471e-15  3.354384e-14  3.181464e-15  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -3.868786e+00 -3.965265e+00 -2.782619e+00  \n",
       "25%   -8.284860e-01 -7.175293e-01 -7.554874e-01  \n",
       "50%   -1.918681e-01 -1.644871e-02  1.601343e-02  \n",
       "75%    7.535070e-01  7.077023e-01  7.440291e-01  \n",
       "max    1.698787e+00  3.054866e+00  2.753135e+00  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:40.279531Z",
     "start_time": "2021-12-30T02:03:40.221528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.426493</td>\n",
       "      <td>65.832202</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>0.079806</td>\n",
       "      <td>0.672361</td>\n",
       "      <td>2.283694</td>\n",
       "      <td>1.937404</td>\n",
       "      <td>7.449352</td>\n",
       "      <td>9.327724</td>\n",
       "      <td>5.756380</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>15482.226219</td>\n",
       "      <td>1.051691</td>\n",
       "      <td>3.676586</td>\n",
       "      <td>12.803597</td>\n",
       "      <td>11.687312</td>\n",
       "      <td>1.046624</td>\n",
       "      <td>0.813470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.536335</td>\n",
       "      <td>12.405338</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.176061</td>\n",
       "      <td>0.523410</td>\n",
       "      <td>0.306804</td>\n",
       "      <td>2.431622</td>\n",
       "      <td>3.291614</td>\n",
       "      <td>2.725299</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>6063.422584</td>\n",
       "      <td>0.303361</td>\n",
       "      <td>0.481140</td>\n",
       "      <td>3.602422</td>\n",
       "      <td>3.020925</td>\n",
       "      <td>0.263948</td>\n",
       "      <td>0.292340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.833239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1616.845054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.926550</td>\n",
       "      <td>50.952479</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>0.055291</td>\n",
       "      <td>0.562804</td>\n",
       "      <td>1.938097</td>\n",
       "      <td>1.735287</td>\n",
       "      <td>5.766358</td>\n",
       "      <td>7.204513</td>\n",
       "      <td>3.853588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10617.557930</td>\n",
       "      <td>0.852464</td>\n",
       "      <td>3.245618</td>\n",
       "      <td>9.751980</td>\n",
       "      <td>9.184518</td>\n",
       "      <td>0.857234</td>\n",
       "      <td>0.592611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.525274</td>\n",
       "      <td>63.921527</td>\n",
       "      <td>0.188618</td>\n",
       "      <td>0.076901</td>\n",
       "      <td>0.672848</td>\n",
       "      <td>2.270782</td>\n",
       "      <td>1.916995</td>\n",
       "      <td>7.472206</td>\n",
       "      <td>9.283713</td>\n",
       "      <td>5.763730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15534.166404</td>\n",
       "      <td>1.035990</td>\n",
       "      <td>3.534372</td>\n",
       "      <td>12.099014</td>\n",
       "      <td>11.107693</td>\n",
       "      <td>1.042283</td>\n",
       "      <td>0.818152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>88.521007</td>\n",
       "      <td>79.522794</td>\n",
       "      <td>0.215417</td>\n",
       "      <td>0.103613</td>\n",
       "      <td>0.775804</td>\n",
       "      <td>2.651342</td>\n",
       "      <td>2.143833</td>\n",
       "      <td>9.063998</td>\n",
       "      <td>11.523345</td>\n",
       "      <td>7.603404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20398.022735</td>\n",
       "      <td>1.243713</td>\n",
       "      <td>3.834142</td>\n",
       "      <td>15.383128</td>\n",
       "      <td>13.963600</td>\n",
       "      <td>1.233421</td>\n",
       "      <td>1.030980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.380091</td>\n",
       "      <td>120.311749</td>\n",
       "      <td>0.306532</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>1.192886</td>\n",
       "      <td>3.876332</td>\n",
       "      <td>2.905076</td>\n",
       "      <td>20.678088</td>\n",
       "      <td>20.721569</td>\n",
       "      <td>14.709463</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>30295.187454</td>\n",
       "      <td>2.192628</td>\n",
       "      <td>7.863631</td>\n",
       "      <td>18.965279</td>\n",
       "      <td>16.819218</td>\n",
       "      <td>1.852950</td>\n",
       "      <td>1.618322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     70.426493    65.832202     0.186377     0.079806     0.672361   \n",
       "std      25.536335    12.405338     0.041562     0.032614     0.176061   \n",
       "min      12.833239     0.000000     0.068067     0.000000     0.000000   \n",
       "25%      49.926550    50.952479     0.158556     0.055291     0.562804   \n",
       "50%      70.525274    63.921527     0.188618     0.076901     0.672848   \n",
       "75%      88.521007    79.522794     0.215417     0.103613     0.775804   \n",
       "max     133.380091   120.311749     0.306532     0.160805     1.192886   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      2.283694     1.937404     7.449352     9.327724     5.756380   \n",
       "std       0.523410     0.306804     2.431622     3.291614     2.725299   \n",
       "min       0.000000     0.769032     0.000000     0.000000     0.000000   \n",
       "25%       1.938097     1.735287     5.766358     7.204513     3.853588   \n",
       "50%       2.270782     1.916995     7.472206     9.283713     5.763730   \n",
       "75%       2.651342     2.143833     9.063998    11.523345     7.603404   \n",
       "max       3.876332     2.905076    20.678088    20.721569    14.709463   \n",
       "\n",
       "                10            11           12           13           14  \\\n",
       "count  5760.000000   5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.008977  15482.226219     1.051691     3.676586    12.803597   \n",
       "std       0.035324   6063.422584     0.303361     0.481140     3.602422   \n",
       "min       0.000000   1616.845054     0.000000     0.000000     0.096879   \n",
       "25%       0.000000  10617.557930     0.852464     3.245618     9.751980   \n",
       "50%       0.000000  15534.166404     1.035990     3.534372    12.099014   \n",
       "75%       0.000000  20398.022735     1.243713     3.834142    15.383128   \n",
       "max       0.161645  30295.187454     2.192628     7.863631    18.965279   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean     11.687312     1.046624     0.813470  \n",
       "std       3.020925     0.263948     0.292340  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       9.184518     0.857234     0.592611  \n",
       "50%      11.107693     1.042283     0.818152  \n",
       "75%      13.963600     1.233421     1.030980  \n",
       "max      16.819218     1.852950     1.618322  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:59:37.954304Z",
     "start_time": "2021-12-30T05:59:37.935303Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data3={}\n",
    "for m in range(12):\n",
    "    month_data3=np.empty((18,480))\n",
    "    month_data3[:,:]=all_train_data3.T.iloc[:,m*480:(m+1)*480]\n",
    "    year_data3[m]=month_data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## diff with hw_test81 end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:59:56.968392Z",
     "start_time": "2021-12-30T05:59:56.911388Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x4=np.empty((12*471,18*9))\n",
    "y4=np.empty((12*471,1))\n",
    "\n",
    "for m in range(12):\n",
    "    for g in range(471):\n",
    "        x4[m*471+g:m*471+g+1,:]=year_data3[m][:,g:g+9].reshape(1,-1)\n",
    "        y4[m*471+g:m*471+g+1,:]=year_data3[m][9,g+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T05:59:58.289467Z",
     "start_time": "2021-12-30T05:59:58.279467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.58579693,  3.58579693,  4.10611904,  2.28868315,  0.80300331,\n",
       "        0.80300331,  3.29995821,  6.74890197,  8.4854749 , -0.25412602,\n",
       "       -0.25412602])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-6,81:92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:00:04.015795Z",
     "start_time": "2021-12-30T06:00:04.006794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.58579693,  4.10611904,  2.28868315,  0.80300331,  0.80300331,\n",
       "        3.29995821,  6.74890197,  8.4854749 ,  9.79861041, -0.25412602,\n",
       "       -0.25412602])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-5,81:92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:00:09.448105Z",
     "start_time": "2021-12-30T06:00:09.439105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.10611904,  2.28868315,  0.80300331,  0.80300331,  3.29995821,\n",
       "        6.74890197,  8.4854749 ,  9.79861041,  8.4854749 , -0.25412602,\n",
       "       -0.25412602])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-4,81:92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:00:10.052140Z",
     "start_time": "2021-12-30T06:00:10.045140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5652, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:00:35.544598Z",
     "start_time": "2021-12-30T06:00:35.535598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.79861041],\n",
       "       [8.4854749 ],\n",
       "       [7.33028592],\n",
       "       [5.58250973],\n",
       "       [6.74890197],\n",
       "       [7.46817766]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:00:36.013625Z",
     "start_time": "2021-12-30T06:00:36.007625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.4854749 ],\n",
       "       [7.33028592],\n",
       "       [5.58250973],\n",
       "       [6.74890197],\n",
       "       [7.46817766]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:00:37.141689Z",
     "start_time": "2021-12-30T06:00:37.133689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.33028592],\n",
       "       [5.58250973],\n",
       "       [6.74890197],\n",
       "       [7.46817766]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:00:40.436878Z",
     "start_time": "2021-12-30T06:00:40.416877Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x44=torch.Tensor(x4)\n",
    "y44=torch.Tensor(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:04:41.200649Z",
     "start_time": "2021-12-30T06:00:42.383989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 3.504328 , test loss : 3.717892\n",
      "epoch = 2 train_loss : 2.726987 , test loss : 2.886399\n",
      "epoch = 3 train_loss : 2.450238 , test loss : 2.628571\n",
      "epoch = 4 train_loss : 2.264201 , test loss : 2.455116\n",
      "epoch = 5 train_loss : 2.137608 , test loss : 2.314301\n",
      "epoch = 6 train_loss : 2.024401 , test loss : 2.222916\n",
      "epoch = 7 train_loss : 1.921412 , test loss : 2.105918\n",
      "epoch = 8 train_loss : 1.834726 , test loss : 2.020422\n",
      "epoch = 9 train_loss : 1.741218 , test loss : 1.920065\n",
      "epoch = 10 train_loss : 1.666982 , test loss : 1.836863\n",
      "epoch = 11 train_loss : 1.586737 , test loss : 1.749018\n",
      "epoch = 12 train_loss : 1.529387 , test loss : 1.671179\n",
      "epoch = 13 train_loss : 1.469672 , test loss : 1.618733\n",
      "epoch = 14 train_loss : 1.418860 , test loss : 1.551594\n",
      "epoch = 15 train_loss : 1.379516 , test loss : 1.499390\n",
      "epoch = 16 train_loss : 1.334978 , test loss : 1.461260\n",
      "epoch = 17 train_loss : 1.313400 , test loss : 1.442127\n",
      "epoch = 18 train_loss : 1.286206 , test loss : 1.391436\n",
      "epoch = 19 train_loss : 1.254890 , test loss : 1.362626\n",
      "epoch = 20 train_loss : 1.240643 , test loss : 1.338844\n",
      "epoch = 21 train_loss : 1.210174 , test loss : 1.313284\n",
      "epoch = 22 train_loss : 1.194998 , test loss : 1.286783\n",
      "epoch = 23 train_loss : 1.172887 , test loss : 1.257597\n",
      "epoch = 24 train_loss : 1.168008 , test loss : 1.252750\n",
      "epoch = 25 train_loss : 1.156188 , test loss : 1.245413\n",
      "epoch = 26 train_loss : 1.139679 , test loss : 1.232074\n",
      "epoch = 28 train_loss : 1.141794 , test loss : 1.213960\n",
      "epoch = 31 train_loss : 1.108679 , test loss : 1.184421\n",
      "epoch = 34 train_loss : 1.115620 , test loss : 1.181122\n",
      "epoch = 35 train_loss : 1.086042 , test loss : 1.168671\n",
      "epoch = 36 train_loss : 1.077384 , test loss : 1.157405\n",
      "epoch = 39 train_loss : 1.081246 , test loss : 1.151202\n",
      "epoch = 44 train_loss : 1.062032 , test loss : 1.142329\n",
      "epoch = 48 train_loss : 1.049847 , test loss : 1.129302\n",
      "epoch = 52 train_loss : 1.048270 , test loss : 1.126483\n",
      "epoch = 53 train_loss : 1.047037 , test loss : 1.120606\n",
      "epoch = 59 train_loss : 1.031069 , test loss : 1.114994\n",
      "epoch = 65 train_loss : 1.029737 , test loss : 1.111073\n",
      "epoch = 68 train_loss : 1.026415 , test loss : 1.111057\n",
      "epoch = 82 train_loss : 1.025396 , test loss : 1.105419\n",
      "epoch = 136 train_loss : 1.020296 , test loss : 1.104876\n",
      "epoch = 217 train_loss : 1.018094 , test loss : 1.104351\n",
      "epoch = 241 train_loss : 1.026238 , test loss : 1.103196\n",
      "epoch = 282 train_loss : 1.020549 , test loss : 1.100585\n",
      "epoch = 446 train_loss : 1.015752 , test loss : 1.097644\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 1.015752,test loss : 1.097644\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 3.528845 , test loss : 4.040123\n",
      "epoch = 2 train_loss : 2.582773 , test loss : 2.856699\n",
      "epoch = 3 train_loss : 2.299048 , test loss : 2.630069\n",
      "epoch = 4 train_loss : 2.148741 , test loss : 2.480089\n",
      "epoch = 5 train_loss : 2.049876 , test loss : 2.375984\n",
      "epoch = 6 train_loss : 1.926304 , test loss : 2.257318\n",
      "epoch = 7 train_loss : 1.838620 , test loss : 2.162326\n",
      "epoch = 8 train_loss : 1.752725 , test loss : 2.072215\n",
      "epoch = 9 train_loss : 1.685501 , test loss : 1.992111\n",
      "epoch = 10 train_loss : 1.612685 , test loss : 1.930345\n",
      "epoch = 11 train_loss : 1.530514 , test loss : 1.849071\n",
      "epoch = 12 train_loss : 1.475898 , test loss : 1.804281\n",
      "epoch = 13 train_loss : 1.439574 , test loss : 1.787353\n",
      "epoch = 14 train_loss : 1.398932 , test loss : 1.742815\n",
      "epoch = 15 train_loss : 1.334189 , test loss : 1.646537\n",
      "epoch = 16 train_loss : 1.282138 , test loss : 1.578402\n",
      "epoch = 17 train_loss : 1.265495 , test loss : 1.525850\n",
      "epoch = 18 train_loss : 1.223606 , test loss : 1.509827\n",
      "epoch = 19 train_loss : 1.224351 , test loss : 1.497875\n",
      "epoch = 20 train_loss : 1.186154 , test loss : 1.467253\n",
      "epoch = 21 train_loss : 1.178271 , test loss : 1.461768\n",
      "epoch = 22 train_loss : 1.153158 , test loss : 1.435252\n",
      "epoch = 23 train_loss : 1.137713 , test loss : 1.402902\n",
      "epoch = 24 train_loss : 1.144435 , test loss : 1.398939\n",
      "epoch = 25 train_loss : 1.127312 , test loss : 1.395738\n",
      "epoch = 26 train_loss : 1.101196 , test loss : 1.359252\n",
      "epoch = 27 train_loss : 1.092476 , test loss : 1.337389\n",
      "epoch = 28 train_loss : 1.086434 , test loss : 1.336579\n",
      "epoch = 29 train_loss : 1.082343 , test loss : 1.329455\n",
      "epoch = 30 train_loss : 1.071488 , test loss : 1.317815\n",
      "epoch = 31 train_loss : 1.086104 , test loss : 1.303406\n",
      "epoch = 32 train_loss : 1.075007 , test loss : 1.301980\n",
      "epoch = 35 train_loss : 1.075560 , test loss : 1.274233\n",
      "epoch = 38 train_loss : 1.064438 , test loss : 1.238495\n",
      "epoch = 41 train_loss : 1.041301 , test loss : 1.232670\n",
      "epoch = 45 train_loss : 1.037342 , test loss : 1.219977\n",
      "epoch = 52 train_loss : 1.034586 , test loss : 1.215209\n",
      "epoch = 54 train_loss : 1.012809 , test loss : 1.202828\n",
      "epoch = 60 train_loss : 1.014330 , test loss : 1.190077\n",
      "epoch = 64 train_loss : 1.015043 , test loss : 1.189827\n",
      "epoch = 67 train_loss : 1.013529 , test loss : 1.179903\n",
      "epoch = 106 train_loss : 1.005963 , test loss : 1.177176\n",
      "epoch = 168 train_loss : 1.001203 , test loss : 1.176072\n",
      "epoch = 173 train_loss : 1.012050 , test loss : 1.175948\n",
      "epoch = 200 train_loss : 1.003258 , test loss : 1.175017\n",
      "epoch = 205 train_loss : 1.007395 , test loss : 1.172233\n",
      "epoch = 317 train_loss : 1.005690 , test loss : 1.171309\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 1.005690,test loss : 1.171309\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 3.475588 , test loss : 3.206058\n",
      "epoch = 2 train_loss : 2.683464 , test loss : 2.560720\n",
      "epoch = 3 train_loss : 2.409772 , test loss : 2.272402\n",
      "epoch = 4 train_loss : 2.239849 , test loss : 2.136258\n",
      "epoch = 5 train_loss : 2.122326 , test loss : 2.003391\n",
      "epoch = 6 train_loss : 2.018202 , test loss : 1.934850\n",
      "epoch = 7 train_loss : 1.917742 , test loss : 1.838269\n",
      "epoch = 8 train_loss : 1.832548 , test loss : 1.758657\n",
      "epoch = 9 train_loss : 1.751646 , test loss : 1.694627\n",
      "epoch = 10 train_loss : 1.703652 , test loss : 1.672292\n",
      "epoch = 11 train_loss : 1.610526 , test loss : 1.575165\n",
      "epoch = 12 train_loss : 1.550915 , test loss : 1.519964\n",
      "epoch = 13 train_loss : 1.497514 , test loss : 1.474125\n",
      "epoch = 14 train_loss : 1.449471 , test loss : 1.410677\n",
      "epoch = 15 train_loss : 1.397082 , test loss : 1.393186\n",
      "epoch = 16 train_loss : 1.368461 , test loss : 1.370312\n",
      "epoch = 17 train_loss : 1.340605 , test loss : 1.350416\n",
      "epoch = 18 train_loss : 1.315463 , test loss : 1.303464\n",
      "epoch = 19 train_loss : 1.277218 , test loss : 1.284632\n",
      "epoch = 20 train_loss : 1.261228 , test loss : 1.271510\n",
      "epoch = 21 train_loss : 1.237930 , test loss : 1.258092\n",
      "epoch = 22 train_loss : 1.211759 , test loss : 1.234121\n",
      "epoch = 23 train_loss : 1.201136 , test loss : 1.222600\n",
      "epoch = 24 train_loss : 1.181985 , test loss : 1.208492\n",
      "epoch = 25 train_loss : 1.165113 , test loss : 1.202051\n",
      "epoch = 26 train_loss : 1.161567 , test loss : 1.192998\n",
      "epoch = 27 train_loss : 1.145446 , test loss : 1.177931\n",
      "epoch = 30 train_loss : 1.132336 , test loss : 1.168865\n",
      "epoch = 31 train_loss : 1.120661 , test loss : 1.155145\n",
      "epoch = 35 train_loss : 1.099076 , test loss : 1.142794\n",
      "epoch = 37 train_loss : 1.092069 , test loss : 1.142559\n",
      "epoch = 40 train_loss : 1.081713 , test loss : 1.133559\n",
      "epoch = 41 train_loss : 1.080329 , test loss : 1.131760\n",
      "epoch = 43 train_loss : 1.064316 , test loss : 1.118912\n",
      "epoch = 48 train_loss : 1.055276 , test loss : 1.114573\n",
      "epoch = 53 train_loss : 1.052361 , test loss : 1.109726\n",
      "epoch = 58 train_loss : 1.031049 , test loss : 1.105355\n",
      "epoch = 67 train_loss : 1.040134 , test loss : 1.105176\n",
      "epoch = 71 train_loss : 1.033535 , test loss : 1.102735\n",
      "epoch = 79 train_loss : 1.023900 , test loss : 1.102250\n",
      "epoch = 87 train_loss : 1.024015 , test loss : 1.099626\n",
      "epoch = 97 train_loss : 1.020336 , test loss : 1.096941\n",
      "epoch = 177 train_loss : 1.020144 , test loss : 1.096177\n",
      "epoch = 246 train_loss : 1.017684 , test loss : 1.096096\n",
      "epoch = 250 train_loss : 1.023733 , test loss : 1.095716\n",
      "epoch = 263 train_loss : 1.021092 , test loss : 1.095174\n",
      "epoch = 424 train_loss : 1.017625 , test loss : 1.091960\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 1.017625,test loss : 1.091960\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 3.296263 , test loss : 3.347130\n",
      "epoch = 2 train_loss : 2.676857 , test loss : 2.747433\n",
      "epoch = 3 train_loss : 2.329408 , test loss : 2.383826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4 train_loss : 2.163123 , test loss : 2.232615\n",
      "epoch = 5 train_loss : 2.055344 , test loss : 2.122760\n",
      "epoch = 6 train_loss : 1.949438 , test loss : 2.019058\n",
      "epoch = 7 train_loss : 1.864309 , test loss : 1.934603\n",
      "epoch = 8 train_loss : 1.775264 , test loss : 1.853217\n",
      "epoch = 9 train_loss : 1.697602 , test loss : 1.772805\n",
      "epoch = 10 train_loss : 1.626087 , test loss : 1.686844\n",
      "epoch = 11 train_loss : 1.572963 , test loss : 1.644774\n",
      "epoch = 12 train_loss : 1.509646 , test loss : 1.581525\n",
      "epoch = 13 train_loss : 1.463017 , test loss : 1.539784\n",
      "epoch = 14 train_loss : 1.411677 , test loss : 1.475603\n",
      "epoch = 15 train_loss : 1.379737 , test loss : 1.431802\n",
      "epoch = 16 train_loss : 1.371167 , test loss : 1.420839\n",
      "epoch = 17 train_loss : 1.331148 , test loss : 1.392930\n",
      "epoch = 18 train_loss : 1.290711 , test loss : 1.342434\n",
      "epoch = 20 train_loss : 1.254861 , test loss : 1.289572\n",
      "epoch = 21 train_loss : 1.234999 , test loss : 1.289115\n",
      "epoch = 22 train_loss : 1.207430 , test loss : 1.273852\n",
      "epoch = 23 train_loss : 1.199990 , test loss : 1.229222\n",
      "epoch = 25 train_loss : 1.169036 , test loss : 1.215908\n",
      "epoch = 27 train_loss : 1.150370 , test loss : 1.205328\n",
      "epoch = 28 train_loss : 1.157734 , test loss : 1.195869\n",
      "epoch = 29 train_loss : 1.140324 , test loss : 1.168882\n",
      "epoch = 32 train_loss : 1.116741 , test loss : 1.155479\n",
      "epoch = 36 train_loss : 1.122088 , test loss : 1.137269\n",
      "epoch = 37 train_loss : 1.098088 , test loss : 1.122875\n",
      "epoch = 43 train_loss : 1.081866 , test loss : 1.121958\n",
      "epoch = 45 train_loss : 1.091238 , test loss : 1.117710\n",
      "epoch = 47 train_loss : 1.065932 , test loss : 1.117455\n",
      "epoch = 49 train_loss : 1.094477 , test loss : 1.106112\n",
      "epoch = 52 train_loss : 1.055696 , test loss : 1.097718\n",
      "epoch = 54 train_loss : 1.065397 , test loss : 1.078237\n",
      "epoch = 62 train_loss : 1.056563 , test loss : 1.077803\n",
      "epoch = 64 train_loss : 1.055160 , test loss : 1.066409\n",
      "epoch = 73 train_loss : 1.056019 , test loss : 1.054831\n",
      "epoch = 110 train_loss : 1.045668 , test loss : 1.047611\n",
      "epoch = 128 train_loss : 1.055022 , test loss : 1.046618\n",
      "epoch = 188 train_loss : 1.044243 , test loss : 1.040179\n",
      "epoch = 242 train_loss : 1.040796 , test loss : 1.039225\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 1.040796,test loss : 1.039225\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 3.728982 , test loss : 3.488833\n",
      "epoch = 2 train_loss : 2.890231 , test loss : 2.666553\n",
      "epoch = 3 train_loss : 2.564185 , test loss : 2.459690\n",
      "epoch = 4 train_loss : 2.384398 , test loss : 2.237516\n",
      "epoch = 5 train_loss : 2.245735 , test loss : 2.119542\n",
      "epoch = 6 train_loss : 2.132955 , test loss : 2.022326\n",
      "epoch = 7 train_loss : 2.057263 , test loss : 1.981694\n",
      "epoch = 8 train_loss : 1.940617 , test loss : 1.863697\n",
      "epoch = 9 train_loss : 1.850504 , test loss : 1.759325\n",
      "epoch = 10 train_loss : 1.772105 , test loss : 1.674665\n",
      "epoch = 11 train_loss : 1.706451 , test loss : 1.631678\n",
      "epoch = 12 train_loss : 1.657849 , test loss : 1.583261\n",
      "epoch = 13 train_loss : 1.583718 , test loss : 1.511568\n",
      "epoch = 14 train_loss : 1.537780 , test loss : 1.455515\n",
      "epoch = 15 train_loss : 1.484678 , test loss : 1.416751\n",
      "epoch = 16 train_loss : 1.438879 , test loss : 1.375029\n",
      "epoch = 17 train_loss : 1.409609 , test loss : 1.357499\n",
      "epoch = 18 train_loss : 1.380237 , test loss : 1.344264\n",
      "epoch = 19 train_loss : 1.348171 , test loss : 1.301777\n",
      "epoch = 20 train_loss : 1.326168 , test loss : 1.271421\n",
      "epoch = 21 train_loss : 1.306656 , test loss : 1.251504\n",
      "epoch = 22 train_loss : 1.305102 , test loss : 1.235859\n",
      "epoch = 23 train_loss : 1.261589 , test loss : 1.207329\n",
      "epoch = 24 train_loss : 1.238233 , test loss : 1.204177\n",
      "epoch = 26 train_loss : 1.219023 , test loss : 1.181928\n",
      "epoch = 28 train_loss : 1.198883 , test loss : 1.180717\n",
      "epoch = 29 train_loss : 1.167283 , test loss : 1.143876\n",
      "epoch = 32 train_loss : 1.145486 , test loss : 1.125738\n",
      "epoch = 34 train_loss : 1.135689 , test loss : 1.104365\n",
      "epoch = 42 train_loss : 1.088327 , test loss : 1.076602\n",
      "epoch = 44 train_loss : 1.082782 , test loss : 1.063841\n",
      "epoch = 59 train_loss : 1.068739 , test loss : 1.060103\n",
      "epoch = 61 train_loss : 1.051766 , test loss : 1.047288\n",
      "epoch = 72 train_loss : 1.046319 , test loss : 1.040269\n",
      "epoch = 335 train_loss : 1.035215 , test loss : 1.039996\n",
      "epoch = 346 train_loss : 1.043053 , test loss : 1.038180\n",
      "epoch = 426 train_loss : 1.039579 , test loss : 1.037031\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 1.039579,test loss : 1.037031\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 1.023889,total test loss mean : 1.087434 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T08:55:32.368982Z",
     "start_time": "2021-12-30T08:43:00.087954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 38.885269 , test loss : 38.548832\n",
      "epoch = 2 train_loss : 38.290874 , test loss : 37.960293\n",
      "epoch = 3 train_loss : 37.702095 , test loss : 37.377399\n",
      "epoch = 4 train_loss : 37.122219 , test loss : 36.803692\n",
      "epoch = 5 train_loss : 36.547825 , test loss : 36.234722\n",
      "epoch = 6 train_loss : 35.981426 , test loss : 35.673561\n",
      "epoch = 7 train_loss : 35.425308 , test loss : 35.122005\n",
      "epoch = 8 train_loss : 34.872532 , test loss : 34.573776\n",
      "epoch = 9 train_loss : 34.321320 , test loss : 34.027050\n",
      "epoch = 10 train_loss : 33.780022 , test loss : 33.491055\n",
      "epoch = 11 train_loss : 33.241642 , test loss : 32.957764\n",
      "epoch = 12 train_loss : 32.707577 , test loss : 32.428703\n",
      "epoch = 13 train_loss : 32.182568 , test loss : 31.908239\n",
      "epoch = 14 train_loss : 31.664822 , test loss : 31.395452\n",
      "epoch = 15 train_loss : 31.147839 , test loss : 30.884081\n",
      "epoch = 16 train_loss : 30.634022 , test loss : 30.375669\n",
      "epoch = 17 train_loss : 30.124798 , test loss : 29.871794\n",
      "epoch = 18 train_loss : 29.626150 , test loss : 29.378857\n",
      "epoch = 19 train_loss : 29.123749 , test loss : 28.881952\n",
      "epoch = 20 train_loss : 28.628540 , test loss : 28.392807\n",
      "epoch = 21 train_loss : 28.134876 , test loss : 27.905334\n",
      "epoch = 22 train_loss : 27.650890 , test loss : 27.427347\n",
      "epoch = 23 train_loss : 27.168200 , test loss : 26.951174\n",
      "epoch = 24 train_loss : 26.690281 , test loss : 26.479658\n",
      "epoch = 25 train_loss : 26.214594 , test loss : 26.010353\n",
      "epoch = 26 train_loss : 25.747570 , test loss : 25.549644\n",
      "epoch = 27 train_loss : 25.280041 , test loss : 25.088394\n",
      "epoch = 28 train_loss : 24.822138 , test loss : 24.636988\n",
      "epoch = 29 train_loss : 24.367594 , test loss : 24.188597\n",
      "epoch = 30 train_loss : 23.912630 , test loss : 23.739807\n",
      "epoch = 31 train_loss : 23.464554 , test loss : 23.297842\n",
      "epoch = 32 train_loss : 23.025654 , test loss : 22.864763\n",
      "epoch = 33 train_loss : 22.586924 , test loss : 22.431742\n",
      "epoch = 34 train_loss : 22.154919 , test loss : 22.005579\n",
      "epoch = 35 train_loss : 21.721754 , test loss : 21.578552\n",
      "epoch = 36 train_loss : 21.298700 , test loss : 21.161385\n",
      "epoch = 37 train_loss : 20.878834 , test loss : 20.747871\n",
      "epoch = 38 train_loss : 20.464083 , test loss : 20.339735\n",
      "epoch = 39 train_loss : 20.052923 , test loss : 19.934700\n",
      "epoch = 40 train_loss : 19.649096 , test loss : 19.537363\n",
      "epoch = 41 train_loss : 19.249998 , test loss : 19.144634\n",
      "epoch = 42 train_loss : 18.852634 , test loss : 18.753666\n",
      "epoch = 43 train_loss : 18.463854 , test loss : 18.371046\n",
      "epoch = 44 train_loss : 18.077490 , test loss : 17.990719\n",
      "epoch = 45 train_loss : 17.700031 , test loss : 17.619436\n",
      "epoch = 46 train_loss : 17.328447 , test loss : 17.253725\n",
      "epoch = 47 train_loss : 16.960205 , test loss : 16.891455\n",
      "epoch = 48 train_loss : 16.596981 , test loss : 16.534012\n",
      "epoch = 49 train_loss : 16.238419 , test loss : 16.181044\n",
      "epoch = 50 train_loss : 15.885356 , test loss : 15.833561\n",
      "epoch = 51 train_loss : 15.540374 , test loss : 15.494292\n",
      "epoch = 52 train_loss : 15.201437 , test loss : 15.161096\n",
      "epoch = 53 train_loss : 14.865100 , test loss : 14.830357\n",
      "epoch = 54 train_loss : 14.535024 , test loss : 14.506024\n",
      "epoch = 55 train_loss : 14.212467 , test loss : 14.188828\n",
      "epoch = 56 train_loss : 13.896152 , test loss : 13.877900\n",
      "epoch = 57 train_loss : 13.584575 , test loss : 13.571547\n",
      "epoch = 58 train_loss : 13.279902 , test loss : 13.272101\n",
      "epoch = 59 train_loss : 12.980331 , test loss : 12.977724\n",
      "epoch = 60 train_loss : 12.685510 , test loss : 12.688340\n",
      "epoch = 61 train_loss : 12.398193 , test loss : 12.406041\n",
      "epoch = 62 train_loss : 12.117115 , test loss : 12.130266\n",
      "epoch = 63 train_loss : 11.840491 , test loss : 11.858600\n",
      "epoch = 64 train_loss : 11.569228 , test loss : 11.592556\n",
      "epoch = 65 train_loss : 11.305515 , test loss : 11.333939\n",
      "epoch = 66 train_loss : 11.047200 , test loss : 11.080740\n",
      "epoch = 67 train_loss : 10.793736 , test loss : 10.832460\n",
      "epoch = 68 train_loss : 10.545288 , test loss : 10.589078\n",
      "epoch = 69 train_loss : 10.303318 , test loss : 10.352386\n",
      "epoch = 70 train_loss : 10.068115 , test loss : 10.122145\n",
      "epoch = 71 train_loss : 9.837168 , test loss : 9.896045\n",
      "epoch = 72 train_loss : 9.611433 , test loss : 9.674941\n",
      "epoch = 73 train_loss : 9.391707 , test loss : 9.459988\n",
      "epoch = 74 train_loss : 9.177620 , test loss : 9.250037\n",
      "epoch = 75 train_loss : 8.969392 , test loss : 9.045906\n",
      "epoch = 76 train_loss : 8.765587 , test loss : 8.846454\n",
      "epoch = 77 train_loss : 8.567129 , test loss : 8.651929\n",
      "epoch = 78 train_loss : 8.374063 , test loss : 8.462677\n",
      "epoch = 79 train_loss : 8.185372 , test loss : 8.277671\n",
      "epoch = 80 train_loss : 8.002575 , test loss : 8.098507\n",
      "epoch = 81 train_loss : 7.825412 , test loss : 7.924909\n",
      "epoch = 82 train_loss : 7.650577 , test loss : 7.753479\n",
      "epoch = 83 train_loss : 7.484011 , test loss : 7.590473\n",
      "epoch = 84 train_loss : 7.320745 , test loss : 7.430420\n",
      "epoch = 85 train_loss : 7.159785 , test loss : 7.272768\n",
      "epoch = 86 train_loss : 7.005143 , test loss : 7.121283\n",
      "epoch = 87 train_loss : 6.856603 , test loss : 6.975803\n",
      "epoch = 88 train_loss : 6.710517 , test loss : 6.832748\n",
      "epoch = 89 train_loss : 6.569006 , test loss : 6.694107\n",
      "epoch = 90 train_loss : 6.432259 , test loss : 6.560195\n",
      "epoch = 91 train_loss : 6.298545 , test loss : 6.429325\n",
      "epoch = 92 train_loss : 6.169783 , test loss : 6.303094\n",
      "epoch = 93 train_loss : 6.043948 , test loss : 6.179995\n",
      "epoch = 94 train_loss : 5.923835 , test loss : 6.062504\n",
      "epoch = 95 train_loss : 5.806899 , test loss : 5.948034\n",
      "epoch = 96 train_loss : 5.694189 , test loss : 5.837778\n",
      "epoch = 97 train_loss : 5.583877 , test loss : 5.729897\n",
      "epoch = 98 train_loss : 5.477979 , test loss : 5.626313\n",
      "epoch = 99 train_loss : 5.374876 , test loss : 5.525520\n",
      "epoch = 100 train_loss : 5.275347 , test loss : 5.428170\n",
      "epoch = 101 train_loss : 5.178204 , test loss : 5.333159\n",
      "epoch = 102 train_loss : 5.085114 , test loss : 5.242299\n",
      "epoch = 103 train_loss : 4.995894 , test loss : 5.154975\n",
      "epoch = 104 train_loss : 4.908702 , test loss : 5.069475\n",
      "epoch = 105 train_loss : 4.825606 , test loss : 4.988436\n",
      "epoch = 106 train_loss : 4.743896 , test loss : 4.908335\n",
      "epoch = 107 train_loss : 4.665711 , test loss : 4.832093\n",
      "epoch = 108 train_loss : 4.590539 , test loss : 4.758548\n",
      "epoch = 109 train_loss : 4.517438 , test loss : 4.687115\n",
      "epoch = 110 train_loss : 4.447907 , test loss : 4.619222\n",
      "epoch = 111 train_loss : 4.380282 , test loss : 4.553101\n",
      "epoch = 112 train_loss : 4.314825 , test loss : 4.489278\n",
      "epoch = 113 train_loss : 4.252920 , test loss : 4.428845\n",
      "epoch = 114 train_loss : 4.193102 , test loss : 4.370275\n",
      "epoch = 115 train_loss : 4.135444 , test loss : 4.314137\n",
      "epoch = 116 train_loss : 4.079659 , test loss : 4.259762\n",
      "epoch = 117 train_loss : 4.025658 , test loss : 4.207098\n",
      "epoch = 118 train_loss : 3.974762 , test loss : 4.157518\n",
      "epoch = 119 train_loss : 3.925926 , test loss : 4.110051\n",
      "epoch = 120 train_loss : 3.878503 , test loss : 4.063850\n",
      "epoch = 121 train_loss : 3.832377 , test loss : 4.018735\n",
      "epoch = 122 train_loss : 3.789113 , test loss : 3.976771\n",
      "epoch = 123 train_loss : 3.746893 , test loss : 3.935654\n",
      "epoch = 124 train_loss : 3.706358 , test loss : 3.896178\n",
      "epoch = 125 train_loss : 3.667677 , test loss : 3.858551\n",
      "epoch = 126 train_loss : 3.631258 , test loss : 3.823220\n",
      "epoch = 127 train_loss : 3.595283 , test loss : 3.788222\n",
      "epoch = 128 train_loss : 3.560634 , test loss : 3.754532\n",
      "epoch = 129 train_loss : 3.528310 , test loss : 3.723268\n",
      "epoch = 130 train_loss : 3.497040 , test loss : 3.692823\n",
      "epoch = 131 train_loss : 3.466936 , test loss : 3.663732\n",
      "epoch = 132 train_loss : 3.438313 , test loss : 3.635842\n",
      "epoch = 133 train_loss : 3.410249 , test loss : 3.608618\n",
      "epoch = 134 train_loss : 3.383950 , test loss : 3.583162\n",
      "epoch = 135 train_loss : 3.358676 , test loss : 3.558676\n",
      "epoch = 136 train_loss : 3.334074 , test loss : 3.535105\n",
      "epoch = 137 train_loss : 3.311117 , test loss : 3.512965\n",
      "epoch = 138 train_loss : 3.289078 , test loss : 3.491576\n",
      "epoch = 139 train_loss : 3.267586 , test loss : 3.470908\n",
      "epoch = 140 train_loss : 3.246889 , test loss : 3.451008\n",
      "epoch = 141 train_loss : 3.226972 , test loss : 3.431953\n",
      "epoch = 142 train_loss : 3.208697 , test loss : 3.414322\n",
      "epoch = 143 train_loss : 3.190280 , test loss : 3.396769\n",
      "epoch = 144 train_loss : 3.173172 , test loss : 3.380353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 145 train_loss : 3.156706 , test loss : 3.364714\n",
      "epoch = 146 train_loss : 3.140682 , test loss : 3.349366\n",
      "epoch = 147 train_loss : 3.125174 , test loss : 3.334765\n",
      "epoch = 148 train_loss : 3.110409 , test loss : 3.320730\n",
      "epoch = 149 train_loss : 3.096464 , test loss : 3.307517\n",
      "epoch = 150 train_loss : 3.083144 , test loss : 3.294913\n",
      "epoch = 151 train_loss : 3.070057 , test loss : 3.282583\n",
      "epoch = 152 train_loss : 3.057637 , test loss : 3.270829\n",
      "epoch = 153 train_loss : 3.045659 , test loss : 3.259583\n",
      "epoch = 154 train_loss : 3.033980 , test loss : 3.248638\n",
      "epoch = 155 train_loss : 3.022860 , test loss : 3.238200\n",
      "epoch = 156 train_loss : 3.011951 , test loss : 3.227963\n",
      "epoch = 157 train_loss : 3.001627 , test loss : 3.218406\n",
      "epoch = 158 train_loss : 2.991614 , test loss : 3.209137\n",
      "epoch = 159 train_loss : 2.981694 , test loss : 3.199873\n",
      "epoch = 160 train_loss : 2.972461 , test loss : 3.191523\n",
      "epoch = 161 train_loss : 2.963391 , test loss : 3.182996\n",
      "epoch = 162 train_loss : 2.954552 , test loss : 3.174874\n",
      "epoch = 163 train_loss : 2.946129 , test loss : 3.167123\n",
      "epoch = 164 train_loss : 2.937823 , test loss : 3.159660\n",
      "epoch = 165 train_loss : 2.929485 , test loss : 3.151921\n",
      "epoch = 166 train_loss : 2.921599 , test loss : 3.144542\n",
      "epoch = 167 train_loss : 2.913884 , test loss : 3.137386\n",
      "epoch = 168 train_loss : 2.906385 , test loss : 3.130596\n",
      "epoch = 169 train_loss : 2.899185 , test loss : 3.124209\n",
      "epoch = 170 train_loss : 2.891768 , test loss : 3.117268\n",
      "epoch = 171 train_loss : 2.885070 , test loss : 3.111223\n",
      "epoch = 172 train_loss : 2.878242 , test loss : 3.105273\n",
      "epoch = 173 train_loss : 2.871549 , test loss : 3.099280\n",
      "epoch = 174 train_loss : 2.864994 , test loss : 3.093116\n",
      "epoch = 175 train_loss : 2.858738 , test loss : 3.087586\n",
      "epoch = 176 train_loss : 2.852421 , test loss : 3.081745\n",
      "epoch = 177 train_loss : 2.846018 , test loss : 3.076110\n",
      "epoch = 178 train_loss : 2.839874 , test loss : 3.070475\n",
      "epoch = 179 train_loss : 2.833824 , test loss : 3.065054\n",
      "epoch = 180 train_loss : 2.827990 , test loss : 3.059752\n",
      "epoch = 181 train_loss : 2.822145 , test loss : 3.054720\n",
      "epoch = 182 train_loss : 2.816346 , test loss : 3.049501\n",
      "epoch = 183 train_loss : 2.810714 , test loss : 3.044513\n",
      "epoch = 184 train_loss : 2.805080 , test loss : 3.039351\n",
      "epoch = 185 train_loss : 2.799593 , test loss : 3.034394\n",
      "epoch = 186 train_loss : 2.793887 , test loss : 3.029201\n",
      "epoch = 187 train_loss : 2.788466 , test loss : 3.024308\n",
      "epoch = 188 train_loss : 2.782996 , test loss : 3.019460\n",
      "epoch = 189 train_loss : 2.777716 , test loss : 3.014690\n",
      "epoch = 190 train_loss : 2.772357 , test loss : 3.010030\n",
      "epoch = 191 train_loss : 2.767085 , test loss : 3.005161\n",
      "epoch = 192 train_loss : 2.761938 , test loss : 3.000707\n",
      "epoch = 193 train_loss : 2.756731 , test loss : 2.995809\n",
      "epoch = 194 train_loss : 2.751608 , test loss : 2.991103\n",
      "epoch = 195 train_loss : 2.746524 , test loss : 2.986604\n",
      "epoch = 196 train_loss : 2.741367 , test loss : 2.981896\n",
      "epoch = 197 train_loss : 2.736269 , test loss : 2.977303\n",
      "epoch = 198 train_loss : 2.731085 , test loss : 2.972722\n",
      "epoch = 199 train_loss : 2.726187 , test loss : 2.968171\n",
      "epoch = 200 train_loss : 2.721219 , test loss : 2.963741\n",
      "epoch = 201 train_loss : 2.716212 , test loss : 2.959203\n",
      "epoch = 202 train_loss : 2.711246 , test loss : 2.954608\n",
      "epoch = 203 train_loss : 2.706339 , test loss : 2.950086\n",
      "epoch = 204 train_loss : 2.701399 , test loss : 2.945508\n",
      "epoch = 205 train_loss : 2.696529 , test loss : 2.941093\n",
      "epoch = 206 train_loss : 2.691618 , test loss : 2.936523\n",
      "epoch = 207 train_loss : 2.686713 , test loss : 2.932295\n",
      "epoch = 208 train_loss : 2.681907 , test loss : 2.927757\n",
      "epoch = 209 train_loss : 2.677032 , test loss : 2.923320\n",
      "epoch = 210 train_loss : 2.672211 , test loss : 2.918960\n",
      "epoch = 211 train_loss : 2.667342 , test loss : 2.914494\n",
      "epoch = 212 train_loss : 2.662510 , test loss : 2.910030\n",
      "epoch = 213 train_loss : 2.657724 , test loss : 2.905601\n",
      "epoch = 214 train_loss : 2.652889 , test loss : 2.901166\n",
      "epoch = 215 train_loss : 2.648103 , test loss : 2.896908\n",
      "epoch = 216 train_loss : 2.643275 , test loss : 2.892360\n",
      "epoch = 217 train_loss : 2.638432 , test loss : 2.887844\n",
      "epoch = 218 train_loss : 2.633671 , test loss : 2.883423\n",
      "epoch = 219 train_loss : 2.628780 , test loss : 2.879239\n",
      "epoch = 220 train_loss : 2.623990 , test loss : 2.874779\n",
      "epoch = 221 train_loss : 2.619104 , test loss : 2.870122\n",
      "epoch = 222 train_loss : 2.614274 , test loss : 2.865713\n",
      "epoch = 223 train_loss : 2.609324 , test loss : 2.861121\n",
      "epoch = 224 train_loss : 2.604515 , test loss : 2.856548\n",
      "epoch = 225 train_loss : 2.599703 , test loss : 2.852039\n",
      "epoch = 226 train_loss : 2.594881 , test loss : 2.847493\n",
      "epoch = 227 train_loss : 2.590050 , test loss : 2.842987\n",
      "epoch = 228 train_loss : 2.585267 , test loss : 2.838489\n",
      "epoch = 229 train_loss : 2.580420 , test loss : 2.833697\n",
      "epoch = 230 train_loss : 2.575556 , test loss : 2.829419\n",
      "epoch = 231 train_loss : 2.570726 , test loss : 2.824780\n",
      "epoch = 232 train_loss : 2.565919 , test loss : 2.820222\n",
      "epoch = 233 train_loss : 2.561063 , test loss : 2.815616\n",
      "epoch = 234 train_loss : 2.556263 , test loss : 2.810950\n",
      "epoch = 235 train_loss : 2.551443 , test loss : 2.806208\n",
      "epoch = 236 train_loss : 2.546652 , test loss : 2.801690\n",
      "epoch = 237 train_loss : 2.541827 , test loss : 2.797115\n",
      "epoch = 238 train_loss : 2.536868 , test loss : 2.792325\n",
      "epoch = 239 train_loss : 2.531978 , test loss : 2.787702\n",
      "epoch = 240 train_loss : 2.527091 , test loss : 2.782897\n",
      "epoch = 241 train_loss : 2.522227 , test loss : 2.778216\n",
      "epoch = 242 train_loss : 2.517296 , test loss : 2.773588\n",
      "epoch = 243 train_loss : 2.512357 , test loss : 2.768968\n",
      "epoch = 244 train_loss : 2.507499 , test loss : 2.764230\n",
      "epoch = 245 train_loss : 2.502591 , test loss : 2.759232\n",
      "epoch = 246 train_loss : 2.497728 , test loss : 2.754578\n",
      "epoch = 247 train_loss : 2.492834 , test loss : 2.749897\n",
      "epoch = 248 train_loss : 2.487879 , test loss : 2.745103\n",
      "epoch = 249 train_loss : 2.482978 , test loss : 2.740302\n",
      "epoch = 250 train_loss : 2.478092 , test loss : 2.735493\n",
      "epoch = 251 train_loss : 2.473132 , test loss : 2.730667\n",
      "epoch = 252 train_loss : 2.468241 , test loss : 2.725719\n",
      "epoch = 253 train_loss : 2.463338 , test loss : 2.720916\n",
      "epoch = 254 train_loss : 2.458407 , test loss : 2.715978\n",
      "epoch = 255 train_loss : 2.453590 , test loss : 2.711306\n",
      "epoch = 256 train_loss : 2.448662 , test loss : 2.706303\n",
      "epoch = 257 train_loss : 2.443805 , test loss : 2.701461\n",
      "epoch = 258 train_loss : 2.438907 , test loss : 2.696507\n",
      "epoch = 259 train_loss : 2.433958 , test loss : 2.691456\n",
      "epoch = 260 train_loss : 2.429122 , test loss : 2.686629\n",
      "epoch = 261 train_loss : 2.424233 , test loss : 2.681564\n",
      "epoch = 262 train_loss : 2.419392 , test loss : 2.676521\n",
      "epoch = 263 train_loss : 2.414546 , test loss : 2.672037\n",
      "epoch = 264 train_loss : 2.409567 , test loss : 2.667179\n",
      "epoch = 265 train_loss : 2.404719 , test loss : 2.662055\n",
      "epoch = 266 train_loss : 2.399780 , test loss : 2.657173\n",
      "epoch = 267 train_loss : 2.394861 , test loss : 2.652345\n",
      "epoch = 268 train_loss : 2.390059 , test loss : 2.647542\n",
      "epoch = 269 train_loss : 2.385183 , test loss : 2.642705\n",
      "epoch = 270 train_loss : 2.380212 , test loss : 2.637804\n",
      "epoch = 271 train_loss : 2.375362 , test loss : 2.632685\n",
      "epoch = 272 train_loss : 2.370520 , test loss : 2.627903\n",
      "epoch = 273 train_loss : 2.365553 , test loss : 2.623091\n",
      "epoch = 274 train_loss : 2.360668 , test loss : 2.618042\n",
      "epoch = 275 train_loss : 2.355790 , test loss : 2.613309\n",
      "epoch = 276 train_loss : 2.350953 , test loss : 2.608384\n",
      "epoch = 277 train_loss : 2.346169 , test loss : 2.603398\n",
      "epoch = 278 train_loss : 2.341435 , test loss : 2.598796\n",
      "epoch = 279 train_loss : 2.336541 , test loss : 2.594044\n",
      "epoch = 280 train_loss : 2.331807 , test loss : 2.589175\n",
      "epoch = 281 train_loss : 2.326898 , test loss : 2.584348\n",
      "epoch = 282 train_loss : 2.322111 , test loss : 2.579604\n",
      "epoch = 283 train_loss : 2.317306 , test loss : 2.574842\n",
      "epoch = 284 train_loss : 2.312426 , test loss : 2.569865\n",
      "epoch = 285 train_loss : 2.307579 , test loss : 2.565111\n",
      "epoch = 286 train_loss : 2.302793 , test loss : 2.560041\n",
      "epoch = 287 train_loss : 2.297969 , test loss : 2.555252\n",
      "epoch = 288 train_loss : 2.293171 , test loss : 2.550492\n",
      "epoch = 289 train_loss : 2.288376 , test loss : 2.545638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 290 train_loss : 2.283571 , test loss : 2.540809\n",
      "epoch = 291 train_loss : 2.278741 , test loss : 2.536167\n",
      "epoch = 292 train_loss : 2.274041 , test loss : 2.531569\n",
      "epoch = 293 train_loss : 2.269097 , test loss : 2.526529\n",
      "epoch = 294 train_loss : 2.264227 , test loss : 2.521821\n",
      "epoch = 295 train_loss : 2.259400 , test loss : 2.516807\n",
      "epoch = 296 train_loss : 2.254527 , test loss : 2.512112\n",
      "epoch = 297 train_loss : 2.249724 , test loss : 2.506962\n",
      "epoch = 298 train_loss : 2.244932 , test loss : 2.502254\n",
      "epoch = 299 train_loss : 2.240043 , test loss : 2.497167\n",
      "epoch = 300 train_loss : 2.235164 , test loss : 2.492429\n",
      "epoch = 301 train_loss : 2.230303 , test loss : 2.487216\n",
      "epoch = 302 train_loss : 2.225441 , test loss : 2.482330\n",
      "epoch = 303 train_loss : 2.220475 , test loss : 2.477428\n",
      "epoch = 304 train_loss : 2.215606 , test loss : 2.472494\n",
      "epoch = 305 train_loss : 2.210679 , test loss : 2.467577\n",
      "epoch = 306 train_loss : 2.205823 , test loss : 2.462949\n",
      "epoch = 307 train_loss : 2.200867 , test loss : 2.458145\n",
      "epoch = 308 train_loss : 2.196026 , test loss : 2.453409\n",
      "epoch = 309 train_loss : 2.191151 , test loss : 2.448479\n",
      "epoch = 310 train_loss : 2.186215 , test loss : 2.443789\n",
      "epoch = 311 train_loss : 2.181283 , test loss : 2.438868\n",
      "epoch = 312 train_loss : 2.176471 , test loss : 2.434083\n",
      "epoch = 313 train_loss : 2.171540 , test loss : 2.429131\n",
      "epoch = 314 train_loss : 2.166494 , test loss : 2.424253\n",
      "epoch = 315 train_loss : 2.161740 , test loss : 2.419377\n",
      "epoch = 316 train_loss : 2.156857 , test loss : 2.414709\n",
      "epoch = 317 train_loss : 2.151930 , test loss : 2.409602\n",
      "epoch = 318 train_loss : 2.146878 , test loss : 2.404858\n",
      "epoch = 319 train_loss : 2.142157 , test loss : 2.400177\n",
      "epoch = 320 train_loss : 2.137341 , test loss : 2.395332\n",
      "epoch = 321 train_loss : 2.132549 , test loss : 2.390513\n",
      "epoch = 322 train_loss : 2.127617 , test loss : 2.385640\n",
      "epoch = 323 train_loss : 2.122806 , test loss : 2.380876\n",
      "epoch = 324 train_loss : 2.117912 , test loss : 2.375839\n",
      "epoch = 325 train_loss : 2.113097 , test loss : 2.371150\n",
      "epoch = 326 train_loss : 2.108387 , test loss : 2.366428\n",
      "epoch = 327 train_loss : 2.103429 , test loss : 2.361805\n",
      "epoch = 328 train_loss : 2.098710 , test loss : 2.357054\n",
      "epoch = 329 train_loss : 2.094006 , test loss : 2.352560\n",
      "epoch = 330 train_loss : 2.089234 , test loss : 2.347610\n",
      "epoch = 331 train_loss : 2.084514 , test loss : 2.343108\n",
      "epoch = 332 train_loss : 2.079724 , test loss : 2.338352\n",
      "epoch = 333 train_loss : 2.075008 , test loss : 2.333829\n",
      "epoch = 334 train_loss : 2.070361 , test loss : 2.329181\n",
      "epoch = 335 train_loss : 2.065799 , test loss : 2.324683\n",
      "epoch = 336 train_loss : 2.061175 , test loss : 2.319986\n",
      "epoch = 337 train_loss : 2.056605 , test loss : 2.315563\n",
      "epoch = 338 train_loss : 2.051999 , test loss : 2.310726\n",
      "epoch = 339 train_loss : 2.047343 , test loss : 2.306250\n",
      "epoch = 340 train_loss : 2.042849 , test loss : 2.301839\n",
      "epoch = 341 train_loss : 2.038326 , test loss : 2.297344\n",
      "epoch = 342 train_loss : 2.033889 , test loss : 2.292915\n",
      "epoch = 343 train_loss : 2.029390 , test loss : 2.288321\n",
      "epoch = 344 train_loss : 2.024965 , test loss : 2.283967\n",
      "epoch = 345 train_loss : 2.020517 , test loss : 2.279459\n",
      "epoch = 346 train_loss : 2.016055 , test loss : 2.275003\n",
      "epoch = 347 train_loss : 2.011603 , test loss : 2.270533\n",
      "epoch = 348 train_loss : 2.007209 , test loss : 2.265912\n",
      "epoch = 349 train_loss : 2.002827 , test loss : 2.261640\n",
      "epoch = 350 train_loss : 1.998460 , test loss : 2.257400\n",
      "epoch = 351 train_loss : 1.994085 , test loss : 2.253079\n",
      "epoch = 352 train_loss : 1.989787 , test loss : 2.248964\n",
      "epoch = 353 train_loss : 1.985468 , test loss : 2.244462\n",
      "epoch = 354 train_loss : 1.981176 , test loss : 2.240283\n",
      "epoch = 355 train_loss : 1.976912 , test loss : 2.236169\n",
      "epoch = 356 train_loss : 1.972660 , test loss : 2.231983\n",
      "epoch = 357 train_loss : 1.968353 , test loss : 2.227507\n",
      "epoch = 358 train_loss : 1.964117 , test loss : 2.223412\n",
      "epoch = 359 train_loss : 1.959975 , test loss : 2.219325\n",
      "epoch = 360 train_loss : 1.955825 , test loss : 2.214891\n",
      "epoch = 361 train_loss : 1.951660 , test loss : 2.210908\n",
      "epoch = 362 train_loss : 1.947497 , test loss : 2.206499\n",
      "epoch = 363 train_loss : 1.943436 , test loss : 2.202616\n",
      "epoch = 364 train_loss : 1.939301 , test loss : 2.198735\n",
      "epoch = 365 train_loss : 1.935166 , test loss : 2.194337\n",
      "epoch = 366 train_loss : 1.931111 , test loss : 2.190165\n",
      "epoch = 367 train_loss : 1.926947 , test loss : 2.186065\n",
      "epoch = 368 train_loss : 1.922931 , test loss : 2.182038\n",
      "epoch = 369 train_loss : 1.918959 , test loss : 2.178072\n",
      "epoch = 370 train_loss : 1.914985 , test loss : 2.174304\n",
      "epoch = 371 train_loss : 1.911019 , test loss : 2.170041\n",
      "epoch = 372 train_loss : 1.906994 , test loss : 2.166209\n",
      "epoch = 373 train_loss : 1.902989 , test loss : 2.161880\n",
      "epoch = 374 train_loss : 1.899073 , test loss : 2.157954\n",
      "epoch = 375 train_loss : 1.895082 , test loss : 2.154132\n",
      "epoch = 376 train_loss : 1.891144 , test loss : 2.150083\n",
      "epoch = 377 train_loss : 1.887229 , test loss : 2.146111\n",
      "epoch = 378 train_loss : 1.883278 , test loss : 2.141975\n",
      "epoch = 379 train_loss : 1.879417 , test loss : 2.138073\n",
      "epoch = 380 train_loss : 1.875610 , test loss : 2.133967\n",
      "epoch = 381 train_loss : 1.871790 , test loss : 2.130299\n",
      "epoch = 382 train_loss : 1.868014 , test loss : 2.126569\n",
      "epoch = 383 train_loss : 1.864134 , test loss : 2.122391\n",
      "epoch = 384 train_loss : 1.860473 , test loss : 2.118697\n",
      "epoch = 385 train_loss : 1.856593 , test loss : 2.114805\n",
      "epoch = 386 train_loss : 1.852786 , test loss : 2.110906\n",
      "epoch = 387 train_loss : 1.849100 , test loss : 2.106917\n",
      "epoch = 388 train_loss : 1.845395 , test loss : 2.103238\n",
      "epoch = 389 train_loss : 1.841669 , test loss : 2.099717\n",
      "epoch = 390 train_loss : 1.837935 , test loss : 2.095945\n",
      "epoch = 391 train_loss : 1.834222 , test loss : 2.092228\n",
      "epoch = 392 train_loss : 1.830593 , test loss : 2.088275\n",
      "epoch = 393 train_loss : 1.826936 , test loss : 2.084835\n",
      "epoch = 394 train_loss : 1.823289 , test loss : 2.080870\n",
      "epoch = 395 train_loss : 1.819574 , test loss : 2.077091\n",
      "epoch = 396 train_loss : 1.816022 , test loss : 2.073913\n",
      "epoch = 397 train_loss : 1.812516 , test loss : 2.070332\n",
      "epoch = 398 train_loss : 1.808944 , test loss : 2.066671\n",
      "epoch = 399 train_loss : 1.805296 , test loss : 2.062923\n",
      "epoch = 400 train_loss : 1.801742 , test loss : 2.059212\n",
      "epoch = 401 train_loss : 1.798196 , test loss : 2.055673\n",
      "epoch = 402 train_loss : 1.794674 , test loss : 2.052366\n",
      "epoch = 403 train_loss : 1.791223 , test loss : 2.048841\n",
      "epoch = 404 train_loss : 1.787642 , test loss : 2.044809\n",
      "epoch = 405 train_loss : 1.784118 , test loss : 2.041448\n",
      "epoch = 406 train_loss : 1.780580 , test loss : 2.037695\n",
      "epoch = 407 train_loss : 1.777142 , test loss : 2.034196\n",
      "epoch = 408 train_loss : 1.773688 , test loss : 2.030425\n",
      "epoch = 409 train_loss : 1.770210 , test loss : 2.027308\n",
      "epoch = 410 train_loss : 1.766796 , test loss : 2.023732\n",
      "epoch = 411 train_loss : 1.763337 , test loss : 2.020167\n",
      "epoch = 412 train_loss : 1.759934 , test loss : 2.016908\n",
      "epoch = 413 train_loss : 1.756648 , test loss : 2.013622\n",
      "epoch = 414 train_loss : 1.753189 , test loss : 2.009660\n",
      "epoch = 415 train_loss : 1.749851 , test loss : 2.006321\n",
      "epoch = 416 train_loss : 1.746539 , test loss : 2.002898\n",
      "epoch = 417 train_loss : 1.743249 , test loss : 1.999384\n",
      "epoch = 418 train_loss : 1.739972 , test loss : 1.996053\n",
      "epoch = 419 train_loss : 1.736608 , test loss : 1.992741\n",
      "epoch = 420 train_loss : 1.733405 , test loss : 1.989414\n",
      "epoch = 421 train_loss : 1.730103 , test loss : 1.985834\n",
      "epoch = 422 train_loss : 1.726729 , test loss : 1.982465\n",
      "epoch = 423 train_loss : 1.723540 , test loss : 1.979376\n",
      "epoch = 424 train_loss : 1.720278 , test loss : 1.975843\n",
      "epoch = 425 train_loss : 1.717033 , test loss : 1.972549\n",
      "epoch = 426 train_loss : 1.713867 , test loss : 1.969029\n",
      "epoch = 427 train_loss : 1.710588 , test loss : 1.965765\n",
      "epoch = 428 train_loss : 1.707442 , test loss : 1.962705\n",
      "epoch = 429 train_loss : 1.704270 , test loss : 1.959051\n",
      "epoch = 430 train_loss : 1.701087 , test loss : 1.955919\n",
      "epoch = 431 train_loss : 1.697982 , test loss : 1.952611\n",
      "epoch = 432 train_loss : 1.694763 , test loss : 1.949318\n",
      "epoch = 433 train_loss : 1.691597 , test loss : 1.946100\n",
      "epoch = 434 train_loss : 1.688512 , test loss : 1.942825\n",
      "epoch = 435 train_loss : 1.685441 , test loss : 1.939920\n",
      "epoch = 436 train_loss : 1.682384 , test loss : 1.936335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 437 train_loss : 1.679372 , test loss : 1.933469\n",
      "epoch = 438 train_loss : 1.676344 , test loss : 1.930094\n",
      "epoch = 439 train_loss : 1.673285 , test loss : 1.926675\n",
      "epoch = 440 train_loss : 1.670315 , test loss : 1.923923\n",
      "epoch = 441 train_loss : 1.667343 , test loss : 1.920747\n",
      "epoch = 442 train_loss : 1.664323 , test loss : 1.917625\n",
      "epoch = 443 train_loss : 1.661394 , test loss : 1.914384\n",
      "epoch = 444 train_loss : 1.658387 , test loss : 1.911082\n",
      "epoch = 445 train_loss : 1.655467 , test loss : 1.908183\n",
      "epoch = 446 train_loss : 1.652579 , test loss : 1.905098\n",
      "epoch = 447 train_loss : 1.649664 , test loss : 1.902146\n",
      "epoch = 448 train_loss : 1.646764 , test loss : 1.898970\n",
      "epoch = 449 train_loss : 1.643876 , test loss : 1.895901\n",
      "epoch = 450 train_loss : 1.640983 , test loss : 1.893041\n",
      "epoch = 451 train_loss : 1.638132 , test loss : 1.890016\n",
      "epoch = 452 train_loss : 1.635273 , test loss : 1.887284\n",
      "epoch = 453 train_loss : 1.632379 , test loss : 1.884065\n",
      "epoch = 454 train_loss : 1.629521 , test loss : 1.880848\n",
      "epoch = 455 train_loss : 1.626711 , test loss : 1.878090\n",
      "epoch = 456 train_loss : 1.623922 , test loss : 1.875401\n",
      "epoch = 457 train_loss : 1.621077 , test loss : 1.871988\n",
      "epoch = 458 train_loss : 1.618242 , test loss : 1.869027\n",
      "epoch = 459 train_loss : 1.615493 , test loss : 1.866125\n",
      "epoch = 460 train_loss : 1.612646 , test loss : 1.862843\n",
      "epoch = 461 train_loss : 1.609914 , test loss : 1.860255\n",
      "epoch = 462 train_loss : 1.607066 , test loss : 1.857213\n",
      "epoch = 463 train_loss : 1.604300 , test loss : 1.854057\n",
      "epoch = 464 train_loss : 1.601460 , test loss : 1.851281\n",
      "epoch = 465 train_loss : 1.598698 , test loss : 1.848314\n",
      "epoch = 466 train_loss : 1.596016 , test loss : 1.845484\n",
      "epoch = 467 train_loss : 1.593223 , test loss : 1.842687\n",
      "epoch = 468 train_loss : 1.590445 , test loss : 1.839276\n",
      "epoch = 469 train_loss : 1.587743 , test loss : 1.836768\n",
      "epoch = 470 train_loss : 1.585104 , test loss : 1.834041\n",
      "epoch = 471 train_loss : 1.582382 , test loss : 1.831232\n",
      "epoch = 472 train_loss : 1.579682 , test loss : 1.828264\n",
      "epoch = 473 train_loss : 1.577014 , test loss : 1.825351\n",
      "epoch = 474 train_loss : 1.574390 , test loss : 1.822630\n",
      "epoch = 475 train_loss : 1.571713 , test loss : 1.819985\n",
      "epoch = 476 train_loss : 1.569101 , test loss : 1.817194\n",
      "epoch = 477 train_loss : 1.566459 , test loss : 1.814523\n",
      "epoch = 478 train_loss : 1.563875 , test loss : 1.811731\n",
      "epoch = 479 train_loss : 1.561268 , test loss : 1.809182\n",
      "epoch = 480 train_loss : 1.558625 , test loss : 1.806227\n",
      "epoch = 481 train_loss : 1.556052 , test loss : 1.803568\n",
      "epoch = 482 train_loss : 1.553465 , test loss : 1.800928\n",
      "epoch = 483 train_loss : 1.550943 , test loss : 1.798311\n",
      "epoch = 484 train_loss : 1.548418 , test loss : 1.795825\n",
      "epoch = 485 train_loss : 1.545840 , test loss : 1.793171\n",
      "epoch = 486 train_loss : 1.543333 , test loss : 1.790620\n",
      "epoch = 487 train_loss : 1.540857 , test loss : 1.788084\n",
      "epoch = 488 train_loss : 1.538332 , test loss : 1.785533\n",
      "epoch = 489 train_loss : 1.535892 , test loss : 1.782953\n",
      "epoch = 490 train_loss : 1.533372 , test loss : 1.780174\n",
      "epoch = 491 train_loss : 1.530943 , test loss : 1.777624\n",
      "epoch = 492 train_loss : 1.528458 , test loss : 1.775161\n",
      "epoch = 493 train_loss : 1.526034 , test loss : 1.772620\n",
      "epoch = 494 train_loss : 1.523591 , test loss : 1.770095\n",
      "epoch = 495 train_loss : 1.521168 , test loss : 1.767435\n",
      "epoch = 496 train_loss : 1.518721 , test loss : 1.764871\n",
      "epoch = 497 train_loss : 1.516340 , test loss : 1.762446\n",
      "epoch = 498 train_loss : 1.513943 , test loss : 1.760021\n",
      "epoch = 499 train_loss : 1.511567 , test loss : 1.757346\n",
      "epoch = 500 train_loss : 1.509143 , test loss : 1.754990\n",
      "epoch = 501 train_loss : 1.506788 , test loss : 1.752568\n",
      "epoch = 502 train_loss : 1.504421 , test loss : 1.750056\n",
      "epoch = 503 train_loss : 1.502057 , test loss : 1.747476\n",
      "epoch = 504 train_loss : 1.499719 , test loss : 1.745271\n",
      "epoch = 505 train_loss : 1.497409 , test loss : 1.742703\n",
      "epoch = 506 train_loss : 1.495077 , test loss : 1.740454\n",
      "epoch = 507 train_loss : 1.492702 , test loss : 1.737928\n",
      "epoch = 508 train_loss : 1.490406 , test loss : 1.735665\n",
      "epoch = 509 train_loss : 1.488147 , test loss : 1.733106\n",
      "epoch = 510 train_loss : 1.485823 , test loss : 1.730844\n",
      "epoch = 511 train_loss : 1.483504 , test loss : 1.728484\n",
      "epoch = 512 train_loss : 1.481274 , test loss : 1.726161\n",
      "epoch = 513 train_loss : 1.478993 , test loss : 1.723802\n",
      "epoch = 514 train_loss : 1.476752 , test loss : 1.721681\n",
      "epoch = 515 train_loss : 1.474622 , test loss : 1.719222\n",
      "epoch = 516 train_loss : 1.472263 , test loss : 1.716754\n",
      "epoch = 517 train_loss : 1.470046 , test loss : 1.714546\n",
      "epoch = 518 train_loss : 1.467835 , test loss : 1.712411\n",
      "epoch = 519 train_loss : 1.465643 , test loss : 1.709908\n",
      "epoch = 520 train_loss : 1.463501 , test loss : 1.707586\n",
      "epoch = 521 train_loss : 1.461301 , test loss : 1.705645\n",
      "epoch = 522 train_loss : 1.459103 , test loss : 1.703214\n",
      "epoch = 523 train_loss : 1.456972 , test loss : 1.700857\n",
      "epoch = 524 train_loss : 1.454789 , test loss : 1.698762\n",
      "epoch = 525 train_loss : 1.452644 , test loss : 1.696360\n",
      "epoch = 526 train_loss : 1.450541 , test loss : 1.694227\n",
      "epoch = 527 train_loss : 1.448433 , test loss : 1.692121\n",
      "epoch = 528 train_loss : 1.446263 , test loss : 1.689865\n",
      "epoch = 529 train_loss : 1.444170 , test loss : 1.687721\n",
      "epoch = 530 train_loss : 1.442139 , test loss : 1.685425\n",
      "epoch = 531 train_loss : 1.439971 , test loss : 1.683348\n",
      "epoch = 532 train_loss : 1.437928 , test loss : 1.681084\n",
      "epoch = 533 train_loss : 1.435877 , test loss : 1.679148\n",
      "epoch = 534 train_loss : 1.433793 , test loss : 1.677010\n",
      "epoch = 535 train_loss : 1.431742 , test loss : 1.674851\n",
      "epoch = 536 train_loss : 1.429745 , test loss : 1.672485\n",
      "epoch = 537 train_loss : 1.427707 , test loss : 1.670642\n",
      "epoch = 538 train_loss : 1.425634 , test loss : 1.668463\n",
      "epoch = 539 train_loss : 1.423639 , test loss : 1.666535\n",
      "epoch = 540 train_loss : 1.421586 , test loss : 1.664533\n",
      "epoch = 541 train_loss : 1.419546 , test loss : 1.662396\n",
      "epoch = 542 train_loss : 1.417595 , test loss : 1.660188\n",
      "epoch = 543 train_loss : 1.415620 , test loss : 1.657837\n",
      "epoch = 544 train_loss : 1.413613 , test loss : 1.655921\n",
      "epoch = 545 train_loss : 1.411696 , test loss : 1.653852\n",
      "epoch = 546 train_loss : 1.409691 , test loss : 1.652160\n",
      "epoch = 547 train_loss : 1.407740 , test loss : 1.650089\n",
      "epoch = 548 train_loss : 1.405747 , test loss : 1.647840\n",
      "epoch = 549 train_loss : 1.403767 , test loss : 1.645969\n",
      "epoch = 550 train_loss : 1.401846 , test loss : 1.644204\n",
      "epoch = 551 train_loss : 1.399920 , test loss : 1.642051\n",
      "epoch = 552 train_loss : 1.398015 , test loss : 1.640080\n",
      "epoch = 553 train_loss : 1.396102 , test loss : 1.638058\n",
      "epoch = 554 train_loss : 1.394192 , test loss : 1.635996\n",
      "epoch = 555 train_loss : 1.392291 , test loss : 1.634079\n",
      "epoch = 556 train_loss : 1.390426 , test loss : 1.632370\n",
      "epoch = 557 train_loss : 1.388580 , test loss : 1.630400\n",
      "epoch = 558 train_loss : 1.386771 , test loss : 1.628663\n",
      "epoch = 559 train_loss : 1.384816 , test loss : 1.626718\n",
      "epoch = 560 train_loss : 1.382976 , test loss : 1.624521\n",
      "epoch = 561 train_loss : 1.381138 , test loss : 1.622542\n",
      "epoch = 562 train_loss : 1.379293 , test loss : 1.620822\n",
      "epoch = 563 train_loss : 1.377460 , test loss : 1.618891\n",
      "epoch = 564 train_loss : 1.375663 , test loss : 1.616923\n",
      "epoch = 565 train_loss : 1.373840 , test loss : 1.615116\n",
      "epoch = 566 train_loss : 1.372040 , test loss : 1.613134\n",
      "epoch = 567 train_loss : 1.370257 , test loss : 1.611118\n",
      "epoch = 568 train_loss : 1.368448 , test loss : 1.609435\n",
      "epoch = 569 train_loss : 1.366689 , test loss : 1.607798\n",
      "epoch = 570 train_loss : 1.364911 , test loss : 1.605601\n",
      "epoch = 571 train_loss : 1.363193 , test loss : 1.603961\n",
      "epoch = 572 train_loss : 1.361446 , test loss : 1.602236\n",
      "epoch = 573 train_loss : 1.359751 , test loss : 1.600361\n",
      "epoch = 574 train_loss : 1.357939 , test loss : 1.598701\n",
      "epoch = 575 train_loss : 1.356188 , test loss : 1.596889\n",
      "epoch = 576 train_loss : 1.354455 , test loss : 1.595219\n",
      "epoch = 577 train_loss : 1.352686 , test loss : 1.593210\n",
      "epoch = 578 train_loss : 1.350977 , test loss : 1.591329\n",
      "epoch = 579 train_loss : 1.349312 , test loss : 1.589757\n",
      "epoch = 580 train_loss : 1.347623 , test loss : 1.587723\n",
      "epoch = 581 train_loss : 1.345916 , test loss : 1.586001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 582 train_loss : 1.344221 , test loss : 1.584225\n",
      "epoch = 583 train_loss : 1.342531 , test loss : 1.582417\n",
      "epoch = 584 train_loss : 1.340884 , test loss : 1.580827\n",
      "epoch = 585 train_loss : 1.339222 , test loss : 1.579191\n",
      "epoch = 586 train_loss : 1.337587 , test loss : 1.577494\n",
      "epoch = 587 train_loss : 1.335931 , test loss : 1.575678\n",
      "epoch = 588 train_loss : 1.334273 , test loss : 1.573884\n",
      "epoch = 589 train_loss : 1.332630 , test loss : 1.572130\n",
      "epoch = 590 train_loss : 1.331019 , test loss : 1.570594\n",
      "epoch = 591 train_loss : 1.329408 , test loss : 1.568772\n",
      "epoch = 592 train_loss : 1.327811 , test loss : 1.567203\n",
      "epoch = 593 train_loss : 1.326171 , test loss : 1.565393\n",
      "epoch = 594 train_loss : 1.324562 , test loss : 1.563946\n",
      "epoch = 595 train_loss : 1.322950 , test loss : 1.562139\n",
      "epoch = 596 train_loss : 1.321403 , test loss : 1.560698\n",
      "epoch = 597 train_loss : 1.319811 , test loss : 1.558861\n",
      "epoch = 598 train_loss : 1.318227 , test loss : 1.557367\n",
      "epoch = 599 train_loss : 1.316673 , test loss : 1.555698\n",
      "epoch = 600 train_loss : 1.315133 , test loss : 1.554034\n",
      "epoch = 601 train_loss : 1.313595 , test loss : 1.552361\n",
      "epoch = 602 train_loss : 1.311995 , test loss : 1.550745\n",
      "epoch = 603 train_loss : 1.310440 , test loss : 1.549058\n",
      "epoch = 604 train_loss : 1.308850 , test loss : 1.547553\n",
      "epoch = 605 train_loss : 1.307307 , test loss : 1.545864\n",
      "epoch = 606 train_loss : 1.305769 , test loss : 1.544334\n",
      "epoch = 607 train_loss : 1.304266 , test loss : 1.542778\n",
      "epoch = 608 train_loss : 1.302711 , test loss : 1.540991\n",
      "epoch = 609 train_loss : 1.301196 , test loss : 1.539393\n",
      "epoch = 610 train_loss : 1.299632 , test loss : 1.537938\n",
      "epoch = 611 train_loss : 1.298156 , test loss : 1.536663\n",
      "epoch = 612 train_loss : 1.296725 , test loss : 1.535056\n",
      "epoch = 613 train_loss : 1.295131 , test loss : 1.533491\n",
      "epoch = 614 train_loss : 1.293662 , test loss : 1.531770\n",
      "epoch = 615 train_loss : 1.292123 , test loss : 1.530217\n",
      "epoch = 616 train_loss : 1.290654 , test loss : 1.528746\n",
      "epoch = 617 train_loss : 1.289140 , test loss : 1.527198\n",
      "epoch = 618 train_loss : 1.287703 , test loss : 1.525786\n",
      "epoch = 619 train_loss : 1.286200 , test loss : 1.524088\n",
      "epoch = 620 train_loss : 1.284771 , test loss : 1.522715\n",
      "epoch = 621 train_loss : 1.283293 , test loss : 1.521254\n",
      "epoch = 622 train_loss : 1.281863 , test loss : 1.519561\n",
      "epoch = 623 train_loss : 1.280386 , test loss : 1.518171\n",
      "epoch = 624 train_loss : 1.278957 , test loss : 1.516724\n",
      "epoch = 625 train_loss : 1.277502 , test loss : 1.515188\n",
      "epoch = 626 train_loss : 1.276044 , test loss : 1.513848\n",
      "epoch = 627 train_loss : 1.274612 , test loss : 1.512407\n",
      "epoch = 628 train_loss : 1.273213 , test loss : 1.510626\n",
      "epoch = 629 train_loss : 1.271801 , test loss : 1.509240\n",
      "epoch = 630 train_loss : 1.270355 , test loss : 1.507834\n",
      "epoch = 631 train_loss : 1.268926 , test loss : 1.506220\n",
      "epoch = 632 train_loss : 1.267512 , test loss : 1.504783\n",
      "epoch = 633 train_loss : 1.266115 , test loss : 1.503599\n",
      "epoch = 634 train_loss : 1.264771 , test loss : 1.501994\n",
      "epoch = 635 train_loss : 1.263350 , test loss : 1.500952\n",
      "epoch = 636 train_loss : 1.261935 , test loss : 1.499195\n",
      "epoch = 637 train_loss : 1.260542 , test loss : 1.497894\n",
      "epoch = 638 train_loss : 1.259233 , test loss : 1.496338\n",
      "epoch = 639 train_loss : 1.257789 , test loss : 1.494886\n",
      "epoch = 640 train_loss : 1.256434 , test loss : 1.493477\n",
      "epoch = 641 train_loss : 1.255062 , test loss : 1.492182\n",
      "epoch = 642 train_loss : 1.253732 , test loss : 1.490860\n",
      "epoch = 643 train_loss : 1.252424 , test loss : 1.489695\n",
      "epoch = 644 train_loss : 1.251083 , test loss : 1.488250\n",
      "epoch = 645 train_loss : 1.249749 , test loss : 1.486982\n",
      "epoch = 646 train_loss : 1.248412 , test loss : 1.485565\n",
      "epoch = 647 train_loss : 1.247120 , test loss : 1.484279\n",
      "epoch = 648 train_loss : 1.245812 , test loss : 1.482874\n",
      "epoch = 649 train_loss : 1.244501 , test loss : 1.481469\n",
      "epoch = 650 train_loss : 1.243206 , test loss : 1.480105\n",
      "epoch = 651 train_loss : 1.241935 , test loss : 1.478881\n",
      "epoch = 652 train_loss : 1.240607 , test loss : 1.477361\n",
      "epoch = 653 train_loss : 1.239328 , test loss : 1.476003\n",
      "epoch = 654 train_loss : 1.238047 , test loss : 1.474743\n",
      "epoch = 655 train_loss : 1.236800 , test loss : 1.473532\n",
      "epoch = 656 train_loss : 1.235539 , test loss : 1.472114\n",
      "epoch = 657 train_loss : 1.234251 , test loss : 1.470726\n",
      "epoch = 658 train_loss : 1.233002 , test loss : 1.469579\n",
      "epoch = 659 train_loss : 1.231772 , test loss : 1.468183\n",
      "epoch = 660 train_loss : 1.230601 , test loss : 1.467052\n",
      "epoch = 661 train_loss : 1.229288 , test loss : 1.465714\n",
      "epoch = 662 train_loss : 1.228035 , test loss : 1.464468\n",
      "epoch = 663 train_loss : 1.226838 , test loss : 1.463182\n",
      "epoch = 664 train_loss : 1.225626 , test loss : 1.462135\n",
      "epoch = 665 train_loss : 1.224429 , test loss : 1.460895\n",
      "epoch = 666 train_loss : 1.223215 , test loss : 1.459666\n",
      "epoch = 667 train_loss : 1.222016 , test loss : 1.458254\n",
      "epoch = 668 train_loss : 1.220856 , test loss : 1.457225\n",
      "epoch = 669 train_loss : 1.219648 , test loss : 1.456095\n",
      "epoch = 670 train_loss : 1.218470 , test loss : 1.454792\n",
      "epoch = 671 train_loss : 1.217281 , test loss : 1.453366\n",
      "epoch = 672 train_loss : 1.216094 , test loss : 1.452440\n",
      "epoch = 673 train_loss : 1.214929 , test loss : 1.451221\n",
      "epoch = 674 train_loss : 1.213772 , test loss : 1.450192\n",
      "epoch = 675 train_loss : 1.212667 , test loss : 1.448809\n",
      "epoch = 676 train_loss : 1.211513 , test loss : 1.447802\n",
      "epoch = 677 train_loss : 1.210333 , test loss : 1.446602\n",
      "epoch = 678 train_loss : 1.209225 , test loss : 1.445563\n",
      "epoch = 679 train_loss : 1.208099 , test loss : 1.444379\n",
      "epoch = 680 train_loss : 1.206964 , test loss : 1.443260\n",
      "epoch = 681 train_loss : 1.205873 , test loss : 1.442070\n",
      "epoch = 682 train_loss : 1.204752 , test loss : 1.440933\n",
      "epoch = 683 train_loss : 1.203638 , test loss : 1.439858\n",
      "epoch = 684 train_loss : 1.202569 , test loss : 1.438874\n",
      "epoch = 685 train_loss : 1.201515 , test loss : 1.437762\n",
      "epoch = 686 train_loss : 1.200315 , test loss : 1.436539\n",
      "epoch = 687 train_loss : 1.199215 , test loss : 1.435427\n",
      "epoch = 688 train_loss : 1.198126 , test loss : 1.434421\n",
      "epoch = 689 train_loss : 1.197061 , test loss : 1.433086\n",
      "epoch = 690 train_loss : 1.196001 , test loss : 1.432402\n",
      "epoch = 691 train_loss : 1.194875 , test loss : 1.431076\n",
      "epoch = 692 train_loss : 1.193788 , test loss : 1.430071\n",
      "epoch = 693 train_loss : 1.192719 , test loss : 1.429075\n",
      "epoch = 694 train_loss : 1.191650 , test loss : 1.427880\n",
      "epoch = 695 train_loss : 1.190585 , test loss : 1.427008\n",
      "epoch = 696 train_loss : 1.189530 , test loss : 1.425728\n",
      "epoch = 697 train_loss : 1.188472 , test loss : 1.424940\n",
      "epoch = 698 train_loss : 1.187424 , test loss : 1.423841\n",
      "epoch = 699 train_loss : 1.186373 , test loss : 1.422836\n",
      "epoch = 700 train_loss : 1.185382 , test loss : 1.421928\n",
      "epoch = 701 train_loss : 1.184283 , test loss : 1.420821\n",
      "epoch = 702 train_loss : 1.183256 , test loss : 1.419797\n",
      "epoch = 703 train_loss : 1.182218 , test loss : 1.418626\n",
      "epoch = 704 train_loss : 1.181152 , test loss : 1.417682\n",
      "epoch = 705 train_loss : 1.180113 , test loss : 1.416616\n",
      "epoch = 706 train_loss : 1.179107 , test loss : 1.415573\n",
      "epoch = 707 train_loss : 1.178081 , test loss : 1.414488\n",
      "epoch = 708 train_loss : 1.177055 , test loss : 1.413392\n",
      "epoch = 709 train_loss : 1.176033 , test loss : 1.412399\n",
      "epoch = 710 train_loss : 1.175017 , test loss : 1.411481\n",
      "epoch = 711 train_loss : 1.174012 , test loss : 1.410557\n",
      "epoch = 712 train_loss : 1.172973 , test loss : 1.409547\n",
      "epoch = 713 train_loss : 1.171967 , test loss : 1.408703\n",
      "epoch = 714 train_loss : 1.170998 , test loss : 1.407621\n",
      "epoch = 715 train_loss : 1.169973 , test loss : 1.406603\n",
      "epoch = 716 train_loss : 1.168968 , test loss : 1.405590\n",
      "epoch = 717 train_loss : 1.167964 , test loss : 1.404655\n",
      "epoch = 718 train_loss : 1.166979 , test loss : 1.403622\n",
      "epoch = 719 train_loss : 1.166035 , test loss : 1.402745\n",
      "epoch = 720 train_loss : 1.165044 , test loss : 1.401576\n",
      "epoch = 721 train_loss : 1.164058 , test loss : 1.400776\n",
      "epoch = 722 train_loss : 1.163066 , test loss : 1.399749\n",
      "epoch = 723 train_loss : 1.162065 , test loss : 1.398736\n",
      "epoch = 724 train_loss : 1.161119 , test loss : 1.397729\n",
      "epoch = 725 train_loss : 1.160172 , test loss : 1.397032\n",
      "epoch = 726 train_loss : 1.159173 , test loss : 1.396115\n",
      "epoch = 727 train_loss : 1.158215 , test loss : 1.395017\n",
      "epoch = 728 train_loss : 1.157280 , test loss : 1.394023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 729 train_loss : 1.156290 , test loss : 1.393048\n",
      "epoch = 730 train_loss : 1.155369 , test loss : 1.392119\n",
      "epoch = 731 train_loss : 1.154449 , test loss : 1.391192\n",
      "epoch = 732 train_loss : 1.153457 , test loss : 1.390455\n",
      "epoch = 733 train_loss : 1.152532 , test loss : 1.389263\n",
      "epoch = 734 train_loss : 1.151614 , test loss : 1.388479\n",
      "epoch = 735 train_loss : 1.150728 , test loss : 1.387724\n",
      "epoch = 736 train_loss : 1.149721 , test loss : 1.386765\n",
      "epoch = 737 train_loss : 1.148777 , test loss : 1.385899\n",
      "epoch = 738 train_loss : 1.147864 , test loss : 1.385044\n",
      "epoch = 739 train_loss : 1.146977 , test loss : 1.384097\n",
      "epoch = 740 train_loss : 1.146016 , test loss : 1.383150\n",
      "epoch = 741 train_loss : 1.145174 , test loss : 1.382355\n",
      "epoch = 742 train_loss : 1.144198 , test loss : 1.381450\n",
      "epoch = 743 train_loss : 1.143415 , test loss : 1.380536\n",
      "epoch = 744 train_loss : 1.142372 , test loss : 1.379730\n",
      "epoch = 745 train_loss : 1.141520 , test loss : 1.378898\n",
      "epoch = 746 train_loss : 1.140598 , test loss : 1.377776\n",
      "epoch = 747 train_loss : 1.139711 , test loss : 1.376953\n",
      "epoch = 748 train_loss : 1.138817 , test loss : 1.376122\n",
      "epoch = 749 train_loss : 1.137959 , test loss : 1.375445\n",
      "epoch = 750 train_loss : 1.137034 , test loss : 1.374679\n",
      "epoch = 751 train_loss : 1.136157 , test loss : 1.373788\n",
      "epoch = 752 train_loss : 1.135272 , test loss : 1.372896\n",
      "epoch = 753 train_loss : 1.134398 , test loss : 1.372227\n",
      "epoch = 754 train_loss : 1.133529 , test loss : 1.371387\n",
      "epoch = 755 train_loss : 1.132656 , test loss : 1.370531\n",
      "epoch = 756 train_loss : 1.131802 , test loss : 1.369853\n",
      "epoch = 757 train_loss : 1.130904 , test loss : 1.368848\n",
      "epoch = 758 train_loss : 1.130055 , test loss : 1.367914\n",
      "epoch = 759 train_loss : 1.129150 , test loss : 1.367189\n",
      "epoch = 760 train_loss : 1.128407 , test loss : 1.366627\n",
      "epoch = 761 train_loss : 1.127517 , test loss : 1.365728\n",
      "epoch = 762 train_loss : 1.126603 , test loss : 1.364660\n",
      "epoch = 763 train_loss : 1.125761 , test loss : 1.364039\n",
      "epoch = 764 train_loss : 1.124909 , test loss : 1.363248\n",
      "epoch = 765 train_loss : 1.124062 , test loss : 1.362463\n",
      "epoch = 766 train_loss : 1.123229 , test loss : 1.361857\n",
      "epoch = 767 train_loss : 1.122420 , test loss : 1.361042\n",
      "epoch = 768 train_loss : 1.121550 , test loss : 1.360204\n",
      "epoch = 769 train_loss : 1.120735 , test loss : 1.359410\n",
      "epoch = 770 train_loss : 1.119952 , test loss : 1.358579\n",
      "epoch = 771 train_loss : 1.119097 , test loss : 1.357623\n",
      "epoch = 772 train_loss : 1.118272 , test loss : 1.356937\n",
      "epoch = 773 train_loss : 1.117452 , test loss : 1.356227\n",
      "epoch = 774 train_loss : 1.116646 , test loss : 1.355431\n",
      "epoch = 775 train_loss : 1.115863 , test loss : 1.354864\n",
      "epoch = 776 train_loss : 1.115018 , test loss : 1.354022\n",
      "epoch = 777 train_loss : 1.114260 , test loss : 1.353419\n",
      "epoch = 778 train_loss : 1.113383 , test loss : 1.352531\n",
      "epoch = 779 train_loss : 1.112623 , test loss : 1.351864\n",
      "epoch = 780 train_loss : 1.111813 , test loss : 1.351126\n",
      "epoch = 781 train_loss : 1.111007 , test loss : 1.350379\n",
      "epoch = 782 train_loss : 1.110273 , test loss : 1.349732\n",
      "epoch = 783 train_loss : 1.109412 , test loss : 1.349009\n",
      "epoch = 784 train_loss : 1.108645 , test loss : 1.348358\n",
      "epoch = 785 train_loss : 1.107840 , test loss : 1.347368\n",
      "epoch = 786 train_loss : 1.107031 , test loss : 1.346729\n",
      "epoch = 787 train_loss : 1.106256 , test loss : 1.346179\n",
      "epoch = 788 train_loss : 1.105488 , test loss : 1.345312\n",
      "epoch = 789 train_loss : 1.104704 , test loss : 1.344773\n",
      "epoch = 790 train_loss : 1.103964 , test loss : 1.344024\n",
      "epoch = 791 train_loss : 1.103197 , test loss : 1.343133\n",
      "epoch = 792 train_loss : 1.102390 , test loss : 1.342301\n",
      "epoch = 793 train_loss : 1.101611 , test loss : 1.341812\n",
      "epoch = 794 train_loss : 1.100876 , test loss : 1.341120\n",
      "epoch = 795 train_loss : 1.100101 , test loss : 1.340407\n",
      "epoch = 796 train_loss : 1.099350 , test loss : 1.339732\n",
      "epoch = 797 train_loss : 1.098585 , test loss : 1.339069\n",
      "epoch = 798 train_loss : 1.097923 , test loss : 1.338589\n",
      "epoch = 799 train_loss : 1.097083 , test loss : 1.337768\n",
      "epoch = 800 train_loss : 1.096350 , test loss : 1.337009\n",
      "epoch = 801 train_loss : 1.095650 , test loss : 1.336622\n",
      "epoch = 802 train_loss : 1.094940 , test loss : 1.335904\n",
      "epoch = 803 train_loss : 1.094096 , test loss : 1.335170\n",
      "epoch = 804 train_loss : 1.093390 , test loss : 1.334441\n",
      "epoch = 805 train_loss : 1.092651 , test loss : 1.333965\n",
      "epoch = 806 train_loss : 1.091918 , test loss : 1.333161\n",
      "epoch = 807 train_loss : 1.091209 , test loss : 1.332502\n",
      "epoch = 808 train_loss : 1.090513 , test loss : 1.331765\n",
      "epoch = 809 train_loss : 1.089753 , test loss : 1.331424\n",
      "epoch = 810 train_loss : 1.089021 , test loss : 1.330704\n",
      "epoch = 811 train_loss : 1.088304 , test loss : 1.330167\n",
      "epoch = 812 train_loss : 1.087587 , test loss : 1.329620\n",
      "epoch = 813 train_loss : 1.086902 , test loss : 1.328951\n",
      "epoch = 814 train_loss : 1.086150 , test loss : 1.328146\n",
      "epoch = 815 train_loss : 1.085449 , test loss : 1.327408\n",
      "epoch = 816 train_loss : 1.084722 , test loss : 1.326775\n",
      "epoch = 817 train_loss : 1.084017 , test loss : 1.326448\n",
      "epoch = 818 train_loss : 1.083344 , test loss : 1.325675\n",
      "epoch = 819 train_loss : 1.082626 , test loss : 1.325066\n",
      "epoch = 820 train_loss : 1.081943 , test loss : 1.324299\n",
      "epoch = 821 train_loss : 1.081240 , test loss : 1.323834\n",
      "epoch = 822 train_loss : 1.080529 , test loss : 1.323143\n",
      "epoch = 823 train_loss : 1.079844 , test loss : 1.322584\n",
      "epoch = 824 train_loss : 1.079162 , test loss : 1.322035\n",
      "epoch = 825 train_loss : 1.078465 , test loss : 1.321338\n",
      "epoch = 826 train_loss : 1.077760 , test loss : 1.320820\n",
      "epoch = 827 train_loss : 1.077128 , test loss : 1.320319\n",
      "epoch = 828 train_loss : 1.076463 , test loss : 1.319796\n",
      "epoch = 829 train_loss : 1.075704 , test loss : 1.318995\n",
      "epoch = 830 train_loss : 1.075056 , test loss : 1.318448\n",
      "epoch = 831 train_loss : 1.074330 , test loss : 1.317832\n",
      "epoch = 832 train_loss : 1.073650 , test loss : 1.317331\n",
      "epoch = 833 train_loss : 1.073028 , test loss : 1.316700\n",
      "epoch = 834 train_loss : 1.072294 , test loss : 1.316077\n",
      "epoch = 835 train_loss : 1.071732 , test loss : 1.315644\n",
      "epoch = 836 train_loss : 1.071014 , test loss : 1.315030\n",
      "epoch = 837 train_loss : 1.070312 , test loss : 1.314690\n",
      "epoch = 838 train_loss : 1.069600 , test loss : 1.313804\n",
      "epoch = 839 train_loss : 1.068966 , test loss : 1.313340\n",
      "epoch = 840 train_loss : 1.068274 , test loss : 1.312817\n",
      "epoch = 841 train_loss : 1.067643 , test loss : 1.312240\n",
      "epoch = 842 train_loss : 1.066959 , test loss : 1.311664\n",
      "epoch = 843 train_loss : 1.066369 , test loss : 1.311043\n",
      "epoch = 844 train_loss : 1.065660 , test loss : 1.310469\n",
      "epoch = 845 train_loss : 1.065033 , test loss : 1.309686\n",
      "epoch = 846 train_loss : 1.064326 , test loss : 1.309165\n",
      "epoch = 847 train_loss : 1.063686 , test loss : 1.308602\n",
      "epoch = 848 train_loss : 1.063058 , test loss : 1.308188\n",
      "epoch = 849 train_loss : 1.062442 , test loss : 1.307546\n",
      "epoch = 850 train_loss : 1.061761 , test loss : 1.307116\n",
      "epoch = 851 train_loss : 1.061155 , test loss : 1.306446\n",
      "epoch = 852 train_loss : 1.060585 , test loss : 1.306106\n",
      "epoch = 853 train_loss : 1.059866 , test loss : 1.305417\n",
      "epoch = 854 train_loss : 1.059257 , test loss : 1.305050\n",
      "epoch = 855 train_loss : 1.058622 , test loss : 1.304554\n",
      "epoch = 856 train_loss : 1.057990 , test loss : 1.303916\n",
      "epoch = 857 train_loss : 1.057384 , test loss : 1.303304\n",
      "epoch = 858 train_loss : 1.056769 , test loss : 1.302802\n",
      "epoch = 859 train_loss : 1.056155 , test loss : 1.302505\n",
      "epoch = 860 train_loss : 1.055526 , test loss : 1.301929\n",
      "epoch = 861 train_loss : 1.054938 , test loss : 1.301507\n",
      "epoch = 862 train_loss : 1.054317 , test loss : 1.300661\n",
      "epoch = 863 train_loss : 1.053690 , test loss : 1.300276\n",
      "epoch = 864 train_loss : 1.053075 , test loss : 1.299623\n",
      "epoch = 865 train_loss : 1.052568 , test loss : 1.299180\n",
      "epoch = 866 train_loss : 1.051916 , test loss : 1.298507\n",
      "epoch = 867 train_loss : 1.051285 , test loss : 1.298197\n",
      "epoch = 868 train_loss : 1.050673 , test loss : 1.297535\n",
      "epoch = 869 train_loss : 1.050094 , test loss : 1.297147\n",
      "epoch = 870 train_loss : 1.049492 , test loss : 1.296445\n",
      "epoch = 871 train_loss : 1.048886 , test loss : 1.296033\n",
      "epoch = 872 train_loss : 1.048365 , test loss : 1.295525\n",
      "epoch = 873 train_loss : 1.047760 , test loss : 1.295150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 874 train_loss : 1.047127 , test loss : 1.294283\n",
      "epoch = 875 train_loss : 1.046535 , test loss : 1.294041\n",
      "epoch = 876 train_loss : 1.046030 , test loss : 1.293570\n",
      "epoch = 877 train_loss : 1.045416 , test loss : 1.292754\n",
      "epoch = 878 train_loss : 1.044837 , test loss : 1.292269\n",
      "epoch = 879 train_loss : 1.044238 , test loss : 1.292248\n",
      "epoch = 880 train_loss : 1.043655 , test loss : 1.291499\n",
      "epoch = 881 train_loss : 1.043127 , test loss : 1.290962\n",
      "epoch = 882 train_loss : 1.042486 , test loss : 1.290542\n",
      "epoch = 883 train_loss : 1.041956 , test loss : 1.290223\n",
      "epoch = 884 train_loss : 1.041386 , test loss : 1.289473\n",
      "epoch = 885 train_loss : 1.040779 , test loss : 1.289134\n",
      "epoch = 886 train_loss : 1.040220 , test loss : 1.288510\n",
      "epoch = 887 train_loss : 1.039660 , test loss : 1.288072\n",
      "epoch = 888 train_loss : 1.039088 , test loss : 1.287739\n",
      "epoch = 889 train_loss : 1.038530 , test loss : 1.287094\n",
      "epoch = 890 train_loss : 1.037986 , test loss : 1.286402\n",
      "epoch = 891 train_loss : 1.037430 , test loss : 1.286174\n",
      "epoch = 892 train_loss : 1.036868 , test loss : 1.285757\n",
      "epoch = 893 train_loss : 1.036403 , test loss : 1.285747\n",
      "epoch = 894 train_loss : 1.035873 , test loss : 1.284671\n",
      "epoch = 895 train_loss : 1.035196 , test loss : 1.284392\n",
      "epoch = 896 train_loss : 1.034687 , test loss : 1.284103\n",
      "epoch = 897 train_loss : 1.034135 , test loss : 1.283494\n",
      "epoch = 898 train_loss : 1.033567 , test loss : 1.282951\n",
      "epoch = 899 train_loss : 1.033098 , test loss : 1.282759\n",
      "epoch = 900 train_loss : 1.032528 , test loss : 1.282108\n",
      "epoch = 901 train_loss : 1.031934 , test loss : 1.281623\n",
      "epoch = 902 train_loss : 1.031435 , test loss : 1.281340\n",
      "epoch = 903 train_loss : 1.030883 , test loss : 1.280758\n",
      "epoch = 904 train_loss : 1.030314 , test loss : 1.280487\n",
      "epoch = 905 train_loss : 1.029842 , test loss : 1.279956\n",
      "epoch = 906 train_loss : 1.029311 , test loss : 1.279560\n",
      "epoch = 907 train_loss : 1.028737 , test loss : 1.279124\n",
      "epoch = 908 train_loss : 1.028228 , test loss : 1.278766\n",
      "epoch = 909 train_loss : 1.027674 , test loss : 1.278172\n",
      "epoch = 910 train_loss : 1.027179 , test loss : 1.277886\n",
      "epoch = 911 train_loss : 1.026613 , test loss : 1.277228\n",
      "epoch = 912 train_loss : 1.026118 , test loss : 1.276912\n",
      "epoch = 914 train_loss : 1.025054 , test loss : 1.276122\n",
      "epoch = 915 train_loss : 1.024540 , test loss : 1.275686\n",
      "epoch = 916 train_loss : 1.024078 , test loss : 1.275571\n",
      "epoch = 917 train_loss : 1.023512 , test loss : 1.275031\n",
      "epoch = 918 train_loss : 1.023049 , test loss : 1.274533\n",
      "epoch = 919 train_loss : 1.022511 , test loss : 1.274274\n",
      "epoch = 920 train_loss : 1.022025 , test loss : 1.273757\n",
      "epoch = 921 train_loss : 1.021453 , test loss : 1.273532\n",
      "epoch = 922 train_loss : 1.020998 , test loss : 1.272995\n",
      "epoch = 923 train_loss : 1.020423 , test loss : 1.272580\n",
      "epoch = 924 train_loss : 1.019922 , test loss : 1.272168\n",
      "epoch = 925 train_loss : 1.019430 , test loss : 1.271848\n",
      "epoch = 926 train_loss : 1.018946 , test loss : 1.271397\n",
      "epoch = 927 train_loss : 1.018421 , test loss : 1.270834\n",
      "epoch = 928 train_loss : 1.017911 , test loss : 1.270549\n",
      "epoch = 929 train_loss : 1.017427 , test loss : 1.270162\n",
      "epoch = 930 train_loss : 1.016922 , test loss : 1.269627\n",
      "epoch = 931 train_loss : 1.016427 , test loss : 1.269493\n",
      "epoch = 932 train_loss : 1.015968 , test loss : 1.269143\n",
      "epoch = 933 train_loss : 1.015465 , test loss : 1.268421\n",
      "epoch = 934 train_loss : 1.014938 , test loss : 1.268319\n",
      "epoch = 935 train_loss : 1.014465 , test loss : 1.267767\n",
      "epoch = 936 train_loss : 1.013988 , test loss : 1.267523\n",
      "epoch = 937 train_loss : 1.013538 , test loss : 1.267384\n",
      "epoch = 938 train_loss : 1.013002 , test loss : 1.266654\n",
      "epoch = 939 train_loss : 1.012533 , test loss : 1.266220\n",
      "epoch = 940 train_loss : 1.012035 , test loss : 1.265849\n",
      "epoch = 941 train_loss : 1.011542 , test loss : 1.265669\n",
      "epoch = 942 train_loss : 1.011082 , test loss : 1.265561\n",
      "epoch = 943 train_loss : 1.010580 , test loss : 1.264911\n",
      "epoch = 944 train_loss : 1.010152 , test loss : 1.264377\n",
      "epoch = 945 train_loss : 1.009632 , test loss : 1.264274\n",
      "epoch = 946 train_loss : 1.009150 , test loss : 1.263692\n",
      "epoch = 947 train_loss : 1.008676 , test loss : 1.263465\n",
      "epoch = 948 train_loss : 1.008194 , test loss : 1.263221\n",
      "epoch = 949 train_loss : 1.007727 , test loss : 1.262746\n",
      "epoch = 950 train_loss : 1.007232 , test loss : 1.262173\n",
      "epoch = 951 train_loss : 1.006765 , test loss : 1.261882\n",
      "epoch = 952 train_loss : 1.006303 , test loss : 1.261477\n",
      "epoch = 953 train_loss : 1.005855 , test loss : 1.261343\n",
      "epoch = 954 train_loss : 1.005344 , test loss : 1.260825\n",
      "epoch = 955 train_loss : 1.004864 , test loss : 1.260470\n",
      "epoch = 956 train_loss : 1.004386 , test loss : 1.260087\n",
      "epoch = 957 train_loss : 1.003914 , test loss : 1.259639\n",
      "epoch = 958 train_loss : 1.003513 , test loss : 1.259370\n",
      "epoch = 959 train_loss : 1.003038 , test loss : 1.259128\n",
      "epoch = 960 train_loss : 1.002533 , test loss : 1.258928\n",
      "epoch = 961 train_loss : 1.002132 , test loss : 1.258285\n",
      "epoch = 962 train_loss : 1.001579 , test loss : 1.258036\n",
      "epoch = 963 train_loss : 1.001156 , test loss : 1.257819\n",
      "epoch = 964 train_loss : 1.000682 , test loss : 1.257026\n",
      "epoch = 966 train_loss : 0.999717 , test loss : 1.256504\n",
      "epoch = 967 train_loss : 0.999260 , test loss : 1.256433\n",
      "epoch = 968 train_loss : 0.998824 , test loss : 1.256208\n",
      "epoch = 969 train_loss : 0.998337 , test loss : 1.255653\n",
      "epoch = 970 train_loss : 0.997916 , test loss : 1.255150\n",
      "epoch = 971 train_loss : 0.997494 , test loss : 1.254952\n",
      "epoch = 972 train_loss : 0.997006 , test loss : 1.254397\n",
      "epoch = 973 train_loss : 0.996532 , test loss : 1.254183\n",
      "epoch = 974 train_loss : 0.996093 , test loss : 1.253716\n",
      "epoch = 976 train_loss : 0.995167 , test loss : 1.252956\n",
      "epoch = 977 train_loss : 0.994715 , test loss : 1.252737\n",
      "epoch = 978 train_loss : 0.994309 , test loss : 1.252364\n",
      "epoch = 979 train_loss : 0.993833 , test loss : 1.252170\n",
      "epoch = 980 train_loss : 0.993378 , test loss : 1.251749\n",
      "epoch = 982 train_loss : 0.992565 , test loss : 1.251023\n",
      "epoch = 983 train_loss : 0.992084 , test loss : 1.250967\n",
      "epoch = 984 train_loss : 0.991624 , test loss : 1.250283\n",
      "epoch = 986 train_loss : 0.990704 , test loss : 1.249755\n",
      "epoch = 987 train_loss : 0.990376 , test loss : 1.249310\n",
      "epoch = 988 train_loss : 0.989840 , test loss : 1.249099\n",
      "epoch = 989 train_loss : 0.989391 , test loss : 1.248852\n",
      "epoch = 990 train_loss : 0.989006 , test loss : 1.248415\n",
      "epoch = 991 train_loss : 0.988542 , test loss : 1.248022\n",
      "epoch = 992 train_loss : 0.988092 , test loss : 1.247885\n",
      "epoch = 993 train_loss : 0.987809 , test loss : 1.247799\n",
      "epoch = 994 train_loss : 0.987226 , test loss : 1.247171\n",
      "epoch = 995 train_loss : 0.986802 , test loss : 1.246890\n",
      "epoch = 996 train_loss : 0.986382 , test loss : 1.246707\n",
      "epoch = 997 train_loss : 0.985948 , test loss : 1.246351\n",
      "epoch = 998 train_loss : 0.985513 , test loss : 1.245930\n",
      "epoch = 999 train_loss : 0.985106 , test loss : 1.245726\n",
      "epoch = 1000 train_loss : 0.984649 , test loss : 1.245489\n",
      "epoch = 1001 train_loss : 0.984247 , test loss : 1.245091\n",
      "epoch = 1002 train_loss : 0.983821 , test loss : 1.244608\n",
      "epoch = 1003 train_loss : 0.983385 , test loss : 1.244392\n",
      "epoch = 1004 train_loss : 0.982961 , test loss : 1.244203\n",
      "epoch = 1005 train_loss : 0.982562 , test loss : 1.243866\n",
      "epoch = 1006 train_loss : 0.982099 , test loss : 1.243653\n",
      "epoch = 1007 train_loss : 0.981719 , test loss : 1.243280\n",
      "epoch = 1008 train_loss : 0.981255 , test loss : 1.243101\n",
      "epoch = 1009 train_loss : 0.980829 , test loss : 1.242794\n",
      "epoch = 1010 train_loss : 0.980510 , test loss : 1.242514\n",
      "epoch = 1011 train_loss : 0.979982 , test loss : 1.242156\n",
      "epoch = 1012 train_loss : 0.979582 , test loss : 1.241753\n",
      "epoch = 1013 train_loss : 0.979176 , test loss : 1.241356\n",
      "epoch = 1014 train_loss : 0.978716 , test loss : 1.241304\n",
      "epoch = 1015 train_loss : 0.978362 , test loss : 1.241013\n",
      "epoch = 1017 train_loss : 0.977476 , test loss : 1.240368\n",
      "epoch = 1018 train_loss : 0.977091 , test loss : 1.240090\n",
      "epoch = 1019 train_loss : 0.976660 , test loss : 1.239681\n",
      "epoch = 1020 train_loss : 0.976228 , test loss : 1.239300\n",
      "epoch = 1021 train_loss : 0.975829 , test loss : 1.239112\n",
      "epoch = 1022 train_loss : 0.975402 , test loss : 1.238991\n",
      "epoch = 1023 train_loss : 0.974983 , test loss : 1.238489\n",
      "epoch = 1024 train_loss : 0.974573 , test loss : 1.238183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1025 train_loss : 0.974160 , test loss : 1.237976\n",
      "epoch = 1026 train_loss : 0.973745 , test loss : 1.237786\n",
      "epoch = 1027 train_loss : 0.973399 , test loss : 1.237444\n",
      "epoch = 1028 train_loss : 0.972937 , test loss : 1.237076\n",
      "epoch = 1029 train_loss : 0.972520 , test loss : 1.236969\n",
      "epoch = 1030 train_loss : 0.972192 , test loss : 1.236843\n",
      "epoch = 1031 train_loss : 0.971694 , test loss : 1.236297\n",
      "epoch = 1032 train_loss : 0.971312 , test loss : 1.235888\n",
      "epoch = 1033 train_loss : 0.970876 , test loss : 1.235786\n",
      "epoch = 1034 train_loss : 0.970477 , test loss : 1.235589\n",
      "epoch = 1035 train_loss : 0.970065 , test loss : 1.235239\n",
      "epoch = 1036 train_loss : 0.969694 , test loss : 1.235187\n",
      "epoch = 1037 train_loss : 0.969261 , test loss : 1.234676\n",
      "epoch = 1039 train_loss : 0.968449 , test loss : 1.234191\n",
      "epoch = 1040 train_loss : 0.968052 , test loss : 1.234048\n",
      "epoch = 1041 train_loss : 0.967647 , test loss : 1.233714\n",
      "epoch = 1042 train_loss : 0.967239 , test loss : 1.233497\n",
      "epoch = 1043 train_loss : 0.966855 , test loss : 1.233354\n",
      "epoch = 1044 train_loss : 0.966466 , test loss : 1.232843\n",
      "epoch = 1045 train_loss : 0.966065 , test loss : 1.232248\n",
      "epoch = 1046 train_loss : 0.965650 , test loss : 1.232225\n",
      "epoch = 1048 train_loss : 0.964864 , test loss : 1.231504\n",
      "epoch = 1050 train_loss : 0.964179 , test loss : 1.231119\n",
      "epoch = 1051 train_loss : 0.963663 , test loss : 1.231073\n",
      "epoch = 1052 train_loss : 0.963283 , test loss : 1.230799\n",
      "epoch = 1053 train_loss : 0.962882 , test loss : 1.230508\n",
      "epoch = 1054 train_loss : 0.962494 , test loss : 1.230022\n",
      "epoch = 1056 train_loss : 0.961745 , test loss : 1.229797\n",
      "epoch = 1057 train_loss : 0.961322 , test loss : 1.229477\n",
      "epoch = 1058 train_loss : 0.960940 , test loss : 1.229217\n",
      "epoch = 1059 train_loss : 0.960541 , test loss : 1.228868\n",
      "epoch = 1060 train_loss : 0.960231 , test loss : 1.228807\n",
      "epoch = 1061 train_loss : 0.959807 , test loss : 1.228652\n",
      "epoch = 1062 train_loss : 0.959382 , test loss : 1.228311\n",
      "epoch = 1063 train_loss : 0.959001 , test loss : 1.227888\n",
      "epoch = 1064 train_loss : 0.958734 , test loss : 1.227594\n",
      "epoch = 1065 train_loss : 0.958275 , test loss : 1.227231\n",
      "epoch = 1066 train_loss : 0.957846 , test loss : 1.227108\n",
      "epoch = 1067 train_loss : 0.957478 , test loss : 1.226917\n",
      "epoch = 1068 train_loss : 0.957133 , test loss : 1.226708\n",
      "epoch = 1069 train_loss : 0.956722 , test loss : 1.226511\n",
      "epoch = 1070 train_loss : 0.956381 , test loss : 1.225853\n",
      "epoch = 1072 train_loss : 0.955597 , test loss : 1.225690\n",
      "epoch = 1073 train_loss : 0.955227 , test loss : 1.225155\n",
      "epoch = 1076 train_loss : 0.954114 , test loss : 1.224614\n",
      "epoch = 1077 train_loss : 0.953739 , test loss : 1.224253\n",
      "epoch = 1078 train_loss : 0.953371 , test loss : 1.224226\n",
      "epoch = 1080 train_loss : 0.952638 , test loss : 1.223464\n",
      "epoch = 1081 train_loss : 0.952245 , test loss : 1.223386\n",
      "epoch = 1082 train_loss : 0.951865 , test loss : 1.223089\n",
      "epoch = 1084 train_loss : 0.951143 , test loss : 1.222910\n",
      "epoch = 1085 train_loss : 0.950855 , test loss : 1.222360\n",
      "epoch = 1087 train_loss : 0.950035 , test loss : 1.222224\n",
      "epoch = 1088 train_loss : 0.949669 , test loss : 1.222010\n",
      "epoch = 1089 train_loss : 0.949306 , test loss : 1.221874\n",
      "epoch = 1090 train_loss : 0.949008 , test loss : 1.221545\n",
      "epoch = 1091 train_loss : 0.948574 , test loss : 1.221365\n",
      "epoch = 1092 train_loss : 0.948228 , test loss : 1.221130\n",
      "epoch = 1093 train_loss : 0.947904 , test loss : 1.220847\n",
      "epoch = 1095 train_loss : 0.947214 , test loss : 1.220393\n",
      "epoch = 1097 train_loss : 0.946430 , test loss : 1.219904\n",
      "epoch = 1099 train_loss : 0.945720 , test loss : 1.219728\n",
      "epoch = 1100 train_loss : 0.945383 , test loss : 1.219554\n",
      "epoch = 1101 train_loss : 0.944987 , test loss : 1.219100\n",
      "epoch = 1102 train_loss : 0.944657 , test loss : 1.218643\n",
      "epoch = 1103 train_loss : 0.944277 , test loss : 1.218511\n",
      "epoch = 1104 train_loss : 0.943931 , test loss : 1.218404\n",
      "epoch = 1105 train_loss : 0.943583 , test loss : 1.218326\n",
      "epoch = 1106 train_loss : 0.943241 , test loss : 1.218319\n",
      "epoch = 1107 train_loss : 0.942872 , test loss : 1.217764\n",
      "epoch = 1109 train_loss : 0.942165 , test loss : 1.217314\n",
      "epoch = 1111 train_loss : 0.941472 , test loss : 1.216884\n",
      "epoch = 1112 train_loss : 0.941129 , test loss : 1.216727\n",
      "epoch = 1113 train_loss : 0.940766 , test loss : 1.216634\n",
      "epoch = 1114 train_loss : 0.940431 , test loss : 1.216543\n",
      "epoch = 1115 train_loss : 0.940108 , test loss : 1.216312\n",
      "epoch = 1116 train_loss : 0.939776 , test loss : 1.215858\n",
      "epoch = 1118 train_loss : 0.939048 , test loss : 1.215560\n",
      "epoch = 1119 train_loss : 0.938692 , test loss : 1.215283\n",
      "epoch = 1120 train_loss : 0.938379 , test loss : 1.215119\n",
      "epoch = 1122 train_loss : 0.937846 , test loss : 1.214545\n",
      "epoch = 1123 train_loss : 0.937352 , test loss : 1.214537\n",
      "epoch = 1124 train_loss : 0.937028 , test loss : 1.214359\n",
      "epoch = 1125 train_loss : 0.936648 , test loss : 1.214340\n",
      "epoch = 1126 train_loss : 0.936282 , test loss : 1.213985\n",
      "epoch = 1127 train_loss : 0.935950 , test loss : 1.213656\n",
      "epoch = 1128 train_loss : 0.935622 , test loss : 1.213562\n",
      "epoch = 1129 train_loss : 0.935271 , test loss : 1.213228\n",
      "epoch = 1130 train_loss : 0.934924 , test loss : 1.212990\n",
      "epoch = 1132 train_loss : 0.934240 , test loss : 1.212667\n",
      "epoch = 1133 train_loss : 0.933999 , test loss : 1.212636\n",
      "epoch = 1134 train_loss : 0.933632 , test loss : 1.212248\n",
      "epoch = 1135 train_loss : 0.933212 , test loss : 1.212027\n",
      "epoch = 1137 train_loss : 0.932537 , test loss : 1.211775\n",
      "epoch = 1138 train_loss : 0.932210 , test loss : 1.211408\n",
      "epoch = 1139 train_loss : 0.931869 , test loss : 1.211397\n",
      "epoch = 1140 train_loss : 0.931517 , test loss : 1.210968\n",
      "epoch = 1141 train_loss : 0.931223 , test loss : 1.210967\n",
      "epoch = 1142 train_loss : 0.930858 , test loss : 1.210603\n",
      "epoch = 1143 train_loss : 0.930508 , test loss : 1.210542\n",
      "epoch = 1144 train_loss : 0.930182 , test loss : 1.210438\n",
      "epoch = 1145 train_loss : 0.929972 , test loss : 1.210357\n",
      "epoch = 1146 train_loss : 0.929551 , test loss : 1.209955\n",
      "epoch = 1147 train_loss : 0.929181 , test loss : 1.209762\n",
      "epoch = 1148 train_loss : 0.928833 , test loss : 1.209365\n",
      "epoch = 1149 train_loss : 0.928514 , test loss : 1.209091\n",
      "epoch = 1151 train_loss : 0.927867 , test loss : 1.208997\n",
      "epoch = 1152 train_loss : 0.927546 , test loss : 1.208664\n",
      "epoch = 1154 train_loss : 0.926857 , test loss : 1.208492\n",
      "epoch = 1155 train_loss : 0.926499 , test loss : 1.208303\n",
      "epoch = 1156 train_loss : 0.926200 , test loss : 1.207952\n",
      "epoch = 1157 train_loss : 0.925848 , test loss : 1.207944\n",
      "epoch = 1159 train_loss : 0.925180 , test loss : 1.207831\n",
      "epoch = 1160 train_loss : 0.924874 , test loss : 1.207483\n",
      "epoch = 1161 train_loss : 0.924561 , test loss : 1.207067\n",
      "epoch = 1163 train_loss : 0.923881 , test loss : 1.206839\n",
      "epoch = 1165 train_loss : 0.923381 , test loss : 1.206429\n",
      "epoch = 1167 train_loss : 0.922587 , test loss : 1.206417\n",
      "epoch = 1168 train_loss : 0.922274 , test loss : 1.205888\n",
      "epoch = 1169 train_loss : 0.921966 , test loss : 1.205708\n",
      "epoch = 1171 train_loss : 0.921280 , test loss : 1.205627\n",
      "epoch = 1172 train_loss : 0.920960 , test loss : 1.205341\n",
      "epoch = 1173 train_loss : 0.920701 , test loss : 1.205011\n",
      "epoch = 1174 train_loss : 0.920308 , test loss : 1.204814\n",
      "epoch = 1176 train_loss : 0.919690 , test loss : 1.204587\n",
      "epoch = 1177 train_loss : 0.919370 , test loss : 1.204397\n",
      "epoch = 1178 train_loss : 0.919060 , test loss : 1.204154\n",
      "epoch = 1179 train_loss : 0.918730 , test loss : 1.204076\n",
      "epoch = 1180 train_loss : 0.918398 , test loss : 1.203778\n",
      "epoch = 1181 train_loss : 0.918077 , test loss : 1.203609\n",
      "epoch = 1183 train_loss : 0.917521 , test loss : 1.203019\n",
      "epoch = 1185 train_loss : 0.916856 , test loss : 1.202863\n",
      "epoch = 1187 train_loss : 0.916180 , test loss : 1.202718\n",
      "epoch = 1188 train_loss : 0.915868 , test loss : 1.202515\n",
      "epoch = 1190 train_loss : 0.915306 , test loss : 1.202075\n",
      "epoch = 1192 train_loss : 0.914680 , test loss : 1.202001\n",
      "epoch = 1193 train_loss : 0.914311 , test loss : 1.201886\n",
      "epoch = 1194 train_loss : 0.914002 , test loss : 1.201568\n",
      "epoch = 1195 train_loss : 0.913697 , test loss : 1.201337\n",
      "epoch = 1196 train_loss : 0.913372 , test loss : 1.201293\n",
      "epoch = 1197 train_loss : 0.913079 , test loss : 1.200862\n",
      "epoch = 1198 train_loss : 0.912806 , test loss : 1.200811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1200 train_loss : 0.912172 , test loss : 1.200440\n",
      "epoch = 1201 train_loss : 0.911822 , test loss : 1.200212\n",
      "epoch = 1202 train_loss : 0.911501 , test loss : 1.200000\n",
      "epoch = 1203 train_loss : 0.911194 , test loss : 1.199838\n",
      "epoch = 1204 train_loss : 0.910895 , test loss : 1.199825\n",
      "epoch = 1205 train_loss : 0.910574 , test loss : 1.199442\n",
      "epoch = 1207 train_loss : 0.909986 , test loss : 1.199398\n",
      "epoch = 1208 train_loss : 0.909675 , test loss : 1.199358\n",
      "epoch = 1209 train_loss : 0.909352 , test loss : 1.199311\n",
      "epoch = 1210 train_loss : 0.909051 , test loss : 1.199012\n",
      "epoch = 1211 train_loss : 0.908738 , test loss : 1.198904\n",
      "epoch = 1212 train_loss : 0.908429 , test loss : 1.198787\n",
      "epoch = 1213 train_loss : 0.908125 , test loss : 1.198572\n",
      "epoch = 1214 train_loss : 0.907836 , test loss : 1.198337\n",
      "epoch = 1215 train_loss : 0.907508 , test loss : 1.198119\n",
      "epoch = 1217 train_loss : 0.906900 , test loss : 1.198087\n",
      "epoch = 1218 train_loss : 0.906609 , test loss : 1.197647\n",
      "epoch = 1219 train_loss : 0.906341 , test loss : 1.197641\n",
      "epoch = 1221 train_loss : 0.905702 , test loss : 1.197593\n",
      "epoch = 1223 train_loss : 0.905085 , test loss : 1.197118\n",
      "epoch = 1224 train_loss : 0.904795 , test loss : 1.196709\n",
      "epoch = 1227 train_loss : 0.903865 , test loss : 1.196471\n",
      "epoch = 1228 train_loss : 0.903594 , test loss : 1.196173\n",
      "epoch = 1229 train_loss : 0.903295 , test loss : 1.196090\n",
      "epoch = 1231 train_loss : 0.902697 , test loss : 1.195913\n",
      "epoch = 1233 train_loss : 0.902120 , test loss : 1.195756\n",
      "epoch = 1234 train_loss : 0.901797 , test loss : 1.195512\n",
      "epoch = 1235 train_loss : 0.901491 , test loss : 1.195440\n",
      "epoch = 1236 train_loss : 0.901228 , test loss : 1.195331\n",
      "epoch = 1237 train_loss : 0.900981 , test loss : 1.194839\n",
      "epoch = 1241 train_loss : 0.899779 , test loss : 1.194813\n",
      "epoch = 1242 train_loss : 0.899454 , test loss : 1.194304\n",
      "epoch = 1244 train_loss : 0.898872 , test loss : 1.194165\n",
      "epoch = 1245 train_loss : 0.898584 , test loss : 1.193816\n",
      "epoch = 1247 train_loss : 0.898017 , test loss : 1.193763\n",
      "epoch = 1248 train_loss : 0.897718 , test loss : 1.193585\n",
      "epoch = 1249 train_loss : 0.897410 , test loss : 1.193415\n",
      "epoch = 1250 train_loss : 0.897118 , test loss : 1.193183\n",
      "epoch = 1251 train_loss : 0.896833 , test loss : 1.192911\n",
      "epoch = 1254 train_loss : 0.895967 , test loss : 1.192832\n",
      "epoch = 1255 train_loss : 0.895687 , test loss : 1.192381\n",
      "epoch = 1257 train_loss : 0.895113 , test loss : 1.192274\n",
      "epoch = 1258 train_loss : 0.894840 , test loss : 1.192154\n",
      "epoch = 1259 train_loss : 0.894564 , test loss : 1.191991\n",
      "epoch = 1260 train_loss : 0.894274 , test loss : 1.191816\n",
      "epoch = 1261 train_loss : 0.893989 , test loss : 1.191706\n",
      "epoch = 1262 train_loss : 0.893753 , test loss : 1.191652\n",
      "epoch = 1263 train_loss : 0.893415 , test loss : 1.191505\n",
      "epoch = 1264 train_loss : 0.893148 , test loss : 1.191448\n",
      "epoch = 1265 train_loss : 0.892853 , test loss : 1.191149\n",
      "epoch = 1266 train_loss : 0.892587 , test loss : 1.190816\n",
      "epoch = 1269 train_loss : 0.891718 , test loss : 1.190673\n",
      "epoch = 1270 train_loss : 0.891439 , test loss : 1.190463\n",
      "epoch = 1271 train_loss : 0.891179 , test loss : 1.190379\n",
      "epoch = 1272 train_loss : 0.890888 , test loss : 1.190167\n",
      "epoch = 1274 train_loss : 0.890397 , test loss : 1.190064\n",
      "epoch = 1276 train_loss : 0.889778 , test loss : 1.189567\n",
      "epoch = 1277 train_loss : 0.889536 , test loss : 1.189560\n",
      "epoch = 1278 train_loss : 0.889301 , test loss : 1.189264\n",
      "epoch = 1280 train_loss : 0.888645 , test loss : 1.189229\n",
      "epoch = 1281 train_loss : 0.888396 , test loss : 1.189095\n",
      "epoch = 1282 train_loss : 0.888098 , test loss : 1.189020\n",
      "epoch = 1283 train_loss : 0.887845 , test loss : 1.188824\n",
      "epoch = 1284 train_loss : 0.887544 , test loss : 1.188655\n",
      "epoch = 1286 train_loss : 0.886994 , test loss : 1.188615\n",
      "epoch = 1287 train_loss : 0.886724 , test loss : 1.188283\n",
      "epoch = 1289 train_loss : 0.886174 , test loss : 1.188167\n",
      "epoch = 1290 train_loss : 0.885917 , test loss : 1.188112\n",
      "epoch = 1291 train_loss : 0.885652 , test loss : 1.187722\n",
      "epoch = 1293 train_loss : 0.885110 , test loss : 1.187455\n",
      "epoch = 1296 train_loss : 0.884306 , test loss : 1.187202\n",
      "epoch = 1297 train_loss : 0.884032 , test loss : 1.187020\n",
      "epoch = 1298 train_loss : 0.883762 , test loss : 1.186927\n",
      "epoch = 1300 train_loss : 0.883216 , test loss : 1.186848\n",
      "epoch = 1302 train_loss : 0.882686 , test loss : 1.186681\n",
      "epoch = 1303 train_loss : 0.882438 , test loss : 1.186660\n",
      "epoch = 1304 train_loss : 0.882208 , test loss : 1.186433\n",
      "epoch = 1305 train_loss : 0.881915 , test loss : 1.186400\n",
      "epoch = 1307 train_loss : 0.881356 , test loss : 1.185981\n",
      "epoch = 1308 train_loss : 0.881102 , test loss : 1.185958\n",
      "epoch = 1309 train_loss : 0.880818 , test loss : 1.185839\n",
      "epoch = 1310 train_loss : 0.880538 , test loss : 1.185717\n",
      "epoch = 1311 train_loss : 0.880281 , test loss : 1.185636\n",
      "epoch = 1312 train_loss : 0.880038 , test loss : 1.185586\n",
      "epoch = 1315 train_loss : 0.879243 , test loss : 1.185084\n",
      "epoch = 1318 train_loss : 0.878520 , test loss : 1.184841\n",
      "epoch = 1320 train_loss : 0.877964 , test loss : 1.184814\n",
      "epoch = 1321 train_loss : 0.877659 , test loss : 1.184705\n",
      "epoch = 1322 train_loss : 0.877400 , test loss : 1.184430\n",
      "epoch = 1323 train_loss : 0.877154 , test loss : 1.184116\n",
      "epoch = 1326 train_loss : 0.876376 , test loss : 1.183861\n",
      "epoch = 1330 train_loss : 0.875353 , test loss : 1.183549\n",
      "epoch = 1332 train_loss : 0.874832 , test loss : 1.183444\n",
      "epoch = 1333 train_loss : 0.874557 , test loss : 1.183300\n",
      "epoch = 1334 train_loss : 0.874295 , test loss : 1.183290\n",
      "epoch = 1335 train_loss : 0.874040 , test loss : 1.182866\n",
      "epoch = 1338 train_loss : 0.873271 , test loss : 1.182467\n",
      "epoch = 1342 train_loss : 0.872256 , test loss : 1.182164\n",
      "epoch = 1345 train_loss : 0.871475 , test loss : 1.182027\n",
      "epoch = 1347 train_loss : 0.870967 , test loss : 1.181897\n",
      "epoch = 1348 train_loss : 0.870719 , test loss : 1.181618\n",
      "epoch = 1350 train_loss : 0.870206 , test loss : 1.181366\n",
      "epoch = 1353 train_loss : 0.869448 , test loss : 1.181278\n",
      "epoch = 1354 train_loss : 0.869209 , test loss : 1.181052\n",
      "epoch = 1356 train_loss : 0.868682 , test loss : 1.180724\n",
      "epoch = 1360 train_loss : 0.867695 , test loss : 1.180346\n",
      "epoch = 1363 train_loss : 0.866923 , test loss : 1.180125\n",
      "epoch = 1365 train_loss : 0.866416 , test loss : 1.180006\n",
      "epoch = 1366 train_loss : 0.866173 , test loss : 1.179768\n",
      "epoch = 1369 train_loss : 0.865425 , test loss : 1.179645\n",
      "epoch = 1370 train_loss : 0.865181 , test loss : 1.179439\n",
      "epoch = 1372 train_loss : 0.864681 , test loss : 1.179299\n",
      "epoch = 1374 train_loss : 0.864183 , test loss : 1.179201\n",
      "epoch = 1376 train_loss : 0.863681 , test loss : 1.178969\n",
      "epoch = 1377 train_loss : 0.863437 , test loss : 1.178853\n",
      "epoch = 1380 train_loss : 0.862735 , test loss : 1.178454\n",
      "epoch = 1381 train_loss : 0.862462 , test loss : 1.178404\n",
      "epoch = 1384 train_loss : 0.861794 , test loss : 1.178179\n",
      "epoch = 1386 train_loss : 0.861228 , test loss : 1.178053\n",
      "epoch = 1387 train_loss : 0.860983 , test loss : 1.178046\n",
      "epoch = 1388 train_loss : 0.860735 , test loss : 1.177967\n",
      "epoch = 1390 train_loss : 0.860323 , test loss : 1.177538\n",
      "epoch = 1393 train_loss : 0.859539 , test loss : 1.177485\n",
      "epoch = 1394 train_loss : 0.859295 , test loss : 1.177352\n",
      "epoch = 1395 train_loss : 0.859100 , test loss : 1.177336\n",
      "epoch = 1396 train_loss : 0.858816 , test loss : 1.177333\n",
      "epoch = 1397 train_loss : 0.858583 , test loss : 1.176999\n",
      "epoch = 1399 train_loss : 0.858106 , test loss : 1.176871\n",
      "epoch = 1401 train_loss : 0.857626 , test loss : 1.176848\n",
      "epoch = 1402 train_loss : 0.857443 , test loss : 1.176588\n",
      "epoch = 1405 train_loss : 0.856710 , test loss : 1.176192\n",
      "epoch = 1409 train_loss : 0.855817 , test loss : 1.176161\n",
      "epoch = 1410 train_loss : 0.855494 , test loss : 1.175831\n",
      "epoch = 1414 train_loss : 0.854602 , test loss : 1.175466\n",
      "epoch = 1416 train_loss : 0.854112 , test loss : 1.175452\n",
      "epoch = 1418 train_loss : 0.853644 , test loss : 1.175209\n",
      "epoch = 1420 train_loss : 0.853129 , test loss : 1.175131\n",
      "epoch = 1421 train_loss : 0.852918 , test loss : 1.175038\n",
      "epoch = 1423 train_loss : 0.852438 , test loss : 1.174675\n",
      "epoch = 1424 train_loss : 0.852189 , test loss : 1.174605\n",
      "epoch = 1425 train_loss : 0.851974 , test loss : 1.174367\n",
      "epoch = 1431 train_loss : 0.850550 , test loss : 1.174019\n",
      "epoch = 1432 train_loss : 0.850318 , test loss : 1.173878\n",
      "epoch = 1434 train_loss : 0.849869 , test loss : 1.173584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1437 train_loss : 0.849237 , test loss : 1.173547\n",
      "epoch = 1439 train_loss : 0.848675 , test loss : 1.173530\n",
      "epoch = 1440 train_loss : 0.848483 , test loss : 1.173233\n",
      "epoch = 1443 train_loss : 0.847740 , test loss : 1.173024\n",
      "epoch = 1445 train_loss : 0.847290 , test loss : 1.172935\n",
      "epoch = 1447 train_loss : 0.846832 , test loss : 1.172709\n",
      "epoch = 1449 train_loss : 0.846405 , test loss : 1.172534\n",
      "epoch = 1450 train_loss : 0.846148 , test loss : 1.172228\n",
      "epoch = 1456 train_loss : 0.844764 , test loss : 1.171976\n",
      "epoch = 1459 train_loss : 0.844117 , test loss : 1.171563\n",
      "epoch = 1462 train_loss : 0.843402 , test loss : 1.171517\n",
      "epoch = 1465 train_loss : 0.842741 , test loss : 1.171303\n",
      "epoch = 1466 train_loss : 0.842492 , test loss : 1.171168\n",
      "epoch = 1469 train_loss : 0.841826 , test loss : 1.170888\n",
      "epoch = 1472 train_loss : 0.841124 , test loss : 1.170797\n",
      "epoch = 1473 train_loss : 0.840905 , test loss : 1.170780\n",
      "epoch = 1474 train_loss : 0.840680 , test loss : 1.170695\n",
      "epoch = 1475 train_loss : 0.840522 , test loss : 1.170455\n",
      "epoch = 1480 train_loss : 0.839366 , test loss : 1.169925\n",
      "epoch = 1486 train_loss : 0.837992 , test loss : 1.169721\n",
      "epoch = 1489 train_loss : 0.837322 , test loss : 1.169719\n",
      "epoch = 1490 train_loss : 0.837106 , test loss : 1.169576\n",
      "epoch = 1493 train_loss : 0.836443 , test loss : 1.169454\n",
      "epoch = 1495 train_loss : 0.836024 , test loss : 1.169289\n",
      "epoch = 1497 train_loss : 0.835574 , test loss : 1.169225\n",
      "epoch = 1499 train_loss : 0.835125 , test loss : 1.168865\n",
      "epoch = 1503 train_loss : 0.834247 , test loss : 1.168745\n",
      "epoch = 1505 train_loss : 0.833809 , test loss : 1.168703\n",
      "epoch = 1506 train_loss : 0.833607 , test loss : 1.168650\n",
      "epoch = 1507 train_loss : 0.833363 , test loss : 1.168588\n",
      "epoch = 1511 train_loss : 0.832548 , test loss : 1.168041\n",
      "epoch = 1516 train_loss : 0.831448 , test loss : 1.167586\n",
      "epoch = 1525 train_loss : 0.829554 , test loss : 1.167491\n",
      "epoch = 1527 train_loss : 0.829037 , test loss : 1.167420\n",
      "epoch = 1528 train_loss : 0.828852 , test loss : 1.167316\n",
      "epoch = 1529 train_loss : 0.828669 , test loss : 1.167158\n",
      "epoch = 1530 train_loss : 0.828432 , test loss : 1.167021\n",
      "epoch = 1534 train_loss : 0.827613 , test loss : 1.166841\n",
      "epoch = 1537 train_loss : 0.826955 , test loss : 1.166664\n",
      "epoch = 1541 train_loss : 0.826073 , test loss : 1.166593\n",
      "epoch = 1542 train_loss : 0.825893 , test loss : 1.166468\n",
      "epoch = 1545 train_loss : 0.825237 , test loss : 1.166301\n",
      "epoch = 1546 train_loss : 0.825053 , test loss : 1.166205\n",
      "epoch = 1548 train_loss : 0.824622 , test loss : 1.166054\n",
      "epoch = 1549 train_loss : 0.824541 , test loss : 1.166004\n",
      "epoch = 1552 train_loss : 0.823865 , test loss : 1.165883\n",
      "epoch = 1555 train_loss : 0.823192 , test loss : 1.165699\n",
      "epoch = 1557 train_loss : 0.822733 , test loss : 1.165588\n",
      "epoch = 1558 train_loss : 0.822563 , test loss : 1.165384\n",
      "epoch = 1561 train_loss : 0.821993 , test loss : 1.164975\n",
      "epoch = 1570 train_loss : 0.820057 , test loss : 1.164904\n",
      "epoch = 1571 train_loss : 0.819879 , test loss : 1.164839\n",
      "epoch = 1573 train_loss : 0.819447 , test loss : 1.164718\n",
      "epoch = 1575 train_loss : 0.819076 , test loss : 1.164707\n",
      "epoch = 1576 train_loss : 0.818823 , test loss : 1.164670\n",
      "epoch = 1577 train_loss : 0.818647 , test loss : 1.164608\n",
      "epoch = 1578 train_loss : 0.818441 , test loss : 1.164217\n",
      "epoch = 1587 train_loss : 0.816593 , test loss : 1.164169\n",
      "epoch = 1590 train_loss : 0.816014 , test loss : 1.163754\n",
      "epoch = 1594 train_loss : 0.815194 , test loss : 1.163593\n",
      "epoch = 1597 train_loss : 0.814650 , test loss : 1.163593\n",
      "epoch = 1600 train_loss : 0.813978 , test loss : 1.163504\n",
      "epoch = 1602 train_loss : 0.813567 , test loss : 1.163486\n",
      "epoch = 1604 train_loss : 0.813161 , test loss : 1.163275\n",
      "epoch = 1606 train_loss : 0.812774 , test loss : 1.163191\n",
      "epoch = 1609 train_loss : 0.812183 , test loss : 1.163106\n",
      "epoch = 1612 train_loss : 0.811559 , test loss : 1.163071\n",
      "epoch = 1613 train_loss : 0.811394 , test loss : 1.163037\n",
      "epoch = 1614 train_loss : 0.811166 , test loss : 1.162813\n",
      "epoch = 1617 train_loss : 0.810573 , test loss : 1.162745\n",
      "epoch = 1618 train_loss : 0.810367 , test loss : 1.162716\n",
      "epoch = 1619 train_loss : 0.810185 , test loss : 1.162663\n",
      "epoch = 1622 train_loss : 0.809581 , test loss : 1.162461\n",
      "epoch = 1630 train_loss : 0.808050 , test loss : 1.162137\n",
      "epoch = 1633 train_loss : 0.807422 , test loss : 1.161886\n",
      "epoch = 1641 train_loss : 0.805917 , test loss : 1.161681\n",
      "epoch = 1649 train_loss : 0.804231 , test loss : 1.161562\n",
      "epoch = 1650 train_loss : 0.804099 , test loss : 1.161498\n",
      "epoch = 1654 train_loss : 0.803246 , test loss : 1.161478\n",
      "epoch = 1657 train_loss : 0.802708 , test loss : 1.161428\n",
      "epoch = 1658 train_loss : 0.802493 , test loss : 1.161084\n",
      "epoch = 1664 train_loss : 0.801448 , test loss : 1.160840\n",
      "epoch = 1669 train_loss : 0.800363 , test loss : 1.160830\n",
      "epoch = 1671 train_loss : 0.799986 , test loss : 1.160801\n",
      "epoch = 1674 train_loss : 0.799405 , test loss : 1.160591\n",
      "epoch = 1675 train_loss : 0.799181 , test loss : 1.160467\n",
      "epoch = 1678 train_loss : 0.798655 , test loss : 1.160364\n",
      "epoch = 1681 train_loss : 0.798042 , test loss : 1.160195\n",
      "epoch = 1685 train_loss : 0.797262 , test loss : 1.160134\n",
      "epoch = 1691 train_loss : 0.796121 , test loss : 1.159928\n",
      "epoch = 1695 train_loss : 0.795349 , test loss : 1.159900\n",
      "epoch = 1698 train_loss : 0.794771 , test loss : 1.159889\n",
      "epoch = 1702 train_loss : 0.794044 , test loss : 1.159716\n",
      "epoch = 1703 train_loss : 0.793829 , test loss : 1.159579\n",
      "epoch = 1705 train_loss : 0.793562 , test loss : 1.159348\n",
      "epoch = 1717 train_loss : 0.791178 , test loss : 1.159210\n",
      "epoch = 1721 train_loss : 0.790456 , test loss : 1.159123\n",
      "epoch = 1727 train_loss : 0.789382 , test loss : 1.158877\n",
      "epoch = 1733 train_loss : 0.788244 , test loss : 1.158665\n",
      "epoch = 1743 train_loss : 0.786334 , test loss : 1.158611\n",
      "epoch = 1746 train_loss : 0.785813 , test loss : 1.158561\n",
      "epoch = 1749 train_loss : 0.785240 , test loss : 1.158554\n",
      "epoch = 1750 train_loss : 0.785065 , test loss : 1.158401\n",
      "epoch = 1751 train_loss : 0.784947 , test loss : 1.158278\n",
      "epoch = 1755 train_loss : 0.784115 , test loss : 1.158215\n",
      "epoch = 1756 train_loss : 0.783946 , test loss : 1.158173\n",
      "epoch = 1763 train_loss : 0.782661 , test loss : 1.158108\n",
      "epoch = 1767 train_loss : 0.782023 , test loss : 1.157473\n",
      "epoch = 1800 train_loss : 0.775938 , test loss : 1.157444\n",
      "epoch = 1808 train_loss : 0.774495 , test loss : 1.157310\n",
      "epoch = 1814 train_loss : 0.773441 , test loss : 1.157304\n",
      "epoch = 1824 train_loss : 0.771610 , test loss : 1.157287\n",
      "epoch = 1828 train_loss : 0.770894 , test loss : 1.157194\n",
      "epoch = 1833 train_loss : 0.770022 , test loss : 1.157131\n",
      "epoch = 1840 train_loss : 0.768785 , test loss : 1.156993\n",
      "epoch = 1845 train_loss : 0.767940 , test loss : 1.156804\n",
      "epoch = 1896 train_loss : 0.758888 , test loss : 1.156757\n",
      "epoch = 1903 train_loss : 0.757625 , test loss : 1.156687\n",
      "epoch = 1920 train_loss : 0.754719 , test loss : 1.156360\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.754719,test loss : 1.156360\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 41.929100 , test loss : 40.859310\n",
      "epoch = 2 train_loss : 41.327923 , test loss : 40.275890\n",
      "epoch = 3 train_loss : 40.734234 , test loss : 39.699371\n",
      "epoch = 4 train_loss : 40.148220 , test loss : 39.130272\n",
      "epoch = 5 train_loss : 39.571285 , test loss : 38.570473\n",
      "epoch = 6 train_loss : 39.002342 , test loss : 38.018150\n",
      "epoch = 7 train_loss : 38.436180 , test loss : 37.468616\n",
      "epoch = 8 train_loss : 37.878376 , test loss : 36.927929\n",
      "epoch = 9 train_loss : 37.327641 , test loss : 36.393787\n",
      "epoch = 10 train_loss : 36.777420 , test loss : 35.860485\n",
      "epoch = 11 train_loss : 36.239681 , test loss : 35.339622\n",
      "epoch = 12 train_loss : 35.702160 , test loss : 34.819046\n",
      "epoch = 13 train_loss : 35.170902 , test loss : 34.304039\n",
      "epoch = 14 train_loss : 34.641563 , test loss : 33.790714\n",
      "epoch = 15 train_loss : 34.122364 , test loss : 33.286816\n",
      "epoch = 16 train_loss : 33.602695 , test loss : 32.782440\n",
      "epoch = 17 train_loss : 33.085453 , test loss : 32.279922\n",
      "epoch = 18 train_loss : 32.574799 , test loss : 31.783754\n",
      "epoch = 19 train_loss : 32.070683 , test loss : 31.293531\n",
      "epoch = 20 train_loss : 31.563576 , test loss : 30.800776\n",
      "epoch = 21 train_loss : 31.062193 , test loss : 30.313902\n",
      "epoch = 22 train_loss : 30.570791 , test loss : 29.836781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 23 train_loss : 30.076731 , test loss : 29.356855\n",
      "epoch = 24 train_loss : 29.585310 , test loss : 28.879635\n",
      "epoch = 25 train_loss : 29.102707 , test loss : 28.411482\n",
      "epoch = 26 train_loss : 28.621634 , test loss : 27.945063\n",
      "epoch = 27 train_loss : 28.140991 , test loss : 27.479044\n",
      "epoch = 28 train_loss : 27.665396 , test loss : 27.017836\n",
      "epoch = 29 train_loss : 27.191654 , test loss : 26.558462\n",
      "epoch = 30 train_loss : 26.723719 , test loss : 26.105263\n",
      "epoch = 31 train_loss : 26.259211 , test loss : 25.655722\n",
      "epoch = 32 train_loss : 25.795631 , test loss : 25.207422\n",
      "epoch = 33 train_loss : 25.339050 , test loss : 24.765631\n",
      "epoch = 34 train_loss : 24.888380 , test loss : 24.329300\n",
      "epoch = 35 train_loss : 24.433481 , test loss : 23.888891\n",
      "epoch = 36 train_loss : 23.988737 , test loss : 23.458126\n",
      "epoch = 37 train_loss : 23.545219 , test loss : 23.028851\n",
      "epoch = 38 train_loss : 23.108696 , test loss : 22.606216\n",
      "epoch = 39 train_loss : 22.678101 , test loss : 22.189373\n",
      "epoch = 40 train_loss : 22.249279 , test loss : 21.773973\n",
      "epoch = 41 train_loss : 21.825239 , test loss : 21.363661\n",
      "epoch = 42 train_loss : 21.404903 , test loss : 20.956451\n",
      "epoch = 43 train_loss : 20.988237 , test loss : 20.553356\n",
      "epoch = 44 train_loss : 20.580093 , test loss : 20.158092\n",
      "epoch = 45 train_loss : 20.174692 , test loss : 19.765602\n",
      "epoch = 46 train_loss : 19.778418 , test loss : 19.381693\n",
      "epoch = 47 train_loss : 19.381752 , test loss : 18.997133\n",
      "epoch = 48 train_loss : 18.991262 , test loss : 18.618567\n",
      "epoch = 49 train_loss : 18.607161 , test loss : 18.246046\n",
      "epoch = 50 train_loss : 18.229164 , test loss : 17.879066\n",
      "epoch = 51 train_loss : 17.855715 , test loss : 17.516434\n",
      "epoch = 52 train_loss : 17.485094 , test loss : 17.156725\n",
      "epoch = 53 train_loss : 17.123573 , test loss : 16.806124\n",
      "epoch = 54 train_loss : 16.767279 , test loss : 16.460325\n",
      "epoch = 55 train_loss : 16.415701 , test loss : 16.119083\n",
      "epoch = 56 train_loss : 16.068394 , test loss : 15.782266\n",
      "epoch = 57 train_loss : 15.725968 , test loss : 15.449884\n",
      "epoch = 58 train_loss : 15.392792 , test loss : 15.126718\n",
      "epoch = 59 train_loss : 15.063536 , test loss : 14.807348\n",
      "epoch = 60 train_loss : 14.740434 , test loss : 14.494290\n",
      "epoch = 61 train_loss : 14.421848 , test loss : 14.185774\n",
      "epoch = 62 train_loss : 14.109184 , test loss : 13.882958\n",
      "epoch = 63 train_loss : 13.803686 , test loss : 13.586926\n",
      "epoch = 64 train_loss : 13.501163 , test loss : 13.294098\n",
      "epoch = 65 train_loss : 13.206677 , test loss : 13.008900\n",
      "epoch = 66 train_loss : 12.916672 , test loss : 12.728055\n",
      "epoch = 67 train_loss : 12.633363 , test loss : 12.453785\n",
      "epoch = 68 train_loss : 12.356126 , test loss : 12.185301\n",
      "epoch = 69 train_loss : 12.084504 , test loss : 11.922338\n",
      "epoch = 70 train_loss : 11.816661 , test loss : 11.663032\n",
      "epoch = 71 train_loss : 11.555770 , test loss : 11.410416\n",
      "epoch = 72 train_loss : 11.297861 , test loss : 11.161086\n",
      "epoch = 73 train_loss : 11.048230 , test loss : 10.919878\n",
      "epoch = 74 train_loss : 10.803374 , test loss : 10.683256\n",
      "epoch = 75 train_loss : 10.562773 , test loss : 10.450470\n",
      "epoch = 76 train_loss : 10.327600 , test loss : 10.223330\n",
      "epoch = 77 train_loss : 10.098022 , test loss : 10.001549\n",
      "epoch = 78 train_loss : 9.873610 , test loss : 9.784695\n",
      "epoch = 79 train_loss : 9.653881 , test loss : 9.572738\n",
      "epoch = 80 train_loss : 9.440310 , test loss : 9.366700\n",
      "epoch = 81 train_loss : 9.230890 , test loss : 9.164471\n",
      "epoch = 82 train_loss : 9.026075 , test loss : 8.966893\n",
      "epoch = 83 train_loss : 8.826338 , test loss : 8.774364\n",
      "epoch = 84 train_loss : 8.630965 , test loss : 8.585849\n",
      "epoch = 85 train_loss : 8.440965 , test loss : 8.402586\n",
      "epoch = 86 train_loss : 8.257192 , test loss : 8.225329\n",
      "epoch = 87 train_loss : 8.072633 , test loss : 8.047626\n",
      "epoch = 88 train_loss : 7.897522 , test loss : 7.878778\n",
      "epoch = 89 train_loss : 7.725132 , test loss : 7.712811\n",
      "epoch = 90 train_loss : 7.556364 , test loss : 7.550317\n",
      "epoch = 91 train_loss : 7.394089 , test loss : 7.394224\n",
      "epoch = 92 train_loss : 7.233831 , test loss : 7.240067\n",
      "epoch = 93 train_loss : 7.079271 , test loss : 7.091507\n",
      "epoch = 94 train_loss : 6.926488 , test loss : 6.944676\n",
      "epoch = 95 train_loss : 6.778509 , test loss : 6.802490\n",
      "epoch = 96 train_loss : 6.634079 , test loss : 6.664039\n",
      "epoch = 97 train_loss : 6.494664 , test loss : 6.530123\n",
      "epoch = 98 train_loss : 6.360120 , test loss : 6.400962\n",
      "epoch = 99 train_loss : 6.227783 , test loss : 6.274012\n",
      "epoch = 100 train_loss : 6.098204 , test loss : 6.149828\n",
      "epoch = 101 train_loss : 5.972970 , test loss : 6.029947\n",
      "epoch = 102 train_loss : 5.851640 , test loss : 5.913857\n",
      "epoch = 103 train_loss : 5.733159 , test loss : 5.800451\n",
      "epoch = 104 train_loss : 5.617637 , test loss : 5.690305\n",
      "epoch = 105 train_loss : 5.505268 , test loss : 5.582928\n",
      "epoch = 106 train_loss : 5.397350 , test loss : 5.479927\n",
      "epoch = 107 train_loss : 5.292326 , test loss : 5.379645\n",
      "epoch = 108 train_loss : 5.189797 , test loss : 5.281872\n",
      "epoch = 109 train_loss : 5.090792 , test loss : 5.187654\n",
      "epoch = 110 train_loss : 4.994206 , test loss : 5.095538\n",
      "epoch = 111 train_loss : 4.901175 , test loss : 5.007028\n",
      "epoch = 112 train_loss : 4.811114 , test loss : 4.921210\n",
      "epoch = 113 train_loss : 4.723016 , test loss : 4.837410\n",
      "epoch = 114 train_loss : 4.637835 , test loss : 4.756622\n",
      "epoch = 115 train_loss : 4.555975 , test loss : 4.678761\n",
      "epoch = 116 train_loss : 4.475704 , test loss : 4.602676\n",
      "epoch = 117 train_loss : 4.399182 , test loss : 4.530227\n",
      "epoch = 118 train_loss : 4.324087 , test loss : 4.458934\n",
      "epoch = 119 train_loss : 4.252468 , test loss : 4.391018\n",
      "epoch = 120 train_loss : 4.181802 , test loss : 4.324160\n",
      "epoch = 121 train_loss : 4.114619 , test loss : 4.260514\n",
      "epoch = 122 train_loss : 4.049830 , test loss : 4.199319\n",
      "epoch = 123 train_loss : 3.986351 , test loss : 4.139412\n",
      "epoch = 124 train_loss : 3.926549 , test loss : 4.083068\n",
      "epoch = 125 train_loss : 3.867396 , test loss : 4.027262\n",
      "epoch = 126 train_loss : 3.810792 , test loss : 3.974032\n",
      "epoch = 127 train_loss : 3.755557 , test loss : 3.922004\n",
      "epoch = 128 train_loss : 3.702935 , test loss : 3.872528\n",
      "epoch = 129 train_loss : 3.652161 , test loss : 3.824861\n",
      "epoch = 130 train_loss : 3.603589 , test loss : 3.779125\n",
      "epoch = 131 train_loss : 3.556836 , test loss : 3.735132\n",
      "epoch = 132 train_loss : 3.511902 , test loss : 3.692930\n",
      "epoch = 133 train_loss : 3.468582 , test loss : 3.652239\n",
      "epoch = 134 train_loss : 3.426190 , test loss : 3.612445\n",
      "epoch = 135 train_loss : 3.385858 , test loss : 3.574783\n",
      "epoch = 136 train_loss : 3.347414 , test loss : 3.538842\n",
      "epoch = 137 train_loss : 3.309734 , test loss : 3.503508\n",
      "epoch = 138 train_loss : 3.273705 , test loss : 3.469804\n",
      "epoch = 139 train_loss : 3.239615 , test loss : 3.438067\n",
      "epoch = 140 train_loss : 3.206585 , test loss : 3.407317\n",
      "epoch = 141 train_loss : 3.175124 , test loss : 3.378186\n",
      "epoch = 142 train_loss : 3.144729 , test loss : 3.349777\n",
      "epoch = 143 train_loss : 3.115342 , test loss : 3.322454\n",
      "epoch = 144 train_loss : 3.087141 , test loss : 3.296422\n",
      "epoch = 145 train_loss : 3.060601 , test loss : 3.271890\n",
      "epoch = 146 train_loss : 3.034411 , test loss : 3.247667\n",
      "epoch = 147 train_loss : 3.009626 , test loss : 3.224746\n",
      "epoch = 148 train_loss : 2.985802 , test loss : 3.202840\n",
      "epoch = 149 train_loss : 2.963286 , test loss : 3.182045\n",
      "epoch = 150 train_loss : 2.941481 , test loss : 3.161821\n",
      "epoch = 151 train_loss : 2.920452 , test loss : 3.142689\n",
      "epoch = 152 train_loss : 2.900334 , test loss : 3.124198\n",
      "epoch = 153 train_loss : 2.881214 , test loss : 3.106763\n",
      "epoch = 154 train_loss : 2.862196 , test loss : 3.089454\n",
      "epoch = 155 train_loss : 2.844526 , test loss : 3.073414\n",
      "epoch = 156 train_loss : 2.828215 , test loss : 3.058691\n",
      "epoch = 157 train_loss : 2.811476 , test loss : 3.043490\n",
      "epoch = 158 train_loss : 2.796124 , test loss : 3.029526\n",
      "epoch = 159 train_loss : 2.780892 , test loss : 3.015676\n",
      "epoch = 160 train_loss : 2.767017 , test loss : 3.003067\n",
      "epoch = 161 train_loss : 2.752847 , test loss : 2.990424\n",
      "epoch = 162 train_loss : 2.739740 , test loss : 2.978701\n",
      "epoch = 163 train_loss : 2.727009 , test loss : 2.967375\n",
      "epoch = 164 train_loss : 2.714866 , test loss : 2.956410\n",
      "epoch = 165 train_loss : 2.703140 , test loss : 2.945808\n",
      "epoch = 166 train_loss : 2.691606 , test loss : 2.935572\n",
      "epoch = 167 train_loss : 2.680837 , test loss : 2.925962\n",
      "epoch = 168 train_loss : 2.670261 , test loss : 2.916740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 169 train_loss : 2.660360 , test loss : 2.907640\n",
      "epoch = 170 train_loss : 2.650764 , test loss : 2.899298\n",
      "epoch = 171 train_loss : 2.641483 , test loss : 2.891033\n",
      "epoch = 172 train_loss : 2.632465 , test loss : 2.883326\n",
      "epoch = 173 train_loss : 2.623598 , test loss : 2.875419\n",
      "epoch = 174 train_loss : 2.615304 , test loss : 2.868021\n",
      "epoch = 175 train_loss : 2.606857 , test loss : 2.860803\n",
      "epoch = 176 train_loss : 2.599164 , test loss : 2.853892\n",
      "epoch = 177 train_loss : 2.591546 , test loss : 2.847482\n",
      "epoch = 178 train_loss : 2.584112 , test loss : 2.840804\n",
      "epoch = 179 train_loss : 2.576850 , test loss : 2.834439\n",
      "epoch = 180 train_loss : 2.569782 , test loss : 2.828324\n",
      "epoch = 181 train_loss : 2.562906 , test loss : 2.822297\n",
      "epoch = 182 train_loss : 2.556332 , test loss : 2.816558\n",
      "epoch = 183 train_loss : 2.549797 , test loss : 2.810732\n",
      "epoch = 184 train_loss : 2.543536 , test loss : 2.805354\n",
      "epoch = 185 train_loss : 2.537370 , test loss : 2.799884\n",
      "epoch = 186 train_loss : 2.531255 , test loss : 2.794678\n",
      "epoch = 187 train_loss : 2.525396 , test loss : 2.789245\n",
      "epoch = 188 train_loss : 2.519635 , test loss : 2.784506\n",
      "epoch = 189 train_loss : 2.513934 , test loss : 2.779538\n",
      "epoch = 190 train_loss : 2.508372 , test loss : 2.774742\n",
      "epoch = 191 train_loss : 2.502830 , test loss : 2.770011\n",
      "epoch = 192 train_loss : 2.497417 , test loss : 2.765501\n",
      "epoch = 193 train_loss : 2.492225 , test loss : 2.760742\n",
      "epoch = 194 train_loss : 2.486982 , test loss : 2.756246\n",
      "epoch = 195 train_loss : 2.481756 , test loss : 2.751653\n",
      "epoch = 196 train_loss : 2.476898 , test loss : 2.747208\n",
      "epoch = 197 train_loss : 2.471818 , test loss : 2.743042\n",
      "epoch = 198 train_loss : 2.466992 , test loss : 2.738891\n",
      "epoch = 199 train_loss : 2.462040 , test loss : 2.734408\n",
      "epoch = 200 train_loss : 2.457293 , test loss : 2.730211\n",
      "epoch = 201 train_loss : 2.452527 , test loss : 2.726028\n",
      "epoch = 202 train_loss : 2.447858 , test loss : 2.722135\n",
      "epoch = 203 train_loss : 2.443067 , test loss : 2.717883\n",
      "epoch = 204 train_loss : 2.438526 , test loss : 2.713978\n",
      "epoch = 205 train_loss : 2.433896 , test loss : 2.709992\n",
      "epoch = 206 train_loss : 2.429310 , test loss : 2.705965\n",
      "epoch = 207 train_loss : 2.424864 , test loss : 2.702179\n",
      "epoch = 208 train_loss : 2.420488 , test loss : 2.698538\n",
      "epoch = 209 train_loss : 2.415981 , test loss : 2.694800\n",
      "epoch = 210 train_loss : 2.411651 , test loss : 2.690739\n",
      "epoch = 211 train_loss : 2.407238 , test loss : 2.686881\n",
      "epoch = 212 train_loss : 2.402874 , test loss : 2.683111\n",
      "epoch = 213 train_loss : 2.398440 , test loss : 2.679435\n",
      "epoch = 214 train_loss : 2.394173 , test loss : 2.675801\n",
      "epoch = 215 train_loss : 2.389952 , test loss : 2.671779\n",
      "epoch = 216 train_loss : 2.385703 , test loss : 2.668430\n",
      "epoch = 217 train_loss : 2.381487 , test loss : 2.664564\n",
      "epoch = 218 train_loss : 2.377266 , test loss : 2.660706\n",
      "epoch = 219 train_loss : 2.373067 , test loss : 2.657041\n",
      "epoch = 220 train_loss : 2.368932 , test loss : 2.653443\n",
      "epoch = 221 train_loss : 2.364699 , test loss : 2.649777\n",
      "epoch = 222 train_loss : 2.360470 , test loss : 2.646117\n",
      "epoch = 223 train_loss : 2.356405 , test loss : 2.642670\n",
      "epoch = 224 train_loss : 2.352386 , test loss : 2.639105\n",
      "epoch = 225 train_loss : 2.348278 , test loss : 2.635836\n",
      "epoch = 226 train_loss : 2.344303 , test loss : 2.632235\n",
      "epoch = 227 train_loss : 2.340269 , test loss : 2.628432\n",
      "epoch = 228 train_loss : 2.336357 , test loss : 2.625128\n",
      "epoch = 229 train_loss : 2.332243 , test loss : 2.621453\n",
      "epoch = 230 train_loss : 2.328421 , test loss : 2.618009\n",
      "epoch = 231 train_loss : 2.324387 , test loss : 2.614471\n",
      "epoch = 232 train_loss : 2.320496 , test loss : 2.611289\n",
      "epoch = 233 train_loss : 2.316587 , test loss : 2.607751\n",
      "epoch = 234 train_loss : 2.312649 , test loss : 2.604260\n",
      "epoch = 235 train_loss : 2.308903 , test loss : 2.600803\n",
      "epoch = 236 train_loss : 2.304928 , test loss : 2.596993\n",
      "epoch = 237 train_loss : 2.301005 , test loss : 2.593634\n",
      "epoch = 238 train_loss : 2.297152 , test loss : 2.590068\n",
      "epoch = 239 train_loss : 2.293310 , test loss : 2.586857\n",
      "epoch = 240 train_loss : 2.289472 , test loss : 2.583360\n",
      "epoch = 241 train_loss : 2.285673 , test loss : 2.580207\n",
      "epoch = 242 train_loss : 2.281858 , test loss : 2.576483\n",
      "epoch = 243 train_loss : 2.278122 , test loss : 2.573343\n",
      "epoch = 244 train_loss : 2.274353 , test loss : 2.569953\n",
      "epoch = 245 train_loss : 2.270569 , test loss : 2.566505\n",
      "epoch = 246 train_loss : 2.266824 , test loss : 2.563352\n",
      "epoch = 247 train_loss : 2.263055 , test loss : 2.559911\n",
      "epoch = 248 train_loss : 2.259373 , test loss : 2.556631\n",
      "epoch = 249 train_loss : 2.255692 , test loss : 2.553256\n",
      "epoch = 250 train_loss : 2.251981 , test loss : 2.549804\n",
      "epoch = 251 train_loss : 2.248295 , test loss : 2.546524\n",
      "epoch = 252 train_loss : 2.244541 , test loss : 2.542930\n",
      "epoch = 253 train_loss : 2.240846 , test loss : 2.539791\n",
      "epoch = 254 train_loss : 2.237251 , test loss : 2.536750\n",
      "epoch = 255 train_loss : 2.233506 , test loss : 2.533334\n",
      "epoch = 256 train_loss : 2.229795 , test loss : 2.529572\n",
      "epoch = 257 train_loss : 2.226220 , test loss : 2.526798\n",
      "epoch = 258 train_loss : 2.222557 , test loss : 2.523479\n",
      "epoch = 259 train_loss : 2.218897 , test loss : 2.519906\n",
      "epoch = 260 train_loss : 2.215291 , test loss : 2.516741\n",
      "epoch = 261 train_loss : 2.211539 , test loss : 2.513437\n",
      "epoch = 262 train_loss : 2.207921 , test loss : 2.509997\n",
      "epoch = 263 train_loss : 2.204415 , test loss : 2.506611\n",
      "epoch = 264 train_loss : 2.200738 , test loss : 2.503228\n",
      "epoch = 265 train_loss : 2.197124 , test loss : 2.499869\n",
      "epoch = 266 train_loss : 2.193459 , test loss : 2.496704\n",
      "epoch = 267 train_loss : 2.189940 , test loss : 2.493654\n",
      "epoch = 268 train_loss : 2.186319 , test loss : 2.490207\n",
      "epoch = 269 train_loss : 2.182706 , test loss : 2.486968\n",
      "epoch = 270 train_loss : 2.179140 , test loss : 2.483504\n",
      "epoch = 271 train_loss : 2.175486 , test loss : 2.480055\n",
      "epoch = 272 train_loss : 2.171950 , test loss : 2.476737\n",
      "epoch = 273 train_loss : 2.168301 , test loss : 2.473481\n",
      "epoch = 274 train_loss : 2.164654 , test loss : 2.469798\n",
      "epoch = 275 train_loss : 2.161024 , test loss : 2.466793\n",
      "epoch = 276 train_loss : 2.157370 , test loss : 2.463144\n",
      "epoch = 277 train_loss : 2.153760 , test loss : 2.459692\n",
      "epoch = 278 train_loss : 2.150098 , test loss : 2.456406\n",
      "epoch = 279 train_loss : 2.146489 , test loss : 2.452955\n",
      "epoch = 280 train_loss : 2.142801 , test loss : 2.449665\n",
      "epoch = 281 train_loss : 2.139058 , test loss : 2.445962\n",
      "epoch = 282 train_loss : 2.135427 , test loss : 2.442833\n",
      "epoch = 283 train_loss : 2.131817 , test loss : 2.439562\n",
      "epoch = 284 train_loss : 2.128164 , test loss : 2.436378\n",
      "epoch = 285 train_loss : 2.124509 , test loss : 2.432672\n",
      "epoch = 286 train_loss : 2.120916 , test loss : 2.429128\n",
      "epoch = 287 train_loss : 2.117308 , test loss : 2.425946\n",
      "epoch = 288 train_loss : 2.113595 , test loss : 2.422346\n",
      "epoch = 289 train_loss : 2.109971 , test loss : 2.418817\n",
      "epoch = 290 train_loss : 2.106295 , test loss : 2.415582\n",
      "epoch = 291 train_loss : 2.102668 , test loss : 2.411967\n",
      "epoch = 292 train_loss : 2.099011 , test loss : 2.408623\n",
      "epoch = 293 train_loss : 2.095349 , test loss : 2.405500\n",
      "epoch = 294 train_loss : 2.091652 , test loss : 2.401867\n",
      "epoch = 295 train_loss : 2.087948 , test loss : 2.398533\n",
      "epoch = 296 train_loss : 2.084283 , test loss : 2.395133\n",
      "epoch = 297 train_loss : 2.080636 , test loss : 2.391559\n",
      "epoch = 298 train_loss : 2.077031 , test loss : 2.388097\n",
      "epoch = 299 train_loss : 2.073402 , test loss : 2.384531\n",
      "epoch = 300 train_loss : 2.069793 , test loss : 2.381508\n",
      "epoch = 301 train_loss : 2.066203 , test loss : 2.378002\n",
      "epoch = 302 train_loss : 2.062522 , test loss : 2.374761\n",
      "epoch = 303 train_loss : 2.058894 , test loss : 2.371115\n",
      "epoch = 304 train_loss : 2.055231 , test loss : 2.367668\n",
      "epoch = 305 train_loss : 2.051603 , test loss : 2.364505\n",
      "epoch = 306 train_loss : 2.047971 , test loss : 2.361295\n",
      "epoch = 307 train_loss : 2.044293 , test loss : 2.357929\n",
      "epoch = 308 train_loss : 2.040681 , test loss : 2.353962\n",
      "epoch = 309 train_loss : 2.037026 , test loss : 2.350676\n",
      "epoch = 310 train_loss : 2.033354 , test loss : 2.347424\n",
      "epoch = 311 train_loss : 2.029688 , test loss : 2.343860\n",
      "epoch = 312 train_loss : 2.026059 , test loss : 2.340608\n",
      "epoch = 313 train_loss : 2.022405 , test loss : 2.336598\n",
      "epoch = 314 train_loss : 2.018783 , test loss : 2.333244\n",
      "epoch = 315 train_loss : 2.015131 , test loss : 2.329707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 316 train_loss : 2.011544 , test loss : 2.326263\n",
      "epoch = 317 train_loss : 2.007793 , test loss : 2.323056\n",
      "epoch = 318 train_loss : 2.004182 , test loss : 2.319427\n",
      "epoch = 319 train_loss : 2.000532 , test loss : 2.315904\n",
      "epoch = 320 train_loss : 1.996925 , test loss : 2.312625\n",
      "epoch = 321 train_loss : 1.993337 , test loss : 2.309479\n",
      "epoch = 322 train_loss : 1.989688 , test loss : 2.306056\n",
      "epoch = 323 train_loss : 1.986164 , test loss : 2.302772\n",
      "epoch = 324 train_loss : 1.982518 , test loss : 2.299164\n",
      "epoch = 325 train_loss : 1.978872 , test loss : 2.295570\n",
      "epoch = 326 train_loss : 1.975284 , test loss : 2.292130\n",
      "epoch = 327 train_loss : 1.971699 , test loss : 2.288983\n",
      "epoch = 328 train_loss : 1.968156 , test loss : 2.285403\n",
      "epoch = 329 train_loss : 1.964555 , test loss : 2.281601\n",
      "epoch = 330 train_loss : 1.960967 , test loss : 2.278457\n",
      "epoch = 331 train_loss : 1.957280 , test loss : 2.274876\n",
      "epoch = 332 train_loss : 1.953782 , test loss : 2.271619\n",
      "epoch = 333 train_loss : 1.950189 , test loss : 2.268084\n",
      "epoch = 334 train_loss : 1.946645 , test loss : 2.264551\n",
      "epoch = 335 train_loss : 1.943098 , test loss : 2.261258\n",
      "epoch = 336 train_loss : 1.939542 , test loss : 2.257700\n",
      "epoch = 337 train_loss : 1.935947 , test loss : 2.254237\n",
      "epoch = 338 train_loss : 1.932384 , test loss : 2.251148\n",
      "epoch = 339 train_loss : 1.928795 , test loss : 2.247259\n",
      "epoch = 340 train_loss : 1.925220 , test loss : 2.244452\n",
      "epoch = 341 train_loss : 1.921651 , test loss : 2.240529\n",
      "epoch = 342 train_loss : 1.918087 , test loss : 2.237116\n",
      "epoch = 343 train_loss : 1.914570 , test loss : 2.233855\n",
      "epoch = 344 train_loss : 1.911012 , test loss : 2.230618\n",
      "epoch = 345 train_loss : 1.907451 , test loss : 2.226963\n",
      "epoch = 346 train_loss : 1.903908 , test loss : 2.223801\n",
      "epoch = 347 train_loss : 1.900346 , test loss : 2.220489\n",
      "epoch = 348 train_loss : 1.896864 , test loss : 2.217024\n",
      "epoch = 349 train_loss : 1.893320 , test loss : 2.213400\n",
      "epoch = 350 train_loss : 1.889872 , test loss : 2.210128\n",
      "epoch = 351 train_loss : 1.886217 , test loss : 2.206388\n",
      "epoch = 352 train_loss : 1.882771 , test loss : 2.202853\n",
      "epoch = 353 train_loss : 1.879195 , test loss : 2.199896\n",
      "epoch = 354 train_loss : 1.875658 , test loss : 2.196038\n",
      "epoch = 355 train_loss : 1.872143 , test loss : 2.192673\n",
      "epoch = 356 train_loss : 1.868734 , test loss : 2.189717\n",
      "epoch = 357 train_loss : 1.865269 , test loss : 2.185801\n",
      "epoch = 358 train_loss : 1.861737 , test loss : 2.182557\n",
      "epoch = 359 train_loss : 1.858241 , test loss : 2.179071\n",
      "epoch = 360 train_loss : 1.854766 , test loss : 2.175755\n",
      "epoch = 361 train_loss : 1.851280 , test loss : 2.172282\n",
      "epoch = 362 train_loss : 1.847823 , test loss : 2.169078\n",
      "epoch = 363 train_loss : 1.844358 , test loss : 2.165454\n",
      "epoch = 364 train_loss : 1.840834 , test loss : 2.161995\n",
      "epoch = 365 train_loss : 1.837413 , test loss : 2.159050\n",
      "epoch = 366 train_loss : 1.833927 , test loss : 2.155454\n",
      "epoch = 367 train_loss : 1.830491 , test loss : 2.152148\n",
      "epoch = 368 train_loss : 1.827073 , test loss : 2.148641\n",
      "epoch = 369 train_loss : 1.823627 , test loss : 2.145160\n",
      "epoch = 370 train_loss : 1.820190 , test loss : 2.141942\n",
      "epoch = 371 train_loss : 1.816690 , test loss : 2.138275\n",
      "epoch = 372 train_loss : 1.813301 , test loss : 2.135481\n",
      "epoch = 373 train_loss : 1.809881 , test loss : 2.132006\n",
      "epoch = 374 train_loss : 1.806514 , test loss : 2.128256\n",
      "epoch = 375 train_loss : 1.803072 , test loss : 2.124900\n",
      "epoch = 376 train_loss : 1.799706 , test loss : 2.122129\n",
      "epoch = 377 train_loss : 1.796296 , test loss : 2.118511\n",
      "epoch = 378 train_loss : 1.792963 , test loss : 2.115312\n",
      "epoch = 379 train_loss : 1.789595 , test loss : 2.112307\n",
      "epoch = 380 train_loss : 1.786252 , test loss : 2.108374\n",
      "epoch = 381 train_loss : 1.782904 , test loss : 2.104714\n",
      "epoch = 382 train_loss : 1.779548 , test loss : 2.102009\n",
      "epoch = 383 train_loss : 1.776217 , test loss : 2.098364\n",
      "epoch = 384 train_loss : 1.772866 , test loss : 2.095346\n",
      "epoch = 385 train_loss : 1.769533 , test loss : 2.091990\n",
      "epoch = 386 train_loss : 1.766236 , test loss : 2.088661\n",
      "epoch = 387 train_loss : 1.762969 , test loss : 2.085826\n",
      "epoch = 388 train_loss : 1.759613 , test loss : 2.082193\n",
      "epoch = 389 train_loss : 1.756267 , test loss : 2.078841\n",
      "epoch = 390 train_loss : 1.752946 , test loss : 2.075786\n",
      "epoch = 391 train_loss : 1.749687 , test loss : 2.072541\n",
      "epoch = 392 train_loss : 1.746398 , test loss : 2.068925\n",
      "epoch = 393 train_loss : 1.743148 , test loss : 2.066342\n",
      "epoch = 394 train_loss : 1.739851 , test loss : 2.062827\n",
      "epoch = 395 train_loss : 1.736621 , test loss : 2.059704\n",
      "epoch = 396 train_loss : 1.733406 , test loss : 2.056881\n",
      "epoch = 397 train_loss : 1.730117 , test loss : 2.053532\n",
      "epoch = 398 train_loss : 1.726876 , test loss : 2.050592\n",
      "epoch = 399 train_loss : 1.723622 , test loss : 2.047397\n",
      "epoch = 400 train_loss : 1.720486 , test loss : 2.044500\n",
      "epoch = 401 train_loss : 1.717198 , test loss : 2.041339\n",
      "epoch = 402 train_loss : 1.714077 , test loss : 2.037617\n",
      "epoch = 403 train_loss : 1.710879 , test loss : 2.034905\n",
      "epoch = 404 train_loss : 1.707617 , test loss : 2.031967\n",
      "epoch = 405 train_loss : 1.704465 , test loss : 2.028712\n",
      "epoch = 406 train_loss : 1.701275 , test loss : 2.025406\n",
      "epoch = 407 train_loss : 1.698117 , test loss : 2.022872\n",
      "epoch = 408 train_loss : 1.695024 , test loss : 2.018943\n",
      "epoch = 409 train_loss : 1.691868 , test loss : 2.016606\n",
      "epoch = 410 train_loss : 1.688688 , test loss : 2.013161\n",
      "epoch = 411 train_loss : 1.685580 , test loss : 2.010403\n",
      "epoch = 412 train_loss : 1.682459 , test loss : 2.007417\n",
      "epoch = 413 train_loss : 1.679330 , test loss : 2.003895\n",
      "epoch = 414 train_loss : 1.676263 , test loss : 2.001765\n",
      "epoch = 415 train_loss : 1.673208 , test loss : 1.998890\n",
      "epoch = 416 train_loss : 1.670113 , test loss : 1.995772\n",
      "epoch = 417 train_loss : 1.667041 , test loss : 1.992609\n",
      "epoch = 418 train_loss : 1.663978 , test loss : 1.990008\n",
      "epoch = 419 train_loss : 1.660920 , test loss : 1.986755\n",
      "epoch = 420 train_loss : 1.657910 , test loss : 1.983855\n",
      "epoch = 421 train_loss : 1.654867 , test loss : 1.981306\n",
      "epoch = 422 train_loss : 1.651827 , test loss : 1.978414\n",
      "epoch = 423 train_loss : 1.648808 , test loss : 1.974810\n",
      "epoch = 424 train_loss : 1.645756 , test loss : 1.971580\n",
      "epoch = 425 train_loss : 1.642821 , test loss : 1.969271\n",
      "epoch = 426 train_loss : 1.639806 , test loss : 1.966526\n",
      "epoch = 427 train_loss : 1.636844 , test loss : 1.963407\n",
      "epoch = 428 train_loss : 1.633826 , test loss : 1.961167\n",
      "epoch = 429 train_loss : 1.630773 , test loss : 1.958169\n",
      "epoch = 430 train_loss : 1.627844 , test loss : 1.955196\n",
      "epoch = 431 train_loss : 1.624904 , test loss : 1.951938\n",
      "epoch = 432 train_loss : 1.621914 , test loss : 1.949768\n",
      "epoch = 433 train_loss : 1.619006 , test loss : 1.946484\n",
      "epoch = 434 train_loss : 1.616056 , test loss : 1.943840\n",
      "epoch = 435 train_loss : 1.613144 , test loss : 1.940893\n",
      "epoch = 436 train_loss : 1.610171 , test loss : 1.938522\n",
      "epoch = 437 train_loss : 1.607287 , test loss : 1.935845\n",
      "epoch = 438 train_loss : 1.604388 , test loss : 1.932371\n",
      "epoch = 439 train_loss : 1.601442 , test loss : 1.929763\n",
      "epoch = 440 train_loss : 1.598544 , test loss : 1.927203\n",
      "epoch = 441 train_loss : 1.595737 , test loss : 1.924676\n",
      "epoch = 442 train_loss : 1.592795 , test loss : 1.921279\n",
      "epoch = 443 train_loss : 1.589986 , test loss : 1.918473\n",
      "epoch = 444 train_loss : 1.587050 , test loss : 1.915916\n",
      "epoch = 445 train_loss : 1.584134 , test loss : 1.913684\n",
      "epoch = 446 train_loss : 1.581260 , test loss : 1.910989\n",
      "epoch = 447 train_loss : 1.578413 , test loss : 1.907898\n",
      "epoch = 448 train_loss : 1.575536 , test loss : 1.905235\n",
      "epoch = 449 train_loss : 1.572685 , test loss : 1.902874\n",
      "epoch = 450 train_loss : 1.569903 , test loss : 1.900023\n",
      "epoch = 451 train_loss : 1.567071 , test loss : 1.897243\n",
      "epoch = 452 train_loss : 1.564279 , test loss : 1.894393\n",
      "epoch = 453 train_loss : 1.561399 , test loss : 1.891742\n",
      "epoch = 454 train_loss : 1.558630 , test loss : 1.889182\n",
      "epoch = 455 train_loss : 1.555756 , test loss : 1.886479\n",
      "epoch = 456 train_loss : 1.553005 , test loss : 1.884137\n",
      "epoch = 457 train_loss : 1.550262 , test loss : 1.881663\n",
      "epoch = 458 train_loss : 1.547499 , test loss : 1.879123\n",
      "epoch = 459 train_loss : 1.544723 , test loss : 1.876539\n",
      "epoch = 460 train_loss : 1.542039 , test loss : 1.873936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 461 train_loss : 1.539320 , test loss : 1.870372\n",
      "epoch = 462 train_loss : 1.536493 , test loss : 1.868204\n",
      "epoch = 463 train_loss : 1.533860 , test loss : 1.865404\n",
      "epoch = 464 train_loss : 1.531164 , test loss : 1.863445\n",
      "epoch = 465 train_loss : 1.528484 , test loss : 1.860887\n",
      "epoch = 466 train_loss : 1.525833 , test loss : 1.858338\n",
      "epoch = 467 train_loss : 1.523129 , test loss : 1.855742\n",
      "epoch = 468 train_loss : 1.520458 , test loss : 1.853103\n",
      "epoch = 469 train_loss : 1.517798 , test loss : 1.850346\n",
      "epoch = 470 train_loss : 1.515168 , test loss : 1.847939\n",
      "epoch = 471 train_loss : 1.512446 , test loss : 1.845096\n",
      "epoch = 472 train_loss : 1.509830 , test loss : 1.843127\n",
      "epoch = 473 train_loss : 1.507213 , test loss : 1.840361\n",
      "epoch = 474 train_loss : 1.504611 , test loss : 1.837641\n",
      "epoch = 475 train_loss : 1.502056 , test loss : 1.835441\n",
      "epoch = 476 train_loss : 1.499440 , test loss : 1.832709\n",
      "epoch = 477 train_loss : 1.496928 , test loss : 1.829495\n",
      "epoch = 478 train_loss : 1.494320 , test loss : 1.828089\n",
      "epoch = 479 train_loss : 1.491797 , test loss : 1.825790\n",
      "epoch = 480 train_loss : 1.489278 , test loss : 1.823097\n",
      "epoch = 481 train_loss : 1.486753 , test loss : 1.820666\n",
      "epoch = 482 train_loss : 1.484228 , test loss : 1.818153\n",
      "epoch = 483 train_loss : 1.481701 , test loss : 1.815454\n",
      "epoch = 484 train_loss : 1.479229 , test loss : 1.813214\n",
      "epoch = 485 train_loss : 1.476745 , test loss : 1.811016\n",
      "epoch = 486 train_loss : 1.474292 , test loss : 1.808562\n",
      "epoch = 487 train_loss : 1.471818 , test loss : 1.806545\n",
      "epoch = 488 train_loss : 1.469343 , test loss : 1.804242\n",
      "epoch = 489 train_loss : 1.466938 , test loss : 1.802063\n",
      "epoch = 490 train_loss : 1.464525 , test loss : 1.798795\n",
      "epoch = 491 train_loss : 1.462137 , test loss : 1.796507\n",
      "epoch = 492 train_loss : 1.459769 , test loss : 1.794976\n",
      "epoch = 493 train_loss : 1.457366 , test loss : 1.792333\n",
      "epoch = 494 train_loss : 1.454964 , test loss : 1.789725\n",
      "epoch = 495 train_loss : 1.452629 , test loss : 1.787828\n",
      "epoch = 496 train_loss : 1.450269 , test loss : 1.785271\n",
      "epoch = 497 train_loss : 1.447900 , test loss : 1.783551\n",
      "epoch = 498 train_loss : 1.445562 , test loss : 1.781161\n",
      "epoch = 499 train_loss : 1.443170 , test loss : 1.779453\n",
      "epoch = 500 train_loss : 1.440918 , test loss : 1.777050\n",
      "epoch = 501 train_loss : 1.438525 , test loss : 1.774215\n",
      "epoch = 502 train_loss : 1.436215 , test loss : 1.772098\n",
      "epoch = 503 train_loss : 1.433915 , test loss : 1.770416\n",
      "epoch = 504 train_loss : 1.431584 , test loss : 1.768122\n",
      "epoch = 505 train_loss : 1.429361 , test loss : 1.765208\n",
      "epoch = 506 train_loss : 1.427067 , test loss : 1.763660\n",
      "epoch = 507 train_loss : 1.424814 , test loss : 1.761806\n",
      "epoch = 508 train_loss : 1.422526 , test loss : 1.759296\n",
      "epoch = 509 train_loss : 1.420247 , test loss : 1.756697\n",
      "epoch = 510 train_loss : 1.418043 , test loss : 1.754939\n",
      "epoch = 511 train_loss : 1.415785 , test loss : 1.753377\n",
      "epoch = 512 train_loss : 1.413586 , test loss : 1.751461\n",
      "epoch = 513 train_loss : 1.411375 , test loss : 1.749192\n",
      "epoch = 514 train_loss : 1.409211 , test loss : 1.746797\n",
      "epoch = 515 train_loss : 1.407043 , test loss : 1.744982\n",
      "epoch = 516 train_loss : 1.404915 , test loss : 1.742476\n",
      "epoch = 517 train_loss : 1.402737 , test loss : 1.739897\n",
      "epoch = 518 train_loss : 1.400556 , test loss : 1.738391\n",
      "epoch = 519 train_loss : 1.398421 , test loss : 1.737487\n",
      "epoch = 520 train_loss : 1.396323 , test loss : 1.735176\n",
      "epoch = 521 train_loss : 1.394130 , test loss : 1.732401\n",
      "epoch = 522 train_loss : 1.392028 , test loss : 1.730603\n",
      "epoch = 523 train_loss : 1.389948 , test loss : 1.728218\n",
      "epoch = 524 train_loss : 1.387864 , test loss : 1.726190\n",
      "epoch = 525 train_loss : 1.385755 , test loss : 1.724302\n",
      "epoch = 526 train_loss : 1.383714 , test loss : 1.723414\n",
      "epoch = 527 train_loss : 1.381654 , test loss : 1.721155\n",
      "epoch = 528 train_loss : 1.379571 , test loss : 1.718851\n",
      "epoch = 529 train_loss : 1.377564 , test loss : 1.717290\n",
      "epoch = 530 train_loss : 1.375517 , test loss : 1.715219\n",
      "epoch = 531 train_loss : 1.373497 , test loss : 1.712659\n",
      "epoch = 532 train_loss : 1.371393 , test loss : 1.711028\n",
      "epoch = 533 train_loss : 1.369428 , test loss : 1.710156\n",
      "epoch = 534 train_loss : 1.367418 , test loss : 1.707743\n",
      "epoch = 535 train_loss : 1.365405 , test loss : 1.706167\n",
      "epoch = 536 train_loss : 1.363365 , test loss : 1.703571\n",
      "epoch = 537 train_loss : 1.361439 , test loss : 1.702156\n",
      "epoch = 538 train_loss : 1.359424 , test loss : 1.700212\n",
      "epoch = 539 train_loss : 1.357449 , test loss : 1.698471\n",
      "epoch = 540 train_loss : 1.355499 , test loss : 1.695863\n",
      "epoch = 541 train_loss : 1.353549 , test loss : 1.694772\n",
      "epoch = 542 train_loss : 1.351578 , test loss : 1.692124\n",
      "epoch = 543 train_loss : 1.349646 , test loss : 1.691022\n",
      "epoch = 544 train_loss : 1.347719 , test loss : 1.689330\n",
      "epoch = 545 train_loss : 1.345791 , test loss : 1.686786\n",
      "epoch = 546 train_loss : 1.343894 , test loss : 1.685140\n",
      "epoch = 547 train_loss : 1.342021 , test loss : 1.683649\n",
      "epoch = 548 train_loss : 1.340142 , test loss : 1.681213\n",
      "epoch = 549 train_loss : 1.338307 , test loss : 1.680811\n",
      "epoch = 550 train_loss : 1.336352 , test loss : 1.678617\n",
      "epoch = 551 train_loss : 1.334488 , test loss : 1.676612\n",
      "epoch = 552 train_loss : 1.332658 , test loss : 1.674775\n",
      "epoch = 553 train_loss : 1.330813 , test loss : 1.673025\n",
      "epoch = 554 train_loss : 1.328954 , test loss : 1.671453\n",
      "epoch = 555 train_loss : 1.327136 , test loss : 1.669643\n",
      "epoch = 556 train_loss : 1.325290 , test loss : 1.668140\n",
      "epoch = 557 train_loss : 1.323516 , test loss : 1.666153\n",
      "epoch = 558 train_loss : 1.321704 , test loss : 1.664629\n",
      "epoch = 559 train_loss : 1.319906 , test loss : 1.662780\n",
      "epoch = 560 train_loss : 1.318128 , test loss : 1.660453\n",
      "epoch = 561 train_loss : 1.316421 , test loss : 1.658790\n",
      "epoch = 562 train_loss : 1.314604 , test loss : 1.658344\n",
      "epoch = 563 train_loss : 1.312798 , test loss : 1.656347\n",
      "epoch = 564 train_loss : 1.311056 , test loss : 1.654475\n",
      "epoch = 565 train_loss : 1.309313 , test loss : 1.653103\n",
      "epoch = 566 train_loss : 1.307641 , test loss : 1.651609\n",
      "epoch = 567 train_loss : 1.305848 , test loss : 1.649999\n",
      "epoch = 568 train_loss : 1.304143 , test loss : 1.647827\n",
      "epoch = 569 train_loss : 1.302390 , test loss : 1.645988\n",
      "epoch = 570 train_loss : 1.300693 , test loss : 1.644408\n",
      "epoch = 571 train_loss : 1.299051 , test loss : 1.643226\n",
      "epoch = 572 train_loss : 1.297374 , test loss : 1.641018\n",
      "epoch = 573 train_loss : 1.295671 , test loss : 1.639424\n",
      "epoch = 574 train_loss : 1.294001 , test loss : 1.639055\n",
      "epoch = 575 train_loss : 1.292277 , test loss : 1.636370\n",
      "epoch = 576 train_loss : 1.290632 , test loss : 1.634499\n",
      "epoch = 577 train_loss : 1.288975 , test loss : 1.633061\n",
      "epoch = 578 train_loss : 1.287290 , test loss : 1.631643\n",
      "epoch = 579 train_loss : 1.285635 , test loss : 1.630154\n",
      "epoch = 580 train_loss : 1.284046 , test loss : 1.628976\n",
      "epoch = 581 train_loss : 1.282379 , test loss : 1.627435\n",
      "epoch = 582 train_loss : 1.280774 , test loss : 1.625326\n",
      "epoch = 583 train_loss : 1.279247 , test loss : 1.623210\n",
      "epoch = 584 train_loss : 1.277557 , test loss : 1.622689\n",
      "epoch = 585 train_loss : 1.275944 , test loss : 1.620609\n",
      "epoch = 586 train_loss : 1.274338 , test loss : 1.619694\n",
      "epoch = 587 train_loss : 1.272750 , test loss : 1.617844\n",
      "epoch = 588 train_loss : 1.271163 , test loss : 1.615914\n",
      "epoch = 589 train_loss : 1.269615 , test loss : 1.614167\n",
      "epoch = 590 train_loss : 1.268064 , test loss : 1.613813\n",
      "epoch = 591 train_loss : 1.266466 , test loss : 1.611653\n",
      "epoch = 592 train_loss : 1.264918 , test loss : 1.610324\n",
      "epoch = 593 train_loss : 1.263398 , test loss : 1.608509\n",
      "epoch = 594 train_loss : 1.261778 , test loss : 1.606692\n",
      "epoch = 595 train_loss : 1.260256 , test loss : 1.606316\n",
      "epoch = 596 train_loss : 1.258699 , test loss : 1.604922\n",
      "epoch = 597 train_loss : 1.257204 , test loss : 1.603218\n",
      "epoch = 598 train_loss : 1.255682 , test loss : 1.602257\n",
      "epoch = 599 train_loss : 1.254130 , test loss : 1.600228\n",
      "epoch = 600 train_loss : 1.252710 , test loss : 1.598487\n",
      "epoch = 601 train_loss : 1.251222 , test loss : 1.597861\n",
      "epoch = 602 train_loss : 1.249676 , test loss : 1.595629\n",
      "epoch = 603 train_loss : 1.248166 , test loss : 1.594872\n",
      "epoch = 604 train_loss : 1.246695 , test loss : 1.593110\n",
      "epoch = 605 train_loss : 1.245208 , test loss : 1.591908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 606 train_loss : 1.243729 , test loss : 1.590567\n",
      "epoch = 607 train_loss : 1.242279 , test loss : 1.589548\n",
      "epoch = 608 train_loss : 1.240826 , test loss : 1.587935\n",
      "epoch = 609 train_loss : 1.239391 , test loss : 1.586283\n",
      "epoch = 610 train_loss : 1.237950 , test loss : 1.584752\n",
      "epoch = 611 train_loss : 1.236537 , test loss : 1.584012\n",
      "epoch = 612 train_loss : 1.235094 , test loss : 1.582088\n",
      "epoch = 613 train_loss : 1.233712 , test loss : 1.580273\n",
      "epoch = 614 train_loss : 1.232256 , test loss : 1.579725\n",
      "epoch = 615 train_loss : 1.230940 , test loss : 1.578943\n",
      "epoch = 616 train_loss : 1.229456 , test loss : 1.576324\n",
      "epoch = 617 train_loss : 1.228008 , test loss : 1.575599\n",
      "epoch = 618 train_loss : 1.226661 , test loss : 1.574850\n",
      "epoch = 619 train_loss : 1.225266 , test loss : 1.573551\n",
      "epoch = 620 train_loss : 1.223922 , test loss : 1.571956\n",
      "epoch = 621 train_loss : 1.222557 , test loss : 1.569697\n",
      "epoch = 622 train_loss : 1.221181 , test loss : 1.568810\n",
      "epoch = 623 train_loss : 1.219847 , test loss : 1.568568\n",
      "epoch = 624 train_loss : 1.218499 , test loss : 1.566311\n",
      "epoch = 625 train_loss : 1.217140 , test loss : 1.564714\n",
      "epoch = 626 train_loss : 1.215826 , test loss : 1.564331\n",
      "epoch = 627 train_loss : 1.214495 , test loss : 1.562699\n",
      "epoch = 628 train_loss : 1.213159 , test loss : 1.561707\n",
      "epoch = 629 train_loss : 1.211868 , test loss : 1.560537\n",
      "epoch = 630 train_loss : 1.210548 , test loss : 1.558753\n",
      "epoch = 631 train_loss : 1.209229 , test loss : 1.558012\n",
      "epoch = 632 train_loss : 1.207944 , test loss : 1.556118\n",
      "epoch = 633 train_loss : 1.206781 , test loss : 1.555853\n",
      "epoch = 634 train_loss : 1.205382 , test loss : 1.554217\n",
      "epoch = 635 train_loss : 1.204049 , test loss : 1.552739\n",
      "epoch = 636 train_loss : 1.202806 , test loss : 1.551216\n",
      "epoch = 637 train_loss : 1.201508 , test loss : 1.550197\n",
      "epoch = 638 train_loss : 1.200243 , test loss : 1.548942\n",
      "epoch = 639 train_loss : 1.199013 , test loss : 1.547577\n",
      "epoch = 640 train_loss : 1.197772 , test loss : 1.546477\n",
      "epoch = 641 train_loss : 1.196491 , test loss : 1.545246\n",
      "epoch = 642 train_loss : 1.195265 , test loss : 1.544094\n",
      "epoch = 643 train_loss : 1.194018 , test loss : 1.542766\n",
      "epoch = 644 train_loss : 1.192796 , test loss : 1.542165\n",
      "epoch = 645 train_loss : 1.191569 , test loss : 1.540955\n",
      "epoch = 646 train_loss : 1.190364 , test loss : 1.539618\n",
      "epoch = 647 train_loss : 1.189142 , test loss : 1.538109\n",
      "epoch = 648 train_loss : 1.187958 , test loss : 1.537561\n",
      "epoch = 649 train_loss : 1.186748 , test loss : 1.535890\n",
      "epoch = 651 train_loss : 1.184332 , test loss : 1.533679\n",
      "epoch = 652 train_loss : 1.183218 , test loss : 1.533297\n",
      "epoch = 653 train_loss : 1.182021 , test loss : 1.531257\n",
      "epoch = 654 train_loss : 1.180817 , test loss : 1.530701\n",
      "epoch = 655 train_loss : 1.179669 , test loss : 1.528921\n",
      "epoch = 656 train_loss : 1.178514 , test loss : 1.527947\n",
      "epoch = 657 train_loss : 1.177366 , test loss : 1.526811\n",
      "epoch = 658 train_loss : 1.176246 , test loss : 1.526183\n",
      "epoch = 659 train_loss : 1.175101 , test loss : 1.524871\n",
      "epoch = 660 train_loss : 1.173977 , test loss : 1.523355\n",
      "epoch = 661 train_loss : 1.172832 , test loss : 1.522537\n",
      "epoch = 662 train_loss : 1.171705 , test loss : 1.521621\n",
      "epoch = 663 train_loss : 1.170617 , test loss : 1.520682\n",
      "epoch = 664 train_loss : 1.169476 , test loss : 1.519967\n",
      "epoch = 665 train_loss : 1.168422 , test loss : 1.519279\n",
      "epoch = 666 train_loss : 1.167237 , test loss : 1.517098\n",
      "epoch = 667 train_loss : 1.166202 , test loss : 1.515378\n",
      "epoch = 668 train_loss : 1.165031 , test loss : 1.515365\n",
      "epoch = 669 train_loss : 1.163948 , test loss : 1.514415\n",
      "epoch = 670 train_loss : 1.162881 , test loss : 1.512774\n",
      "epoch = 671 train_loss : 1.161765 , test loss : 1.512047\n",
      "epoch = 672 train_loss : 1.160718 , test loss : 1.511165\n",
      "epoch = 673 train_loss : 1.159605 , test loss : 1.510167\n",
      "epoch = 674 train_loss : 1.158523 , test loss : 1.509339\n",
      "epoch = 675 train_loss : 1.157449 , test loss : 1.507860\n",
      "epoch = 676 train_loss : 1.156427 , test loss : 1.506721\n",
      "epoch = 677 train_loss : 1.155370 , test loss : 1.505682\n",
      "epoch = 678 train_loss : 1.154292 , test loss : 1.504932\n",
      "epoch = 679 train_loss : 1.153243 , test loss : 1.503969\n",
      "epoch = 680 train_loss : 1.152234 , test loss : 1.502939\n",
      "epoch = 681 train_loss : 1.151151 , test loss : 1.501654\n",
      "epoch = 682 train_loss : 1.150125 , test loss : 1.500069\n",
      "epoch = 683 train_loss : 1.149081 , test loss : 1.499924\n",
      "epoch = 684 train_loss : 1.148063 , test loss : 1.498993\n",
      "epoch = 685 train_loss : 1.147078 , test loss : 1.497673\n",
      "epoch = 686 train_loss : 1.146034 , test loss : 1.496484\n",
      "epoch = 687 train_loss : 1.145053 , test loss : 1.496290\n",
      "epoch = 688 train_loss : 1.144071 , test loss : 1.494376\n",
      "epoch = 689 train_loss : 1.143038 , test loss : 1.494264\n",
      "epoch = 690 train_loss : 1.142018 , test loss : 1.493097\n",
      "epoch = 691 train_loss : 1.141049 , test loss : 1.491456\n",
      "epoch = 693 train_loss : 1.139076 , test loss : 1.490141\n",
      "epoch = 694 train_loss : 1.138096 , test loss : 1.488694\n",
      "epoch = 696 train_loss : 1.136124 , test loss : 1.487522\n",
      "epoch = 697 train_loss : 1.135162 , test loss : 1.486403\n",
      "epoch = 698 train_loss : 1.134224 , test loss : 1.486356\n",
      "epoch = 699 train_loss : 1.133242 , test loss : 1.484441\n",
      "epoch = 700 train_loss : 1.132277 , test loss : 1.483834\n",
      "epoch = 701 train_loss : 1.131333 , test loss : 1.482521\n",
      "epoch = 702 train_loss : 1.130378 , test loss : 1.481839\n",
      "epoch = 703 train_loss : 1.129431 , test loss : 1.480005\n",
      "epoch = 705 train_loss : 1.127568 , test loss : 1.478932\n",
      "epoch = 706 train_loss : 1.126673 , test loss : 1.478302\n",
      "epoch = 707 train_loss : 1.125713 , test loss : 1.477132\n",
      "epoch = 708 train_loss : 1.124815 , test loss : 1.475315\n",
      "epoch = 710 train_loss : 1.122945 , test loss : 1.474750\n",
      "epoch = 711 train_loss : 1.121992 , test loss : 1.473471\n",
      "epoch = 712 train_loss : 1.121085 , test loss : 1.472383\n",
      "epoch = 713 train_loss : 1.120165 , test loss : 1.471210\n",
      "epoch = 714 train_loss : 1.119301 , test loss : 1.470932\n",
      "epoch = 715 train_loss : 1.118369 , test loss : 1.469198\n",
      "epoch = 716 train_loss : 1.117473 , test loss : 1.469139\n",
      "epoch = 717 train_loss : 1.116594 , test loss : 1.467632\n",
      "epoch = 719 train_loss : 1.114786 , test loss : 1.466459\n",
      "epoch = 720 train_loss : 1.113950 , test loss : 1.465175\n",
      "epoch = 721 train_loss : 1.113075 , test loss : 1.463550\n",
      "epoch = 723 train_loss : 1.111301 , test loss : 1.463040\n",
      "epoch = 724 train_loss : 1.110461 , test loss : 1.462286\n",
      "epoch = 725 train_loss : 1.109608 , test loss : 1.461333\n",
      "epoch = 726 train_loss : 1.108749 , test loss : 1.460241\n",
      "epoch = 727 train_loss : 1.107872 , test loss : 1.459809\n",
      "epoch = 728 train_loss : 1.107035 , test loss : 1.458341\n",
      "epoch = 729 train_loss : 1.106161 , test loss : 1.458320\n",
      "epoch = 730 train_loss : 1.105313 , test loss : 1.457663\n",
      "epoch = 731 train_loss : 1.104469 , test loss : 1.456568\n",
      "epoch = 732 train_loss : 1.103630 , test loss : 1.455777\n",
      "epoch = 733 train_loss : 1.102782 , test loss : 1.454555\n",
      "epoch = 734 train_loss : 1.101966 , test loss : 1.454241\n",
      "epoch = 735 train_loss : 1.101128 , test loss : 1.453435\n",
      "epoch = 736 train_loss : 1.100328 , test loss : 1.453068\n",
      "epoch = 737 train_loss : 1.099506 , test loss : 1.452343\n",
      "epoch = 738 train_loss : 1.098634 , test loss : 1.451474\n",
      "epoch = 739 train_loss : 1.097847 , test loss : 1.451077\n",
      "epoch = 740 train_loss : 1.097005 , test loss : 1.449278\n",
      "epoch = 741 train_loss : 1.096208 , test loss : 1.448401\n",
      "epoch = 742 train_loss : 1.095386 , test loss : 1.448265\n",
      "epoch = 743 train_loss : 1.094654 , test loss : 1.447583\n",
      "epoch = 744 train_loss : 1.093790 , test loss : 1.446137\n",
      "epoch = 745 train_loss : 1.092973 , test loss : 1.445750\n",
      "epoch = 746 train_loss : 1.092180 , test loss : 1.445161\n",
      "epoch = 747 train_loss : 1.091385 , test loss : 1.444476\n",
      "epoch = 748 train_loss : 1.090620 , test loss : 1.443604\n",
      "epoch = 749 train_loss : 1.089808 , test loss : 1.442412\n",
      "epoch = 750 train_loss : 1.089014 , test loss : 1.442363\n",
      "epoch = 751 train_loss : 1.088203 , test loss : 1.441436\n",
      "epoch = 752 train_loss : 1.087447 , test loss : 1.440315\n",
      "epoch = 753 train_loss : 1.086678 , test loss : 1.439579\n",
      "epoch = 754 train_loss : 1.085878 , test loss : 1.439021\n",
      "epoch = 755 train_loss : 1.085131 , test loss : 1.437811\n",
      "epoch = 756 train_loss : 1.084351 , test loss : 1.436502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 758 train_loss : 1.082796 , test loss : 1.435705\n",
      "epoch = 759 train_loss : 1.082070 , test loss : 1.434670\n",
      "epoch = 760 train_loss : 1.081287 , test loss : 1.434068\n",
      "epoch = 762 train_loss : 1.079798 , test loss : 1.431990\n",
      "epoch = 764 train_loss : 1.078296 , test loss : 1.431367\n",
      "epoch = 765 train_loss : 1.077640 , test loss : 1.431289\n",
      "epoch = 766 train_loss : 1.076805 , test loss : 1.430096\n",
      "epoch = 767 train_loss : 1.076062 , test loss : 1.428917\n",
      "epoch = 768 train_loss : 1.075336 , test loss : 1.428283\n",
      "epoch = 769 train_loss : 1.074607 , test loss : 1.427910\n",
      "epoch = 770 train_loss : 1.073851 , test loss : 1.426973\n",
      "epoch = 771 train_loss : 1.073149 , test loss : 1.425846\n",
      "epoch = 772 train_loss : 1.072423 , test loss : 1.425140\n",
      "epoch = 773 train_loss : 1.071694 , test loss : 1.424814\n",
      "epoch = 774 train_loss : 1.070956 , test loss : 1.424619\n",
      "epoch = 775 train_loss : 1.070236 , test loss : 1.423476\n",
      "epoch = 776 train_loss : 1.069536 , test loss : 1.422796\n",
      "epoch = 777 train_loss : 1.068781 , test loss : 1.421920\n",
      "epoch = 778 train_loss : 1.068094 , test loss : 1.421432\n",
      "epoch = 779 train_loss : 1.067385 , test loss : 1.420987\n",
      "epoch = 781 train_loss : 1.065965 , test loss : 1.419336\n",
      "epoch = 782 train_loss : 1.065267 , test loss : 1.418831\n",
      "epoch = 783 train_loss : 1.064555 , test loss : 1.418396\n",
      "epoch = 784 train_loss : 1.063891 , test loss : 1.417493\n",
      "epoch = 785 train_loss : 1.063178 , test loss : 1.416762\n",
      "epoch = 786 train_loss : 1.062456 , test loss : 1.416439\n",
      "epoch = 787 train_loss : 1.061792 , test loss : 1.414648\n",
      "epoch = 790 train_loss : 1.059698 , test loss : 1.413734\n",
      "epoch = 791 train_loss : 1.059048 , test loss : 1.412307\n",
      "epoch = 792 train_loss : 1.058365 , test loss : 1.411584\n",
      "epoch = 794 train_loss : 1.056996 , test loss : 1.410090\n",
      "epoch = 795 train_loss : 1.056305 , test loss : 1.410053\n",
      "epoch = 797 train_loss : 1.055002 , test loss : 1.408454\n",
      "epoch = 798 train_loss : 1.054321 , test loss : 1.408217\n",
      "epoch = 800 train_loss : 1.052976 , test loss : 1.407416\n",
      "epoch = 801 train_loss : 1.052330 , test loss : 1.405910\n",
      "epoch = 803 train_loss : 1.051003 , test loss : 1.405207\n",
      "epoch = 804 train_loss : 1.050340 , test loss : 1.404944\n",
      "epoch = 805 train_loss : 1.049724 , test loss : 1.404773\n",
      "epoch = 806 train_loss : 1.049081 , test loss : 1.404026\n",
      "epoch = 807 train_loss : 1.048400 , test loss : 1.402547\n",
      "epoch = 808 train_loss : 1.047791 , test loss : 1.401397\n",
      "epoch = 809 train_loss : 1.047133 , test loss : 1.401215\n",
      "epoch = 811 train_loss : 1.045836 , test loss : 1.400469\n",
      "epoch = 813 train_loss : 1.044623 , test loss : 1.398783\n",
      "epoch = 814 train_loss : 1.043949 , test loss : 1.397930\n",
      "epoch = 816 train_loss : 1.042734 , test loss : 1.397698\n",
      "epoch = 817 train_loss : 1.042064 , test loss : 1.396524\n",
      "epoch = 818 train_loss : 1.041434 , test loss : 1.396109\n",
      "epoch = 819 train_loss : 1.040836 , test loss : 1.395761\n",
      "epoch = 820 train_loss : 1.040181 , test loss : 1.394483\n",
      "epoch = 821 train_loss : 1.039594 , test loss : 1.393812\n",
      "epoch = 822 train_loss : 1.038973 , test loss : 1.393091\n",
      "epoch = 824 train_loss : 1.037740 , test loss : 1.392606\n",
      "epoch = 825 train_loss : 1.037118 , test loss : 1.392435\n",
      "epoch = 826 train_loss : 1.036527 , test loss : 1.391193\n",
      "epoch = 828 train_loss : 1.035321 , test loss : 1.390992\n",
      "epoch = 829 train_loss : 1.034763 , test loss : 1.390534\n",
      "epoch = 830 train_loss : 1.034088 , test loss : 1.388545\n",
      "epoch = 832 train_loss : 1.032926 , test loss : 1.387291\n",
      "epoch = 835 train_loss : 1.031109 , test loss : 1.385859\n",
      "epoch = 836 train_loss : 1.030604 , test loss : 1.384258\n",
      "epoch = 840 train_loss : 1.028162 , test loss : 1.383267\n",
      "epoch = 842 train_loss : 1.026988 , test loss : 1.382351\n",
      "epoch = 843 train_loss : 1.026377 , test loss : 1.381809\n",
      "epoch = 844 train_loss : 1.025823 , test loss : 1.380572\n",
      "epoch = 845 train_loss : 1.025245 , test loss : 1.379905\n",
      "epoch = 846 train_loss : 1.024638 , test loss : 1.379889\n",
      "epoch = 847 train_loss : 1.024066 , test loss : 1.379501\n",
      "epoch = 848 train_loss : 1.023533 , test loss : 1.379365\n",
      "epoch = 849 train_loss : 1.022988 , test loss : 1.378872\n",
      "epoch = 850 train_loss : 1.022352 , test loss : 1.377658\n",
      "epoch = 851 train_loss : 1.021796 , test loss : 1.376980\n",
      "epoch = 853 train_loss : 1.020616 , test loss : 1.376584\n",
      "epoch = 854 train_loss : 1.020067 , test loss : 1.375354\n",
      "epoch = 855 train_loss : 1.019516 , test loss : 1.374540\n",
      "epoch = 856 train_loss : 1.018940 , test loss : 1.374151\n",
      "epoch = 857 train_loss : 1.018391 , test loss : 1.374110\n",
      "epoch = 858 train_loss : 1.017828 , test loss : 1.373423\n",
      "epoch = 859 train_loss : 1.017288 , test loss : 1.372693\n",
      "epoch = 861 train_loss : 1.016179 , test loss : 1.372234\n",
      "epoch = 862 train_loss : 1.015558 , test loss : 1.371533\n",
      "epoch = 864 train_loss : 1.014444 , test loss : 1.370318\n",
      "epoch = 865 train_loss : 1.013917 , test loss : 1.369935\n",
      "epoch = 866 train_loss : 1.013340 , test loss : 1.369508\n",
      "epoch = 867 train_loss : 1.012787 , test loss : 1.369176\n",
      "epoch = 868 train_loss : 1.012233 , test loss : 1.368130\n",
      "epoch = 870 train_loss : 1.011129 , test loss : 1.367140\n",
      "epoch = 872 train_loss : 1.010047 , test loss : 1.366508\n",
      "epoch = 873 train_loss : 1.009510 , test loss : 1.365817\n",
      "epoch = 874 train_loss : 1.008965 , test loss : 1.365775\n",
      "epoch = 875 train_loss : 1.008455 , test loss : 1.365240\n",
      "epoch = 876 train_loss : 1.007910 , test loss : 1.364655\n",
      "epoch = 878 train_loss : 1.006855 , test loss : 1.364430\n",
      "epoch = 879 train_loss : 1.006287 , test loss : 1.363175\n",
      "epoch = 881 train_loss : 1.005255 , test loss : 1.362178\n",
      "epoch = 883 train_loss : 1.004182 , test loss : 1.361102\n",
      "epoch = 886 train_loss : 1.002640 , test loss : 1.359670\n",
      "epoch = 887 train_loss : 1.002096 , test loss : 1.359595\n",
      "epoch = 889 train_loss : 1.001123 , test loss : 1.358089\n",
      "epoch = 890 train_loss : 1.000563 , test loss : 1.358081\n",
      "epoch = 891 train_loss : 1.000046 , test loss : 1.357548\n",
      "epoch = 893 train_loss : 0.999022 , test loss : 1.356784\n",
      "epoch = 894 train_loss : 0.998546 , test loss : 1.355328\n",
      "epoch = 897 train_loss : 0.997036 , test loss : 1.355102\n",
      "epoch = 898 train_loss : 0.996511 , test loss : 1.354985\n",
      "epoch = 900 train_loss : 0.995522 , test loss : 1.353596\n",
      "epoch = 901 train_loss : 0.995034 , test loss : 1.352566\n",
      "epoch = 903 train_loss : 0.994025 , test loss : 1.351902\n",
      "epoch = 904 train_loss : 0.993544 , test loss : 1.351799\n",
      "epoch = 905 train_loss : 0.993046 , test loss : 1.351573\n",
      "epoch = 906 train_loss : 0.992559 , test loss : 1.350898\n",
      "epoch = 907 train_loss : 0.992119 , test loss : 1.350478\n",
      "epoch = 908 train_loss : 0.991584 , test loss : 1.349871\n",
      "epoch = 910 train_loss : 0.990627 , test loss : 1.349163\n",
      "epoch = 911 train_loss : 0.990157 , test loss : 1.348582\n",
      "epoch = 912 train_loss : 0.989685 , test loss : 1.347596\n",
      "epoch = 914 train_loss : 0.988700 , test loss : 1.347236\n",
      "epoch = 915 train_loss : 0.988249 , test loss : 1.346242\n",
      "epoch = 916 train_loss : 0.987746 , test loss : 1.346159\n",
      "epoch = 918 train_loss : 0.986805 , test loss : 1.345690\n",
      "epoch = 919 train_loss : 0.986331 , test loss : 1.345606\n",
      "epoch = 920 train_loss : 0.985878 , test loss : 1.344834\n",
      "epoch = 921 train_loss : 0.985405 , test loss : 1.344649\n",
      "epoch = 922 train_loss : 0.984929 , test loss : 1.344049\n",
      "epoch = 923 train_loss : 0.984456 , test loss : 1.343633\n",
      "epoch = 925 train_loss : 0.983535 , test loss : 1.342227\n",
      "epoch = 926 train_loss : 0.983121 , test loss : 1.341767\n",
      "epoch = 928 train_loss : 0.982163 , test loss : 1.341607\n",
      "epoch = 929 train_loss : 0.981683 , test loss : 1.340549\n",
      "epoch = 931 train_loss : 0.980833 , test loss : 1.339957\n",
      "epoch = 933 train_loss : 0.979867 , test loss : 1.339930\n",
      "epoch = 934 train_loss : 0.979404 , test loss : 1.338939\n",
      "epoch = 935 train_loss : 0.978980 , test loss : 1.338073\n",
      "epoch = 937 train_loss : 0.978050 , test loss : 1.337980\n",
      "epoch = 938 train_loss : 0.977614 , test loss : 1.337249\n",
      "epoch = 939 train_loss : 0.977160 , test loss : 1.336551\n",
      "epoch = 941 train_loss : 0.976280 , test loss : 1.336194\n",
      "epoch = 943 train_loss : 0.975446 , test loss : 1.335106\n",
      "epoch = 945 train_loss : 0.974552 , test loss : 1.334811\n",
      "epoch = 946 train_loss : 0.974095 , test loss : 1.334396\n",
      "epoch = 947 train_loss : 0.973677 , test loss : 1.334159\n",
      "epoch = 948 train_loss : 0.973207 , test loss : 1.333200\n",
      "epoch = 949 train_loss : 0.972782 , test loss : 1.332411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 952 train_loss : 0.971482 , test loss : 1.332130\n",
      "epoch = 953 train_loss : 0.971083 , test loss : 1.331261\n",
      "epoch = 955 train_loss : 0.970196 , test loss : 1.330815\n",
      "epoch = 957 train_loss : 0.969400 , test loss : 1.330485\n",
      "epoch = 958 train_loss : 0.968996 , test loss : 1.329420\n",
      "epoch = 959 train_loss : 0.968539 , test loss : 1.329033\n",
      "epoch = 960 train_loss : 0.968110 , test loss : 1.328977\n",
      "epoch = 961 train_loss : 0.967683 , test loss : 1.328586\n",
      "epoch = 963 train_loss : 0.966855 , test loss : 1.327955\n",
      "epoch = 964 train_loss : 0.966428 , test loss : 1.327538\n",
      "epoch = 966 train_loss : 0.965616 , test loss : 1.326852\n",
      "epoch = 967 train_loss : 0.965239 , test loss : 1.325786\n",
      "epoch = 968 train_loss : 0.964867 , test loss : 1.325219\n",
      "epoch = 970 train_loss : 0.963964 , test loss : 1.325038\n",
      "epoch = 972 train_loss : 0.963141 , test loss : 1.324354\n",
      "epoch = 974 train_loss : 0.962344 , test loss : 1.323382\n",
      "epoch = 975 train_loss : 0.961933 , test loss : 1.323303\n",
      "epoch = 976 train_loss : 0.961557 , test loss : 1.323229\n",
      "epoch = 977 train_loss : 0.961136 , test loss : 1.322437\n",
      "epoch = 979 train_loss : 0.960329 , test loss : 1.322019\n",
      "epoch = 980 train_loss : 0.959916 , test loss : 1.321526\n",
      "epoch = 982 train_loss : 0.959125 , test loss : 1.321286\n",
      "epoch = 983 train_loss : 0.958747 , test loss : 1.320830\n",
      "epoch = 984 train_loss : 0.958345 , test loss : 1.320193\n",
      "epoch = 985 train_loss : 0.957953 , test loss : 1.319921\n",
      "epoch = 986 train_loss : 0.957534 , test loss : 1.319789\n",
      "epoch = 987 train_loss : 0.957158 , test loss : 1.318651\n",
      "epoch = 991 train_loss : 0.955604 , test loss : 1.317996\n",
      "epoch = 992 train_loss : 0.955181 , test loss : 1.317376\n",
      "epoch = 995 train_loss : 0.954061 , test loss : 1.315915\n",
      "epoch = 997 train_loss : 0.953256 , test loss : 1.315882\n",
      "epoch = 1000 train_loss : 0.952076 , test loss : 1.314971\n",
      "epoch = 1001 train_loss : 0.951722 , test loss : 1.314692\n",
      "epoch = 1002 train_loss : 0.951307 , test loss : 1.314185\n",
      "epoch = 1004 train_loss : 0.950541 , test loss : 1.313640\n",
      "epoch = 1007 train_loss : 0.949404 , test loss : 1.311972\n",
      "epoch = 1009 train_loss : 0.948644 , test loss : 1.311765\n",
      "epoch = 1010 train_loss : 0.948266 , test loss : 1.311661\n",
      "epoch = 1012 train_loss : 0.947538 , test loss : 1.310989\n",
      "epoch = 1013 train_loss : 0.947132 , test loss : 1.310799\n",
      "epoch = 1014 train_loss : 0.946762 , test loss : 1.309994\n",
      "epoch = 1017 train_loss : 0.945641 , test loss : 1.309334\n",
      "epoch = 1018 train_loss : 0.945320 , test loss : 1.308717\n",
      "epoch = 1020 train_loss : 0.944530 , test loss : 1.307992\n",
      "epoch = 1023 train_loss : 0.943442 , test loss : 1.307579\n",
      "epoch = 1025 train_loss : 0.942849 , test loss : 1.306405\n",
      "epoch = 1029 train_loss : 0.941252 , test loss : 1.306052\n",
      "epoch = 1030 train_loss : 0.941021 , test loss : 1.304660\n",
      "epoch = 1033 train_loss : 0.939804 , test loss : 1.304304\n",
      "epoch = 1034 train_loss : 0.939579 , test loss : 1.303783\n",
      "epoch = 1036 train_loss : 0.938760 , test loss : 1.303087\n",
      "epoch = 1037 train_loss : 0.938356 , test loss : 1.302808\n",
      "epoch = 1039 train_loss : 0.937641 , test loss : 1.302741\n",
      "epoch = 1041 train_loss : 0.936925 , test loss : 1.302110\n",
      "epoch = 1042 train_loss : 0.936569 , test loss : 1.301503\n",
      "epoch = 1044 train_loss : 0.935881 , test loss : 1.301008\n",
      "epoch = 1046 train_loss : 0.935156 , test loss : 1.300368\n",
      "epoch = 1048 train_loss : 0.934462 , test loss : 1.299841\n",
      "epoch = 1049 train_loss : 0.934124 , test loss : 1.299311\n",
      "epoch = 1050 train_loss : 0.933773 , test loss : 1.299068\n",
      "epoch = 1053 train_loss : 0.932745 , test loss : 1.298225\n",
      "epoch = 1054 train_loss : 0.932385 , test loss : 1.297997\n",
      "epoch = 1055 train_loss : 0.932053 , test loss : 1.297772\n",
      "epoch = 1056 train_loss : 0.931724 , test loss : 1.297598\n",
      "epoch = 1057 train_loss : 0.931413 , test loss : 1.297459\n",
      "epoch = 1058 train_loss : 0.931042 , test loss : 1.297158\n",
      "epoch = 1059 train_loss : 0.930698 , test loss : 1.297128\n",
      "epoch = 1060 train_loss : 0.930579 , test loss : 1.296116\n",
      "epoch = 1062 train_loss : 0.929661 , test loss : 1.296036\n",
      "epoch = 1064 train_loss : 0.929050 , test loss : 1.294764\n",
      "epoch = 1068 train_loss : 0.927664 , test loss : 1.293528\n",
      "epoch = 1071 train_loss : 0.926678 , test loss : 1.292877\n",
      "epoch = 1073 train_loss : 0.925974 , test loss : 1.292804\n",
      "epoch = 1075 train_loss : 0.925360 , test loss : 1.291610\n",
      "epoch = 1076 train_loss : 0.925008 , test loss : 1.291499\n",
      "epoch = 1079 train_loss : 0.923981 , test loss : 1.291051\n",
      "epoch = 1080 train_loss : 0.923660 , test loss : 1.291004\n",
      "epoch = 1082 train_loss : 0.923017 , test loss : 1.290449\n",
      "epoch = 1083 train_loss : 0.922678 , test loss : 1.289599\n",
      "epoch = 1087 train_loss : 0.921375 , test loss : 1.288745\n",
      "epoch = 1088 train_loss : 0.921117 , test loss : 1.288081\n",
      "epoch = 1090 train_loss : 0.920408 , test loss : 1.287942\n",
      "epoch = 1091 train_loss : 0.920099 , test loss : 1.287754\n",
      "epoch = 1094 train_loss : 0.919118 , test loss : 1.286852\n",
      "epoch = 1096 train_loss : 0.918509 , test loss : 1.286440\n",
      "epoch = 1097 train_loss : 0.918206 , test loss : 1.286365\n",
      "epoch = 1099 train_loss : 0.917556 , test loss : 1.285959\n",
      "epoch = 1100 train_loss : 0.917234 , test loss : 1.285435\n",
      "epoch = 1101 train_loss : 0.916888 , test loss : 1.285362\n",
      "epoch = 1103 train_loss : 0.916341 , test loss : 1.284322\n",
      "epoch = 1105 train_loss : 0.915650 , test loss : 1.284283\n",
      "epoch = 1108 train_loss : 0.914701 , test loss : 1.283068\n",
      "epoch = 1112 train_loss : 0.913415 , test loss : 1.282711\n",
      "epoch = 1115 train_loss : 0.912468 , test loss : 1.282192\n",
      "epoch = 1116 train_loss : 0.912170 , test loss : 1.281960\n",
      "epoch = 1117 train_loss : 0.911854 , test loss : 1.281322\n",
      "epoch = 1120 train_loss : 0.910943 , test loss : 1.280793\n",
      "epoch = 1122 train_loss : 0.910334 , test loss : 1.280589\n",
      "epoch = 1123 train_loss : 0.910053 , test loss : 1.279337\n",
      "epoch = 1127 train_loss : 0.908879 , test loss : 1.278827\n",
      "epoch = 1129 train_loss : 0.908178 , test loss : 1.278588\n",
      "epoch = 1130 train_loss : 0.907887 , test loss : 1.278281\n",
      "epoch = 1131 train_loss : 0.907593 , test loss : 1.277967\n",
      "epoch = 1133 train_loss : 0.906963 , test loss : 1.277426\n",
      "epoch = 1134 train_loss : 0.906663 , test loss : 1.277416\n",
      "epoch = 1135 train_loss : 0.906348 , test loss : 1.277137\n",
      "epoch = 1137 train_loss : 0.905753 , test loss : 1.277063\n",
      "epoch = 1138 train_loss : 0.905456 , test loss : 1.275874\n",
      "epoch = 1143 train_loss : 0.903943 , test loss : 1.275228\n",
      "epoch = 1144 train_loss : 0.903637 , test loss : 1.275064\n",
      "epoch = 1146 train_loss : 0.903054 , test loss : 1.275046\n",
      "epoch = 1147 train_loss : 0.902747 , test loss : 1.273979\n",
      "epoch = 1150 train_loss : 0.901850 , test loss : 1.273875\n",
      "epoch = 1151 train_loss : 0.901554 , test loss : 1.273392\n",
      "epoch = 1153 train_loss : 0.900980 , test loss : 1.273070\n",
      "epoch = 1155 train_loss : 0.900372 , test loss : 1.272041\n",
      "epoch = 1156 train_loss : 0.900113 , test loss : 1.272010\n",
      "epoch = 1158 train_loss : 0.899517 , test loss : 1.271621\n",
      "epoch = 1159 train_loss : 0.899203 , test loss : 1.271521\n",
      "epoch = 1160 train_loss : 0.898921 , test loss : 1.270968\n",
      "epoch = 1163 train_loss : 0.898029 , test loss : 1.270602\n",
      "epoch = 1165 train_loss : 0.897509 , test loss : 1.269434\n",
      "epoch = 1171 train_loss : 0.895733 , test loss : 1.269307\n",
      "epoch = 1172 train_loss : 0.895427 , test loss : 1.268390\n",
      "epoch = 1176 train_loss : 0.894277 , test loss : 1.267582\n",
      "epoch = 1179 train_loss : 0.893426 , test loss : 1.267527\n",
      "epoch = 1180 train_loss : 0.893130 , test loss : 1.267142\n",
      "epoch = 1182 train_loss : 0.892561 , test loss : 1.266767\n",
      "epoch = 1183 train_loss : 0.892306 , test loss : 1.266553\n",
      "epoch = 1185 train_loss : 0.891774 , test loss : 1.266419\n",
      "epoch = 1186 train_loss : 0.891464 , test loss : 1.265457\n",
      "epoch = 1187 train_loss : 0.891228 , test loss : 1.265339\n",
      "epoch = 1192 train_loss : 0.889752 , test loss : 1.264516\n",
      "epoch = 1194 train_loss : 0.889199 , test loss : 1.264101\n",
      "epoch = 1196 train_loss : 0.888678 , test loss : 1.263807\n",
      "epoch = 1197 train_loss : 0.888378 , test loss : 1.263319\n",
      "epoch = 1201 train_loss : 0.887270 , test loss : 1.262594\n",
      "epoch = 1204 train_loss : 0.886452 , test loss : 1.261793\n",
      "epoch = 1207 train_loss : 0.885612 , test loss : 1.261782\n",
      "epoch = 1209 train_loss : 0.885068 , test loss : 1.261460\n",
      "epoch = 1210 train_loss : 0.884822 , test loss : 1.261423\n",
      "epoch = 1211 train_loss : 0.884530 , test loss : 1.261157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1213 train_loss : 0.884054 , test loss : 1.260626\n",
      "epoch = 1215 train_loss : 0.883448 , test loss : 1.259534\n",
      "epoch = 1216 train_loss : 0.883187 , test loss : 1.259488\n",
      "epoch = 1219 train_loss : 0.882380 , test loss : 1.259019\n",
      "epoch = 1222 train_loss : 0.881555 , test loss : 1.258909\n",
      "epoch = 1224 train_loss : 0.881048 , test loss : 1.257774\n",
      "epoch = 1228 train_loss : 0.879967 , test loss : 1.257672\n",
      "epoch = 1229 train_loss : 0.879694 , test loss : 1.257440\n",
      "epoch = 1230 train_loss : 0.879452 , test loss : 1.256919\n",
      "epoch = 1233 train_loss : 0.878614 , test loss : 1.256735\n",
      "epoch = 1235 train_loss : 0.878072 , test loss : 1.256529\n",
      "epoch = 1236 train_loss : 0.877869 , test loss : 1.255588\n",
      "epoch = 1240 train_loss : 0.876755 , test loss : 1.255432\n",
      "epoch = 1241 train_loss : 0.876538 , test loss : 1.255352\n",
      "epoch = 1242 train_loss : 0.876230 , test loss : 1.254751\n",
      "epoch = 1243 train_loss : 0.875960 , test loss : 1.254345\n",
      "epoch = 1246 train_loss : 0.875178 , test loss : 1.253778\n",
      "epoch = 1249 train_loss : 0.874558 , test loss : 1.253497\n",
      "epoch = 1251 train_loss : 0.873855 , test loss : 1.253214\n",
      "epoch = 1252 train_loss : 0.873583 , test loss : 1.252843\n",
      "epoch = 1256 train_loss : 0.872554 , test loss : 1.252580\n",
      "epoch = 1257 train_loss : 0.872286 , test loss : 1.252559\n",
      "epoch = 1258 train_loss : 0.872055 , test loss : 1.252251\n",
      "epoch = 1260 train_loss : 0.871543 , test loss : 1.251647\n",
      "epoch = 1263 train_loss : 0.870730 , test loss : 1.250846\n",
      "epoch = 1267 train_loss : 0.869697 , test loss : 1.250434\n",
      "epoch = 1270 train_loss : 0.868937 , test loss : 1.249829\n",
      "epoch = 1272 train_loss : 0.868418 , test loss : 1.249574\n",
      "epoch = 1275 train_loss : 0.867646 , test loss : 1.249472\n",
      "epoch = 1276 train_loss : 0.867428 , test loss : 1.248497\n",
      "epoch = 1281 train_loss : 0.866131 , test loss : 1.248416\n",
      "epoch = 1282 train_loss : 0.865868 , test loss : 1.248290\n",
      "epoch = 1283 train_loss : 0.865612 , test loss : 1.247643\n",
      "epoch = 1284 train_loss : 0.865420 , test loss : 1.247461\n",
      "epoch = 1287 train_loss : 0.864621 , test loss : 1.247194\n",
      "epoch = 1288 train_loss : 0.864379 , test loss : 1.246454\n",
      "epoch = 1291 train_loss : 0.863697 , test loss : 1.246315\n",
      "epoch = 1292 train_loss : 0.863354 , test loss : 1.246285\n",
      "epoch = 1297 train_loss : 0.862140 , test loss : 1.245481\n",
      "epoch = 1298 train_loss : 0.862023 , test loss : 1.245195\n",
      "epoch = 1300 train_loss : 0.861381 , test loss : 1.245155\n",
      "epoch = 1302 train_loss : 0.860924 , test loss : 1.245129\n",
      "epoch = 1303 train_loss : 0.860667 , test loss : 1.244604\n",
      "epoch = 1306 train_loss : 0.859934 , test loss : 1.244250\n",
      "epoch = 1307 train_loss : 0.859695 , test loss : 1.243604\n",
      "epoch = 1310 train_loss : 0.858935 , test loss : 1.243323\n",
      "epoch = 1312 train_loss : 0.858464 , test loss : 1.243234\n",
      "epoch = 1316 train_loss : 0.857476 , test loss : 1.242722\n",
      "epoch = 1317 train_loss : 0.857252 , test loss : 1.242422\n",
      "epoch = 1321 train_loss : 0.856257 , test loss : 1.242311\n",
      "epoch = 1322 train_loss : 0.856020 , test loss : 1.242212\n",
      "epoch = 1323 train_loss : 0.855783 , test loss : 1.242183\n",
      "epoch = 1324 train_loss : 0.855557 , test loss : 1.241272\n",
      "epoch = 1327 train_loss : 0.854835 , test loss : 1.240885\n",
      "epoch = 1329 train_loss : 0.854330 , test loss : 1.240513\n",
      "epoch = 1330 train_loss : 0.854102 , test loss : 1.240505\n",
      "epoch = 1331 train_loss : 0.853861 , test loss : 1.240493\n",
      "epoch = 1333 train_loss : 0.853380 , test loss : 1.239865\n",
      "epoch = 1338 train_loss : 0.852242 , test loss : 1.239389\n",
      "epoch = 1340 train_loss : 0.851707 , test loss : 1.239180\n",
      "epoch = 1343 train_loss : 0.851061 , test loss : 1.238876\n",
      "epoch = 1346 train_loss : 0.850307 , test loss : 1.238303\n",
      "epoch = 1351 train_loss : 0.849174 , test loss : 1.237359\n",
      "epoch = 1354 train_loss : 0.848388 , test loss : 1.237218\n",
      "epoch = 1355 train_loss : 0.848159 , test loss : 1.236997\n",
      "epoch = 1358 train_loss : 0.847458 , test loss : 1.236567\n",
      "epoch = 1364 train_loss : 0.846034 , test loss : 1.236263\n",
      "epoch = 1365 train_loss : 0.845809 , test loss : 1.235685\n",
      "epoch = 1368 train_loss : 0.845142 , test loss : 1.234813\n",
      "epoch = 1373 train_loss : 0.843924 , test loss : 1.234748\n",
      "epoch = 1374 train_loss : 0.843693 , test loss : 1.234578\n",
      "epoch = 1377 train_loss : 0.843002 , test loss : 1.234346\n",
      "epoch = 1378 train_loss : 0.842805 , test loss : 1.234257\n",
      "epoch = 1380 train_loss : 0.842316 , test loss : 1.234112\n",
      "epoch = 1382 train_loss : 0.841910 , test loss : 1.233234\n",
      "epoch = 1385 train_loss : 0.841146 , test loss : 1.232958\n",
      "epoch = 1388 train_loss : 0.840454 , test loss : 1.232946\n",
      "epoch = 1389 train_loss : 0.840226 , test loss : 1.232882\n",
      "epoch = 1392 train_loss : 0.839533 , test loss : 1.232272\n",
      "epoch = 1393 train_loss : 0.839323 , test loss : 1.232061\n",
      "epoch = 1395 train_loss : 0.838836 , test loss : 1.232044\n",
      "epoch = 1398 train_loss : 0.838187 , test loss : 1.231388\n",
      "epoch = 1401 train_loss : 0.837481 , test loss : 1.231247\n",
      "epoch = 1404 train_loss : 0.836797 , test loss : 1.231056\n",
      "epoch = 1405 train_loss : 0.836553 , test loss : 1.231023\n",
      "epoch = 1406 train_loss : 0.836343 , test loss : 1.230614\n",
      "epoch = 1408 train_loss : 0.835875 , test loss : 1.230148\n",
      "epoch = 1413 train_loss : 0.834749 , test loss : 1.230102\n",
      "epoch = 1414 train_loss : 0.834536 , test loss : 1.229129\n",
      "epoch = 1420 train_loss : 0.833155 , test loss : 1.229083\n",
      "epoch = 1421 train_loss : 0.832930 , test loss : 1.228807\n",
      "epoch = 1423 train_loss : 0.832497 , test loss : 1.228266\n",
      "epoch = 1427 train_loss : 0.831587 , test loss : 1.227840\n",
      "epoch = 1428 train_loss : 0.831392 , test loss : 1.227543\n",
      "epoch = 1430 train_loss : 0.830954 , test loss : 1.227103\n",
      "epoch = 1439 train_loss : 0.828918 , test loss : 1.226422\n",
      "epoch = 1443 train_loss : 0.828039 , test loss : 1.226208\n",
      "epoch = 1446 train_loss : 0.827362 , test loss : 1.225868\n",
      "epoch = 1447 train_loss : 0.827165 , test loss : 1.225818\n",
      "epoch = 1449 train_loss : 0.826747 , test loss : 1.225112\n",
      "epoch = 1455 train_loss : 0.825429 , test loss : 1.224356\n",
      "epoch = 1461 train_loss : 0.824119 , test loss : 1.223968\n",
      "epoch = 1463 train_loss : 0.823662 , test loss : 1.223750\n",
      "epoch = 1465 train_loss : 0.823250 , test loss : 1.223632\n",
      "epoch = 1466 train_loss : 0.823035 , test loss : 1.223067\n",
      "epoch = 1471 train_loss : 0.822012 , test loss : 1.222761\n",
      "epoch = 1474 train_loss : 0.821316 , test loss : 1.222585\n",
      "epoch = 1475 train_loss : 0.821112 , test loss : 1.222189\n",
      "epoch = 1479 train_loss : 0.820322 , test loss : 1.221500\n",
      "epoch = 1490 train_loss : 0.817926 , test loss : 1.221355\n",
      "epoch = 1492 train_loss : 0.817534 , test loss : 1.220502\n",
      "epoch = 1494 train_loss : 0.817090 , test loss : 1.220407\n",
      "epoch = 1498 train_loss : 0.816271 , test loss : 1.220384\n",
      "epoch = 1499 train_loss : 0.816060 , test loss : 1.220224\n",
      "epoch = 1500 train_loss : 0.815836 , test loss : 1.220024\n",
      "epoch = 1503 train_loss : 0.815210 , test loss : 1.219510\n",
      "epoch = 1506 train_loss : 0.814624 , test loss : 1.219331\n",
      "epoch = 1512 train_loss : 0.813350 , test loss : 1.218744\n",
      "epoch = 1514 train_loss : 0.812937 , test loss : 1.218436\n",
      "epoch = 1515 train_loss : 0.812736 , test loss : 1.218262\n",
      "epoch = 1519 train_loss : 0.811895 , test loss : 1.218181\n",
      "epoch = 1521 train_loss : 0.811517 , test loss : 1.217850\n",
      "epoch = 1522 train_loss : 0.811285 , test loss : 1.217578\n",
      "epoch = 1523 train_loss : 0.811096 , test loss : 1.217375\n",
      "epoch = 1527 train_loss : 0.810290 , test loss : 1.217047\n",
      "epoch = 1529 train_loss : 0.809844 , test loss : 1.216978\n",
      "epoch = 1531 train_loss : 0.809454 , test loss : 1.216833\n",
      "epoch = 1532 train_loss : 0.809237 , test loss : 1.216604\n",
      "epoch = 1537 train_loss : 0.808286 , test loss : 1.215692\n",
      "epoch = 1542 train_loss : 0.807216 , test loss : 1.215655\n",
      "epoch = 1543 train_loss : 0.807001 , test loss : 1.215319\n",
      "epoch = 1547 train_loss : 0.806194 , test loss : 1.214705\n",
      "epoch = 1554 train_loss : 0.804771 , test loss : 1.214575\n",
      "epoch = 1555 train_loss : 0.804566 , test loss : 1.214415\n",
      "epoch = 1558 train_loss : 0.804003 , test loss : 1.214356\n",
      "epoch = 1561 train_loss : 0.803363 , test loss : 1.213644\n",
      "epoch = 1562 train_loss : 0.803181 , test loss : 1.213585\n",
      "epoch = 1568 train_loss : 0.801951 , test loss : 1.213472\n",
      "epoch = 1571 train_loss : 0.801395 , test loss : 1.212994\n",
      "epoch = 1573 train_loss : 0.800976 , test loss : 1.212990\n",
      "epoch = 1574 train_loss : 0.800787 , test loss : 1.212555\n",
      "epoch = 1577 train_loss : 0.800174 , test loss : 1.212480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1582 train_loss : 0.799223 , test loss : 1.211431\n",
      "epoch = 1590 train_loss : 0.797631 , test loss : 1.211068\n",
      "epoch = 1597 train_loss : 0.796368 , test loss : 1.210613\n",
      "epoch = 1601 train_loss : 0.795597 , test loss : 1.210204\n",
      "epoch = 1610 train_loss : 0.793748 , test loss : 1.210073\n",
      "epoch = 1612 train_loss : 0.793362 , test loss : 1.209768\n",
      "epoch = 1613 train_loss : 0.793201 , test loss : 1.209300\n",
      "epoch = 1617 train_loss : 0.792405 , test loss : 1.209144\n",
      "epoch = 1618 train_loss : 0.792202 , test loss : 1.209098\n",
      "epoch = 1624 train_loss : 0.791067 , test loss : 1.208923\n",
      "epoch = 1627 train_loss : 0.790481 , test loss : 1.208055\n",
      "epoch = 1634 train_loss : 0.789145 , test loss : 1.207752\n",
      "epoch = 1644 train_loss : 0.787223 , test loss : 1.207532\n",
      "epoch = 1645 train_loss : 0.787046 , test loss : 1.207397\n",
      "epoch = 1649 train_loss : 0.786360 , test loss : 1.206419\n",
      "epoch = 1655 train_loss : 0.785150 , test loss : 1.205971\n",
      "epoch = 1660 train_loss : 0.784259 , test loss : 1.205574\n",
      "epoch = 1667 train_loss : 0.782885 , test loss : 1.205422\n",
      "epoch = 1668 train_loss : 0.782706 , test loss : 1.205170\n",
      "epoch = 1674 train_loss : 0.781580 , test loss : 1.205129\n",
      "epoch = 1675 train_loss : 0.781415 , test loss : 1.204553\n",
      "epoch = 1684 train_loss : 0.779716 , test loss : 1.204498\n",
      "epoch = 1686 train_loss : 0.779347 , test loss : 1.203895\n",
      "epoch = 1696 train_loss : 0.777509 , test loss : 1.203761\n",
      "epoch = 1701 train_loss : 0.776571 , test loss : 1.203421\n",
      "epoch = 1705 train_loss : 0.775849 , test loss : 1.202626\n",
      "epoch = 1712 train_loss : 0.774599 , test loss : 1.202011\n",
      "epoch = 1726 train_loss : 0.772060 , test loss : 1.201943\n",
      "epoch = 1728 train_loss : 0.771705 , test loss : 1.201932\n",
      "epoch = 1731 train_loss : 0.771084 , test loss : 1.200983\n",
      "epoch = 1745 train_loss : 0.768570 , test loss : 1.200915\n",
      "epoch = 1746 train_loss : 0.768360 , test loss : 1.200565\n",
      "epoch = 1749 train_loss : 0.767837 , test loss : 1.200435\n",
      "epoch = 1750 train_loss : 0.767640 , test loss : 1.200377\n",
      "epoch = 1759 train_loss : 0.766021 , test loss : 1.200365\n",
      "epoch = 1762 train_loss : 0.765494 , test loss : 1.199838\n",
      "epoch = 1764 train_loss : 0.765184 , test loss : 1.199489\n",
      "epoch = 1782 train_loss : 0.761952 , test loss : 1.199096\n",
      "epoch = 1786 train_loss : 0.761280 , test loss : 1.198735\n",
      "epoch = 1795 train_loss : 0.759699 , test loss : 1.198625\n",
      "epoch = 1798 train_loss : 0.759192 , test loss : 1.198055\n",
      "epoch = 1810 train_loss : 0.757071 , test loss : 1.197840\n",
      "epoch = 1812 train_loss : 0.756719 , test loss : 1.197725\n",
      "epoch = 1819 train_loss : 0.755530 , test loss : 1.197672\n",
      "epoch = 1822 train_loss : 0.755038 , test loss : 1.196913\n",
      "epoch = 1832 train_loss : 0.753280 , test loss : 1.196826\n",
      "epoch = 1839 train_loss : 0.752091 , test loss : 1.196571\n",
      "epoch = 1846 train_loss : 0.750870 , test loss : 1.196361\n",
      "epoch = 1849 train_loss : 0.750375 , test loss : 1.196087\n",
      "epoch = 1852 train_loss : 0.749875 , test loss : 1.196066\n",
      "epoch = 1862 train_loss : 0.748174 , test loss : 1.195656\n",
      "epoch = 1871 train_loss : 0.746656 , test loss : 1.195080\n",
      "epoch = 1881 train_loss : 0.744959 , test loss : 1.194617\n",
      "epoch = 1895 train_loss : 0.742629 , test loss : 1.194291\n",
      "epoch = 1903 train_loss : 0.741239 , test loss : 1.194230\n",
      "epoch = 1906 train_loss : 0.740734 , test loss : 1.194002\n",
      "epoch = 1907 train_loss : 0.740631 , test loss : 1.193815\n",
      "epoch = 1912 train_loss : 0.739799 , test loss : 1.192916\n",
      "epoch = 1952 train_loss : 0.733126 , test loss : 1.192548\n",
      "epoch = 1975 train_loss : 0.729337 , test loss : 1.192547\n",
      "epoch = 1977 train_loss : 0.729004 , test loss : 1.192358\n",
      "epoch = 1984 train_loss : 0.727854 , test loss : 1.192249\n",
      "epoch = 1985 train_loss : 0.727713 , test loss : 1.192210\n",
      "epoch = 1987 train_loss : 0.727397 , test loss : 1.192170\n",
      "epoch = 1989 train_loss : 0.727040 , test loss : 1.192066\n",
      "epoch = 1991 train_loss : 0.726797 , test loss : 1.191978\n",
      "epoch = 2000 train_loss : 0.725249 , test loss : 1.191904\n",
      "epoch = 2002 train_loss : 0.724931 , test loss : 1.191695\n",
      "epoch = 2008 train_loss : 0.723974 , test loss : 1.191213\n",
      "epoch = 2016 train_loss : 0.722676 , test loss : 1.191137\n",
      "epoch = 2033 train_loss : 0.719946 , test loss : 1.190967\n",
      "epoch = 2038 train_loss : 0.719154 , test loss : 1.190935\n",
      "epoch = 2045 train_loss : 0.718045 , test loss : 1.190796\n",
      "epoch = 2058 train_loss : 0.715964 , test loss : 1.190355\n",
      "epoch = 2069 train_loss : 0.714224 , test loss : 1.190310\n",
      "epoch = 2082 train_loss : 0.712191 , test loss : 1.190033\n",
      "epoch = 2109 train_loss : 0.708006 , test loss : 1.189754\n",
      "epoch = 2125 train_loss : 0.705529 , test loss : 1.189607\n",
      "epoch = 2147 train_loss : 0.702142 , test loss : 1.189479\n",
      "epoch = 2161 train_loss : 0.699996 , test loss : 1.189438\n",
      "epoch = 2162 train_loss : 0.699854 , test loss : 1.189259\n",
      "epoch = 2171 train_loss : 0.698612 , test loss : 1.189190\n",
      "epoch = 2173 train_loss : 0.698211 , test loss : 1.189006\n",
      "epoch = 2182 train_loss : 0.696788 , test loss : 1.188865\n",
      "epoch = 2194 train_loss : 0.695115 , test loss : 1.188554\n",
      "epoch = 2244 train_loss : 0.687575 , test loss : 1.188513\n",
      "epoch = 2262 train_loss : 0.684951 , test loss : 1.188501\n",
      "epoch = 2267 train_loss : 0.684213 , test loss : 1.188056\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.684213,test loss : 1.188056\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 36.644962 , test loss : 37.644756\n",
      "epoch = 2 train_loss : 36.092758 , test loss : 37.080017\n",
      "epoch = 3 train_loss : 35.549839 , test loss : 36.525967\n",
      "epoch = 4 train_loss : 35.014442 , test loss : 35.978947\n",
      "epoch = 5 train_loss : 34.485161 , test loss : 35.439075\n",
      "epoch = 6 train_loss : 33.960930 , test loss : 34.904106\n",
      "epoch = 7 train_loss : 33.446434 , test loss : 34.380215\n",
      "epoch = 8 train_loss : 32.936069 , test loss : 33.860016\n",
      "epoch = 9 train_loss : 32.434429 , test loss : 33.348129\n",
      "epoch = 10 train_loss : 31.936398 , test loss : 32.841049\n",
      "epoch = 11 train_loss : 31.445335 , test loss : 32.340553\n",
      "epoch = 12 train_loss : 30.954031 , test loss : 31.839027\n",
      "epoch = 13 train_loss : 30.470232 , test loss : 31.345402\n",
      "epoch = 14 train_loss : 29.991022 , test loss : 30.856264\n",
      "epoch = 15 train_loss : 29.513498 , test loss : 30.369074\n",
      "epoch = 16 train_loss : 29.043907 , test loss : 29.889511\n",
      "epoch = 17 train_loss : 28.577486 , test loss : 29.414028\n",
      "epoch = 18 train_loss : 28.116594 , test loss : 28.944197\n",
      "epoch = 19 train_loss : 27.653791 , test loss : 28.472012\n",
      "epoch = 20 train_loss : 27.196907 , test loss : 28.005917\n",
      "epoch = 21 train_loss : 26.745514 , test loss : 27.545849\n",
      "epoch = 22 train_loss : 26.295334 , test loss : 27.086559\n",
      "epoch = 23 train_loss : 25.849974 , test loss : 26.632717\n",
      "epoch = 24 train_loss : 25.409224 , test loss : 26.182791\n",
      "epoch = 25 train_loss : 24.972273 , test loss : 25.737099\n",
      "epoch = 26 train_loss : 24.533287 , test loss : 25.288486\n",
      "epoch = 27 train_loss : 24.101263 , test loss : 24.848421\n",
      "epoch = 28 train_loss : 23.672243 , test loss : 24.410793\n",
      "epoch = 29 train_loss : 23.248724 , test loss : 23.978285\n",
      "epoch = 30 train_loss : 22.827433 , test loss : 23.548025\n",
      "epoch = 31 train_loss : 22.407940 , test loss : 23.119282\n",
      "epoch = 32 train_loss : 21.995832 , test loss : 22.697620\n",
      "epoch = 33 train_loss : 21.585655 , test loss : 22.277519\n",
      "epoch = 34 train_loss : 21.180172 , test loss : 21.862617\n",
      "epoch = 35 train_loss : 20.777317 , test loss : 21.449846\n",
      "epoch = 36 train_loss : 20.381521 , test loss : 21.044333\n",
      "epoch = 37 train_loss : 19.988207 , test loss : 20.640898\n",
      "epoch = 38 train_loss : 19.599779 , test loss : 20.242592\n",
      "epoch = 39 train_loss : 19.215887 , test loss : 19.848471\n",
      "epoch = 40 train_loss : 18.840240 , test loss : 19.462631\n",
      "epoch = 41 train_loss : 18.465090 , test loss : 19.077431\n",
      "epoch = 42 train_loss : 18.093954 , test loss : 18.696035\n",
      "epoch = 43 train_loss : 17.732729 , test loss : 18.325218\n",
      "epoch = 44 train_loss : 17.372280 , test loss : 17.953856\n",
      "epoch = 45 train_loss : 17.018217 , test loss : 17.589489\n",
      "epoch = 46 train_loss : 16.668850 , test loss : 17.228931\n",
      "epoch = 47 train_loss : 16.326391 , test loss : 16.876003\n",
      "epoch = 48 train_loss : 15.985470 , test loss : 16.523825\n",
      "epoch = 49 train_loss : 15.652349 , test loss : 16.180447\n",
      "epoch = 50 train_loss : 15.324784 , test loss : 15.842213\n",
      "epoch = 51 train_loss : 14.999849 , test loss : 15.506169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 52 train_loss : 14.682299 , test loss : 15.177975\n",
      "epoch = 53 train_loss : 14.368855 , test loss : 14.854061\n",
      "epoch = 54 train_loss : 14.061544 , test loss : 14.536222\n",
      "epoch = 55 train_loss : 13.759875 , test loss : 14.224621\n",
      "epoch = 56 train_loss : 13.461041 , test loss : 13.915732\n",
      "epoch = 57 train_loss : 13.169526 , test loss : 13.613617\n",
      "epoch = 58 train_loss : 12.882224 , test loss : 13.316154\n",
      "epoch = 59 train_loss : 12.599787 , test loss : 13.023219\n",
      "epoch = 60 train_loss : 12.322339 , test loss : 12.735022\n",
      "epoch = 61 train_loss : 12.050438 , test loss : 12.452861\n",
      "epoch = 62 train_loss : 11.786110 , test loss : 12.178283\n",
      "epoch = 63 train_loss : 11.522725 , test loss : 11.904557\n",
      "epoch = 64 train_loss : 11.266706 , test loss : 11.638366\n",
      "epoch = 65 train_loss : 11.017377 , test loss : 11.378798\n",
      "epoch = 66 train_loss : 10.770939 , test loss : 11.122241\n",
      "epoch = 67 train_loss : 10.528862 , test loss : 10.869576\n",
      "epoch = 68 train_loss : 10.293313 , test loss : 10.623988\n",
      "epoch = 69 train_loss : 10.063354 , test loss : 10.384172\n",
      "epoch = 70 train_loss : 9.837649 , test loss : 10.148423\n",
      "epoch = 71 train_loss : 9.616527 , test loss : 9.917193\n",
      "epoch = 72 train_loss : 9.401457 , test loss : 9.692391\n",
      "epoch = 73 train_loss : 9.191244 , test loss : 9.472202\n",
      "epoch = 74 train_loss : 8.984521 , test loss : 9.255568\n",
      "epoch = 75 train_loss : 8.783017 , test loss : 9.044433\n",
      "epoch = 76 train_loss : 8.586652 , test loss : 8.838626\n",
      "epoch = 77 train_loss : 8.393190 , test loss : 8.635298\n",
      "epoch = 78 train_loss : 8.208317 , test loss : 8.441397\n",
      "epoch = 79 train_loss : 8.025330 , test loss : 8.249384\n",
      "epoch = 80 train_loss : 7.845539 , test loss : 8.060407\n",
      "epoch = 81 train_loss : 7.673509 , test loss : 7.879570\n",
      "epoch = 82 train_loss : 7.504028 , test loss : 7.701014\n",
      "epoch = 83 train_loss : 7.339494 , test loss : 7.527595\n",
      "epoch = 84 train_loss : 7.179564 , test loss : 7.359146\n",
      "epoch = 85 train_loss : 7.022309 , test loss : 7.193155\n",
      "epoch = 86 train_loss : 6.870635 , test loss : 7.033050\n",
      "epoch = 87 train_loss : 6.723259 , test loss : 6.877458\n",
      "epoch = 88 train_loss : 6.579545 , test loss : 6.725104\n",
      "epoch = 89 train_loss : 6.439714 , test loss : 6.577092\n",
      "epoch = 90 train_loss : 6.303149 , test loss : 6.432402\n",
      "epoch = 91 train_loss : 6.171383 , test loss : 6.292573\n",
      "epoch = 92 train_loss : 6.042880 , test loss : 6.156418\n",
      "epoch = 93 train_loss : 5.918658 , test loss : 6.024209\n",
      "epoch = 94 train_loss : 5.797804 , test loss : 5.895640\n",
      "epoch = 95 train_loss : 5.679660 , test loss : 5.770003\n",
      "epoch = 96 train_loss : 5.565258 , test loss : 5.648144\n",
      "epoch = 97 train_loss : 5.455213 , test loss : 5.531077\n",
      "epoch = 98 train_loss : 5.347993 , test loss : 5.416592\n",
      "epoch = 99 train_loss : 5.243972 , test loss : 5.305274\n",
      "epoch = 100 train_loss : 5.142809 , test loss : 5.197211\n",
      "epoch = 101 train_loss : 5.046513 , test loss : 5.093995\n",
      "epoch = 102 train_loss : 4.951552 , test loss : 4.992398\n",
      "epoch = 103 train_loss : 4.860152 , test loss : 4.894445\n",
      "epoch = 104 train_loss : 4.771474 , test loss : 4.799307\n",
      "epoch = 105 train_loss : 4.686378 , test loss : 4.707829\n",
      "epoch = 106 train_loss : 4.603811 , test loss : 4.619009\n",
      "epoch = 107 train_loss : 4.524590 , test loss : 4.534046\n",
      "epoch = 108 train_loss : 4.447947 , test loss : 4.451547\n",
      "epoch = 109 train_loss : 4.374123 , test loss : 4.371620\n",
      "epoch = 110 train_loss : 4.301620 , test loss : 4.293710\n",
      "epoch = 111 train_loss : 4.231925 , test loss : 4.218465\n",
      "epoch = 112 train_loss : 4.165274 , test loss : 4.146270\n",
      "epoch = 113 train_loss : 4.100057 , test loss : 4.076190\n",
      "epoch = 114 train_loss : 4.038321 , test loss : 4.009209\n",
      "epoch = 115 train_loss : 3.977484 , test loss : 3.943319\n",
      "epoch = 116 train_loss : 3.920126 , test loss : 3.881058\n",
      "epoch = 117 train_loss : 3.863947 , test loss : 3.820197\n",
      "epoch = 118 train_loss : 3.810763 , test loss : 3.762585\n",
      "epoch = 119 train_loss : 3.759356 , test loss : 3.706873\n",
      "epoch = 120 train_loss : 3.709527 , test loss : 3.652419\n",
      "epoch = 121 train_loss : 3.661665 , test loss : 3.600458\n",
      "epoch = 122 train_loss : 3.615292 , test loss : 3.549889\n",
      "epoch = 123 train_loss : 3.571182 , test loss : 3.501966\n",
      "epoch = 124 train_loss : 3.528473 , test loss : 3.455158\n",
      "epoch = 125 train_loss : 3.487540 , test loss : 3.410258\n",
      "epoch = 126 train_loss : 3.448469 , test loss : 3.367422\n",
      "epoch = 127 train_loss : 3.410919 , test loss : 3.326298\n",
      "epoch = 128 train_loss : 3.375292 , test loss : 3.287212\n",
      "epoch = 129 train_loss : 3.340302 , test loss : 3.248847\n",
      "epoch = 130 train_loss : 3.307229 , test loss : 3.212567\n",
      "epoch = 131 train_loss : 3.275861 , test loss : 3.178077\n",
      "epoch = 132 train_loss : 3.245193 , test loss : 3.144222\n",
      "epoch = 133 train_loss : 3.216601 , test loss : 3.112778\n",
      "epoch = 134 train_loss : 3.188167 , test loss : 3.081527\n",
      "epoch = 135 train_loss : 3.161928 , test loss : 3.052594\n",
      "epoch = 136 train_loss : 3.136267 , test loss : 3.024164\n",
      "epoch = 137 train_loss : 3.111777 , test loss : 2.996819\n",
      "epoch = 138 train_loss : 3.088907 , test loss : 2.971607\n",
      "epoch = 139 train_loss : 3.066640 , test loss : 2.946902\n",
      "epoch = 140 train_loss : 3.045302 , test loss : 2.923218\n",
      "epoch = 141 train_loss : 3.025035 , test loss : 2.900650\n",
      "epoch = 142 train_loss : 3.005500 , test loss : 2.878742\n",
      "epoch = 143 train_loss : 2.986606 , test loss : 2.857417\n",
      "epoch = 144 train_loss : 2.968707 , test loss : 2.837228\n",
      "epoch = 145 train_loss : 2.951527 , test loss : 2.818346\n",
      "epoch = 146 train_loss : 2.935274 , test loss : 2.800202\n",
      "epoch = 147 train_loss : 2.919678 , test loss : 2.782842\n",
      "epoch = 148 train_loss : 2.904555 , test loss : 2.766014\n",
      "epoch = 149 train_loss : 2.890372 , test loss : 2.750117\n",
      "epoch = 150 train_loss : 2.876432 , test loss : 2.734414\n",
      "epoch = 151 train_loss : 2.863307 , test loss : 2.719967\n",
      "epoch = 152 train_loss : 2.850632 , test loss : 2.705801\n",
      "epoch = 153 train_loss : 2.838773 , test loss : 2.692489\n",
      "epoch = 154 train_loss : 2.827123 , test loss : 2.679444\n",
      "epoch = 155 train_loss : 2.815910 , test loss : 2.666783\n",
      "epoch = 156 train_loss : 2.805514 , test loss : 2.655524\n",
      "epoch = 157 train_loss : 2.795344 , test loss : 2.643942\n",
      "epoch = 158 train_loss : 2.785362 , test loss : 2.632754\n",
      "epoch = 159 train_loss : 2.775841 , test loss : 2.621954\n",
      "epoch = 160 train_loss : 2.766804 , test loss : 2.612293\n",
      "epoch = 161 train_loss : 2.757791 , test loss : 2.602201\n",
      "epoch = 162 train_loss : 2.749455 , test loss : 2.592915\n",
      "epoch = 163 train_loss : 2.741122 , test loss : 2.583493\n",
      "epoch = 164 train_loss : 2.733027 , test loss : 2.574498\n",
      "epoch = 165 train_loss : 2.725274 , test loss : 2.566013\n",
      "epoch = 166 train_loss : 2.717794 , test loss : 2.557701\n",
      "epoch = 167 train_loss : 2.710477 , test loss : 2.549618\n",
      "epoch = 168 train_loss : 2.703523 , test loss : 2.542033\n",
      "epoch = 169 train_loss : 2.696507 , test loss : 2.534493\n",
      "epoch = 170 train_loss : 2.689707 , test loss : 2.527029\n",
      "epoch = 171 train_loss : 2.683056 , test loss : 2.519904\n",
      "epoch = 172 train_loss : 2.676636 , test loss : 2.512742\n",
      "epoch = 173 train_loss : 2.670258 , test loss : 2.505847\n",
      "epoch = 174 train_loss : 2.664016 , test loss : 2.499280\n",
      "epoch = 175 train_loss : 2.657882 , test loss : 2.492887\n",
      "epoch = 176 train_loss : 2.651959 , test loss : 2.486717\n",
      "epoch = 177 train_loss : 2.645965 , test loss : 2.480434\n",
      "epoch = 178 train_loss : 2.640201 , test loss : 2.474320\n",
      "epoch = 179 train_loss : 2.634329 , test loss : 2.468563\n",
      "epoch = 180 train_loss : 2.628741 , test loss : 2.462600\n",
      "epoch = 181 train_loss : 2.623196 , test loss : 2.457087\n",
      "epoch = 182 train_loss : 2.617584 , test loss : 2.451490\n",
      "epoch = 183 train_loss : 2.612076 , test loss : 2.446063\n",
      "epoch = 184 train_loss : 2.606688 , test loss : 2.440482\n",
      "epoch = 185 train_loss : 2.601349 , test loss : 2.435547\n",
      "epoch = 186 train_loss : 2.596005 , test loss : 2.430194\n",
      "epoch = 187 train_loss : 2.590962 , test loss : 2.425289\n",
      "epoch = 188 train_loss : 2.585600 , test loss : 2.419750\n",
      "epoch = 189 train_loss : 2.580378 , test loss : 2.414699\n",
      "epoch = 190 train_loss : 2.575294 , test loss : 2.409825\n",
      "epoch = 191 train_loss : 2.569968 , test loss : 2.404913\n",
      "epoch = 192 train_loss : 2.565011 , test loss : 2.399723\n",
      "epoch = 193 train_loss : 2.559837 , test loss : 2.395177\n",
      "epoch = 194 train_loss : 2.554760 , test loss : 2.390350\n",
      "epoch = 195 train_loss : 2.549637 , test loss : 2.385211\n",
      "epoch = 196 train_loss : 2.544779 , test loss : 2.380837\n",
      "epoch = 197 train_loss : 2.539722 , test loss : 2.375899\n",
      "epoch = 198 train_loss : 2.534677 , test loss : 2.371085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 199 train_loss : 2.529679 , test loss : 2.366143\n",
      "epoch = 200 train_loss : 2.524761 , test loss : 2.361769\n",
      "epoch = 201 train_loss : 2.519934 , test loss : 2.356922\n",
      "epoch = 202 train_loss : 2.515013 , test loss : 2.352774\n",
      "epoch = 203 train_loss : 2.510050 , test loss : 2.348051\n",
      "epoch = 204 train_loss : 2.505170 , test loss : 2.343295\n",
      "epoch = 205 train_loss : 2.500489 , test loss : 2.338841\n",
      "epoch = 206 train_loss : 2.495588 , test loss : 2.334197\n",
      "epoch = 207 train_loss : 2.490773 , test loss : 2.329845\n",
      "epoch = 208 train_loss : 2.486089 , test loss : 2.325536\n",
      "epoch = 209 train_loss : 2.481341 , test loss : 2.321124\n",
      "epoch = 210 train_loss : 2.476536 , test loss : 2.316530\n",
      "epoch = 211 train_loss : 2.471782 , test loss : 2.312295\n",
      "epoch = 212 train_loss : 2.467239 , test loss : 2.307976\n",
      "epoch = 213 train_loss : 2.462508 , test loss : 2.303663\n",
      "epoch = 214 train_loss : 2.457819 , test loss : 2.299428\n",
      "epoch = 215 train_loss : 2.453235 , test loss : 2.295237\n",
      "epoch = 216 train_loss : 2.448521 , test loss : 2.290781\n",
      "epoch = 217 train_loss : 2.443883 , test loss : 2.286867\n",
      "epoch = 218 train_loss : 2.439330 , test loss : 2.282683\n",
      "epoch = 219 train_loss : 2.434687 , test loss : 2.278645\n",
      "epoch = 220 train_loss : 2.430009 , test loss : 2.274501\n",
      "epoch = 221 train_loss : 2.425557 , test loss : 2.270291\n",
      "epoch = 222 train_loss : 2.420934 , test loss : 2.265985\n",
      "epoch = 223 train_loss : 2.416460 , test loss : 2.262306\n",
      "epoch = 224 train_loss : 2.411942 , test loss : 2.258176\n",
      "epoch = 225 train_loss : 2.407338 , test loss : 2.253814\n",
      "epoch = 226 train_loss : 2.402933 , test loss : 2.250158\n",
      "epoch = 227 train_loss : 2.398463 , test loss : 2.245908\n",
      "epoch = 228 train_loss : 2.394037 , test loss : 2.241972\n",
      "epoch = 229 train_loss : 2.389534 , test loss : 2.238073\n",
      "epoch = 230 train_loss : 2.385077 , test loss : 2.234038\n",
      "epoch = 231 train_loss : 2.380667 , test loss : 2.230378\n",
      "epoch = 232 train_loss : 2.376282 , test loss : 2.226368\n",
      "epoch = 233 train_loss : 2.371814 , test loss : 2.222646\n",
      "epoch = 234 train_loss : 2.367290 , test loss : 2.218611\n",
      "epoch = 235 train_loss : 2.362903 , test loss : 2.215051\n",
      "epoch = 236 train_loss : 2.358539 , test loss : 2.210843\n",
      "epoch = 237 train_loss : 2.354138 , test loss : 2.207180\n",
      "epoch = 238 train_loss : 2.349757 , test loss : 2.203601\n",
      "epoch = 239 train_loss : 2.345423 , test loss : 2.199240\n",
      "epoch = 240 train_loss : 2.341066 , test loss : 2.195894\n",
      "epoch = 241 train_loss : 2.336710 , test loss : 2.191734\n",
      "epoch = 242 train_loss : 2.332346 , test loss : 2.188004\n",
      "epoch = 243 train_loss : 2.328089 , test loss : 2.183935\n",
      "epoch = 244 train_loss : 2.323621 , test loss : 2.180524\n",
      "epoch = 245 train_loss : 2.319290 , test loss : 2.176748\n",
      "epoch = 246 train_loss : 2.314972 , test loss : 2.172936\n",
      "epoch = 247 train_loss : 2.310620 , test loss : 2.168745\n",
      "epoch = 248 train_loss : 2.306378 , test loss : 2.165152\n",
      "epoch = 249 train_loss : 2.302038 , test loss : 2.161347\n",
      "epoch = 250 train_loss : 2.297723 , test loss : 2.157811\n",
      "epoch = 251 train_loss : 2.293442 , test loss : 2.153953\n",
      "epoch = 252 train_loss : 2.289106 , test loss : 2.150257\n",
      "epoch = 253 train_loss : 2.284862 , test loss : 2.146794\n",
      "epoch = 254 train_loss : 2.280641 , test loss : 2.142745\n",
      "epoch = 255 train_loss : 2.276424 , test loss : 2.138979\n",
      "epoch = 256 train_loss : 2.272108 , test loss : 2.135396\n",
      "epoch = 257 train_loss : 2.267912 , test loss : 2.131543\n",
      "epoch = 258 train_loss : 2.263735 , test loss : 2.128047\n",
      "epoch = 259 train_loss : 2.259543 , test loss : 2.124402\n",
      "epoch = 260 train_loss : 2.255332 , test loss : 2.120567\n",
      "epoch = 261 train_loss : 2.251150 , test loss : 2.116848\n",
      "epoch = 262 train_loss : 2.247011 , test loss : 2.113458\n",
      "epoch = 263 train_loss : 2.242861 , test loss : 2.109833\n",
      "epoch = 264 train_loss : 2.238728 , test loss : 2.106030\n",
      "epoch = 265 train_loss : 2.234664 , test loss : 2.102637\n",
      "epoch = 266 train_loss : 2.230523 , test loss : 2.099205\n",
      "epoch = 267 train_loss : 2.226281 , test loss : 2.094894\n",
      "epoch = 268 train_loss : 2.222250 , test loss : 2.091423\n",
      "epoch = 269 train_loss : 2.218094 , test loss : 2.088244\n",
      "epoch = 270 train_loss : 2.214043 , test loss : 2.084764\n",
      "epoch = 271 train_loss : 2.209907 , test loss : 2.080900\n",
      "epoch = 272 train_loss : 2.205836 , test loss : 2.077895\n",
      "epoch = 273 train_loss : 2.201719 , test loss : 2.073868\n",
      "epoch = 274 train_loss : 2.197553 , test loss : 2.070299\n",
      "epoch = 275 train_loss : 2.193498 , test loss : 2.066796\n",
      "epoch = 276 train_loss : 2.189459 , test loss : 2.063281\n",
      "epoch = 277 train_loss : 2.185399 , test loss : 2.059849\n",
      "epoch = 278 train_loss : 2.181287 , test loss : 2.055884\n",
      "epoch = 279 train_loss : 2.177266 , test loss : 2.052073\n",
      "epoch = 280 train_loss : 2.173253 , test loss : 2.048806\n",
      "epoch = 281 train_loss : 2.169267 , test loss : 2.045057\n",
      "epoch = 282 train_loss : 2.165324 , test loss : 2.041815\n",
      "epoch = 283 train_loss : 2.161347 , test loss : 2.037889\n",
      "epoch = 284 train_loss : 2.157326 , test loss : 2.034812\n",
      "epoch = 285 train_loss : 2.153379 , test loss : 2.031380\n",
      "epoch = 286 train_loss : 2.149456 , test loss : 2.028283\n",
      "epoch = 287 train_loss : 2.145413 , test loss : 2.024451\n",
      "epoch = 288 train_loss : 2.141491 , test loss : 2.020892\n",
      "epoch = 289 train_loss : 2.137544 , test loss : 2.017548\n",
      "epoch = 290 train_loss : 2.133563 , test loss : 2.013922\n",
      "epoch = 291 train_loss : 2.129648 , test loss : 2.010365\n",
      "epoch = 292 train_loss : 2.125663 , test loss : 2.006256\n",
      "epoch = 293 train_loss : 2.121727 , test loss : 2.003177\n",
      "epoch = 294 train_loss : 2.117801 , test loss : 2.000200\n",
      "epoch = 295 train_loss : 2.113863 , test loss : 1.996723\n",
      "epoch = 296 train_loss : 2.109926 , test loss : 1.992962\n",
      "epoch = 297 train_loss : 2.105940 , test loss : 1.989782\n",
      "epoch = 298 train_loss : 2.102032 , test loss : 1.986298\n",
      "epoch = 299 train_loss : 2.098101 , test loss : 1.982662\n",
      "epoch = 300 train_loss : 2.094157 , test loss : 1.979262\n",
      "epoch = 301 train_loss : 2.090238 , test loss : 1.976246\n",
      "epoch = 302 train_loss : 2.086286 , test loss : 1.972781\n",
      "epoch = 303 train_loss : 2.082349 , test loss : 1.969501\n",
      "epoch = 304 train_loss : 2.078513 , test loss : 1.965593\n",
      "epoch = 305 train_loss : 2.074599 , test loss : 1.962432\n",
      "epoch = 306 train_loss : 2.070606 , test loss : 1.958753\n",
      "epoch = 307 train_loss : 2.066700 , test loss : 1.955959\n",
      "epoch = 308 train_loss : 2.062744 , test loss : 1.952269\n",
      "epoch = 309 train_loss : 2.058845 , test loss : 1.949065\n",
      "epoch = 310 train_loss : 2.054929 , test loss : 1.945662\n",
      "epoch = 311 train_loss : 2.051149 , test loss : 1.941973\n",
      "epoch = 312 train_loss : 2.047223 , test loss : 1.938657\n",
      "epoch = 313 train_loss : 2.043378 , test loss : 1.935285\n",
      "epoch = 314 train_loss : 2.039548 , test loss : 1.931556\n",
      "epoch = 315 train_loss : 2.035715 , test loss : 1.928316\n",
      "epoch = 316 train_loss : 2.031938 , test loss : 1.924971\n",
      "epoch = 317 train_loss : 2.028104 , test loss : 1.921380\n",
      "epoch = 318 train_loss : 2.024252 , test loss : 1.918502\n",
      "epoch = 319 train_loss : 2.020420 , test loss : 1.914409\n",
      "epoch = 320 train_loss : 2.016680 , test loss : 1.911776\n",
      "epoch = 321 train_loss : 2.012887 , test loss : 1.908551\n",
      "epoch = 322 train_loss : 2.009092 , test loss : 1.905095\n",
      "epoch = 323 train_loss : 2.005305 , test loss : 1.901754\n",
      "epoch = 324 train_loss : 2.001581 , test loss : 1.898582\n",
      "epoch = 325 train_loss : 1.997832 , test loss : 1.895755\n",
      "epoch = 326 train_loss : 1.994093 , test loss : 1.892612\n",
      "epoch = 327 train_loss : 1.990339 , test loss : 1.888715\n",
      "epoch = 328 train_loss : 1.986572 , test loss : 1.885777\n",
      "epoch = 329 train_loss : 1.982891 , test loss : 1.882561\n",
      "epoch = 330 train_loss : 1.979216 , test loss : 1.879501\n",
      "epoch = 331 train_loss : 1.975506 , test loss : 1.876206\n",
      "epoch = 332 train_loss : 1.971800 , test loss : 1.872954\n",
      "epoch = 333 train_loss : 1.968168 , test loss : 1.869927\n",
      "epoch = 334 train_loss : 1.964454 , test loss : 1.866549\n",
      "epoch = 335 train_loss : 1.960775 , test loss : 1.863025\n",
      "epoch = 336 train_loss : 1.957096 , test loss : 1.860084\n",
      "epoch = 337 train_loss : 1.953424 , test loss : 1.857144\n",
      "epoch = 338 train_loss : 1.949727 , test loss : 1.854054\n",
      "epoch = 339 train_loss : 1.946055 , test loss : 1.850648\n",
      "epoch = 340 train_loss : 1.942474 , test loss : 1.847367\n",
      "epoch = 341 train_loss : 1.938764 , test loss : 1.844213\n",
      "epoch = 342 train_loss : 1.935173 , test loss : 1.841353\n",
      "epoch = 343 train_loss : 1.931496 , test loss : 1.838006\n",
      "epoch = 344 train_loss : 1.927856 , test loss : 1.834951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 345 train_loss : 1.924218 , test loss : 1.832117\n",
      "epoch = 346 train_loss : 1.920621 , test loss : 1.829074\n",
      "epoch = 347 train_loss : 1.917004 , test loss : 1.825115\n",
      "epoch = 348 train_loss : 1.913360 , test loss : 1.822760\n",
      "epoch = 349 train_loss : 1.909792 , test loss : 1.819959\n",
      "epoch = 350 train_loss : 1.906138 , test loss : 1.816486\n",
      "epoch = 351 train_loss : 1.902557 , test loss : 1.813516\n",
      "epoch = 352 train_loss : 1.898946 , test loss : 1.809892\n",
      "epoch = 353 train_loss : 1.895416 , test loss : 1.807411\n",
      "epoch = 354 train_loss : 1.891813 , test loss : 1.804137\n",
      "epoch = 355 train_loss : 1.888232 , test loss : 1.800871\n",
      "epoch = 356 train_loss : 1.884723 , test loss : 1.797953\n",
      "epoch = 357 train_loss : 1.881140 , test loss : 1.795406\n",
      "epoch = 358 train_loss : 1.877620 , test loss : 1.792244\n",
      "epoch = 359 train_loss : 1.874167 , test loss : 1.788941\n",
      "epoch = 360 train_loss : 1.870628 , test loss : 1.786282\n",
      "epoch = 361 train_loss : 1.867147 , test loss : 1.783336\n",
      "epoch = 362 train_loss : 1.863657 , test loss : 1.780257\n",
      "epoch = 363 train_loss : 1.860224 , test loss : 1.777051\n",
      "epoch = 364 train_loss : 1.856688 , test loss : 1.774564\n",
      "epoch = 365 train_loss : 1.853295 , test loss : 1.771511\n",
      "epoch = 366 train_loss : 1.849839 , test loss : 1.768722\n",
      "epoch = 367 train_loss : 1.846344 , test loss : 1.765537\n",
      "epoch = 368 train_loss : 1.842955 , test loss : 1.763164\n",
      "epoch = 369 train_loss : 1.839523 , test loss : 1.760437\n",
      "epoch = 370 train_loss : 1.836069 , test loss : 1.757057\n",
      "epoch = 371 train_loss : 1.832647 , test loss : 1.754224\n",
      "epoch = 372 train_loss : 1.829229 , test loss : 1.751481\n",
      "epoch = 373 train_loss : 1.825862 , test loss : 1.748159\n",
      "epoch = 374 train_loss : 1.822472 , test loss : 1.745131\n",
      "epoch = 375 train_loss : 1.819071 , test loss : 1.742603\n",
      "epoch = 376 train_loss : 1.815704 , test loss : 1.740085\n",
      "epoch = 377 train_loss : 1.812326 , test loss : 1.737725\n",
      "epoch = 378 train_loss : 1.808958 , test loss : 1.734549\n",
      "epoch = 379 train_loss : 1.805561 , test loss : 1.731807\n",
      "epoch = 380 train_loss : 1.802253 , test loss : 1.728937\n",
      "epoch = 381 train_loss : 1.798848 , test loss : 1.726180\n",
      "epoch = 382 train_loss : 1.795583 , test loss : 1.722759\n",
      "epoch = 383 train_loss : 1.792177 , test loss : 1.720353\n",
      "epoch = 384 train_loss : 1.788838 , test loss : 1.717990\n",
      "epoch = 385 train_loss : 1.785589 , test loss : 1.714200\n",
      "epoch = 386 train_loss : 1.782222 , test loss : 1.711800\n",
      "epoch = 387 train_loss : 1.778968 , test loss : 1.708627\n",
      "epoch = 388 train_loss : 1.775741 , test loss : 1.706093\n",
      "epoch = 389 train_loss : 1.772366 , test loss : 1.703733\n",
      "epoch = 390 train_loss : 1.769101 , test loss : 1.700648\n",
      "epoch = 391 train_loss : 1.765846 , test loss : 1.698164\n",
      "epoch = 392 train_loss : 1.762586 , test loss : 1.695150\n",
      "epoch = 393 train_loss : 1.759330 , test loss : 1.693029\n",
      "epoch = 394 train_loss : 1.756107 , test loss : 1.689886\n",
      "epoch = 395 train_loss : 1.752800 , test loss : 1.687219\n",
      "epoch = 396 train_loss : 1.749625 , test loss : 1.684437\n",
      "epoch = 397 train_loss : 1.746455 , test loss : 1.681717\n",
      "epoch = 398 train_loss : 1.743261 , test loss : 1.678938\n",
      "epoch = 399 train_loss : 1.739979 , test loss : 1.676125\n",
      "epoch = 400 train_loss : 1.736788 , test loss : 1.673813\n",
      "epoch = 401 train_loss : 1.733614 , test loss : 1.670933\n",
      "epoch = 402 train_loss : 1.730451 , test loss : 1.668584\n",
      "epoch = 403 train_loss : 1.727263 , test loss : 1.665989\n",
      "epoch = 404 train_loss : 1.724164 , test loss : 1.662767\n",
      "epoch = 405 train_loss : 1.721019 , test loss : 1.660823\n",
      "epoch = 406 train_loss : 1.717846 , test loss : 1.657937\n",
      "epoch = 407 train_loss : 1.714762 , test loss : 1.655619\n",
      "epoch = 408 train_loss : 1.711663 , test loss : 1.652505\n",
      "epoch = 409 train_loss : 1.708577 , test loss : 1.650439\n",
      "epoch = 410 train_loss : 1.705428 , test loss : 1.647855\n",
      "epoch = 411 train_loss : 1.702312 , test loss : 1.645577\n",
      "epoch = 412 train_loss : 1.699250 , test loss : 1.643070\n",
      "epoch = 413 train_loss : 1.696129 , test loss : 1.640069\n",
      "epoch = 414 train_loss : 1.693092 , test loss : 1.637468\n",
      "epoch = 415 train_loss : 1.690097 , test loss : 1.634941\n",
      "epoch = 416 train_loss : 1.687052 , test loss : 1.632514\n",
      "epoch = 417 train_loss : 1.683974 , test loss : 1.630223\n",
      "epoch = 418 train_loss : 1.680997 , test loss : 1.627203\n",
      "epoch = 419 train_loss : 1.677887 , test loss : 1.624673\n",
      "epoch = 420 train_loss : 1.674938 , test loss : 1.622376\n",
      "epoch = 421 train_loss : 1.671976 , test loss : 1.620586\n",
      "epoch = 422 train_loss : 1.668928 , test loss : 1.617954\n",
      "epoch = 423 train_loss : 1.665928 , test loss : 1.615242\n",
      "epoch = 424 train_loss : 1.662925 , test loss : 1.612413\n",
      "epoch = 425 train_loss : 1.659890 , test loss : 1.609828\n",
      "epoch = 426 train_loss : 1.656972 , test loss : 1.607368\n",
      "epoch = 427 train_loss : 1.654026 , test loss : 1.605499\n",
      "epoch = 428 train_loss : 1.651101 , test loss : 1.602876\n",
      "epoch = 429 train_loss : 1.648139 , test loss : 1.600877\n",
      "epoch = 430 train_loss : 1.645232 , test loss : 1.598287\n",
      "epoch = 431 train_loss : 1.642331 , test loss : 1.595742\n",
      "epoch = 432 train_loss : 1.639420 , test loss : 1.593809\n",
      "epoch = 433 train_loss : 1.636503 , test loss : 1.590081\n",
      "epoch = 434 train_loss : 1.633552 , test loss : 1.588089\n",
      "epoch = 435 train_loss : 1.630650 , test loss : 1.585993\n",
      "epoch = 436 train_loss : 1.627771 , test loss : 1.583598\n",
      "epoch = 437 train_loss : 1.624916 , test loss : 1.581705\n",
      "epoch = 438 train_loss : 1.622064 , test loss : 1.579366\n",
      "epoch = 439 train_loss : 1.619190 , test loss : 1.576876\n",
      "epoch = 440 train_loss : 1.616369 , test loss : 1.574699\n",
      "epoch = 441 train_loss : 1.613566 , test loss : 1.572522\n",
      "epoch = 442 train_loss : 1.610768 , test loss : 1.570329\n",
      "epoch = 443 train_loss : 1.608005 , test loss : 1.567885\n",
      "epoch = 444 train_loss : 1.605185 , test loss : 1.565525\n",
      "epoch = 445 train_loss : 1.602462 , test loss : 1.563293\n",
      "epoch = 446 train_loss : 1.599683 , test loss : 1.561464\n",
      "epoch = 447 train_loss : 1.596924 , test loss : 1.559114\n",
      "epoch = 448 train_loss : 1.594211 , test loss : 1.556767\n",
      "epoch = 449 train_loss : 1.591529 , test loss : 1.554364\n",
      "epoch = 450 train_loss : 1.588697 , test loss : 1.552540\n",
      "epoch = 451 train_loss : 1.585994 , test loss : 1.550242\n",
      "epoch = 452 train_loss : 1.583266 , test loss : 1.547788\n",
      "epoch = 453 train_loss : 1.580601 , test loss : 1.545935\n",
      "epoch = 454 train_loss : 1.577859 , test loss : 1.543651\n",
      "epoch = 455 train_loss : 1.575182 , test loss : 1.541267\n",
      "epoch = 456 train_loss : 1.572528 , test loss : 1.539419\n",
      "epoch = 457 train_loss : 1.569805 , test loss : 1.537381\n",
      "epoch = 458 train_loss : 1.567129 , test loss : 1.534766\n",
      "epoch = 459 train_loss : 1.564443 , test loss : 1.533104\n",
      "epoch = 460 train_loss : 1.561831 , test loss : 1.531106\n",
      "epoch = 461 train_loss : 1.559200 , test loss : 1.527991\n",
      "epoch = 462 train_loss : 1.556546 , test loss : 1.526384\n",
      "epoch = 463 train_loss : 1.553930 , test loss : 1.524176\n",
      "epoch = 464 train_loss : 1.551337 , test loss : 1.521850\n",
      "epoch = 465 train_loss : 1.548734 , test loss : 1.519855\n",
      "epoch = 466 train_loss : 1.546131 , test loss : 1.517698\n",
      "epoch = 467 train_loss : 1.543547 , test loss : 1.515525\n",
      "epoch = 468 train_loss : 1.540976 , test loss : 1.513402\n",
      "epoch = 469 train_loss : 1.538358 , test loss : 1.511273\n",
      "epoch = 470 train_loss : 1.535800 , test loss : 1.508980\n",
      "epoch = 471 train_loss : 1.533257 , test loss : 1.506828\n",
      "epoch = 472 train_loss : 1.530724 , test loss : 1.504963\n",
      "epoch = 473 train_loss : 1.528140 , test loss : 1.502723\n",
      "epoch = 474 train_loss : 1.525637 , test loss : 1.500365\n",
      "epoch = 475 train_loss : 1.523121 , test loss : 1.498664\n",
      "epoch = 476 train_loss : 1.520682 , test loss : 1.496185\n",
      "epoch = 477 train_loss : 1.518153 , test loss : 1.494469\n",
      "epoch = 478 train_loss : 1.515702 , test loss : 1.492880\n",
      "epoch = 479 train_loss : 1.513151 , test loss : 1.490451\n",
      "epoch = 480 train_loss : 1.510654 , test loss : 1.488371\n",
      "epoch = 481 train_loss : 1.508191 , test loss : 1.486313\n",
      "epoch = 482 train_loss : 1.505741 , test loss : 1.484169\n",
      "epoch = 483 train_loss : 1.503307 , test loss : 1.482428\n",
      "epoch = 484 train_loss : 1.500876 , test loss : 1.480795\n",
      "epoch = 485 train_loss : 1.498407 , test loss : 1.478210\n",
      "epoch = 486 train_loss : 1.496007 , test loss : 1.476705\n",
      "epoch = 487 train_loss : 1.493673 , test loss : 1.473810\n",
      "epoch = 488 train_loss : 1.491224 , test loss : 1.472660\n",
      "epoch = 489 train_loss : 1.488826 , test loss : 1.470755\n",
      "epoch = 490 train_loss : 1.486424 , test loss : 1.468949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 491 train_loss : 1.484083 , test loss : 1.466730\n",
      "epoch = 492 train_loss : 1.481697 , test loss : 1.464958\n",
      "epoch = 493 train_loss : 1.479359 , test loss : 1.462773\n",
      "epoch = 494 train_loss : 1.477022 , test loss : 1.461176\n",
      "epoch = 495 train_loss : 1.474739 , test loss : 1.458751\n",
      "epoch = 496 train_loss : 1.472322 , test loss : 1.457389\n",
      "epoch = 497 train_loss : 1.470016 , test loss : 1.455214\n",
      "epoch = 498 train_loss : 1.467671 , test loss : 1.453476\n",
      "epoch = 499 train_loss : 1.465376 , test loss : 1.451623\n",
      "epoch = 500 train_loss : 1.463051 , test loss : 1.450011\n",
      "epoch = 501 train_loss : 1.460729 , test loss : 1.447612\n",
      "epoch = 502 train_loss : 1.458496 , test loss : 1.445751\n",
      "epoch = 503 train_loss : 1.456159 , test loss : 1.443907\n",
      "epoch = 504 train_loss : 1.453876 , test loss : 1.442278\n",
      "epoch = 505 train_loss : 1.451610 , test loss : 1.439823\n",
      "epoch = 506 train_loss : 1.449321 , test loss : 1.438066\n",
      "epoch = 507 train_loss : 1.447065 , test loss : 1.436750\n",
      "epoch = 508 train_loss : 1.444894 , test loss : 1.435265\n",
      "epoch = 509 train_loss : 1.442590 , test loss : 1.433078\n",
      "epoch = 510 train_loss : 1.440362 , test loss : 1.431116\n",
      "epoch = 511 train_loss : 1.438139 , test loss : 1.429469\n",
      "epoch = 512 train_loss : 1.435927 , test loss : 1.428025\n",
      "epoch = 513 train_loss : 1.433734 , test loss : 1.426216\n",
      "epoch = 514 train_loss : 1.431548 , test loss : 1.424664\n",
      "epoch = 515 train_loss : 1.429389 , test loss : 1.422593\n",
      "epoch = 516 train_loss : 1.427166 , test loss : 1.420419\n",
      "epoch = 517 train_loss : 1.425097 , test loss : 1.419253\n",
      "epoch = 518 train_loss : 1.422905 , test loss : 1.417064\n",
      "epoch = 519 train_loss : 1.420768 , test loss : 1.415638\n",
      "epoch = 520 train_loss : 1.418616 , test loss : 1.413841\n",
      "epoch = 521 train_loss : 1.416515 , test loss : 1.412174\n",
      "epoch = 522 train_loss : 1.414358 , test loss : 1.410014\n",
      "epoch = 523 train_loss : 1.412303 , test loss : 1.408243\n",
      "epoch = 524 train_loss : 1.410168 , test loss : 1.406826\n",
      "epoch = 525 train_loss : 1.408114 , test loss : 1.405527\n",
      "epoch = 526 train_loss : 1.406018 , test loss : 1.403346\n",
      "epoch = 527 train_loss : 1.403966 , test loss : 1.401484\n",
      "epoch = 528 train_loss : 1.401903 , test loss : 1.399870\n",
      "epoch = 529 train_loss : 1.399793 , test loss : 1.398676\n",
      "epoch = 530 train_loss : 1.397731 , test loss : 1.396805\n",
      "epoch = 531 train_loss : 1.395798 , test loss : 1.394791\n",
      "epoch = 532 train_loss : 1.393798 , test loss : 1.394222\n",
      "epoch = 533 train_loss : 1.391674 , test loss : 1.392241\n",
      "epoch = 534 train_loss : 1.389649 , test loss : 1.390074\n",
      "epoch = 535 train_loss : 1.387653 , test loss : 1.388705\n",
      "epoch = 536 train_loss : 1.385667 , test loss : 1.386741\n",
      "epoch = 537 train_loss : 1.383627 , test loss : 1.385307\n",
      "epoch = 538 train_loss : 1.381630 , test loss : 1.384067\n",
      "epoch = 539 train_loss : 1.379645 , test loss : 1.382554\n",
      "epoch = 540 train_loss : 1.377723 , test loss : 1.380965\n",
      "epoch = 541 train_loss : 1.375725 , test loss : 1.379417\n",
      "epoch = 542 train_loss : 1.373883 , test loss : 1.377303\n",
      "epoch = 543 train_loss : 1.371855 , test loss : 1.376207\n",
      "epoch = 544 train_loss : 1.369915 , test loss : 1.374060\n",
      "epoch = 545 train_loss : 1.367989 , test loss : 1.373272\n",
      "epoch = 546 train_loss : 1.366049 , test loss : 1.371835\n",
      "epoch = 547 train_loss : 1.364143 , test loss : 1.370029\n",
      "epoch = 548 train_loss : 1.362255 , test loss : 1.368631\n",
      "epoch = 549 train_loss : 1.360395 , test loss : 1.366531\n",
      "epoch = 550 train_loss : 1.358514 , test loss : 1.365410\n",
      "epoch = 551 train_loss : 1.356593 , test loss : 1.364558\n",
      "epoch = 552 train_loss : 1.354708 , test loss : 1.362896\n",
      "epoch = 553 train_loss : 1.352823 , test loss : 1.360951\n",
      "epoch = 554 train_loss : 1.350938 , test loss : 1.359722\n",
      "epoch = 555 train_loss : 1.349098 , test loss : 1.357967\n",
      "epoch = 556 train_loss : 1.347257 , test loss : 1.356465\n",
      "epoch = 557 train_loss : 1.345446 , test loss : 1.355357\n",
      "epoch = 558 train_loss : 1.343594 , test loss : 1.354232\n",
      "epoch = 559 train_loss : 1.341800 , test loss : 1.353175\n",
      "epoch = 560 train_loss : 1.339956 , test loss : 1.351254\n",
      "epoch = 561 train_loss : 1.338184 , test loss : 1.349931\n",
      "epoch = 562 train_loss : 1.336381 , test loss : 1.348282\n",
      "epoch = 563 train_loss : 1.334588 , test loss : 1.346879\n",
      "epoch = 564 train_loss : 1.332827 , test loss : 1.345526\n",
      "epoch = 565 train_loss : 1.331002 , test loss : 1.344025\n",
      "epoch = 566 train_loss : 1.329226 , test loss : 1.342563\n",
      "epoch = 567 train_loss : 1.327485 , test loss : 1.341368\n",
      "epoch = 568 train_loss : 1.325720 , test loss : 1.339887\n",
      "epoch = 569 train_loss : 1.323982 , test loss : 1.338738\n",
      "epoch = 570 train_loss : 1.322336 , test loss : 1.337741\n",
      "epoch = 571 train_loss : 1.320486 , test loss : 1.335971\n",
      "epoch = 572 train_loss : 1.318818 , test loss : 1.334981\n",
      "epoch = 573 train_loss : 1.317149 , test loss : 1.333110\n",
      "epoch = 574 train_loss : 1.315386 , test loss : 1.332075\n",
      "epoch = 575 train_loss : 1.313707 , test loss : 1.331158\n",
      "epoch = 576 train_loss : 1.312004 , test loss : 1.329600\n",
      "epoch = 577 train_loss : 1.310341 , test loss : 1.328184\n",
      "epoch = 578 train_loss : 1.308674 , test loss : 1.326874\n",
      "epoch = 579 train_loss : 1.307017 , test loss : 1.325832\n",
      "epoch = 580 train_loss : 1.305375 , test loss : 1.324821\n",
      "epoch = 581 train_loss : 1.303719 , test loss : 1.323625\n",
      "epoch = 582 train_loss : 1.302082 , test loss : 1.322069\n",
      "epoch = 583 train_loss : 1.300415 , test loss : 1.320322\n",
      "epoch = 584 train_loss : 1.298819 , test loss : 1.319356\n",
      "epoch = 585 train_loss : 1.297218 , test loss : 1.317940\n",
      "epoch = 586 train_loss : 1.295601 , test loss : 1.317120\n",
      "epoch = 587 train_loss : 1.294017 , test loss : 1.315973\n",
      "epoch = 588 train_loss : 1.292459 , test loss : 1.314577\n",
      "epoch = 589 train_loss : 1.290892 , test loss : 1.313647\n",
      "epoch = 590 train_loss : 1.289334 , test loss : 1.312077\n",
      "epoch = 591 train_loss : 1.287752 , test loss : 1.311197\n",
      "epoch = 592 train_loss : 1.286224 , test loss : 1.309775\n",
      "epoch = 593 train_loss : 1.284679 , test loss : 1.308954\n",
      "epoch = 594 train_loss : 1.283121 , test loss : 1.307519\n",
      "epoch = 595 train_loss : 1.281594 , test loss : 1.306583\n",
      "epoch = 596 train_loss : 1.280100 , test loss : 1.305054\n",
      "epoch = 597 train_loss : 1.278551 , test loss : 1.304022\n",
      "epoch = 598 train_loss : 1.277102 , test loss : 1.303119\n",
      "epoch = 599 train_loss : 1.275552 , test loss : 1.301926\n",
      "epoch = 600 train_loss : 1.274080 , test loss : 1.301565\n",
      "epoch = 601 train_loss : 1.272531 , test loss : 1.300024\n",
      "epoch = 602 train_loss : 1.271060 , test loss : 1.298295\n",
      "epoch = 603 train_loss : 1.269595 , test loss : 1.297274\n",
      "epoch = 604 train_loss : 1.268088 , test loss : 1.296361\n",
      "epoch = 605 train_loss : 1.266645 , test loss : 1.295772\n",
      "epoch = 606 train_loss : 1.265172 , test loss : 1.294181\n",
      "epoch = 607 train_loss : 1.263749 , test loss : 1.292846\n",
      "epoch = 608 train_loss : 1.262362 , test loss : 1.292437\n",
      "epoch = 609 train_loss : 1.260893 , test loss : 1.290987\n",
      "epoch = 610 train_loss : 1.259446 , test loss : 1.289976\n",
      "epoch = 611 train_loss : 1.258048 , test loss : 1.288796\n",
      "epoch = 612 train_loss : 1.256623 , test loss : 1.287893\n",
      "epoch = 613 train_loss : 1.255187 , test loss : 1.287046\n",
      "epoch = 614 train_loss : 1.253754 , test loss : 1.285457\n",
      "epoch = 615 train_loss : 1.252379 , test loss : 1.284779\n",
      "epoch = 616 train_loss : 1.250969 , test loss : 1.284010\n",
      "epoch = 617 train_loss : 1.249527 , test loss : 1.282420\n",
      "epoch = 618 train_loss : 1.248136 , test loss : 1.281794\n",
      "epoch = 619 train_loss : 1.246875 , test loss : 1.280651\n",
      "epoch = 620 train_loss : 1.245403 , test loss : 1.280020\n",
      "epoch = 621 train_loss : 1.243992 , test loss : 1.279063\n",
      "epoch = 622 train_loss : 1.242681 , test loss : 1.278396\n",
      "epoch = 623 train_loss : 1.241286 , test loss : 1.276602\n",
      "epoch = 624 train_loss : 1.239854 , test loss : 1.275982\n",
      "epoch = 625 train_loss : 1.238523 , test loss : 1.275030\n",
      "epoch = 626 train_loss : 1.237160 , test loss : 1.274246\n",
      "epoch = 627 train_loss : 1.235764 , test loss : 1.272661\n",
      "epoch = 628 train_loss : 1.234393 , test loss : 1.271732\n",
      "epoch = 629 train_loss : 1.233089 , test loss : 1.271033\n",
      "epoch = 630 train_loss : 1.231764 , test loss : 1.269929\n",
      "epoch = 631 train_loss : 1.230430 , test loss : 1.268999\n",
      "epoch = 632 train_loss : 1.229140 , test loss : 1.267698\n",
      "epoch = 633 train_loss : 1.227828 , test loss : 1.266826\n",
      "epoch = 634 train_loss : 1.226573 , test loss : 1.266463\n",
      "epoch = 635 train_loss : 1.225318 , test loss : 1.264898\n",
      "epoch = 636 train_loss : 1.223903 , test loss : 1.264064\n",
      "epoch = 637 train_loss : 1.222661 , test loss : 1.262989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 638 train_loss : 1.221384 , test loss : 1.261850\n",
      "epoch = 639 train_loss : 1.220076 , test loss : 1.261024\n",
      "epoch = 640 train_loss : 1.218817 , test loss : 1.260170\n",
      "epoch = 641 train_loss : 1.217507 , test loss : 1.259464\n",
      "epoch = 642 train_loss : 1.216244 , test loss : 1.258235\n",
      "epoch = 643 train_loss : 1.215004 , test loss : 1.257424\n",
      "epoch = 644 train_loss : 1.213740 , test loss : 1.256473\n",
      "epoch = 645 train_loss : 1.212441 , test loss : 1.255513\n",
      "epoch = 646 train_loss : 1.211198 , test loss : 1.254777\n",
      "epoch = 647 train_loss : 1.209972 , test loss : 1.254187\n",
      "epoch = 648 train_loss : 1.208848 , test loss : 1.252957\n",
      "epoch = 649 train_loss : 1.207484 , test loss : 1.252157\n",
      "epoch = 650 train_loss : 1.206210 , test loss : 1.251277\n",
      "epoch = 651 train_loss : 1.204960 , test loss : 1.250453\n",
      "epoch = 652 train_loss : 1.203723 , test loss : 1.249461\n",
      "epoch = 653 train_loss : 1.202522 , test loss : 1.248681\n",
      "epoch = 654 train_loss : 1.201253 , test loss : 1.247724\n",
      "epoch = 655 train_loss : 1.200085 , test loss : 1.246382\n",
      "epoch = 656 train_loss : 1.198835 , test loss : 1.245837\n",
      "epoch = 657 train_loss : 1.197621 , test loss : 1.244828\n",
      "epoch = 658 train_loss : 1.196374 , test loss : 1.244148\n",
      "epoch = 659 train_loss : 1.195208 , test loss : 1.243226\n",
      "epoch = 660 train_loss : 1.194013 , test loss : 1.242875\n",
      "epoch = 661 train_loss : 1.192792 , test loss : 1.242090\n",
      "epoch = 662 train_loss : 1.191606 , test loss : 1.240627\n",
      "epoch = 663 train_loss : 1.190426 , test loss : 1.239730\n",
      "epoch = 664 train_loss : 1.189224 , test loss : 1.239411\n",
      "epoch = 665 train_loss : 1.188021 , test loss : 1.238330\n",
      "epoch = 666 train_loss : 1.186871 , test loss : 1.237694\n",
      "epoch = 667 train_loss : 1.185718 , test loss : 1.236896\n",
      "epoch = 668 train_loss : 1.184620 , test loss : 1.236210\n",
      "epoch = 669 train_loss : 1.183375 , test loss : 1.234476\n",
      "epoch = 670 train_loss : 1.182237 , test loss : 1.234293\n",
      "epoch = 671 train_loss : 1.181035 , test loss : 1.233623\n",
      "epoch = 672 train_loss : 1.180036 , test loss : 1.232323\n",
      "epoch = 674 train_loss : 1.177624 , test loss : 1.231452\n",
      "epoch = 675 train_loss : 1.176506 , test loss : 1.230454\n",
      "epoch = 676 train_loss : 1.175376 , test loss : 1.229481\n",
      "epoch = 677 train_loss : 1.174276 , test loss : 1.228845\n",
      "epoch = 678 train_loss : 1.173162 , test loss : 1.228176\n",
      "epoch = 679 train_loss : 1.172095 , test loss : 1.227320\n",
      "epoch = 680 train_loss : 1.171012 , test loss : 1.226998\n",
      "epoch = 681 train_loss : 1.169899 , test loss : 1.225575\n",
      "epoch = 682 train_loss : 1.168812 , test loss : 1.225108\n",
      "epoch = 683 train_loss : 1.167759 , test loss : 1.224172\n",
      "epoch = 685 train_loss : 1.165601 , test loss : 1.222376\n",
      "epoch = 686 train_loss : 1.164516 , test loss : 1.221854\n",
      "epoch = 687 train_loss : 1.163462 , test loss : 1.221389\n",
      "epoch = 688 train_loss : 1.162447 , test loss : 1.221172\n",
      "epoch = 689 train_loss : 1.161389 , test loss : 1.220022\n",
      "epoch = 690 train_loss : 1.160318 , test loss : 1.219438\n",
      "epoch = 691 train_loss : 1.159272 , test loss : 1.218609\n",
      "epoch = 692 train_loss : 1.158194 , test loss : 1.218103\n",
      "epoch = 693 train_loss : 1.157187 , test loss : 1.217200\n",
      "epoch = 694 train_loss : 1.156158 , test loss : 1.216485\n",
      "epoch = 695 train_loss : 1.155109 , test loss : 1.215725\n",
      "epoch = 696 train_loss : 1.154095 , test loss : 1.215544\n",
      "epoch = 697 train_loss : 1.153085 , test loss : 1.214448\n",
      "epoch = 698 train_loss : 1.152089 , test loss : 1.213958\n",
      "epoch = 699 train_loss : 1.151018 , test loss : 1.212799\n",
      "epoch = 700 train_loss : 1.150020 , test loss : 1.212409\n",
      "epoch = 701 train_loss : 1.149012 , test loss : 1.212035\n",
      "epoch = 702 train_loss : 1.148013 , test loss : 1.211267\n",
      "epoch = 703 train_loss : 1.147000 , test loss : 1.210467\n",
      "epoch = 704 train_loss : 1.146021 , test loss : 1.209724\n",
      "epoch = 705 train_loss : 1.145051 , test loss : 1.209090\n",
      "epoch = 706 train_loss : 1.144019 , test loss : 1.208325\n",
      "epoch = 707 train_loss : 1.143044 , test loss : 1.207518\n",
      "epoch = 708 train_loss : 1.142061 , test loss : 1.206553\n",
      "epoch = 709 train_loss : 1.141058 , test loss : 1.206237\n",
      "epoch = 710 train_loss : 1.140124 , test loss : 1.205660\n",
      "epoch = 711 train_loss : 1.139151 , test loss : 1.205191\n",
      "epoch = 712 train_loss : 1.138231 , test loss : 1.204038\n",
      "epoch = 713 train_loss : 1.137209 , test loss : 1.203847\n",
      "epoch = 714 train_loss : 1.136226 , test loss : 1.202803\n",
      "epoch = 715 train_loss : 1.135320 , test loss : 1.202499\n",
      "epoch = 716 train_loss : 1.134315 , test loss : 1.201922\n",
      "epoch = 717 train_loss : 1.133337 , test loss : 1.201183\n",
      "epoch = 718 train_loss : 1.132420 , test loss : 1.200435\n",
      "epoch = 719 train_loss : 1.131555 , test loss : 1.199890\n",
      "epoch = 720 train_loss : 1.130560 , test loss : 1.199452\n",
      "epoch = 721 train_loss : 1.129635 , test loss : 1.198802\n",
      "epoch = 722 train_loss : 1.128746 , test loss : 1.197900\n",
      "epoch = 723 train_loss : 1.127786 , test loss : 1.197179\n",
      "epoch = 725 train_loss : 1.125938 , test loss : 1.196006\n",
      "epoch = 726 train_loss : 1.125047 , test loss : 1.195757\n",
      "epoch = 727 train_loss : 1.124150 , test loss : 1.194837\n",
      "epoch = 728 train_loss : 1.123271 , test loss : 1.194313\n",
      "epoch = 729 train_loss : 1.122418 , test loss : 1.194039\n",
      "epoch = 730 train_loss : 1.121456 , test loss : 1.192967\n",
      "epoch = 731 train_loss : 1.120560 , test loss : 1.192289\n",
      "epoch = 732 train_loss : 1.119656 , test loss : 1.191734\n",
      "epoch = 733 train_loss : 1.118775 , test loss : 1.191272\n",
      "epoch = 735 train_loss : 1.117151 , test loss : 1.191142\n",
      "epoch = 736 train_loss : 1.116125 , test loss : 1.189722\n",
      "epoch = 737 train_loss : 1.115243 , test loss : 1.189099\n",
      "epoch = 738 train_loss : 1.114395 , test loss : 1.188323\n",
      "epoch = 739 train_loss : 1.113518 , test loss : 1.187968\n",
      "epoch = 740 train_loss : 1.112664 , test loss : 1.187801\n",
      "epoch = 741 train_loss : 1.111786 , test loss : 1.187623\n",
      "epoch = 742 train_loss : 1.110944 , test loss : 1.186903\n",
      "epoch = 743 train_loss : 1.110023 , test loss : 1.185920\n",
      "epoch = 744 train_loss : 1.109199 , test loss : 1.185599\n",
      "epoch = 745 train_loss : 1.108357 , test loss : 1.185176\n",
      "epoch = 746 train_loss : 1.107496 , test loss : 1.184560\n",
      "epoch = 747 train_loss : 1.106630 , test loss : 1.183914\n",
      "epoch = 748 train_loss : 1.105771 , test loss : 1.183366\n",
      "epoch = 749 train_loss : 1.104960 , test loss : 1.183100\n",
      "epoch = 750 train_loss : 1.104078 , test loss : 1.182311\n",
      "epoch = 751 train_loss : 1.103239 , test loss : 1.181890\n",
      "epoch = 752 train_loss : 1.102428 , test loss : 1.181162\n",
      "epoch = 753 train_loss : 1.101586 , test loss : 1.180832\n",
      "epoch = 754 train_loss : 1.100732 , test loss : 1.180146\n",
      "epoch = 755 train_loss : 1.099917 , test loss : 1.179652\n",
      "epoch = 756 train_loss : 1.099079 , test loss : 1.178979\n",
      "epoch = 757 train_loss : 1.098273 , test loss : 1.178937\n",
      "epoch = 758 train_loss : 1.097461 , test loss : 1.178156\n",
      "epoch = 759 train_loss : 1.096633 , test loss : 1.177775\n",
      "epoch = 760 train_loss : 1.095886 , test loss : 1.177166\n",
      "epoch = 761 train_loss : 1.094992 , test loss : 1.177007\n",
      "epoch = 762 train_loss : 1.094166 , test loss : 1.176316\n",
      "epoch = 763 train_loss : 1.093336 , test loss : 1.176052\n",
      "epoch = 764 train_loss : 1.092549 , test loss : 1.175436\n",
      "epoch = 765 train_loss : 1.091739 , test loss : 1.174988\n",
      "epoch = 766 train_loss : 1.090947 , test loss : 1.173946\n",
      "epoch = 768 train_loss : 1.089353 , test loss : 1.173539\n",
      "epoch = 769 train_loss : 1.088573 , test loss : 1.173094\n",
      "epoch = 770 train_loss : 1.087735 , test loss : 1.172568\n",
      "epoch = 771 train_loss : 1.086954 , test loss : 1.171979\n",
      "epoch = 772 train_loss : 1.086220 , test loss : 1.171496\n",
      "epoch = 773 train_loss : 1.085388 , test loss : 1.171145\n",
      "epoch = 774 train_loss : 1.084627 , test loss : 1.170907\n",
      "epoch = 775 train_loss : 1.083848 , test loss : 1.170084\n",
      "epoch = 776 train_loss : 1.083071 , test loss : 1.169896\n",
      "epoch = 777 train_loss : 1.082324 , test loss : 1.169540\n",
      "epoch = 778 train_loss : 1.081582 , test loss : 1.168817\n",
      "epoch = 779 train_loss : 1.080780 , test loss : 1.168499\n",
      "epoch = 780 train_loss : 1.080012 , test loss : 1.168156\n",
      "epoch = 781 train_loss : 1.079290 , test loss : 1.167867\n",
      "epoch = 782 train_loss : 1.078593 , test loss : 1.167334\n",
      "epoch = 783 train_loss : 1.077746 , test loss : 1.166954\n",
      "epoch = 784 train_loss : 1.077014 , test loss : 1.166326\n",
      "epoch = 785 train_loss : 1.076264 , test loss : 1.166165\n",
      "epoch = 786 train_loss : 1.075567 , test loss : 1.165428\n",
      "epoch = 787 train_loss : 1.074805 , test loss : 1.165253\n",
      "epoch = 788 train_loss : 1.074067 , test loss : 1.164968\n",
      "epoch = 789 train_loss : 1.073340 , test loss : 1.164490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 790 train_loss : 1.072610 , test loss : 1.164255\n",
      "epoch = 791 train_loss : 1.071901 , test loss : 1.163530\n",
      "epoch = 792 train_loss : 1.071184 , test loss : 1.163467\n",
      "epoch = 793 train_loss : 1.070456 , test loss : 1.162644\n",
      "epoch = 794 train_loss : 1.069743 , test loss : 1.162308\n",
      "epoch = 795 train_loss : 1.069065 , test loss : 1.162266\n",
      "epoch = 796 train_loss : 1.068334 , test loss : 1.161545\n",
      "epoch = 797 train_loss : 1.067623 , test loss : 1.161015\n",
      "epoch = 798 train_loss : 1.066914 , test loss : 1.160757\n",
      "epoch = 799 train_loss : 1.066240 , test loss : 1.160654\n",
      "epoch = 800 train_loss : 1.065543 , test loss : 1.159903\n",
      "epoch = 802 train_loss : 1.064130 , test loss : 1.159380\n",
      "epoch = 804 train_loss : 1.062768 , test loss : 1.158775\n",
      "epoch = 805 train_loss : 1.062110 , test loss : 1.158583\n",
      "epoch = 806 train_loss : 1.061396 , test loss : 1.158150\n",
      "epoch = 807 train_loss : 1.060710 , test loss : 1.157547\n",
      "epoch = 808 train_loss : 1.060055 , test loss : 1.157461\n",
      "epoch = 809 train_loss : 1.059369 , test loss : 1.157209\n",
      "epoch = 810 train_loss : 1.058697 , test loss : 1.157151\n",
      "epoch = 811 train_loss : 1.058014 , test loss : 1.156398\n",
      "epoch = 812 train_loss : 1.057349 , test loss : 1.156053\n",
      "epoch = 813 train_loss : 1.056717 , test loss : 1.155937\n",
      "epoch = 814 train_loss : 1.056030 , test loss : 1.155498\n",
      "epoch = 815 train_loss : 1.055384 , test loss : 1.154756\n",
      "epoch = 817 train_loss : 1.054082 , test loss : 1.154440\n",
      "epoch = 818 train_loss : 1.053407 , test loss : 1.154283\n",
      "epoch = 819 train_loss : 1.052741 , test loss : 1.153814\n",
      "epoch = 820 train_loss : 1.052122 , test loss : 1.153422\n",
      "epoch = 821 train_loss : 1.051449 , test loss : 1.153297\n",
      "epoch = 822 train_loss : 1.050802 , test loss : 1.153243\n",
      "epoch = 823 train_loss : 1.050205 , test loss : 1.152830\n",
      "epoch = 824 train_loss : 1.049513 , test loss : 1.152674\n",
      "epoch = 825 train_loss : 1.048871 , test loss : 1.151829\n",
      "epoch = 826 train_loss : 1.048254 , test loss : 1.151531\n",
      "epoch = 827 train_loss : 1.047608 , test loss : 1.151304\n",
      "epoch = 828 train_loss : 1.046971 , test loss : 1.151227\n",
      "epoch = 829 train_loss : 1.046368 , test loss : 1.151152\n",
      "epoch = 830 train_loss : 1.045713 , test loss : 1.150596\n",
      "epoch = 831 train_loss : 1.045101 , test loss : 1.149991\n",
      "epoch = 834 train_loss : 1.043267 , test loss : 1.149362\n",
      "epoch = 835 train_loss : 1.042599 , test loss : 1.149230\n",
      "epoch = 836 train_loss : 1.042035 , test loss : 1.148955\n",
      "epoch = 837 train_loss : 1.041379 , test loss : 1.148302\n",
      "epoch = 838 train_loss : 1.040778 , test loss : 1.148224\n",
      "epoch = 839 train_loss : 1.040157 , test loss : 1.148090\n",
      "epoch = 840 train_loss : 1.039542 , test loss : 1.147178\n",
      "epoch = 842 train_loss : 1.038366 , test loss : 1.146884\n",
      "epoch = 843 train_loss : 1.037731 , test loss : 1.146552\n",
      "epoch = 844 train_loss : 1.037142 , test loss : 1.146402\n",
      "epoch = 845 train_loss : 1.036540 , test loss : 1.146015\n",
      "epoch = 847 train_loss : 1.035345 , test loss : 1.145751\n",
      "epoch = 848 train_loss : 1.034785 , test loss : 1.145457\n",
      "epoch = 849 train_loss : 1.034220 , test loss : 1.145063\n",
      "epoch = 850 train_loss : 1.033569 , test loss : 1.144795\n",
      "epoch = 852 train_loss : 1.032421 , test loss : 1.144321\n",
      "epoch = 855 train_loss : 1.030677 , test loss : 1.143785\n",
      "epoch = 856 train_loss : 1.030071 , test loss : 1.143495\n",
      "epoch = 857 train_loss : 1.029479 , test loss : 1.143338\n",
      "epoch = 858 train_loss : 1.028911 , test loss : 1.142965\n",
      "epoch = 859 train_loss : 1.028338 , test loss : 1.142752\n",
      "epoch = 860 train_loss : 1.027834 , test loss : 1.142547\n",
      "epoch = 862 train_loss : 1.026615 , test loss : 1.142175\n",
      "epoch = 864 train_loss : 1.025463 , test loss : 1.141669\n",
      "epoch = 865 train_loss : 1.024897 , test loss : 1.141201\n",
      "epoch = 866 train_loss : 1.024371 , test loss : 1.141142\n",
      "epoch = 867 train_loss : 1.023786 , test loss : 1.140996\n",
      "epoch = 868 train_loss : 1.023184 , test loss : 1.140741\n",
      "epoch = 869 train_loss : 1.022630 , test loss : 1.140247\n",
      "epoch = 870 train_loss : 1.022044 , test loss : 1.140006\n",
      "epoch = 872 train_loss : 1.020935 , test loss : 1.139688\n",
      "epoch = 875 train_loss : 1.019273 , test loss : 1.139607\n",
      "epoch = 876 train_loss : 1.018712 , test loss : 1.139068\n",
      "epoch = 877 train_loss : 1.018170 , test loss : 1.138845\n",
      "epoch = 878 train_loss : 1.017613 , test loss : 1.138634\n",
      "epoch = 879 train_loss : 1.017074 , test loss : 1.138347\n",
      "epoch = 880 train_loss : 1.016516 , test loss : 1.138121\n",
      "epoch = 881 train_loss : 1.015974 , test loss : 1.137908\n",
      "epoch = 882 train_loss : 1.015431 , test loss : 1.137857\n",
      "epoch = 883 train_loss : 1.014893 , test loss : 1.137692\n",
      "epoch = 884 train_loss : 1.014343 , test loss : 1.137367\n",
      "epoch = 885 train_loss : 1.013792 , test loss : 1.137257\n",
      "epoch = 886 train_loss : 1.013255 , test loss : 1.136803\n",
      "epoch = 887 train_loss : 1.012759 , test loss : 1.136467\n",
      "epoch = 889 train_loss : 1.011638 , test loss : 1.136255\n",
      "epoch = 890 train_loss : 1.011131 , test loss : 1.136068\n",
      "epoch = 891 train_loss : 1.010582 , test loss : 1.135753\n",
      "epoch = 892 train_loss : 1.010043 , test loss : 1.135633\n",
      "epoch = 894 train_loss : 1.008975 , test loss : 1.134922\n",
      "epoch = 895 train_loss : 1.008486 , test loss : 1.134777\n",
      "epoch = 897 train_loss : 1.007408 , test loss : 1.134563\n",
      "epoch = 898 train_loss : 1.006884 , test loss : 1.134424\n",
      "epoch = 899 train_loss : 1.006368 , test loss : 1.134172\n",
      "epoch = 900 train_loss : 1.005841 , test loss : 1.133924\n",
      "epoch = 901 train_loss : 1.005308 , test loss : 1.133721\n",
      "epoch = 903 train_loss : 1.004300 , test loss : 1.133220\n",
      "epoch = 904 train_loss : 1.003756 , test loss : 1.133034\n",
      "epoch = 905 train_loss : 1.003255 , test loss : 1.132879\n",
      "epoch = 907 train_loss : 1.002261 , test loss : 1.132661\n",
      "epoch = 908 train_loss : 1.001696 , test loss : 1.132558\n",
      "epoch = 909 train_loss : 1.001182 , test loss : 1.132307\n",
      "epoch = 910 train_loss : 1.000652 , test loss : 1.132071\n",
      "epoch = 911 train_loss : 1.000238 , test loss : 1.131783\n",
      "epoch = 912 train_loss : 0.999701 , test loss : 1.131537\n",
      "epoch = 913 train_loss : 0.999144 , test loss : 1.131335\n",
      "epoch = 914 train_loss : 0.998684 , test loss : 1.131333\n",
      "epoch = 915 train_loss : 0.998173 , test loss : 1.130894\n",
      "epoch = 918 train_loss : 0.996654 , test loss : 1.130611\n",
      "epoch = 919 train_loss : 0.996194 , test loss : 1.130306\n",
      "epoch = 922 train_loss : 0.994655 , test loss : 1.129981\n",
      "epoch = 923 train_loss : 0.994143 , test loss : 1.129937\n",
      "epoch = 924 train_loss : 0.993675 , test loss : 1.129488\n",
      "epoch = 925 train_loss : 0.993158 , test loss : 1.129317\n",
      "epoch = 926 train_loss : 0.992736 , test loss : 1.129167\n",
      "epoch = 927 train_loss : 0.992207 , test loss : 1.128866\n",
      "epoch = 928 train_loss : 0.991692 , test loss : 1.128782\n",
      "epoch = 929 train_loss : 0.991185 , test loss : 1.128674\n",
      "epoch = 930 train_loss : 0.990718 , test loss : 1.128500\n",
      "epoch = 931 train_loss : 0.990222 , test loss : 1.128395\n",
      "epoch = 932 train_loss : 0.989722 , test loss : 1.128253\n",
      "epoch = 935 train_loss : 0.988278 , test loss : 1.127837\n",
      "epoch = 937 train_loss : 0.987308 , test loss : 1.127672\n",
      "epoch = 938 train_loss : 0.986809 , test loss : 1.127263\n",
      "epoch = 939 train_loss : 0.986337 , test loss : 1.127055\n",
      "epoch = 940 train_loss : 0.985888 , test loss : 1.126807\n",
      "epoch = 941 train_loss : 0.985394 , test loss : 1.126645\n",
      "epoch = 942 train_loss : 0.984953 , test loss : 1.126508\n",
      "epoch = 945 train_loss : 0.983528 , test loss : 1.125922\n",
      "epoch = 948 train_loss : 0.982115 , test loss : 1.125544\n",
      "epoch = 950 train_loss : 0.981229 , test loss : 1.125114\n",
      "epoch = 954 train_loss : 0.979370 , test loss : 1.124800\n",
      "epoch = 955 train_loss : 0.978913 , test loss : 1.124637\n",
      "epoch = 956 train_loss : 0.978459 , test loss : 1.124592\n",
      "epoch = 957 train_loss : 0.977976 , test loss : 1.124471\n",
      "epoch = 958 train_loss : 0.977553 , test loss : 1.124160\n",
      "epoch = 960 train_loss : 0.976608 , test loss : 1.124126\n",
      "epoch = 961 train_loss : 0.976244 , test loss : 1.123660\n",
      "epoch = 963 train_loss : 0.975256 , test loss : 1.123141\n",
      "epoch = 966 train_loss : 0.973882 , test loss : 1.122989\n",
      "epoch = 969 train_loss : 0.972512 , test loss : 1.122578\n",
      "epoch = 971 train_loss : 0.971627 , test loss : 1.122287\n",
      "epoch = 973 train_loss : 0.970730 , test loss : 1.122050\n",
      "epoch = 974 train_loss : 0.970321 , test loss : 1.122032\n",
      "epoch = 976 train_loss : 0.969432 , test loss : 1.121815\n",
      "epoch = 977 train_loss : 0.968997 , test loss : 1.121680\n",
      "epoch = 978 train_loss : 0.968622 , test loss : 1.121381\n",
      "epoch = 980 train_loss : 0.967648 , test loss : 1.121235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 981 train_loss : 0.967203 , test loss : 1.120965\n",
      "epoch = 982 train_loss : 0.966796 , test loss : 1.120963\n",
      "epoch = 984 train_loss : 0.965884 , test loss : 1.120802\n",
      "epoch = 985 train_loss : 0.965469 , test loss : 1.120333\n",
      "epoch = 987 train_loss : 0.964709 , test loss : 1.120144\n",
      "epoch = 990 train_loss : 0.963285 , test loss : 1.120101\n",
      "epoch = 991 train_loss : 0.962890 , test loss : 1.120069\n",
      "epoch = 992 train_loss : 0.962410 , test loss : 1.119708\n",
      "epoch = 995 train_loss : 0.961148 , test loss : 1.119435\n",
      "epoch = 996 train_loss : 0.960751 , test loss : 1.119022\n",
      "epoch = 997 train_loss : 0.960282 , test loss : 1.118928\n",
      "epoch = 998 train_loss : 0.959886 , test loss : 1.118873\n",
      "epoch = 1001 train_loss : 0.958606 , test loss : 1.118667\n",
      "epoch = 1002 train_loss : 0.958176 , test loss : 1.118312\n",
      "epoch = 1004 train_loss : 0.957334 , test loss : 1.118306\n",
      "epoch = 1005 train_loss : 0.956990 , test loss : 1.118228\n",
      "epoch = 1006 train_loss : 0.956605 , test loss : 1.118218\n",
      "epoch = 1007 train_loss : 0.956097 , test loss : 1.117790\n",
      "epoch = 1010 train_loss : 0.954866 , test loss : 1.117517\n",
      "epoch = 1011 train_loss : 0.954465 , test loss : 1.117452\n",
      "epoch = 1012 train_loss : 0.954083 , test loss : 1.117444\n",
      "epoch = 1014 train_loss : 0.953248 , test loss : 1.117323\n",
      "epoch = 1015 train_loss : 0.952857 , test loss : 1.117116\n",
      "epoch = 1018 train_loss : 0.951616 , test loss : 1.116588\n",
      "epoch = 1021 train_loss : 0.950405 , test loss : 1.116470\n",
      "epoch = 1022 train_loss : 0.950017 , test loss : 1.116335\n",
      "epoch = 1025 train_loss : 0.948808 , test loss : 1.116226\n",
      "epoch = 1026 train_loss : 0.948419 , test loss : 1.115884\n",
      "epoch = 1030 train_loss : 0.946840 , test loss : 1.115543\n",
      "epoch = 1033 train_loss : 0.945646 , test loss : 1.115361\n",
      "epoch = 1036 train_loss : 0.944552 , test loss : 1.114956\n",
      "epoch = 1040 train_loss : 0.942913 , test loss : 1.114824\n",
      "epoch = 1041 train_loss : 0.942534 , test loss : 1.114753\n",
      "epoch = 1042 train_loss : 0.942152 , test loss : 1.114704\n",
      "epoch = 1043 train_loss : 0.941761 , test loss : 1.114460\n",
      "epoch = 1046 train_loss : 0.940618 , test loss : 1.114371\n",
      "epoch = 1050 train_loss : 0.939080 , test loss : 1.113837\n",
      "epoch = 1051 train_loss : 0.938730 , test loss : 1.113698\n",
      "epoch = 1055 train_loss : 0.937270 , test loss : 1.113460\n",
      "epoch = 1058 train_loss : 0.936046 , test loss : 1.113402\n",
      "epoch = 1059 train_loss : 0.935667 , test loss : 1.113167\n",
      "epoch = 1062 train_loss : 0.934528 , test loss : 1.113152\n",
      "epoch = 1063 train_loss : 0.934192 , test loss : 1.113075\n",
      "epoch = 1064 train_loss : 0.933782 , test loss : 1.113010\n",
      "epoch = 1067 train_loss : 0.932677 , test loss : 1.112838\n",
      "epoch = 1068 train_loss : 0.932308 , test loss : 1.112349\n",
      "epoch = 1076 train_loss : 0.929335 , test loss : 1.112202\n",
      "epoch = 1079 train_loss : 0.928226 , test loss : 1.111930\n",
      "epoch = 1084 train_loss : 0.926422 , test loss : 1.111801\n",
      "epoch = 1085 train_loss : 0.926033 , test loss : 1.111740\n",
      "epoch = 1087 train_loss : 0.925312 , test loss : 1.111676\n",
      "epoch = 1088 train_loss : 0.924945 , test loss : 1.111474\n",
      "epoch = 1090 train_loss : 0.924214 , test loss : 1.111344\n",
      "epoch = 1091 train_loss : 0.923850 , test loss : 1.111281\n",
      "epoch = 1094 train_loss : 0.922762 , test loss : 1.110909\n",
      "epoch = 1097 train_loss : 0.921680 , test loss : 1.110835\n",
      "epoch = 1099 train_loss : 0.920961 , test loss : 1.110660\n",
      "epoch = 1102 train_loss : 0.919897 , test loss : 1.110455\n",
      "epoch = 1104 train_loss : 0.919175 , test loss : 1.110434\n",
      "epoch = 1108 train_loss : 0.917760 , test loss : 1.110315\n",
      "epoch = 1109 train_loss : 0.917416 , test loss : 1.110213\n",
      "epoch = 1110 train_loss : 0.917081 , test loss : 1.110058\n",
      "epoch = 1113 train_loss : 0.916055 , test loss : 1.110033\n",
      "epoch = 1115 train_loss : 0.915300 , test loss : 1.109873\n",
      "epoch = 1117 train_loss : 0.914604 , test loss : 1.109680\n",
      "epoch = 1121 train_loss : 0.913250 , test loss : 1.109443\n",
      "epoch = 1126 train_loss : 0.911541 , test loss : 1.109396\n",
      "epoch = 1127 train_loss : 0.911195 , test loss : 1.109224\n",
      "epoch = 1130 train_loss : 0.910181 , test loss : 1.109219\n",
      "epoch = 1136 train_loss : 0.908140 , test loss : 1.109040\n",
      "epoch = 1138 train_loss : 0.907475 , test loss : 1.108865\n",
      "epoch = 1139 train_loss : 0.907140 , test loss : 1.108645\n",
      "epoch = 1145 train_loss : 0.905158 , test loss : 1.108588\n",
      "epoch = 1149 train_loss : 0.903832 , test loss : 1.108464\n",
      "epoch = 1150 train_loss : 0.903503 , test loss : 1.108438\n",
      "epoch = 1151 train_loss : 0.903238 , test loss : 1.108155\n",
      "epoch = 1156 train_loss : 0.901556 , test loss : 1.108108\n",
      "epoch = 1159 train_loss : 0.900590 , test loss : 1.108013\n",
      "epoch = 1160 train_loss : 0.900276 , test loss : 1.107712\n",
      "epoch = 1168 train_loss : 0.897662 , test loss : 1.107667\n",
      "epoch = 1170 train_loss : 0.897090 , test loss : 1.107549\n",
      "epoch = 1175 train_loss : 0.895454 , test loss : 1.107415\n",
      "epoch = 1179 train_loss : 0.894174 , test loss : 1.107283\n",
      "epoch = 1180 train_loss : 0.893897 , test loss : 1.107122\n",
      "epoch = 1184 train_loss : 0.892639 , test loss : 1.107024\n",
      "epoch = 1187 train_loss : 0.891668 , test loss : 1.106989\n",
      "epoch = 1189 train_loss : 0.891103 , test loss : 1.106937\n",
      "epoch = 1192 train_loss : 0.890101 , test loss : 1.106877\n",
      "epoch = 1196 train_loss : 0.888886 , test loss : 1.106757\n",
      "epoch = 1205 train_loss : 0.886169 , test loss : 1.106584\n",
      "epoch = 1210 train_loss : 0.884626 , test loss : 1.106451\n",
      "epoch = 1211 train_loss : 0.884374 , test loss : 1.106214\n",
      "epoch = 1221 train_loss : 0.881328 , test loss : 1.106168\n",
      "epoch = 1223 train_loss : 0.880695 , test loss : 1.106166\n",
      "epoch = 1230 train_loss : 0.878670 , test loss : 1.106098\n",
      "epoch = 1233 train_loss : 0.877718 , test loss : 1.105897\n",
      "epoch = 1234 train_loss : 0.877425 , test loss : 1.105842\n",
      "epoch = 1236 train_loss : 0.876828 , test loss : 1.105842\n",
      "epoch = 1238 train_loss : 0.876221 , test loss : 1.105801\n",
      "epoch = 1239 train_loss : 0.875984 , test loss : 1.105580\n",
      "epoch = 1249 train_loss : 0.872998 , test loss : 1.105458\n",
      "epoch = 1259 train_loss : 0.870154 , test loss : 1.105205\n",
      "epoch = 1275 train_loss : 0.865631 , test loss : 1.105112\n",
      "epoch = 1295 train_loss : 0.860144 , test loss : 1.104890\n",
      "epoch = 1332 train_loss : 0.850269 , test loss : 1.104849\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.850269,test loss : 1.104849\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 42.517197 , test loss : 43.583248\n",
      "epoch = 2 train_loss : 41.918373 , test loss : 42.957302\n",
      "epoch = 3 train_loss : 41.322437 , test loss : 42.334595\n",
      "epoch = 4 train_loss : 40.731060 , test loss : 41.716660\n",
      "epoch = 5 train_loss : 40.146027 , test loss : 41.105198\n",
      "epoch = 6 train_loss : 39.565636 , test loss : 40.499062\n",
      "epoch = 7 train_loss : 38.985844 , test loss : 39.893276\n",
      "epoch = 8 train_loss : 38.415924 , test loss : 39.298119\n",
      "epoch = 9 train_loss : 37.847580 , test loss : 38.704231\n",
      "epoch = 10 train_loss : 37.285263 , test loss : 38.116989\n",
      "epoch = 11 train_loss : 36.722023 , test loss : 37.528706\n",
      "epoch = 12 train_loss : 36.165871 , test loss : 36.947681\n",
      "epoch = 13 train_loss : 35.614277 , test loss : 36.372375\n",
      "epoch = 14 train_loss : 35.064957 , test loss : 35.799072\n",
      "epoch = 15 train_loss : 34.517399 , test loss : 35.227268\n",
      "epoch = 16 train_loss : 33.972061 , test loss : 34.657764\n",
      "epoch = 17 train_loss : 33.430916 , test loss : 34.093430\n",
      "epoch = 18 train_loss : 32.890991 , test loss : 33.530930\n",
      "epoch = 19 train_loss : 32.353710 , test loss : 32.970676\n",
      "epoch = 20 train_loss : 31.822788 , test loss : 32.418003\n",
      "epoch = 21 train_loss : 31.292597 , test loss : 31.866829\n",
      "epoch = 22 train_loss : 30.764872 , test loss : 31.318768\n",
      "epoch = 23 train_loss : 30.236895 , test loss : 30.770109\n",
      "epoch = 24 train_loss : 29.711828 , test loss : 30.224440\n",
      "epoch = 25 train_loss : 29.188255 , test loss : 29.681099\n",
      "epoch = 26 train_loss : 28.672220 , test loss : 29.145899\n",
      "epoch = 27 train_loss : 28.157164 , test loss : 28.611771\n",
      "epoch = 28 train_loss : 27.646748 , test loss : 28.082716\n",
      "epoch = 29 train_loss : 27.135712 , test loss : 27.552788\n",
      "epoch = 30 train_loss : 26.633030 , test loss : 27.032251\n",
      "epoch = 31 train_loss : 26.132772 , test loss : 26.514296\n",
      "epoch = 32 train_loss : 25.633904 , test loss : 25.997629\n",
      "epoch = 33 train_loss : 25.143078 , test loss : 25.489639\n",
      "epoch = 34 train_loss : 24.651829 , test loss : 24.980913\n",
      "epoch = 35 train_loss : 24.166788 , test loss : 24.479156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 36 train_loss : 23.687300 , test loss : 23.983219\n",
      "epoch = 37 train_loss : 23.208488 , test loss : 23.487188\n",
      "epoch = 38 train_loss : 22.734512 , test loss : 22.996632\n",
      "epoch = 39 train_loss : 22.269112 , test loss : 22.515602\n",
      "epoch = 40 train_loss : 21.802860 , test loss : 22.033504\n",
      "epoch = 41 train_loss : 21.343399 , test loss : 21.559364\n",
      "epoch = 42 train_loss : 20.891546 , test loss : 21.093628\n",
      "epoch = 43 train_loss : 20.442053 , test loss : 20.630253\n",
      "epoch = 44 train_loss : 19.997564 , test loss : 20.172083\n",
      "epoch = 45 train_loss : 19.559687 , test loss : 19.721222\n",
      "epoch = 46 train_loss : 19.127649 , test loss : 19.276466\n",
      "epoch = 47 train_loss : 18.699280 , test loss : 18.835943\n",
      "epoch = 48 train_loss : 18.277311 , test loss : 18.402599\n",
      "epoch = 49 train_loss : 17.862732 , test loss : 17.977196\n",
      "epoch = 50 train_loss : 17.451763 , test loss : 17.555872\n",
      "epoch = 51 train_loss : 17.050873 , test loss : 17.145424\n",
      "epoch = 52 train_loss : 16.652857 , test loss : 16.738047\n",
      "epoch = 53 train_loss : 16.262274 , test loss : 16.338816\n",
      "epoch = 54 train_loss : 15.881105 , test loss : 15.949045\n",
      "epoch = 55 train_loss : 15.502856 , test loss : 15.562451\n",
      "epoch = 56 train_loss : 15.132122 , test loss : 15.184024\n",
      "epoch = 57 train_loss : 14.769096 , test loss : 14.813726\n",
      "epoch = 58 train_loss : 14.413178 , test loss : 14.450961\n",
      "epoch = 59 train_loss : 14.060813 , test loss : 14.091846\n",
      "epoch = 60 train_loss : 13.716221 , test loss : 13.740919\n",
      "epoch = 61 train_loss : 13.379495 , test loss : 13.398883\n",
      "epoch = 62 train_loss : 13.051582 , test loss : 13.066357\n",
      "epoch = 63 train_loss : 12.728324 , test loss : 12.738641\n",
      "epoch = 64 train_loss : 12.411965 , test loss : 12.417574\n",
      "epoch = 65 train_loss : 12.102834 , test loss : 12.104285\n",
      "epoch = 66 train_loss : 11.803320 , test loss : 11.801373\n",
      "epoch = 67 train_loss : 11.507922 , test loss : 11.502390\n",
      "epoch = 68 train_loss : 11.220008 , test loss : 11.211836\n",
      "epoch = 69 train_loss : 10.939486 , test loss : 10.929375\n",
      "epoch = 70 train_loss : 10.663502 , test loss : 10.651361\n",
      "epoch = 71 train_loss : 10.396313 , test loss : 10.382748\n",
      "epoch = 72 train_loss : 10.134470 , test loss : 10.119768\n",
      "epoch = 73 train_loss : 9.879612 , test loss : 9.864499\n",
      "epoch = 74 train_loss : 9.631245 , test loss : 9.615758\n",
      "epoch = 75 train_loss : 9.390488 , test loss : 9.375002\n",
      "epoch = 76 train_loss : 9.154954 , test loss : 9.139650\n",
      "epoch = 77 train_loss : 8.926726 , test loss : 8.911920\n",
      "epoch = 78 train_loss : 8.702201 , test loss : 8.687778\n",
      "epoch = 79 train_loss : 8.487615 , test loss : 8.474046\n",
      "epoch = 80 train_loss : 8.276748 , test loss : 8.264338\n",
      "epoch = 81 train_loss : 8.072483 , test loss : 8.061337\n",
      "epoch = 82 train_loss : 7.874008 , test loss : 7.863987\n",
      "epoch = 83 train_loss : 7.680967 , test loss : 7.672392\n",
      "epoch = 84 train_loss : 7.493723 , test loss : 7.486766\n",
      "epoch = 85 train_loss : 7.312449 , test loss : 7.307345\n",
      "epoch = 86 train_loss : 7.137691 , test loss : 7.134328\n",
      "epoch = 87 train_loss : 6.967111 , test loss : 6.965569\n",
      "epoch = 88 train_loss : 6.800706 , test loss : 6.801259\n",
      "epoch = 89 train_loss : 6.641848 , test loss : 6.644455\n",
      "epoch = 90 train_loss : 6.485984 , test loss : 6.490596\n",
      "epoch = 91 train_loss : 6.335214 , test loss : 6.341905\n",
      "epoch = 92 train_loss : 6.190596 , test loss : 6.199459\n",
      "epoch = 93 train_loss : 6.050974 , test loss : 6.061862\n",
      "epoch = 94 train_loss : 5.914727 , test loss : 5.927740\n",
      "epoch = 95 train_loss : 5.782166 , test loss : 5.797268\n",
      "epoch = 96 train_loss : 5.656287 , test loss : 5.673377\n",
      "epoch = 97 train_loss : 5.533355 , test loss : 5.552676\n",
      "epoch = 98 train_loss : 5.415182 , test loss : 5.436621\n",
      "epoch = 99 train_loss : 5.300425 , test loss : 5.324172\n",
      "epoch = 100 train_loss : 5.190495 , test loss : 5.216492\n",
      "epoch = 101 train_loss : 5.083818 , test loss : 5.112025\n",
      "epoch = 102 train_loss : 4.982346 , test loss : 5.012749\n",
      "epoch = 103 train_loss : 4.883783 , test loss : 4.916393\n",
      "epoch = 104 train_loss : 4.788183 , test loss : 4.822882\n",
      "epoch = 105 train_loss : 4.696877 , test loss : 4.733872\n",
      "epoch = 106 train_loss : 4.608596 , test loss : 4.647626\n",
      "epoch = 107 train_loss : 4.522539 , test loss : 4.563593\n",
      "epoch = 108 train_loss : 4.440287 , test loss : 4.483345\n",
      "epoch = 109 train_loss : 4.361519 , test loss : 4.406272\n",
      "epoch = 110 train_loss : 4.285698 , test loss : 4.332425\n",
      "epoch = 111 train_loss : 4.213462 , test loss : 4.261937\n",
      "epoch = 112 train_loss : 4.144009 , test loss : 4.194134\n",
      "epoch = 113 train_loss : 4.076998 , test loss : 4.128796\n",
      "epoch = 114 train_loss : 4.013097 , test loss : 4.066533\n",
      "epoch = 115 train_loss : 3.951312 , test loss : 4.006267\n",
      "epoch = 116 train_loss : 3.892554 , test loss : 3.948981\n",
      "epoch = 117 train_loss : 3.836036 , test loss : 3.893915\n",
      "epoch = 118 train_loss : 3.781752 , test loss : 3.840992\n",
      "epoch = 119 train_loss : 3.729263 , test loss : 3.789811\n",
      "epoch = 120 train_loss : 3.679535 , test loss : 3.741380\n",
      "epoch = 121 train_loss : 3.631595 , test loss : 3.694604\n",
      "epoch = 122 train_loss : 3.586277 , test loss : 3.650332\n",
      "epoch = 123 train_loss : 3.542579 , test loss : 3.607739\n",
      "epoch = 124 train_loss : 3.500604 , test loss : 3.566645\n",
      "epoch = 125 train_loss : 3.461253 , test loss : 3.528043\n",
      "epoch = 126 train_loss : 3.422669 , test loss : 3.490449\n",
      "epoch = 127 train_loss : 3.386386 , test loss : 3.454946\n",
      "epoch = 128 train_loss : 3.352041 , test loss : 3.421395\n",
      "epoch = 129 train_loss : 3.318292 , test loss : 3.388283\n",
      "epoch = 130 train_loss : 3.286805 , test loss : 3.357494\n",
      "epoch = 131 train_loss : 3.256791 , test loss : 3.328074\n",
      "epoch = 132 train_loss : 3.227870 , test loss : 3.299552\n",
      "epoch = 133 train_loss : 3.200416 , test loss : 3.272662\n",
      "epoch = 134 train_loss : 3.174061 , test loss : 3.246866\n",
      "epoch = 135 train_loss : 3.149420 , test loss : 3.222436\n",
      "epoch = 136 train_loss : 3.124996 , test loss : 3.198334\n",
      "epoch = 137 train_loss : 3.102392 , test loss : 3.176128\n",
      "epoch = 138 train_loss : 3.080180 , test loss : 3.154142\n",
      "epoch = 139 train_loss : 3.059346 , test loss : 3.133830\n",
      "epoch = 140 train_loss : 3.039599 , test loss : 3.114254\n",
      "epoch = 141 train_loss : 3.020608 , test loss : 3.095579\n",
      "epoch = 142 train_loss : 3.002547 , test loss : 3.077559\n",
      "epoch = 143 train_loss : 2.985050 , test loss : 3.060156\n",
      "epoch = 144 train_loss : 2.968481 , test loss : 3.043688\n",
      "epoch = 145 train_loss : 2.952722 , test loss : 3.028170\n",
      "epoch = 146 train_loss : 2.937360 , test loss : 3.012917\n",
      "epoch = 147 train_loss : 2.922992 , test loss : 2.998673\n",
      "epoch = 148 train_loss : 2.908926 , test loss : 2.984560\n",
      "epoch = 149 train_loss : 2.895691 , test loss : 2.971470\n",
      "epoch = 150 train_loss : 2.883286 , test loss : 2.958868\n",
      "epoch = 151 train_loss : 2.871027 , test loss : 2.946617\n",
      "epoch = 152 train_loss : 2.859089 , test loss : 2.934693\n",
      "epoch = 153 train_loss : 2.847751 , test loss : 2.923310\n",
      "epoch = 154 train_loss : 2.836837 , test loss : 2.912375\n",
      "epoch = 155 train_loss : 2.826571 , test loss : 2.902079\n",
      "epoch = 156 train_loss : 2.816407 , test loss : 2.891763\n",
      "epoch = 157 train_loss : 2.806517 , test loss : 2.881678\n",
      "epoch = 158 train_loss : 2.797228 , test loss : 2.872358\n",
      "epoch = 159 train_loss : 2.787974 , test loss : 2.863003\n",
      "epoch = 160 train_loss : 2.779369 , test loss : 2.854314\n",
      "epoch = 161 train_loss : 2.770694 , test loss : 2.845435\n",
      "epoch = 162 train_loss : 2.762706 , test loss : 2.837420\n",
      "epoch = 163 train_loss : 2.754607 , test loss : 2.829056\n",
      "epoch = 164 train_loss : 2.746616 , test loss : 2.820779\n",
      "epoch = 165 train_loss : 2.738945 , test loss : 2.812996\n",
      "epoch = 166 train_loss : 2.731769 , test loss : 2.805592\n",
      "epoch = 167 train_loss : 2.724535 , test loss : 2.798337\n",
      "epoch = 168 train_loss : 2.717573 , test loss : 2.791076\n",
      "epoch = 169 train_loss : 2.710525 , test loss : 2.783700\n",
      "epoch = 170 train_loss : 2.703735 , test loss : 2.776796\n",
      "epoch = 171 train_loss : 2.697279 , test loss : 2.769982\n",
      "epoch = 172 train_loss : 2.690806 , test loss : 2.763387\n",
      "epoch = 173 train_loss : 2.684494 , test loss : 2.756970\n",
      "epoch = 174 train_loss : 2.678261 , test loss : 2.750500\n",
      "epoch = 175 train_loss : 2.671957 , test loss : 2.743964\n",
      "epoch = 176 train_loss : 2.665877 , test loss : 2.737576\n",
      "epoch = 177 train_loss : 2.659889 , test loss : 2.731183\n",
      "epoch = 178 train_loss : 2.653727 , test loss : 2.724985\n",
      "epoch = 179 train_loss : 2.647958 , test loss : 2.718910\n",
      "epoch = 180 train_loss : 2.642089 , test loss : 2.712728\n",
      "epoch = 181 train_loss : 2.636387 , test loss : 2.706870\n",
      "epoch = 182 train_loss : 2.630519 , test loss : 2.700612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 183 train_loss : 2.624757 , test loss : 2.694525\n",
      "epoch = 184 train_loss : 2.618929 , test loss : 2.688560\n",
      "epoch = 185 train_loss : 2.613245 , test loss : 2.682631\n",
      "epoch = 186 train_loss : 2.607358 , test loss : 2.676453\n",
      "epoch = 187 train_loss : 2.601712 , test loss : 2.670799\n",
      "epoch = 188 train_loss : 2.596051 , test loss : 2.664717\n",
      "epoch = 189 train_loss : 2.590515 , test loss : 2.658975\n",
      "epoch = 190 train_loss : 2.584903 , test loss : 2.653303\n",
      "epoch = 191 train_loss : 2.579309 , test loss : 2.647474\n",
      "epoch = 192 train_loss : 2.573643 , test loss : 2.641431\n",
      "epoch = 193 train_loss : 2.568172 , test loss : 2.635861\n",
      "epoch = 194 train_loss : 2.562754 , test loss : 2.629964\n",
      "epoch = 195 train_loss : 2.557138 , test loss : 2.624194\n",
      "epoch = 196 train_loss : 2.551675 , test loss : 2.618576\n",
      "epoch = 197 train_loss : 2.546344 , test loss : 2.612956\n",
      "epoch = 198 train_loss : 2.541023 , test loss : 2.607372\n",
      "epoch = 199 train_loss : 2.535778 , test loss : 2.601672\n",
      "epoch = 200 train_loss : 2.530426 , test loss : 2.595777\n",
      "epoch = 201 train_loss : 2.525093 , test loss : 2.590570\n",
      "epoch = 202 train_loss : 2.519922 , test loss : 2.585201\n",
      "epoch = 203 train_loss : 2.514663 , test loss : 2.579672\n",
      "epoch = 204 train_loss : 2.509493 , test loss : 2.574351\n",
      "epoch = 205 train_loss : 2.504406 , test loss : 2.568853\n",
      "epoch = 206 train_loss : 2.499179 , test loss : 2.563496\n",
      "epoch = 207 train_loss : 2.494024 , test loss : 2.557928\n",
      "epoch = 208 train_loss : 2.488861 , test loss : 2.552597\n",
      "epoch = 209 train_loss : 2.483718 , test loss : 2.547276\n",
      "epoch = 210 train_loss : 2.478698 , test loss : 2.542297\n",
      "epoch = 211 train_loss : 2.473688 , test loss : 2.537070\n",
      "epoch = 212 train_loss : 2.468624 , test loss : 2.531698\n",
      "epoch = 213 train_loss : 2.463583 , test loss : 2.526484\n",
      "epoch = 214 train_loss : 2.458722 , test loss : 2.521301\n",
      "epoch = 215 train_loss : 2.453876 , test loss : 2.516177\n",
      "epoch = 216 train_loss : 2.448814 , test loss : 2.510940\n",
      "epoch = 217 train_loss : 2.443965 , test loss : 2.505972\n",
      "epoch = 218 train_loss : 2.439076 , test loss : 2.500782\n",
      "epoch = 219 train_loss : 2.434231 , test loss : 2.495697\n",
      "epoch = 220 train_loss : 2.429353 , test loss : 2.490606\n",
      "epoch = 221 train_loss : 2.424544 , test loss : 2.485696\n",
      "epoch = 222 train_loss : 2.419776 , test loss : 2.480795\n",
      "epoch = 223 train_loss : 2.414994 , test loss : 2.475712\n",
      "epoch = 224 train_loss : 2.410356 , test loss : 2.470823\n",
      "epoch = 225 train_loss : 2.405616 , test loss : 2.465845\n",
      "epoch = 226 train_loss : 2.400846 , test loss : 2.460818\n",
      "epoch = 227 train_loss : 2.396178 , test loss : 2.456082\n",
      "epoch = 228 train_loss : 2.391474 , test loss : 2.451263\n",
      "epoch = 229 train_loss : 2.386790 , test loss : 2.446386\n",
      "epoch = 230 train_loss : 2.382099 , test loss : 2.441604\n",
      "epoch = 231 train_loss : 2.377521 , test loss : 2.436856\n",
      "epoch = 232 train_loss : 2.372812 , test loss : 2.432198\n",
      "epoch = 233 train_loss : 2.368211 , test loss : 2.427307\n",
      "epoch = 234 train_loss : 2.363611 , test loss : 2.422683\n",
      "epoch = 235 train_loss : 2.358971 , test loss : 2.417927\n",
      "epoch = 236 train_loss : 2.354271 , test loss : 2.412945\n",
      "epoch = 237 train_loss : 2.349722 , test loss : 2.408506\n",
      "epoch = 238 train_loss : 2.345145 , test loss : 2.403701\n",
      "epoch = 239 train_loss : 2.340566 , test loss : 2.398877\n",
      "epoch = 240 train_loss : 2.335959 , test loss : 2.394365\n",
      "epoch = 241 train_loss : 2.331355 , test loss : 2.389304\n",
      "epoch = 242 train_loss : 2.326666 , test loss : 2.384357\n",
      "epoch = 243 train_loss : 2.322123 , test loss : 2.379898\n",
      "epoch = 244 train_loss : 2.317507 , test loss : 2.375111\n",
      "epoch = 245 train_loss : 2.312946 , test loss : 2.370484\n",
      "epoch = 246 train_loss : 2.308264 , test loss : 2.365673\n",
      "epoch = 247 train_loss : 2.303757 , test loss : 2.360876\n",
      "epoch = 248 train_loss : 2.299026 , test loss : 2.356099\n",
      "epoch = 249 train_loss : 2.294486 , test loss : 2.351343\n",
      "epoch = 250 train_loss : 2.289874 , test loss : 2.346800\n",
      "epoch = 251 train_loss : 2.285342 , test loss : 2.342323\n",
      "epoch = 252 train_loss : 2.280839 , test loss : 2.337719\n",
      "epoch = 253 train_loss : 2.276176 , test loss : 2.333002\n",
      "epoch = 254 train_loss : 2.271718 , test loss : 2.328464\n",
      "epoch = 255 train_loss : 2.267159 , test loss : 2.323848\n",
      "epoch = 256 train_loss : 2.262683 , test loss : 2.319371\n",
      "epoch = 257 train_loss : 2.258224 , test loss : 2.314810\n",
      "epoch = 258 train_loss : 2.253762 , test loss : 2.310265\n",
      "epoch = 259 train_loss : 2.249202 , test loss : 2.305748\n",
      "epoch = 260 train_loss : 2.244746 , test loss : 2.301224\n",
      "epoch = 261 train_loss : 2.240269 , test loss : 2.296745\n",
      "epoch = 262 train_loss : 2.235790 , test loss : 2.292424\n",
      "epoch = 263 train_loss : 2.231313 , test loss : 2.287762\n",
      "epoch = 264 train_loss : 2.226743 , test loss : 2.283316\n",
      "epoch = 265 train_loss : 2.222239 , test loss : 2.278706\n",
      "epoch = 266 train_loss : 2.217679 , test loss : 2.274087\n",
      "epoch = 267 train_loss : 2.213257 , test loss : 2.269508\n",
      "epoch = 268 train_loss : 2.208771 , test loss : 2.265338\n",
      "epoch = 269 train_loss : 2.204353 , test loss : 2.260473\n",
      "epoch = 270 train_loss : 2.199835 , test loss : 2.256344\n",
      "epoch = 271 train_loss : 2.195427 , test loss : 2.251740\n",
      "epoch = 272 train_loss : 2.191019 , test loss : 2.247349\n",
      "epoch = 273 train_loss : 2.186562 , test loss : 2.242709\n",
      "epoch = 274 train_loss : 2.182147 , test loss : 2.238423\n",
      "epoch = 275 train_loss : 2.177752 , test loss : 2.234151\n",
      "epoch = 276 train_loss : 2.173344 , test loss : 2.229565\n",
      "epoch = 277 train_loss : 2.168975 , test loss : 2.225393\n",
      "epoch = 278 train_loss : 2.164623 , test loss : 2.221030\n",
      "epoch = 279 train_loss : 2.160225 , test loss : 2.216435\n",
      "epoch = 280 train_loss : 2.155710 , test loss : 2.211893\n",
      "epoch = 281 train_loss : 2.151356 , test loss : 2.207638\n",
      "epoch = 282 train_loss : 2.146982 , test loss : 2.203147\n",
      "epoch = 283 train_loss : 2.142689 , test loss : 2.199201\n",
      "epoch = 284 train_loss : 2.138211 , test loss : 2.194532\n",
      "epoch = 285 train_loss : 2.133922 , test loss : 2.190190\n",
      "epoch = 286 train_loss : 2.129519 , test loss : 2.185974\n",
      "epoch = 287 train_loss : 2.125138 , test loss : 2.181776\n",
      "epoch = 288 train_loss : 2.120809 , test loss : 2.177460\n",
      "epoch = 289 train_loss : 2.116445 , test loss : 2.173010\n",
      "epoch = 290 train_loss : 2.112137 , test loss : 2.168687\n",
      "epoch = 291 train_loss : 2.107698 , test loss : 2.164223\n",
      "epoch = 292 train_loss : 2.103314 , test loss : 2.159917\n",
      "epoch = 293 train_loss : 2.099072 , test loss : 2.156071\n",
      "epoch = 294 train_loss : 2.094706 , test loss : 2.151731\n",
      "epoch = 295 train_loss : 2.090432 , test loss : 2.147707\n",
      "epoch = 296 train_loss : 2.086210 , test loss : 2.143476\n",
      "epoch = 297 train_loss : 2.081933 , test loss : 2.138981\n",
      "epoch = 298 train_loss : 2.077662 , test loss : 2.134862\n",
      "epoch = 299 train_loss : 2.073431 , test loss : 2.131094\n",
      "epoch = 300 train_loss : 2.069202 , test loss : 2.126953\n",
      "epoch = 301 train_loss : 2.064916 , test loss : 2.122704\n",
      "epoch = 302 train_loss : 2.060764 , test loss : 2.118411\n",
      "epoch = 303 train_loss : 2.056420 , test loss : 2.114403\n",
      "epoch = 304 train_loss : 2.052206 , test loss : 2.110580\n",
      "epoch = 305 train_loss : 2.048006 , test loss : 2.106498\n",
      "epoch = 306 train_loss : 2.043898 , test loss : 2.102333\n",
      "epoch = 307 train_loss : 2.039644 , test loss : 2.098349\n",
      "epoch = 308 train_loss : 2.035555 , test loss : 2.094388\n",
      "epoch = 309 train_loss : 2.031441 , test loss : 2.090219\n",
      "epoch = 310 train_loss : 2.027343 , test loss : 2.086252\n",
      "epoch = 311 train_loss : 2.023226 , test loss : 2.082255\n",
      "epoch = 312 train_loss : 2.019121 , test loss : 2.078334\n",
      "epoch = 313 train_loss : 2.015021 , test loss : 2.074497\n",
      "epoch = 314 train_loss : 2.010976 , test loss : 2.070477\n",
      "epoch = 315 train_loss : 2.006860 , test loss : 2.066587\n",
      "epoch = 316 train_loss : 2.002850 , test loss : 2.062325\n",
      "epoch = 317 train_loss : 1.998757 , test loss : 2.058374\n",
      "epoch = 318 train_loss : 1.994677 , test loss : 2.054297\n",
      "epoch = 319 train_loss : 1.990574 , test loss : 2.050316\n",
      "epoch = 320 train_loss : 1.986562 , test loss : 2.046473\n",
      "epoch = 321 train_loss : 1.982532 , test loss : 2.042448\n",
      "epoch = 322 train_loss : 1.978564 , test loss : 2.038658\n",
      "epoch = 323 train_loss : 1.974519 , test loss : 2.034842\n",
      "epoch = 324 train_loss : 1.970546 , test loss : 2.030886\n",
      "epoch = 325 train_loss : 1.966516 , test loss : 2.027081\n",
      "epoch = 326 train_loss : 1.962580 , test loss : 2.022938\n",
      "epoch = 327 train_loss : 1.958594 , test loss : 2.019309\n",
      "epoch = 328 train_loss : 1.954595 , test loss : 2.015456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 329 train_loss : 1.950700 , test loss : 2.011638\n",
      "epoch = 330 train_loss : 1.946684 , test loss : 2.008070\n",
      "epoch = 331 train_loss : 1.942741 , test loss : 2.004046\n",
      "epoch = 332 train_loss : 1.938805 , test loss : 2.000070\n",
      "epoch = 333 train_loss : 1.934864 , test loss : 1.996279\n",
      "epoch = 334 train_loss : 1.931011 , test loss : 1.992756\n",
      "epoch = 335 train_loss : 1.927066 , test loss : 1.988691\n",
      "epoch = 336 train_loss : 1.923145 , test loss : 1.984997\n",
      "epoch = 337 train_loss : 1.919356 , test loss : 1.981463\n",
      "epoch = 338 train_loss : 1.915528 , test loss : 1.977639\n",
      "epoch = 339 train_loss : 1.911655 , test loss : 1.973817\n",
      "epoch = 340 train_loss : 1.907824 , test loss : 1.969983\n",
      "epoch = 341 train_loss : 1.904052 , test loss : 1.966317\n",
      "epoch = 342 train_loss : 1.900231 , test loss : 1.962646\n",
      "epoch = 343 train_loss : 1.896409 , test loss : 1.958845\n",
      "epoch = 344 train_loss : 1.892657 , test loss : 1.955205\n",
      "epoch = 345 train_loss : 1.888930 , test loss : 1.951722\n",
      "epoch = 346 train_loss : 1.885168 , test loss : 1.947912\n",
      "epoch = 347 train_loss : 1.881288 , test loss : 1.944398\n",
      "epoch = 348 train_loss : 1.877577 , test loss : 1.940522\n",
      "epoch = 349 train_loss : 1.873842 , test loss : 1.936850\n",
      "epoch = 350 train_loss : 1.870061 , test loss : 1.933061\n",
      "epoch = 351 train_loss : 1.866340 , test loss : 1.929734\n",
      "epoch = 352 train_loss : 1.862634 , test loss : 1.926117\n",
      "epoch = 353 train_loss : 1.858887 , test loss : 1.922454\n",
      "epoch = 354 train_loss : 1.855218 , test loss : 1.919228\n",
      "epoch = 355 train_loss : 1.851495 , test loss : 1.915237\n",
      "epoch = 356 train_loss : 1.847844 , test loss : 1.911795\n",
      "epoch = 357 train_loss : 1.844175 , test loss : 1.908492\n",
      "epoch = 358 train_loss : 1.840509 , test loss : 1.904743\n",
      "epoch = 359 train_loss : 1.836778 , test loss : 1.901161\n",
      "epoch = 360 train_loss : 1.833197 , test loss : 1.898060\n",
      "epoch = 361 train_loss : 1.829496 , test loss : 1.893916\n",
      "epoch = 362 train_loss : 1.825859 , test loss : 1.890581\n",
      "epoch = 363 train_loss : 1.822324 , test loss : 1.887479\n",
      "epoch = 364 train_loss : 1.818784 , test loss : 1.883410\n",
      "epoch = 365 train_loss : 1.815173 , test loss : 1.880080\n",
      "epoch = 366 train_loss : 1.811607 , test loss : 1.876623\n",
      "epoch = 367 train_loss : 1.808036 , test loss : 1.873168\n",
      "epoch = 368 train_loss : 1.804500 , test loss : 1.869544\n",
      "epoch = 369 train_loss : 1.800977 , test loss : 1.866244\n",
      "epoch = 370 train_loss : 1.797432 , test loss : 1.862699\n",
      "epoch = 371 train_loss : 1.793868 , test loss : 1.859240\n",
      "epoch = 372 train_loss : 1.790450 , test loss : 1.856020\n",
      "epoch = 373 train_loss : 1.786914 , test loss : 1.852655\n",
      "epoch = 374 train_loss : 1.783465 , test loss : 1.849040\n",
      "epoch = 375 train_loss : 1.779981 , test loss : 1.845816\n",
      "epoch = 376 train_loss : 1.776514 , test loss : 1.842445\n",
      "epoch = 377 train_loss : 1.773089 , test loss : 1.838927\n",
      "epoch = 378 train_loss : 1.769621 , test loss : 1.835302\n",
      "epoch = 379 train_loss : 1.766142 , test loss : 1.832204\n",
      "epoch = 380 train_loss : 1.762727 , test loss : 1.828379\n",
      "epoch = 381 train_loss : 1.759318 , test loss : 1.825192\n",
      "epoch = 382 train_loss : 1.756007 , test loss : 1.822334\n",
      "epoch = 383 train_loss : 1.752563 , test loss : 1.818480\n",
      "epoch = 384 train_loss : 1.749151 , test loss : 1.815330\n",
      "epoch = 385 train_loss : 1.745734 , test loss : 1.811817\n",
      "epoch = 386 train_loss : 1.742417 , test loss : 1.808786\n",
      "epoch = 387 train_loss : 1.738997 , test loss : 1.805331\n",
      "epoch = 388 train_loss : 1.735684 , test loss : 1.802146\n",
      "epoch = 389 train_loss : 1.732399 , test loss : 1.798880\n",
      "epoch = 390 train_loss : 1.729053 , test loss : 1.795554\n",
      "epoch = 391 train_loss : 1.725687 , test loss : 1.792145\n",
      "epoch = 392 train_loss : 1.722332 , test loss : 1.788962\n",
      "epoch = 393 train_loss : 1.719072 , test loss : 1.785686\n",
      "epoch = 394 train_loss : 1.715747 , test loss : 1.782101\n",
      "epoch = 395 train_loss : 1.712420 , test loss : 1.779279\n",
      "epoch = 396 train_loss : 1.709128 , test loss : 1.775559\n",
      "epoch = 397 train_loss : 1.705807 , test loss : 1.772223\n",
      "epoch = 398 train_loss : 1.702492 , test loss : 1.769254\n",
      "epoch = 399 train_loss : 1.699255 , test loss : 1.766267\n",
      "epoch = 400 train_loss : 1.695977 , test loss : 1.762844\n",
      "epoch = 401 train_loss : 1.692840 , test loss : 1.759668\n",
      "epoch = 402 train_loss : 1.689614 , test loss : 1.756061\n",
      "epoch = 403 train_loss : 1.686423 , test loss : 1.752874\n",
      "epoch = 404 train_loss : 1.683252 , test loss : 1.749707\n",
      "epoch = 405 train_loss : 1.679982 , test loss : 1.746658\n",
      "epoch = 406 train_loss : 1.676790 , test loss : 1.743541\n",
      "epoch = 407 train_loss : 1.673642 , test loss : 1.740365\n",
      "epoch = 408 train_loss : 1.670560 , test loss : 1.737395\n",
      "epoch = 409 train_loss : 1.667391 , test loss : 1.734477\n",
      "epoch = 410 train_loss : 1.664305 , test loss : 1.731033\n",
      "epoch = 411 train_loss : 1.661129 , test loss : 1.727971\n",
      "epoch = 412 train_loss : 1.658059 , test loss : 1.724861\n",
      "epoch = 413 train_loss : 1.654907 , test loss : 1.721990\n",
      "epoch = 414 train_loss : 1.651835 , test loss : 1.718843\n",
      "epoch = 415 train_loss : 1.648737 , test loss : 1.715575\n",
      "epoch = 416 train_loss : 1.645707 , test loss : 1.712768\n",
      "epoch = 417 train_loss : 1.642613 , test loss : 1.709382\n",
      "epoch = 418 train_loss : 1.639536 , test loss : 1.706538\n",
      "epoch = 419 train_loss : 1.636617 , test loss : 1.703522\n",
      "epoch = 420 train_loss : 1.633586 , test loss : 1.700970\n",
      "epoch = 421 train_loss : 1.630510 , test loss : 1.697790\n",
      "epoch = 422 train_loss : 1.627494 , test loss : 1.694805\n",
      "epoch = 423 train_loss : 1.624519 , test loss : 1.691844\n",
      "epoch = 424 train_loss : 1.621541 , test loss : 1.688655\n",
      "epoch = 425 train_loss : 1.618610 , test loss : 1.686022\n",
      "epoch = 426 train_loss : 1.615706 , test loss : 1.682854\n",
      "epoch = 427 train_loss : 1.612821 , test loss : 1.679999\n",
      "epoch = 428 train_loss : 1.609844 , test loss : 1.676929\n",
      "epoch = 429 train_loss : 1.606909 , test loss : 1.674066\n",
      "epoch = 430 train_loss : 1.603992 , test loss : 1.671225\n",
      "epoch = 431 train_loss : 1.601189 , test loss : 1.668770\n",
      "epoch = 432 train_loss : 1.598286 , test loss : 1.665810\n",
      "epoch = 433 train_loss : 1.595399 , test loss : 1.662794\n",
      "epoch = 434 train_loss : 1.592542 , test loss : 1.659940\n",
      "epoch = 435 train_loss : 1.589704 , test loss : 1.657233\n",
      "epoch = 436 train_loss : 1.586846 , test loss : 1.654488\n",
      "epoch = 437 train_loss : 1.583991 , test loss : 1.651440\n",
      "epoch = 438 train_loss : 1.581232 , test loss : 1.648895\n",
      "epoch = 439 train_loss : 1.578430 , test loss : 1.645908\n",
      "epoch = 440 train_loss : 1.575590 , test loss : 1.643203\n",
      "epoch = 441 train_loss : 1.572810 , test loss : 1.639917\n",
      "epoch = 442 train_loss : 1.570054 , test loss : 1.637277\n",
      "epoch = 443 train_loss : 1.567280 , test loss : 1.634970\n",
      "epoch = 444 train_loss : 1.564537 , test loss : 1.631751\n",
      "epoch = 445 train_loss : 1.561803 , test loss : 1.629111\n",
      "epoch = 446 train_loss : 1.559044 , test loss : 1.626507\n",
      "epoch = 447 train_loss : 1.556333 , test loss : 1.623964\n",
      "epoch = 448 train_loss : 1.553591 , test loss : 1.621391\n",
      "epoch = 449 train_loss : 1.550923 , test loss : 1.618527\n",
      "epoch = 450 train_loss : 1.548325 , test loss : 1.616186\n",
      "epoch = 451 train_loss : 1.545567 , test loss : 1.612989\n",
      "epoch = 452 train_loss : 1.542823 , test loss : 1.610398\n",
      "epoch = 453 train_loss : 1.540167 , test loss : 1.607888\n",
      "epoch = 454 train_loss : 1.537504 , test loss : 1.605010\n",
      "epoch = 455 train_loss : 1.534886 , test loss : 1.602497\n",
      "epoch = 456 train_loss : 1.532227 , test loss : 1.599866\n",
      "epoch = 457 train_loss : 1.529613 , test loss : 1.597481\n",
      "epoch = 458 train_loss : 1.526978 , test loss : 1.595094\n",
      "epoch = 459 train_loss : 1.524313 , test loss : 1.592232\n",
      "epoch = 460 train_loss : 1.521754 , test loss : 1.589529\n",
      "epoch = 461 train_loss : 1.519167 , test loss : 1.587032\n",
      "epoch = 462 train_loss : 1.516546 , test loss : 1.584413\n",
      "epoch = 463 train_loss : 1.513942 , test loss : 1.581988\n",
      "epoch = 464 train_loss : 1.511359 , test loss : 1.579252\n",
      "epoch = 465 train_loss : 1.508883 , test loss : 1.576703\n",
      "epoch = 466 train_loss : 1.506288 , test loss : 1.574225\n",
      "epoch = 467 train_loss : 1.503737 , test loss : 1.571318\n",
      "epoch = 468 train_loss : 1.501221 , test loss : 1.568879\n",
      "epoch = 469 train_loss : 1.498675 , test loss : 1.566581\n",
      "epoch = 470 train_loss : 1.496262 , test loss : 1.563985\n",
      "epoch = 471 train_loss : 1.493734 , test loss : 1.561877\n",
      "epoch = 472 train_loss : 1.491235 , test loss : 1.558694\n",
      "epoch = 473 train_loss : 1.488802 , test loss : 1.556515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 474 train_loss : 1.486330 , test loss : 1.554081\n",
      "epoch = 475 train_loss : 1.483842 , test loss : 1.551686\n",
      "epoch = 476 train_loss : 1.481445 , test loss : 1.549436\n",
      "epoch = 477 train_loss : 1.479028 , test loss : 1.547154\n",
      "epoch = 478 train_loss : 1.476609 , test loss : 1.544677\n",
      "epoch = 479 train_loss : 1.474207 , test loss : 1.542561\n",
      "epoch = 480 train_loss : 1.471819 , test loss : 1.540072\n",
      "epoch = 481 train_loss : 1.469431 , test loss : 1.537646\n",
      "epoch = 482 train_loss : 1.467041 , test loss : 1.535487\n",
      "epoch = 483 train_loss : 1.464682 , test loss : 1.532468\n",
      "epoch = 484 train_loss : 1.462325 , test loss : 1.530573\n",
      "epoch = 485 train_loss : 1.459933 , test loss : 1.528078\n",
      "epoch = 486 train_loss : 1.457605 , test loss : 1.525902\n",
      "epoch = 487 train_loss : 1.455308 , test loss : 1.523737\n",
      "epoch = 488 train_loss : 1.453003 , test loss : 1.521598\n",
      "epoch = 489 train_loss : 1.450634 , test loss : 1.519234\n",
      "epoch = 490 train_loss : 1.448357 , test loss : 1.516640\n",
      "epoch = 491 train_loss : 1.446082 , test loss : 1.514388\n",
      "epoch = 492 train_loss : 1.443831 , test loss : 1.512473\n",
      "epoch = 493 train_loss : 1.441562 , test loss : 1.510295\n",
      "epoch = 494 train_loss : 1.439345 , test loss : 1.508068\n",
      "epoch = 495 train_loss : 1.437011 , test loss : 1.505834\n",
      "epoch = 496 train_loss : 1.434801 , test loss : 1.503301\n",
      "epoch = 497 train_loss : 1.432555 , test loss : 1.501286\n",
      "epoch = 498 train_loss : 1.430317 , test loss : 1.498963\n",
      "epoch = 499 train_loss : 1.428085 , test loss : 1.496819\n",
      "epoch = 500 train_loss : 1.425883 , test loss : 1.495316\n",
      "epoch = 501 train_loss : 1.423705 , test loss : 1.492841\n",
      "epoch = 502 train_loss : 1.421575 , test loss : 1.490345\n",
      "epoch = 503 train_loss : 1.419339 , test loss : 1.488666\n",
      "epoch = 504 train_loss : 1.417231 , test loss : 1.485859\n",
      "epoch = 505 train_loss : 1.415093 , test loss : 1.483760\n",
      "epoch = 506 train_loss : 1.412949 , test loss : 1.482235\n",
      "epoch = 507 train_loss : 1.410894 , test loss : 1.480556\n",
      "epoch = 508 train_loss : 1.408742 , test loss : 1.477831\n",
      "epoch = 509 train_loss : 1.406564 , test loss : 1.475869\n",
      "epoch = 510 train_loss : 1.404569 , test loss : 1.473538\n",
      "epoch = 511 train_loss : 1.402396 , test loss : 1.471573\n",
      "epoch = 512 train_loss : 1.400304 , test loss : 1.469632\n",
      "epoch = 513 train_loss : 1.398309 , test loss : 1.468099\n",
      "epoch = 514 train_loss : 1.396235 , test loss : 1.465578\n",
      "epoch = 515 train_loss : 1.394138 , test loss : 1.463560\n",
      "epoch = 516 train_loss : 1.392150 , test loss : 1.461781\n",
      "epoch = 517 train_loss : 1.390125 , test loss : 1.459928\n",
      "epoch = 518 train_loss : 1.388085 , test loss : 1.457535\n",
      "epoch = 519 train_loss : 1.386066 , test loss : 1.455634\n",
      "epoch = 520 train_loss : 1.384086 , test loss : 1.454011\n",
      "epoch = 521 train_loss : 1.382113 , test loss : 1.451577\n",
      "epoch = 522 train_loss : 1.380108 , test loss : 1.449823\n",
      "epoch = 523 train_loss : 1.378137 , test loss : 1.448017\n",
      "epoch = 524 train_loss : 1.376140 , test loss : 1.446141\n",
      "epoch = 525 train_loss : 1.374223 , test loss : 1.444231\n",
      "epoch = 526 train_loss : 1.372309 , test loss : 1.442244\n",
      "epoch = 527 train_loss : 1.370348 , test loss : 1.440714\n",
      "epoch = 528 train_loss : 1.368461 , test loss : 1.438748\n",
      "epoch = 529 train_loss : 1.366547 , test loss : 1.436887\n",
      "epoch = 530 train_loss : 1.364611 , test loss : 1.434876\n",
      "epoch = 531 train_loss : 1.362739 , test loss : 1.432847\n",
      "epoch = 532 train_loss : 1.360860 , test loss : 1.430834\n",
      "epoch = 533 train_loss : 1.358948 , test loss : 1.429337\n",
      "epoch = 534 train_loss : 1.357083 , test loss : 1.427372\n",
      "epoch = 535 train_loss : 1.355211 , test loss : 1.425569\n",
      "epoch = 536 train_loss : 1.353374 , test loss : 1.423401\n",
      "epoch = 537 train_loss : 1.351601 , test loss : 1.421875\n",
      "epoch = 538 train_loss : 1.349752 , test loss : 1.420146\n",
      "epoch = 539 train_loss : 1.347940 , test loss : 1.417942\n",
      "epoch = 540 train_loss : 1.346106 , test loss : 1.416491\n",
      "epoch = 541 train_loss : 1.344296 , test loss : 1.414786\n",
      "epoch = 542 train_loss : 1.342591 , test loss : 1.413316\n",
      "epoch = 543 train_loss : 1.340747 , test loss : 1.411438\n",
      "epoch = 544 train_loss : 1.338998 , test loss : 1.410043\n",
      "epoch = 545 train_loss : 1.337190 , test loss : 1.408260\n",
      "epoch = 546 train_loss : 1.335469 , test loss : 1.406012\n",
      "epoch = 547 train_loss : 1.333740 , test loss : 1.404551\n",
      "epoch = 548 train_loss : 1.331995 , test loss : 1.402579\n",
      "epoch = 549 train_loss : 1.330248 , test loss : 1.401499\n",
      "epoch = 550 train_loss : 1.328546 , test loss : 1.399847\n",
      "epoch = 551 train_loss : 1.326824 , test loss : 1.398088\n",
      "epoch = 552 train_loss : 1.325088 , test loss : 1.396430\n",
      "epoch = 553 train_loss : 1.323412 , test loss : 1.394550\n",
      "epoch = 554 train_loss : 1.321709 , test loss : 1.392249\n",
      "epoch = 555 train_loss : 1.320054 , test loss : 1.391172\n",
      "epoch = 556 train_loss : 1.318319 , test loss : 1.389733\n",
      "epoch = 557 train_loss : 1.316690 , test loss : 1.387557\n",
      "epoch = 558 train_loss : 1.315006 , test loss : 1.386252\n",
      "epoch = 559 train_loss : 1.313366 , test loss : 1.384790\n",
      "epoch = 560 train_loss : 1.311718 , test loss : 1.383206\n",
      "epoch = 561 train_loss : 1.310149 , test loss : 1.380970\n",
      "epoch = 562 train_loss : 1.308506 , test loss : 1.379669\n",
      "epoch = 563 train_loss : 1.306897 , test loss : 1.377846\n",
      "epoch = 564 train_loss : 1.305259 , test loss : 1.376319\n",
      "epoch = 565 train_loss : 1.303685 , test loss : 1.374940\n",
      "epoch = 566 train_loss : 1.302076 , test loss : 1.373937\n",
      "epoch = 567 train_loss : 1.300451 , test loss : 1.372030\n",
      "epoch = 568 train_loss : 1.298900 , test loss : 1.370496\n",
      "epoch = 569 train_loss : 1.297340 , test loss : 1.368426\n",
      "epoch = 570 train_loss : 1.295821 , test loss : 1.366698\n",
      "epoch = 571 train_loss : 1.294180 , test loss : 1.365953\n",
      "epoch = 572 train_loss : 1.292625 , test loss : 1.364635\n",
      "epoch = 573 train_loss : 1.291093 , test loss : 1.363359\n",
      "epoch = 574 train_loss : 1.289529 , test loss : 1.361508\n",
      "epoch = 575 train_loss : 1.288032 , test loss : 1.359855\n",
      "epoch = 576 train_loss : 1.286513 , test loss : 1.358401\n",
      "epoch = 577 train_loss : 1.284966 , test loss : 1.356829\n",
      "epoch = 578 train_loss : 1.283459 , test loss : 1.355739\n",
      "epoch = 579 train_loss : 1.281965 , test loss : 1.353824\n",
      "epoch = 580 train_loss : 1.280466 , test loss : 1.353258\n",
      "epoch = 581 train_loss : 1.278973 , test loss : 1.351307\n",
      "epoch = 582 train_loss : 1.277496 , test loss : 1.349694\n",
      "epoch = 583 train_loss : 1.276000 , test loss : 1.348463\n",
      "epoch = 584 train_loss : 1.274504 , test loss : 1.346978\n",
      "epoch = 585 train_loss : 1.273095 , test loss : 1.345662\n",
      "epoch = 586 train_loss : 1.271627 , test loss : 1.344603\n",
      "epoch = 587 train_loss : 1.270185 , test loss : 1.342686\n",
      "epoch = 588 train_loss : 1.268808 , test loss : 1.341370\n",
      "epoch = 589 train_loss : 1.267319 , test loss : 1.340084\n",
      "epoch = 590 train_loss : 1.265889 , test loss : 1.338800\n",
      "epoch = 591 train_loss : 1.264454 , test loss : 1.337481\n",
      "epoch = 592 train_loss : 1.263080 , test loss : 1.336384\n",
      "epoch = 593 train_loss : 1.261669 , test loss : 1.334795\n",
      "epoch = 594 train_loss : 1.260259 , test loss : 1.333990\n",
      "epoch = 595 train_loss : 1.258864 , test loss : 1.332194\n",
      "epoch = 596 train_loss : 1.257470 , test loss : 1.330798\n",
      "epoch = 597 train_loss : 1.256115 , test loss : 1.329702\n",
      "epoch = 598 train_loss : 1.254776 , test loss : 1.328091\n",
      "epoch = 599 train_loss : 1.253433 , test loss : 1.327499\n",
      "epoch = 600 train_loss : 1.252048 , test loss : 1.325700\n",
      "epoch = 601 train_loss : 1.250719 , test loss : 1.324128\n",
      "epoch = 602 train_loss : 1.249365 , test loss : 1.322839\n",
      "epoch = 603 train_loss : 1.248018 , test loss : 1.321594\n",
      "epoch = 604 train_loss : 1.246736 , test loss : 1.320235\n",
      "epoch = 605 train_loss : 1.245439 , test loss : 1.318823\n",
      "epoch = 606 train_loss : 1.244088 , test loss : 1.318280\n",
      "epoch = 607 train_loss : 1.242779 , test loss : 1.316607\n",
      "epoch = 608 train_loss : 1.241539 , test loss : 1.316358\n",
      "epoch = 609 train_loss : 1.240184 , test loss : 1.314124\n",
      "epoch = 610 train_loss : 1.238891 , test loss : 1.313074\n",
      "epoch = 611 train_loss : 1.237617 , test loss : 1.311801\n",
      "epoch = 612 train_loss : 1.236357 , test loss : 1.310583\n",
      "epoch = 613 train_loss : 1.235041 , test loss : 1.309196\n",
      "epoch = 614 train_loss : 1.233762 , test loss : 1.308331\n",
      "epoch = 615 train_loss : 1.232533 , test loss : 1.306394\n",
      "epoch = 616 train_loss : 1.231279 , test loss : 1.305590\n",
      "epoch = 617 train_loss : 1.230060 , test loss : 1.304772\n",
      "epoch = 618 train_loss : 1.228806 , test loss : 1.303238\n",
      "epoch = 619 train_loss : 1.227623 , test loss : 1.302287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 620 train_loss : 1.226329 , test loss : 1.301100\n",
      "epoch = 621 train_loss : 1.225153 , test loss : 1.299433\n",
      "epoch = 622 train_loss : 1.223871 , test loss : 1.298149\n",
      "epoch = 623 train_loss : 1.222657 , test loss : 1.297471\n",
      "epoch = 624 train_loss : 1.221450 , test loss : 1.296130\n",
      "epoch = 625 train_loss : 1.220277 , test loss : 1.295714\n",
      "epoch = 626 train_loss : 1.219052 , test loss : 1.294603\n",
      "epoch = 627 train_loss : 1.217875 , test loss : 1.292782\n",
      "epoch = 628 train_loss : 1.216693 , test loss : 1.291658\n",
      "epoch = 629 train_loss : 1.215495 , test loss : 1.290459\n",
      "epoch = 630 train_loss : 1.214351 , test loss : 1.289419\n",
      "epoch = 631 train_loss : 1.213174 , test loss : 1.288203\n",
      "epoch = 632 train_loss : 1.212025 , test loss : 1.287504\n",
      "epoch = 633 train_loss : 1.210873 , test loss : 1.286754\n",
      "epoch = 634 train_loss : 1.209687 , test loss : 1.285103\n",
      "epoch = 635 train_loss : 1.208602 , test loss : 1.284884\n",
      "epoch = 636 train_loss : 1.207422 , test loss : 1.282794\n",
      "epoch = 637 train_loss : 1.206259 , test loss : 1.281369\n",
      "epoch = 638 train_loss : 1.205137 , test loss : 1.280731\n",
      "epoch = 639 train_loss : 1.204002 , test loss : 1.280413\n",
      "epoch = 640 train_loss : 1.202873 , test loss : 1.278575\n",
      "epoch = 641 train_loss : 1.201797 , test loss : 1.277650\n",
      "epoch = 642 train_loss : 1.200640 , test loss : 1.276778\n",
      "epoch = 643 train_loss : 1.199519 , test loss : 1.275634\n",
      "epoch = 644 train_loss : 1.198430 , test loss : 1.274117\n",
      "epoch = 645 train_loss : 1.197315 , test loss : 1.273443\n",
      "epoch = 646 train_loss : 1.196230 , test loss : 1.272386\n",
      "epoch = 647 train_loss : 1.195182 , test loss : 1.270903\n",
      "epoch = 648 train_loss : 1.194103 , test loss : 1.270221\n",
      "epoch = 649 train_loss : 1.192980 , test loss : 1.269647\n",
      "epoch = 650 train_loss : 1.191943 , test loss : 1.268146\n",
      "epoch = 651 train_loss : 1.190833 , test loss : 1.267430\n",
      "epoch = 652 train_loss : 1.189738 , test loss : 1.266338\n",
      "epoch = 653 train_loss : 1.188665 , test loss : 1.265749\n",
      "epoch = 654 train_loss : 1.187677 , test loss : 1.264667\n",
      "epoch = 655 train_loss : 1.186546 , test loss : 1.263269\n",
      "epoch = 656 train_loss : 1.185553 , test loss : 1.262148\n",
      "epoch = 657 train_loss : 1.184459 , test loss : 1.261647\n",
      "epoch = 658 train_loss : 1.183411 , test loss : 1.260871\n",
      "epoch = 659 train_loss : 1.182361 , test loss : 1.259830\n",
      "epoch = 660 train_loss : 1.181321 , test loss : 1.258988\n",
      "epoch = 661 train_loss : 1.180328 , test loss : 1.257400\n",
      "epoch = 662 train_loss : 1.179309 , test loss : 1.257220\n",
      "epoch = 663 train_loss : 1.178246 , test loss : 1.255847\n",
      "epoch = 664 train_loss : 1.177262 , test loss : 1.255220\n",
      "epoch = 665 train_loss : 1.176219 , test loss : 1.253684\n",
      "epoch = 666 train_loss : 1.175229 , test loss : 1.253043\n",
      "epoch = 667 train_loss : 1.174178 , test loss : 1.252261\n",
      "epoch = 668 train_loss : 1.173219 , test loss : 1.251387\n",
      "epoch = 669 train_loss : 1.172189 , test loss : 1.250619\n",
      "epoch = 670 train_loss : 1.171190 , test loss : 1.249556\n",
      "epoch = 671 train_loss : 1.170201 , test loss : 1.248557\n",
      "epoch = 672 train_loss : 1.169282 , test loss : 1.247988\n",
      "epoch = 673 train_loss : 1.168352 , test loss : 1.246490\n",
      "epoch = 674 train_loss : 1.167265 , test loss : 1.246116\n",
      "epoch = 675 train_loss : 1.166557 , test loss : 1.245625\n",
      "epoch = 676 train_loss : 1.165443 , test loss : 1.244108\n",
      "epoch = 677 train_loss : 1.164401 , test loss : 1.242997\n",
      "epoch = 678 train_loss : 1.163458 , test loss : 1.241761\n",
      "epoch = 679 train_loss : 1.162480 , test loss : 1.241356\n",
      "epoch = 680 train_loss : 1.161548 , test loss : 1.240699\n",
      "epoch = 681 train_loss : 1.160587 , test loss : 1.239955\n",
      "epoch = 682 train_loss : 1.159634 , test loss : 1.238960\n",
      "epoch = 683 train_loss : 1.158724 , test loss : 1.237856\n",
      "epoch = 684 train_loss : 1.157808 , test loss : 1.237471\n",
      "epoch = 685 train_loss : 1.156877 , test loss : 1.236831\n",
      "epoch = 686 train_loss : 1.155932 , test loss : 1.235871\n",
      "epoch = 687 train_loss : 1.155012 , test loss : 1.234585\n",
      "epoch = 688 train_loss : 1.154072 , test loss : 1.233656\n",
      "epoch = 689 train_loss : 1.153187 , test loss : 1.232678\n",
      "epoch = 690 train_loss : 1.152254 , test loss : 1.232363\n",
      "epoch = 691 train_loss : 1.151342 , test loss : 1.231450\n",
      "epoch = 692 train_loss : 1.150487 , test loss : 1.229880\n",
      "epoch = 694 train_loss : 1.148710 , test loss : 1.228974\n",
      "epoch = 695 train_loss : 1.147798 , test loss : 1.228288\n",
      "epoch = 696 train_loss : 1.146903 , test loss : 1.227421\n",
      "epoch = 697 train_loss : 1.146050 , test loss : 1.227172\n",
      "epoch = 698 train_loss : 1.145155 , test loss : 1.225897\n",
      "epoch = 699 train_loss : 1.144277 , test loss : 1.225552\n",
      "epoch = 700 train_loss : 1.143460 , test loss : 1.224117\n",
      "epoch = 701 train_loss : 1.142525 , test loss : 1.223658\n",
      "epoch = 702 train_loss : 1.141675 , test loss : 1.222691\n",
      "epoch = 703 train_loss : 1.140815 , test loss : 1.221732\n",
      "epoch = 704 train_loss : 1.139959 , test loss : 1.221729\n",
      "epoch = 705 train_loss : 1.139125 , test loss : 1.220250\n",
      "epoch = 706 train_loss : 1.138311 , test loss : 1.219428\n",
      "epoch = 707 train_loss : 1.137475 , test loss : 1.219000\n",
      "epoch = 708 train_loss : 1.136586 , test loss : 1.218904\n",
      "epoch = 709 train_loss : 1.135776 , test loss : 1.217607\n",
      "epoch = 710 train_loss : 1.134909 , test loss : 1.216740\n",
      "epoch = 711 train_loss : 1.134084 , test loss : 1.215794\n",
      "epoch = 712 train_loss : 1.133255 , test loss : 1.215155\n",
      "epoch = 713 train_loss : 1.132412 , test loss : 1.214379\n",
      "epoch = 714 train_loss : 1.131573 , test loss : 1.213722\n",
      "epoch = 715 train_loss : 1.130761 , test loss : 1.212671\n",
      "epoch = 716 train_loss : 1.129946 , test loss : 1.212547\n",
      "epoch = 717 train_loss : 1.129163 , test loss : 1.211821\n",
      "epoch = 718 train_loss : 1.128336 , test loss : 1.210317\n",
      "epoch = 720 train_loss : 1.126719 , test loss : 1.209370\n",
      "epoch = 721 train_loss : 1.125932 , test loss : 1.208798\n",
      "epoch = 722 train_loss : 1.125113 , test loss : 1.208325\n",
      "epoch = 723 train_loss : 1.124324 , test loss : 1.206947\n",
      "epoch = 724 train_loss : 1.123503 , test loss : 1.206629\n",
      "epoch = 725 train_loss : 1.122716 , test loss : 1.205712\n",
      "epoch = 726 train_loss : 1.121938 , test loss : 1.204907\n",
      "epoch = 727 train_loss : 1.121124 , test loss : 1.204837\n",
      "epoch = 728 train_loss : 1.120359 , test loss : 1.204106\n",
      "epoch = 729 train_loss : 1.119584 , test loss : 1.203242\n",
      "epoch = 730 train_loss : 1.118806 , test loss : 1.202478\n",
      "epoch = 731 train_loss : 1.118033 , test loss : 1.202067\n",
      "epoch = 732 train_loss : 1.117248 , test loss : 1.201050\n",
      "epoch = 733 train_loss : 1.116507 , test loss : 1.200324\n",
      "epoch = 734 train_loss : 1.115713 , test loss : 1.199722\n",
      "epoch = 735 train_loss : 1.114941 , test loss : 1.198988\n",
      "epoch = 736 train_loss : 1.114192 , test loss : 1.198359\n",
      "epoch = 737 train_loss : 1.113429 , test loss : 1.197881\n",
      "epoch = 738 train_loss : 1.112694 , test loss : 1.197198\n",
      "epoch = 739 train_loss : 1.111956 , test loss : 1.196111\n",
      "epoch = 741 train_loss : 1.110454 , test loss : 1.195556\n",
      "epoch = 742 train_loss : 1.109648 , test loss : 1.194804\n",
      "epoch = 743 train_loss : 1.108979 , test loss : 1.193665\n",
      "epoch = 744 train_loss : 1.108168 , test loss : 1.193303\n",
      "epoch = 745 train_loss : 1.107437 , test loss : 1.192494\n",
      "epoch = 746 train_loss : 1.106698 , test loss : 1.192311\n",
      "epoch = 747 train_loss : 1.105970 , test loss : 1.191500\n",
      "epoch = 748 train_loss : 1.105217 , test loss : 1.190941\n",
      "epoch = 749 train_loss : 1.104489 , test loss : 1.190360\n",
      "epoch = 750 train_loss : 1.103767 , test loss : 1.189684\n",
      "epoch = 751 train_loss : 1.103057 , test loss : 1.189122\n",
      "epoch = 752 train_loss : 1.102398 , test loss : 1.187742\n",
      "epoch = 754 train_loss : 1.100925 , test loss : 1.186989\n",
      "epoch = 755 train_loss : 1.100223 , test loss : 1.186417\n",
      "epoch = 756 train_loss : 1.099516 , test loss : 1.185466\n",
      "epoch = 758 train_loss : 1.098122 , test loss : 1.184686\n",
      "epoch = 759 train_loss : 1.097404 , test loss : 1.184326\n",
      "epoch = 760 train_loss : 1.096735 , test loss : 1.183473\n",
      "epoch = 761 train_loss : 1.096013 , test loss : 1.183080\n",
      "epoch = 762 train_loss : 1.095326 , test loss : 1.182199\n",
      "epoch = 763 train_loss : 1.094646 , test loss : 1.181928\n",
      "epoch = 764 train_loss : 1.093988 , test loss : 1.180846\n",
      "epoch = 765 train_loss : 1.093255 , test loss : 1.180630\n",
      "epoch = 766 train_loss : 1.092548 , test loss : 1.180207\n",
      "epoch = 767 train_loss : 1.091883 , test loss : 1.180050\n",
      "epoch = 768 train_loss : 1.091239 , test loss : 1.178791\n",
      "epoch = 769 train_loss : 1.090523 , test loss : 1.178250\n",
      "epoch = 770 train_loss : 1.089841 , test loss : 1.177465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 771 train_loss : 1.089182 , test loss : 1.177176\n",
      "epoch = 772 train_loss : 1.088504 , test loss : 1.176495\n",
      "epoch = 774 train_loss : 1.087211 , test loss : 1.175582\n",
      "epoch = 775 train_loss : 1.086526 , test loss : 1.175308\n",
      "epoch = 776 train_loss : 1.085869 , test loss : 1.174334\n",
      "epoch = 777 train_loss : 1.085236 , test loss : 1.174083\n",
      "epoch = 778 train_loss : 1.084600 , test loss : 1.172993\n",
      "epoch = 780 train_loss : 1.083235 , test loss : 1.172634\n",
      "epoch = 781 train_loss : 1.082607 , test loss : 1.171662\n",
      "epoch = 782 train_loss : 1.081937 , test loss : 1.170992\n",
      "epoch = 784 train_loss : 1.080672 , test loss : 1.170006\n",
      "epoch = 785 train_loss : 1.080010 , test loss : 1.169935\n",
      "epoch = 786 train_loss : 1.079404 , test loss : 1.169369\n",
      "epoch = 787 train_loss : 1.078759 , test loss : 1.168815\n",
      "epoch = 788 train_loss : 1.078109 , test loss : 1.168711\n",
      "epoch = 789 train_loss : 1.077479 , test loss : 1.167548\n",
      "epoch = 790 train_loss : 1.076847 , test loss : 1.166866\n",
      "epoch = 792 train_loss : 1.075603 , test loss : 1.166115\n",
      "epoch = 793 train_loss : 1.074974 , test loss : 1.165571\n",
      "epoch = 794 train_loss : 1.074356 , test loss : 1.165029\n",
      "epoch = 795 train_loss : 1.073734 , test loss : 1.164728\n",
      "epoch = 796 train_loss : 1.073124 , test loss : 1.163784\n",
      "epoch = 797 train_loss : 1.072511 , test loss : 1.163783\n",
      "epoch = 798 train_loss : 1.071914 , test loss : 1.163197\n",
      "epoch = 799 train_loss : 1.071315 , test loss : 1.162238\n",
      "epoch = 801 train_loss : 1.070097 , test loss : 1.161613\n",
      "epoch = 803 train_loss : 1.068881 , test loss : 1.160607\n",
      "epoch = 804 train_loss : 1.068250 , test loss : 1.160089\n",
      "epoch = 805 train_loss : 1.067659 , test loss : 1.159753\n",
      "epoch = 806 train_loss : 1.067083 , test loss : 1.159284\n",
      "epoch = 807 train_loss : 1.066463 , test loss : 1.158874\n",
      "epoch = 808 train_loss : 1.065876 , test loss : 1.158467\n",
      "epoch = 809 train_loss : 1.065258 , test loss : 1.157589\n",
      "epoch = 811 train_loss : 1.064172 , test loss : 1.156560\n",
      "epoch = 812 train_loss : 1.063519 , test loss : 1.156292\n",
      "epoch = 813 train_loss : 1.062934 , test loss : 1.156209\n",
      "epoch = 814 train_loss : 1.062392 , test loss : 1.155461\n",
      "epoch = 815 train_loss : 1.061772 , test loss : 1.155141\n",
      "epoch = 816 train_loss : 1.061201 , test loss : 1.154275\n",
      "epoch = 817 train_loss : 1.060605 , test loss : 1.154188\n",
      "epoch = 818 train_loss : 1.060050 , test loss : 1.153357\n",
      "epoch = 820 train_loss : 1.058980 , test loss : 1.152644\n",
      "epoch = 822 train_loss : 1.057783 , test loss : 1.152577\n",
      "epoch = 823 train_loss : 1.057189 , test loss : 1.151770\n",
      "epoch = 824 train_loss : 1.056624 , test loss : 1.151237\n",
      "epoch = 825 train_loss : 1.056071 , test loss : 1.150887\n",
      "epoch = 826 train_loss : 1.055544 , test loss : 1.150549\n",
      "epoch = 827 train_loss : 1.055009 , test loss : 1.149612\n",
      "epoch = 829 train_loss : 1.053863 , test loss : 1.149010\n",
      "epoch = 830 train_loss : 1.053300 , test loss : 1.148826\n",
      "epoch = 831 train_loss : 1.052762 , test loss : 1.148092\n",
      "epoch = 833 train_loss : 1.051670 , test loss : 1.147659\n",
      "epoch = 834 train_loss : 1.051140 , test loss : 1.147258\n",
      "epoch = 835 train_loss : 1.050637 , test loss : 1.146444\n",
      "epoch = 836 train_loss : 1.050047 , test loss : 1.146217\n",
      "epoch = 837 train_loss : 1.049512 , test loss : 1.145962\n",
      "epoch = 838 train_loss : 1.049003 , test loss : 1.145344\n",
      "epoch = 839 train_loss : 1.048451 , test loss : 1.145303\n",
      "epoch = 840 train_loss : 1.047922 , test loss : 1.144975\n",
      "epoch = 841 train_loss : 1.047401 , test loss : 1.144003\n",
      "epoch = 843 train_loss : 1.046367 , test loss : 1.143940\n",
      "epoch = 844 train_loss : 1.045829 , test loss : 1.143210\n",
      "epoch = 845 train_loss : 1.045361 , test loss : 1.142936\n",
      "epoch = 846 train_loss : 1.044794 , test loss : 1.142020\n",
      "epoch = 848 train_loss : 1.043786 , test loss : 1.141729\n",
      "epoch = 849 train_loss : 1.043346 , test loss : 1.141248\n",
      "epoch = 850 train_loss : 1.042743 , test loss : 1.141120\n",
      "epoch = 851 train_loss : 1.042235 , test loss : 1.140536\n",
      "epoch = 852 train_loss : 1.041725 , test loss : 1.139650\n",
      "epoch = 853 train_loss : 1.041221 , test loss : 1.139485\n",
      "epoch = 855 train_loss : 1.040258 , test loss : 1.139256\n",
      "epoch = 856 train_loss : 1.039714 , test loss : 1.138778\n",
      "epoch = 857 train_loss : 1.039209 , test loss : 1.138077\n",
      "epoch = 858 train_loss : 1.038712 , test loss : 1.137949\n",
      "epoch = 860 train_loss : 1.037745 , test loss : 1.137456\n",
      "epoch = 861 train_loss : 1.037198 , test loss : 1.135979\n",
      "epoch = 863 train_loss : 1.036203 , test loss : 1.135893\n",
      "epoch = 864 train_loss : 1.035713 , test loss : 1.135517\n",
      "epoch = 865 train_loss : 1.035233 , test loss : 1.134792\n",
      "epoch = 866 train_loss : 1.034717 , test loss : 1.134746\n",
      "epoch = 867 train_loss : 1.034242 , test loss : 1.134228\n",
      "epoch = 868 train_loss : 1.033750 , test loss : 1.134156\n",
      "epoch = 870 train_loss : 1.032797 , test loss : 1.133298\n",
      "epoch = 872 train_loss : 1.031821 , test loss : 1.132940\n",
      "epoch = 873 train_loss : 1.031363 , test loss : 1.131904\n",
      "epoch = 875 train_loss : 1.030395 , test loss : 1.131377\n",
      "epoch = 876 train_loss : 1.029943 , test loss : 1.131258\n",
      "epoch = 878 train_loss : 1.029006 , test loss : 1.131163\n",
      "epoch = 879 train_loss : 1.028501 , test loss : 1.130167\n",
      "epoch = 880 train_loss : 1.028077 , test loss : 1.130069\n",
      "epoch = 881 train_loss : 1.027574 , test loss : 1.129471\n",
      "epoch = 882 train_loss : 1.027163 , test loss : 1.128875\n",
      "epoch = 884 train_loss : 1.026205 , test loss : 1.128831\n",
      "epoch = 885 train_loss : 1.025740 , test loss : 1.128474\n",
      "epoch = 886 train_loss : 1.025291 , test loss : 1.128078\n",
      "epoch = 887 train_loss : 1.024880 , test loss : 1.127753\n",
      "epoch = 888 train_loss : 1.024371 , test loss : 1.127012\n",
      "epoch = 889 train_loss : 1.023910 , test loss : 1.126876\n",
      "epoch = 890 train_loss : 1.023442 , test loss : 1.126726\n",
      "epoch = 891 train_loss : 1.023046 , test loss : 1.126508\n",
      "epoch = 892 train_loss : 1.022546 , test loss : 1.126015\n",
      "epoch = 893 train_loss : 1.022086 , test loss : 1.125483\n",
      "epoch = 894 train_loss : 1.021647 , test loss : 1.125381\n",
      "epoch = 895 train_loss : 1.021192 , test loss : 1.125190\n",
      "epoch = 897 train_loss : 1.020302 , test loss : 1.124746\n",
      "epoch = 898 train_loss : 1.019898 , test loss : 1.123413\n",
      "epoch = 902 train_loss : 1.018065 , test loss : 1.123063\n",
      "epoch = 903 train_loss : 1.017646 , test loss : 1.122933\n",
      "epoch = 904 train_loss : 1.017198 , test loss : 1.121668\n",
      "epoch = 906 train_loss : 1.016320 , test loss : 1.121231\n",
      "epoch = 908 train_loss : 1.015447 , test loss : 1.120324\n",
      "epoch = 911 train_loss : 1.014104 , test loss : 1.120116\n",
      "epoch = 912 train_loss : 1.013714 , test loss : 1.119794\n",
      "epoch = 913 train_loss : 1.013273 , test loss : 1.119670\n",
      "epoch = 914 train_loss : 1.012823 , test loss : 1.119146\n",
      "epoch = 915 train_loss : 1.012393 , test loss : 1.118960\n",
      "epoch = 916 train_loss : 1.012000 , test loss : 1.118704\n",
      "epoch = 918 train_loss : 1.011166 , test loss : 1.118471\n",
      "epoch = 919 train_loss : 1.010669 , test loss : 1.117817\n",
      "epoch = 920 train_loss : 1.010302 , test loss : 1.117271\n",
      "epoch = 922 train_loss : 1.009392 , test loss : 1.116989\n",
      "epoch = 923 train_loss : 1.008979 , test loss : 1.116581\n",
      "epoch = 924 train_loss : 1.008565 , test loss : 1.116275\n",
      "epoch = 926 train_loss : 1.007727 , test loss : 1.115865\n",
      "epoch = 927 train_loss : 1.007363 , test loss : 1.115626\n",
      "epoch = 929 train_loss : 1.006522 , test loss : 1.114772\n",
      "epoch = 930 train_loss : 1.006131 , test loss : 1.114752\n",
      "epoch = 931 train_loss : 1.005671 , test loss : 1.114557\n",
      "epoch = 932 train_loss : 1.005266 , test loss : 1.113899\n",
      "epoch = 935 train_loss : 1.004023 , test loss : 1.113834\n",
      "epoch = 936 train_loss : 1.003604 , test loss : 1.112877\n",
      "epoch = 938 train_loss : 1.002821 , test loss : 1.112144\n",
      "epoch = 941 train_loss : 1.001614 , test loss : 1.111880\n",
      "epoch = 942 train_loss : 1.001181 , test loss : 1.111613\n",
      "epoch = 943 train_loss : 1.000786 , test loss : 1.111198\n",
      "epoch = 944 train_loss : 1.000380 , test loss : 1.110777\n",
      "epoch = 946 train_loss : 0.999572 , test loss : 1.110743\n",
      "epoch = 947 train_loss : 0.999209 , test loss : 1.110516\n",
      "epoch = 948 train_loss : 0.998778 , test loss : 1.110345\n",
      "epoch = 949 train_loss : 0.998382 , test loss : 1.109535\n",
      "epoch = 951 train_loss : 0.997584 , test loss : 1.109258\n",
      "epoch = 953 train_loss : 0.996791 , test loss : 1.108570\n",
      "epoch = 955 train_loss : 0.995987 , test loss : 1.108508\n",
      "epoch = 956 train_loss : 0.995620 , test loss : 1.107973\n",
      "epoch = 957 train_loss : 0.995230 , test loss : 1.107750\n",
      "epoch = 958 train_loss : 0.994849 , test loss : 1.107439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 960 train_loss : 0.994082 , test loss : 1.107371\n",
      "epoch = 961 train_loss : 0.993656 , test loss : 1.106711\n",
      "epoch = 964 train_loss : 0.992586 , test loss : 1.105704\n",
      "epoch = 967 train_loss : 0.991356 , test loss : 1.105099\n",
      "epoch = 969 train_loss : 0.990595 , test loss : 1.104980\n",
      "epoch = 970 train_loss : 0.990220 , test loss : 1.104882\n",
      "epoch = 971 train_loss : 0.989841 , test loss : 1.104644\n",
      "epoch = 972 train_loss : 0.989507 , test loss : 1.104536\n",
      "epoch = 973 train_loss : 0.989170 , test loss : 1.103457\n",
      "epoch = 975 train_loss : 0.988385 , test loss : 1.103307\n",
      "epoch = 977 train_loss : 0.987652 , test loss : 1.102936\n",
      "epoch = 978 train_loss : 0.987306 , test loss : 1.102765\n",
      "epoch = 980 train_loss : 0.986500 , test loss : 1.102171\n",
      "epoch = 981 train_loss : 0.986145 , test loss : 1.101424\n",
      "epoch = 986 train_loss : 0.984317 , test loss : 1.100869\n",
      "epoch = 988 train_loss : 0.983617 , test loss : 1.100296\n",
      "epoch = 991 train_loss : 0.982526 , test loss : 1.100025\n",
      "epoch = 992 train_loss : 0.982185 , test loss : 1.099513\n",
      "epoch = 993 train_loss : 0.981820 , test loss : 1.099016\n",
      "epoch = 997 train_loss : 0.980419 , test loss : 1.098343\n",
      "epoch = 1000 train_loss : 0.979320 , test loss : 1.097858\n",
      "epoch = 1001 train_loss : 0.979087 , test loss : 1.097423\n",
      "epoch = 1004 train_loss : 0.977940 , test loss : 1.097373\n",
      "epoch = 1005 train_loss : 0.977655 , test loss : 1.096823\n",
      "epoch = 1008 train_loss : 0.976551 , test loss : 1.096527\n",
      "epoch = 1009 train_loss : 0.976187 , test loss : 1.096341\n",
      "epoch = 1010 train_loss : 0.975843 , test loss : 1.095845\n",
      "epoch = 1012 train_loss : 0.975176 , test loss : 1.095754\n",
      "epoch = 1013 train_loss : 0.974827 , test loss : 1.095154\n",
      "epoch = 1017 train_loss : 0.973450 , test loss : 1.094771\n",
      "epoch = 1018 train_loss : 0.973095 , test loss : 1.094591\n",
      "epoch = 1020 train_loss : 0.972419 , test loss : 1.094259\n",
      "epoch = 1021 train_loss : 0.972080 , test loss : 1.094090\n",
      "epoch = 1022 train_loss : 0.971747 , test loss : 1.094039\n",
      "epoch = 1023 train_loss : 0.971424 , test loss : 1.093551\n",
      "epoch = 1024 train_loss : 0.971148 , test loss : 1.093307\n",
      "epoch = 1025 train_loss : 0.970779 , test loss : 1.092875\n",
      "epoch = 1029 train_loss : 0.969395 , test loss : 1.092306\n",
      "epoch = 1030 train_loss : 0.969071 , test loss : 1.091775\n",
      "epoch = 1033 train_loss : 0.968072 , test loss : 1.091307\n",
      "epoch = 1034 train_loss : 0.967733 , test loss : 1.091294\n",
      "epoch = 1035 train_loss : 0.967409 , test loss : 1.090935\n",
      "epoch = 1037 train_loss : 0.966732 , test loss : 1.090447\n",
      "epoch = 1038 train_loss : 0.966408 , test loss : 1.090332\n",
      "epoch = 1040 train_loss : 0.965777 , test loss : 1.090299\n",
      "epoch = 1041 train_loss : 0.965398 , test loss : 1.090236\n",
      "epoch = 1043 train_loss : 0.964822 , test loss : 1.089220\n",
      "epoch = 1046 train_loss : 0.963754 , test loss : 1.089195\n",
      "epoch = 1047 train_loss : 0.963407 , test loss : 1.089073\n",
      "epoch = 1048 train_loss : 0.963078 , test loss : 1.088544\n",
      "epoch = 1052 train_loss : 0.961748 , test loss : 1.088047\n",
      "epoch = 1054 train_loss : 0.961164 , test loss : 1.087374\n",
      "epoch = 1058 train_loss : 0.959804 , test loss : 1.087216\n",
      "epoch = 1060 train_loss : 0.959164 , test loss : 1.086411\n",
      "epoch = 1063 train_loss : 0.958199 , test loss : 1.086334\n",
      "epoch = 1065 train_loss : 0.957553 , test loss : 1.086319\n",
      "epoch = 1066 train_loss : 0.957243 , test loss : 1.085936\n",
      "epoch = 1067 train_loss : 0.956997 , test loss : 1.084971\n",
      "epoch = 1070 train_loss : 0.956039 , test loss : 1.084561\n",
      "epoch = 1076 train_loss : 0.954081 , test loss : 1.084287\n",
      "epoch = 1077 train_loss : 0.953797 , test loss : 1.083959\n",
      "epoch = 1078 train_loss : 0.953448 , test loss : 1.083901\n",
      "epoch = 1079 train_loss : 0.953174 , test loss : 1.083728\n",
      "epoch = 1080 train_loss : 0.952855 , test loss : 1.083368\n",
      "epoch = 1085 train_loss : 0.951267 , test loss : 1.083130\n",
      "epoch = 1086 train_loss : 0.950959 , test loss : 1.082559\n",
      "epoch = 1087 train_loss : 0.950674 , test loss : 1.082494\n",
      "epoch = 1090 train_loss : 0.949750 , test loss : 1.082010\n",
      "epoch = 1093 train_loss : 0.948862 , test loss : 1.081947\n",
      "epoch = 1095 train_loss : 0.948213 , test loss : 1.081238\n",
      "epoch = 1096 train_loss : 0.947959 , test loss : 1.080997\n",
      "epoch = 1098 train_loss : 0.947324 , test loss : 1.080697\n",
      "epoch = 1100 train_loss : 0.946701 , test loss : 1.080640\n",
      "epoch = 1101 train_loss : 0.946401 , test loss : 1.080419\n",
      "epoch = 1104 train_loss : 0.945517 , test loss : 1.080342\n",
      "epoch = 1105 train_loss : 0.945242 , test loss : 1.080202\n",
      "epoch = 1107 train_loss : 0.944607 , test loss : 1.079703\n",
      "epoch = 1108 train_loss : 0.944311 , test loss : 1.079306\n",
      "epoch = 1110 train_loss : 0.943754 , test loss : 1.079101\n",
      "epoch = 1112 train_loss : 0.943134 , test loss : 1.078885\n",
      "epoch = 1115 train_loss : 0.942250 , test loss : 1.078525\n",
      "epoch = 1116 train_loss : 0.941952 , test loss : 1.078434\n",
      "epoch = 1117 train_loss : 0.941662 , test loss : 1.078269\n",
      "epoch = 1121 train_loss : 0.940510 , test loss : 1.077945\n",
      "epoch = 1123 train_loss : 0.939903 , test loss : 1.077562\n",
      "epoch = 1126 train_loss : 0.939045 , test loss : 1.076919\n",
      "epoch = 1131 train_loss : 0.937652 , test loss : 1.076602\n",
      "epoch = 1132 train_loss : 0.937321 , test loss : 1.076235\n",
      "epoch = 1135 train_loss : 0.936478 , test loss : 1.075866\n",
      "epoch = 1136 train_loss : 0.936196 , test loss : 1.075548\n",
      "epoch = 1138 train_loss : 0.935642 , test loss : 1.075308\n",
      "epoch = 1142 train_loss : 0.934547 , test loss : 1.074335\n",
      "epoch = 1149 train_loss : 0.932506 , test loss : 1.073743\n",
      "epoch = 1153 train_loss : 0.931455 , test loss : 1.073643\n",
      "epoch = 1154 train_loss : 0.931114 , test loss : 1.073053\n",
      "epoch = 1157 train_loss : 0.930278 , test loss : 1.073033\n",
      "epoch = 1158 train_loss : 0.930025 , test loss : 1.072363\n",
      "epoch = 1167 train_loss : 0.927548 , test loss : 1.071753\n",
      "epoch = 1171 train_loss : 0.926448 , test loss : 1.071455\n",
      "epoch = 1173 train_loss : 0.925908 , test loss : 1.071431\n",
      "epoch = 1175 train_loss : 0.925391 , test loss : 1.071380\n",
      "epoch = 1176 train_loss : 0.925100 , test loss : 1.071060\n",
      "epoch = 1177 train_loss : 0.924849 , test loss : 1.070759\n",
      "epoch = 1180 train_loss : 0.924020 , test loss : 1.070536\n",
      "epoch = 1181 train_loss : 0.923764 , test loss : 1.070073\n",
      "epoch = 1184 train_loss : 0.922944 , test loss : 1.070002\n",
      "epoch = 1188 train_loss : 0.922006 , test loss : 1.069134\n",
      "epoch = 1192 train_loss : 0.920868 , test loss : 1.068900\n",
      "epoch = 1194 train_loss : 0.920290 , test loss : 1.068887\n",
      "epoch = 1198 train_loss : 0.919281 , test loss : 1.068190\n",
      "epoch = 1200 train_loss : 0.918733 , test loss : 1.067842\n",
      "epoch = 1207 train_loss : 0.916949 , test loss : 1.067513\n",
      "epoch = 1208 train_loss : 0.916632 , test loss : 1.067317\n",
      "epoch = 1211 train_loss : 0.915859 , test loss : 1.066768\n",
      "epoch = 1213 train_loss : 0.915346 , test loss : 1.066601\n",
      "epoch = 1215 train_loss : 0.914822 , test loss : 1.066299\n",
      "epoch = 1216 train_loss : 0.914597 , test loss : 1.066270\n",
      "epoch = 1218 train_loss : 0.914048 , test loss : 1.066165\n",
      "epoch = 1219 train_loss : 0.913829 , test loss : 1.066075\n",
      "epoch = 1220 train_loss : 0.913589 , test loss : 1.065961\n",
      "epoch = 1224 train_loss : 0.912529 , test loss : 1.065848\n",
      "epoch = 1225 train_loss : 0.912269 , test loss : 1.065709\n",
      "epoch = 1227 train_loss : 0.911914 , test loss : 1.065547\n",
      "epoch = 1229 train_loss : 0.911301 , test loss : 1.064935\n",
      "epoch = 1230 train_loss : 0.911050 , test loss : 1.064547\n",
      "epoch = 1237 train_loss : 0.909334 , test loss : 1.064477\n",
      "epoch = 1240 train_loss : 0.908548 , test loss : 1.064128\n",
      "epoch = 1243 train_loss : 0.907821 , test loss : 1.064015\n",
      "epoch = 1244 train_loss : 0.907604 , test loss : 1.063141\n",
      "epoch = 1248 train_loss : 0.906591 , test loss : 1.063127\n",
      "epoch = 1251 train_loss : 0.905855 , test loss : 1.063038\n",
      "epoch = 1255 train_loss : 0.904921 , test loss : 1.062846\n",
      "epoch = 1256 train_loss : 0.904625 , test loss : 1.062721\n",
      "epoch = 1260 train_loss : 0.903706 , test loss : 1.061777\n",
      "epoch = 1269 train_loss : 0.901482 , test loss : 1.061680\n",
      "epoch = 1271 train_loss : 0.901048 , test loss : 1.061312\n",
      "epoch = 1272 train_loss : 0.900812 , test loss : 1.060499\n",
      "epoch = 1284 train_loss : 0.897907 , test loss : 1.060447\n",
      "epoch = 1287 train_loss : 0.897234 , test loss : 1.059855\n",
      "epoch = 1294 train_loss : 0.895566 , test loss : 1.059457\n",
      "epoch = 1296 train_loss : 0.895109 , test loss : 1.058844\n",
      "epoch = 1307 train_loss : 0.892594 , test loss : 1.058324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1312 train_loss : 0.891495 , test loss : 1.058279\n",
      "epoch = 1314 train_loss : 0.891027 , test loss : 1.058271\n",
      "epoch = 1317 train_loss : 0.890282 , test loss : 1.057812\n",
      "epoch = 1324 train_loss : 0.888714 , test loss : 1.057684\n",
      "epoch = 1327 train_loss : 0.888041 , test loss : 1.056844\n",
      "epoch = 1331 train_loss : 0.887196 , test loss : 1.056605\n",
      "epoch = 1334 train_loss : 0.886501 , test loss : 1.056337\n",
      "epoch = 1338 train_loss : 0.885583 , test loss : 1.056179\n",
      "epoch = 1344 train_loss : 0.884267 , test loss : 1.056093\n",
      "epoch = 1348 train_loss : 0.883373 , test loss : 1.056022\n",
      "epoch = 1349 train_loss : 0.883124 , test loss : 1.056001\n",
      "epoch = 1350 train_loss : 0.882913 , test loss : 1.055587\n",
      "epoch = 1356 train_loss : 0.881718 , test loss : 1.055415\n",
      "epoch = 1359 train_loss : 0.880980 , test loss : 1.055137\n",
      "epoch = 1361 train_loss : 0.880541 , test loss : 1.055078\n",
      "epoch = 1366 train_loss : 0.879492 , test loss : 1.054371\n",
      "epoch = 1371 train_loss : 0.878340 , test loss : 1.054291\n",
      "epoch = 1372 train_loss : 0.878144 , test loss : 1.054014\n",
      "epoch = 1378 train_loss : 0.876920 , test loss : 1.053750\n",
      "epoch = 1383 train_loss : 0.875743 , test loss : 1.053718\n",
      "epoch = 1388 train_loss : 0.874679 , test loss : 1.053567\n",
      "epoch = 1392 train_loss : 0.873821 , test loss : 1.053525\n",
      "epoch = 1394 train_loss : 0.873462 , test loss : 1.052723\n",
      "epoch = 1397 train_loss : 0.872893 , test loss : 1.052521\n",
      "epoch = 1407 train_loss : 0.870672 , test loss : 1.052517\n",
      "epoch = 1410 train_loss : 0.870081 , test loss : 1.052430\n",
      "epoch = 1414 train_loss : 0.869235 , test loss : 1.052303\n",
      "epoch = 1417 train_loss : 0.868577 , test loss : 1.051946\n",
      "epoch = 1422 train_loss : 0.867571 , test loss : 1.051620\n",
      "epoch = 1426 train_loss : 0.866709 , test loss : 1.051568\n",
      "epoch = 1433 train_loss : 0.865294 , test loss : 1.051125\n",
      "epoch = 1441 train_loss : 0.863667 , test loss : 1.051034\n",
      "epoch = 1447 train_loss : 0.862523 , test loss : 1.050511\n",
      "epoch = 1451 train_loss : 0.861684 , test loss : 1.050411\n",
      "epoch = 1452 train_loss : 0.861465 , test loss : 1.050225\n",
      "epoch = 1458 train_loss : 0.860264 , test loss : 1.050180\n",
      "epoch = 1462 train_loss : 0.859496 , test loss : 1.049748\n",
      "epoch = 1471 train_loss : 0.857749 , test loss : 1.049208\n",
      "epoch = 1484 train_loss : 0.855250 , test loss : 1.048489\n",
      "epoch = 1494 train_loss : 0.853212 , test loss : 1.048267\n",
      "epoch = 1501 train_loss : 0.851849 , test loss : 1.048227\n",
      "epoch = 1505 train_loss : 0.851142 , test loss : 1.047944\n",
      "epoch = 1513 train_loss : 0.849533 , test loss : 1.047758\n",
      "epoch = 1525 train_loss : 0.847225 , test loss : 1.047593\n",
      "epoch = 1529 train_loss : 0.846514 , test loss : 1.046860\n",
      "epoch = 1548 train_loss : 0.842862 , test loss : 1.046732\n",
      "epoch = 1553 train_loss : 0.841930 , test loss : 1.046673\n",
      "epoch = 1555 train_loss : 0.841588 , test loss : 1.046448\n",
      "epoch = 1562 train_loss : 0.840295 , test loss : 1.046332\n",
      "epoch = 1569 train_loss : 0.838961 , test loss : 1.046110\n",
      "epoch = 1579 train_loss : 0.837181 , test loss : 1.045750\n",
      "epoch = 1585 train_loss : 0.836036 , test loss : 1.045570\n",
      "epoch = 1587 train_loss : 0.835765 , test loss : 1.045401\n",
      "epoch = 1591 train_loss : 0.834952 , test loss : 1.045384\n",
      "epoch = 1602 train_loss : 0.832971 , test loss : 1.045352\n",
      "epoch = 1605 train_loss : 0.832417 , test loss : 1.045338\n",
      "epoch = 1608 train_loss : 0.831923 , test loss : 1.045131\n",
      "epoch = 1615 train_loss : 0.830659 , test loss : 1.044864\n",
      "epoch = 1620 train_loss : 0.829842 , test loss : 1.044795\n",
      "epoch = 1624 train_loss : 0.829065 , test loss : 1.044577\n",
      "epoch = 1634 train_loss : 0.827339 , test loss : 1.044171\n",
      "epoch = 1660 train_loss : 0.822768 , test loss : 1.043958\n",
      "epoch = 1682 train_loss : 0.818983 , test loss : 1.043903\n",
      "epoch = 1697 train_loss : 0.816445 , test loss : 1.043885\n",
      "epoch = 1702 train_loss : 0.815589 , test loss : 1.043872\n",
      "epoch = 1704 train_loss : 0.815237 , test loss : 1.043627\n",
      "epoch = 1714 train_loss : 0.813556 , test loss : 1.043619\n",
      "epoch = 1722 train_loss : 0.812272 , test loss : 1.043589\n",
      "epoch = 1725 train_loss : 0.811727 , test loss : 1.043276\n",
      "epoch = 1743 train_loss : 0.808713 , test loss : 1.043127\n",
      "epoch = 1788 train_loss : 0.801350 , test loss : 1.042693\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.801350,test loss : 1.042693\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 38.258549 , test loss : 37.786888\n",
      "epoch = 2 train_loss : 37.702438 , test loss : 37.248184\n",
      "epoch = 3 train_loss : 37.153748 , test loss : 36.716827\n",
      "epoch = 4 train_loss : 36.610718 , test loss : 36.190788\n",
      "epoch = 5 train_loss : 36.078053 , test loss : 35.674034\n",
      "epoch = 6 train_loss : 35.550724 , test loss : 35.162186\n",
      "epoch = 7 train_loss : 35.020943 , test loss : 34.648762\n",
      "epoch = 8 train_loss : 34.505035 , test loss : 34.147305\n",
      "epoch = 9 train_loss : 33.991718 , test loss : 33.648865\n",
      "epoch = 10 train_loss : 33.483917 , test loss : 33.155247\n",
      "epoch = 11 train_loss : 32.979256 , test loss : 32.664543\n",
      "epoch = 12 train_loss : 32.477566 , test loss : 32.176361\n",
      "epoch = 13 train_loss : 31.978483 , test loss : 31.691162\n",
      "epoch = 14 train_loss : 31.484232 , test loss : 31.210405\n",
      "epoch = 15 train_loss : 30.999207 , test loss : 30.737953\n",
      "epoch = 16 train_loss : 30.512356 , test loss : 30.263741\n",
      "epoch = 17 train_loss : 30.029219 , test loss : 29.793041\n",
      "epoch = 18 train_loss : 29.548140 , test loss : 29.323851\n",
      "epoch = 19 train_loss : 29.074602 , test loss : 28.861673\n",
      "epoch = 20 train_loss : 28.595842 , test loss : 28.394394\n",
      "epoch = 21 train_loss : 28.130573 , test loss : 27.939089\n",
      "epoch = 22 train_loss : 27.660513 , test loss : 27.479956\n",
      "epoch = 23 train_loss : 27.196484 , test loss : 27.026510\n",
      "epoch = 24 train_loss : 26.734327 , test loss : 26.574646\n",
      "epoch = 25 train_loss : 26.277966 , test loss : 26.127954\n",
      "epoch = 26 train_loss : 25.820721 , test loss : 25.680948\n",
      "epoch = 27 train_loss : 25.369541 , test loss : 25.239307\n",
      "epoch = 28 train_loss : 24.918417 , test loss : 24.797298\n",
      "epoch = 29 train_loss : 24.472160 , test loss : 24.360109\n",
      "epoch = 30 train_loss : 24.027660 , test loss : 23.924204\n",
      "epoch = 31 train_loss : 23.585917 , test loss : 23.491360\n",
      "epoch = 32 train_loss : 23.150394 , test loss : 23.063524\n",
      "epoch = 33 train_loss : 22.713747 , test loss : 22.635134\n",
      "epoch = 34 train_loss : 22.280365 , test loss : 22.209564\n",
      "epoch = 35 train_loss : 21.853573 , test loss : 21.789978\n",
      "epoch = 36 train_loss : 21.429300 , test loss : 21.372791\n",
      "epoch = 37 train_loss : 21.010851 , test loss : 20.961159\n",
      "epoch = 38 train_loss : 20.594591 , test loss : 20.551567\n",
      "epoch = 39 train_loss : 20.185587 , test loss : 20.148602\n",
      "epoch = 40 train_loss : 19.776634 , test loss : 19.745846\n",
      "epoch = 41 train_loss : 19.375885 , test loss : 19.350418\n",
      "epoch = 42 train_loss : 18.977448 , test loss : 18.957449\n",
      "epoch = 43 train_loss : 18.584881 , test loss : 18.569790\n",
      "epoch = 44 train_loss : 18.196772 , test loss : 18.185991\n",
      "epoch = 45 train_loss : 17.813219 , test loss : 17.806618\n",
      "epoch = 46 train_loss : 17.435833 , test loss : 17.432768\n",
      "epoch = 47 train_loss : 17.061775 , test loss : 17.062296\n",
      "epoch = 48 train_loss : 16.694494 , test loss : 16.698380\n",
      "epoch = 49 train_loss : 16.332750 , test loss : 16.339725\n",
      "epoch = 50 train_loss : 15.974855 , test loss : 15.984635\n",
      "epoch = 51 train_loss : 15.621547 , test loss : 15.633924\n",
      "epoch = 52 train_loss : 15.273675 , test loss : 15.288535\n",
      "epoch = 53 train_loss : 14.933004 , test loss : 14.949632\n",
      "epoch = 54 train_loss : 14.598512 , test loss : 14.616644\n",
      "epoch = 55 train_loss : 14.269882 , test loss : 14.289296\n",
      "epoch = 56 train_loss : 13.945196 , test loss : 13.965725\n",
      "epoch = 57 train_loss : 13.624086 , test loss : 13.645692\n",
      "epoch = 58 train_loss : 13.315214 , test loss : 13.337047\n",
      "epoch = 59 train_loss : 13.010439 , test loss : 13.032272\n",
      "epoch = 60 train_loss : 12.708987 , test loss : 12.730487\n",
      "epoch = 61 train_loss : 12.413980 , test loss : 12.435232\n",
      "epoch = 62 train_loss : 12.124877 , test loss : 12.145405\n",
      "epoch = 63 train_loss : 11.842920 , test loss : 11.862054\n",
      "epoch = 64 train_loss : 11.568590 , test loss : 11.586571\n",
      "epoch = 65 train_loss : 11.298086 , test loss : 11.314544\n",
      "epoch = 66 train_loss : 11.034177 , test loss : 11.048915\n",
      "epoch = 67 train_loss : 10.776559 , test loss : 10.789226\n",
      "epoch = 68 train_loss : 10.525505 , test loss : 10.535944\n",
      "epoch = 69 train_loss : 10.278442 , test loss : 10.286485\n",
      "epoch = 70 train_loss : 10.038061 , test loss : 10.043829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 71 train_loss : 9.804434 , test loss : 9.807604\n",
      "epoch = 72 train_loss : 9.575191 , test loss : 9.575662\n",
      "epoch = 73 train_loss : 9.352309 , test loss : 9.349951\n",
      "epoch = 74 train_loss : 9.135534 , test loss : 9.130275\n",
      "epoch = 75 train_loss : 8.922843 , test loss : 8.914448\n",
      "epoch = 76 train_loss : 8.717688 , test loss : 8.706150\n",
      "epoch = 77 train_loss : 8.516352 , test loss : 8.501219\n",
      "epoch = 78 train_loss : 8.319455 , test loss : 8.301002\n",
      "epoch = 79 train_loss : 8.129786 , test loss : 8.107763\n",
      "epoch = 80 train_loss : 7.944396 , test loss : 7.918622\n",
      "epoch = 81 train_loss : 7.764736 , test loss : 7.735261\n",
      "epoch = 82 train_loss : 7.590034 , test loss : 7.556730\n",
      "epoch = 83 train_loss : 7.420287 , test loss : 7.383166\n",
      "epoch = 84 train_loss : 7.256762 , test loss : 7.215947\n",
      "epoch = 85 train_loss : 7.094808 , test loss : 7.050327\n",
      "epoch = 86 train_loss : 6.939297 , test loss : 6.890589\n",
      "epoch = 87 train_loss : 6.788715 , test loss : 6.735950\n",
      "epoch = 88 train_loss : 6.642935 , test loss : 6.586230\n",
      "epoch = 89 train_loss : 6.501587 , test loss : 6.440948\n",
      "epoch = 90 train_loss : 6.364426 , test loss : 6.299669\n",
      "epoch = 91 train_loss : 6.229455 , test loss : 6.160818\n",
      "epoch = 92 train_loss : 6.100531 , test loss : 6.027737\n",
      "epoch = 93 train_loss : 5.976418 , test loss : 5.899929\n",
      "epoch = 94 train_loss : 5.854618 , test loss : 5.774351\n",
      "epoch = 95 train_loss : 5.737252 , test loss : 5.653231\n",
      "epoch = 96 train_loss : 5.623885 , test loss : 5.536315\n",
      "epoch = 97 train_loss : 5.514895 , test loss : 5.423517\n",
      "epoch = 98 train_loss : 5.408961 , test loss : 5.314118\n",
      "epoch = 99 train_loss : 5.305346 , test loss : 5.206758\n",
      "epoch = 100 train_loss : 5.206775 , test loss : 5.104857\n",
      "epoch = 101 train_loss : 5.110782 , test loss : 5.005453\n",
      "epoch = 102 train_loss : 5.018295 , test loss : 4.909692\n",
      "epoch = 103 train_loss : 4.928552 , test loss : 4.816813\n",
      "epoch = 104 train_loss : 4.842825 , test loss : 4.728052\n",
      "epoch = 105 train_loss : 4.759946 , test loss : 4.642297\n",
      "epoch = 106 train_loss : 4.679990 , test loss : 4.559237\n",
      "epoch = 107 train_loss : 4.601902 , test loss : 4.478416\n",
      "epoch = 108 train_loss : 4.527873 , test loss : 4.401556\n",
      "epoch = 109 train_loss : 4.455662 , test loss : 4.326826\n",
      "epoch = 110 train_loss : 4.387281 , test loss : 4.255871\n",
      "epoch = 111 train_loss : 4.320765 , test loss : 4.186751\n",
      "epoch = 112 train_loss : 4.256942 , test loss : 4.120654\n",
      "epoch = 113 train_loss : 4.194863 , test loss : 4.056495\n",
      "epoch = 114 train_loss : 4.135363 , test loss : 3.994590\n",
      "epoch = 115 train_loss : 4.078979 , test loss : 3.936264\n",
      "epoch = 116 train_loss : 4.023206 , test loss : 3.878608\n",
      "epoch = 117 train_loss : 3.970327 , test loss : 3.823888\n",
      "epoch = 118 train_loss : 3.919322 , test loss : 3.771055\n",
      "epoch = 119 train_loss : 3.870808 , test loss : 3.720687\n",
      "epoch = 120 train_loss : 3.823673 , test loss : 3.671992\n",
      "epoch = 121 train_loss : 3.779238 , test loss : 3.626168\n",
      "epoch = 122 train_loss : 3.735350 , test loss : 3.581201\n",
      "epoch = 123 train_loss : 3.694398 , test loss : 3.539008\n",
      "epoch = 124 train_loss : 3.654419 , test loss : 3.497817\n",
      "epoch = 125 train_loss : 3.616200 , test loss : 3.458482\n",
      "epoch = 126 train_loss : 3.579456 , test loss : 3.420646\n",
      "epoch = 127 train_loss : 3.544611 , test loss : 3.385368\n",
      "epoch = 128 train_loss : 3.511111 , test loss : 3.351076\n",
      "epoch = 129 train_loss : 3.478897 , test loss : 3.317580\n",
      "epoch = 130 train_loss : 3.448194 , test loss : 3.286330\n",
      "epoch = 131 train_loss : 3.418939 , test loss : 3.256794\n",
      "epoch = 132 train_loss : 3.390481 , test loss : 3.227524\n",
      "epoch = 133 train_loss : 3.363359 , test loss : 3.199937\n",
      "epoch = 134 train_loss : 3.337632 , test loss : 3.173572\n",
      "epoch = 135 train_loss : 3.312956 , test loss : 3.148611\n",
      "epoch = 136 train_loss : 3.288795 , test loss : 3.124135\n",
      "epoch = 137 train_loss : 3.265982 , test loss : 3.101190\n",
      "epoch = 138 train_loss : 3.244020 , test loss : 3.078912\n",
      "epoch = 139 train_loss : 3.223422 , test loss : 3.058535\n",
      "epoch = 140 train_loss : 3.203734 , test loss : 3.038530\n",
      "epoch = 141 train_loss : 3.184569 , test loss : 3.019575\n",
      "epoch = 142 train_loss : 3.165982 , test loss : 3.001102\n",
      "epoch = 143 train_loss : 3.148595 , test loss : 2.983814\n",
      "epoch = 144 train_loss : 3.131509 , test loss : 2.966955\n",
      "epoch = 145 train_loss : 3.115426 , test loss : 2.951159\n",
      "epoch = 146 train_loss : 3.099568 , test loss : 2.935212\n",
      "epoch = 147 train_loss : 3.084794 , test loss : 2.920687\n",
      "epoch = 148 train_loss : 3.070541 , test loss : 2.906786\n",
      "epoch = 149 train_loss : 3.056659 , test loss : 2.893133\n",
      "epoch = 150 train_loss : 3.043238 , test loss : 2.879896\n",
      "epoch = 151 train_loss : 3.030981 , test loss : 2.867927\n",
      "epoch = 152 train_loss : 3.018967 , test loss : 2.856011\n",
      "epoch = 153 train_loss : 3.007131 , test loss : 2.844472\n",
      "epoch = 154 train_loss : 2.995907 , test loss : 2.833780\n",
      "epoch = 155 train_loss : 2.985164 , test loss : 2.823454\n",
      "epoch = 156 train_loss : 2.974498 , test loss : 2.813030\n",
      "epoch = 157 train_loss : 2.964414 , test loss : 2.803332\n",
      "epoch = 158 train_loss : 2.954443 , test loss : 2.794040\n",
      "epoch = 159 train_loss : 2.944974 , test loss : 2.784929\n",
      "epoch = 160 train_loss : 2.935823 , test loss : 2.776566\n",
      "epoch = 161 train_loss : 2.926978 , test loss : 2.767921\n",
      "epoch = 162 train_loss : 2.918419 , test loss : 2.760217\n",
      "epoch = 163 train_loss : 2.910163 , test loss : 2.752166\n",
      "epoch = 164 train_loss : 2.902009 , test loss : 2.744943\n",
      "epoch = 165 train_loss : 2.894240 , test loss : 2.737291\n",
      "epoch = 166 train_loss : 2.886488 , test loss : 2.730386\n",
      "epoch = 167 train_loss : 2.878870 , test loss : 2.723303\n",
      "epoch = 168 train_loss : 2.871521 , test loss : 2.716619\n",
      "epoch = 169 train_loss : 2.864369 , test loss : 2.710097\n",
      "epoch = 170 train_loss : 2.857316 , test loss : 2.703333\n",
      "epoch = 171 train_loss : 2.850543 , test loss : 2.697279\n",
      "epoch = 172 train_loss : 2.843776 , test loss : 2.691085\n",
      "epoch = 173 train_loss : 2.837184 , test loss : 2.685381\n",
      "epoch = 174 train_loss : 2.830776 , test loss : 2.679662\n",
      "epoch = 175 train_loss : 2.824553 , test loss : 2.673700\n",
      "epoch = 176 train_loss : 2.818310 , test loss : 2.668133\n",
      "epoch = 177 train_loss : 2.812169 , test loss : 2.662609\n",
      "epoch = 178 train_loss : 2.806113 , test loss : 2.657627\n",
      "epoch = 179 train_loss : 2.800138 , test loss : 2.651945\n",
      "epoch = 180 train_loss : 2.794285 , test loss : 2.646631\n",
      "epoch = 181 train_loss : 2.788390 , test loss : 2.641346\n",
      "epoch = 182 train_loss : 2.782759 , test loss : 2.636490\n",
      "epoch = 183 train_loss : 2.777045 , test loss : 2.631621\n",
      "epoch = 184 train_loss : 2.771309 , test loss : 2.626353\n",
      "epoch = 185 train_loss : 2.765720 , test loss : 2.621202\n",
      "epoch = 186 train_loss : 2.760196 , test loss : 2.616176\n",
      "epoch = 187 train_loss : 2.754657 , test loss : 2.611288\n",
      "epoch = 188 train_loss : 2.749317 , test loss : 2.606633\n",
      "epoch = 189 train_loss : 2.743842 , test loss : 2.601887\n",
      "epoch = 190 train_loss : 2.738332 , test loss : 2.596706\n",
      "epoch = 191 train_loss : 2.733042 , test loss : 2.592212\n",
      "epoch = 192 train_loss : 2.727814 , test loss : 2.587678\n",
      "epoch = 193 train_loss : 2.722466 , test loss : 2.582639\n",
      "epoch = 194 train_loss : 2.717351 , test loss : 2.578015\n",
      "epoch = 195 train_loss : 2.712029 , test loss : 2.573055\n",
      "epoch = 196 train_loss : 2.706814 , test loss : 2.568489\n",
      "epoch = 197 train_loss : 2.701689 , test loss : 2.563670\n",
      "epoch = 198 train_loss : 2.696513 , test loss : 2.559317\n",
      "epoch = 199 train_loss : 2.691340 , test loss : 2.554667\n",
      "epoch = 200 train_loss : 2.686358 , test loss : 2.549957\n",
      "epoch = 201 train_loss : 2.681226 , test loss : 2.545160\n",
      "epoch = 202 train_loss : 2.676122 , test loss : 2.540675\n",
      "epoch = 203 train_loss : 2.671134 , test loss : 2.536044\n",
      "epoch = 204 train_loss : 2.666082 , test loss : 2.531458\n",
      "epoch = 205 train_loss : 2.660986 , test loss : 2.526870\n",
      "epoch = 206 train_loss : 2.655855 , test loss : 2.522413\n",
      "epoch = 207 train_loss : 2.650825 , test loss : 2.517601\n",
      "epoch = 208 train_loss : 2.645850 , test loss : 2.513341\n",
      "epoch = 209 train_loss : 2.640820 , test loss : 2.508873\n",
      "epoch = 210 train_loss : 2.635804 , test loss : 2.504795\n",
      "epoch = 211 train_loss : 2.630792 , test loss : 2.500217\n",
      "epoch = 212 train_loss : 2.625707 , test loss : 2.495661\n",
      "epoch = 213 train_loss : 2.620637 , test loss : 2.490915\n",
      "epoch = 214 train_loss : 2.615614 , test loss : 2.486400\n",
      "epoch = 215 train_loss : 2.610568 , test loss : 2.481649\n",
      "epoch = 216 train_loss : 2.605577 , test loss : 2.477447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 217 train_loss : 2.600514 , test loss : 2.472630\n",
      "epoch = 218 train_loss : 2.595526 , test loss : 2.468404\n",
      "epoch = 219 train_loss : 2.590313 , test loss : 2.463883\n",
      "epoch = 220 train_loss : 2.585319 , test loss : 2.459193\n",
      "epoch = 221 train_loss : 2.580232 , test loss : 2.454413\n",
      "epoch = 222 train_loss : 2.575167 , test loss : 2.450079\n",
      "epoch = 223 train_loss : 2.570109 , test loss : 2.445292\n",
      "epoch = 224 train_loss : 2.565140 , test loss : 2.441098\n",
      "epoch = 225 train_loss : 2.560060 , test loss : 2.436658\n",
      "epoch = 226 train_loss : 2.555050 , test loss : 2.432029\n",
      "epoch = 227 train_loss : 2.549994 , test loss : 2.427833\n",
      "epoch = 228 train_loss : 2.544874 , test loss : 2.423231\n",
      "epoch = 229 train_loss : 2.539854 , test loss : 2.418860\n",
      "epoch = 230 train_loss : 2.534883 , test loss : 2.414578\n",
      "epoch = 231 train_loss : 2.529865 , test loss : 2.409669\n",
      "epoch = 232 train_loss : 2.524920 , test loss : 2.405830\n",
      "epoch = 233 train_loss : 2.519870 , test loss : 2.401263\n",
      "epoch = 234 train_loss : 2.514862 , test loss : 2.396852\n",
      "epoch = 235 train_loss : 2.509876 , test loss : 2.392475\n",
      "epoch = 236 train_loss : 2.504924 , test loss : 2.387890\n",
      "epoch = 237 train_loss : 2.499950 , test loss : 2.383424\n",
      "epoch = 238 train_loss : 2.495011 , test loss : 2.378757\n",
      "epoch = 239 train_loss : 2.490160 , test loss : 2.374933\n",
      "epoch = 240 train_loss : 2.485261 , test loss : 2.369862\n",
      "epoch = 241 train_loss : 2.480386 , test loss : 2.365935\n",
      "epoch = 242 train_loss : 2.475469 , test loss : 2.361613\n",
      "epoch = 243 train_loss : 2.470720 , test loss : 2.357323\n",
      "epoch = 244 train_loss : 2.465779 , test loss : 2.353298\n",
      "epoch = 245 train_loss : 2.461030 , test loss : 2.348811\n",
      "epoch = 246 train_loss : 2.456265 , test loss : 2.344681\n",
      "epoch = 247 train_loss : 2.451486 , test loss : 2.340681\n",
      "epoch = 248 train_loss : 2.446576 , test loss : 2.336415\n",
      "epoch = 249 train_loss : 2.441778 , test loss : 2.332332\n",
      "epoch = 250 train_loss : 2.437013 , test loss : 2.327591\n",
      "epoch = 251 train_loss : 2.432223 , test loss : 2.323686\n",
      "epoch = 252 train_loss : 2.427523 , test loss : 2.319509\n",
      "epoch = 253 train_loss : 2.422743 , test loss : 2.315278\n",
      "epoch = 254 train_loss : 2.418037 , test loss : 2.310881\n",
      "epoch = 255 train_loss : 2.413360 , test loss : 2.306786\n",
      "epoch = 256 train_loss : 2.408581 , test loss : 2.302317\n",
      "epoch = 257 train_loss : 2.403904 , test loss : 2.298126\n",
      "epoch = 258 train_loss : 2.399194 , test loss : 2.294292\n",
      "epoch = 259 train_loss : 2.394436 , test loss : 2.289894\n",
      "epoch = 260 train_loss : 2.389820 , test loss : 2.285552\n",
      "epoch = 261 train_loss : 2.385145 , test loss : 2.281796\n",
      "epoch = 262 train_loss : 2.380372 , test loss : 2.277479\n",
      "epoch = 263 train_loss : 2.375813 , test loss : 2.272930\n",
      "epoch = 264 train_loss : 2.370989 , test loss : 2.268979\n",
      "epoch = 265 train_loss : 2.366380 , test loss : 2.264721\n",
      "epoch = 266 train_loss : 2.361798 , test loss : 2.260103\n",
      "epoch = 267 train_loss : 2.357089 , test loss : 2.255938\n",
      "epoch = 268 train_loss : 2.352563 , test loss : 2.252007\n",
      "epoch = 269 train_loss : 2.347863 , test loss : 2.248158\n",
      "epoch = 270 train_loss : 2.343244 , test loss : 2.243803\n",
      "epoch = 271 train_loss : 2.338625 , test loss : 2.239540\n",
      "epoch = 272 train_loss : 2.334094 , test loss : 2.235400\n",
      "epoch = 273 train_loss : 2.329539 , test loss : 2.231097\n",
      "epoch = 274 train_loss : 2.324947 , test loss : 2.226739\n",
      "epoch = 275 train_loss : 2.320317 , test loss : 2.222490\n",
      "epoch = 276 train_loss : 2.315723 , test loss : 2.218877\n",
      "epoch = 277 train_loss : 2.311193 , test loss : 2.214553\n",
      "epoch = 278 train_loss : 2.306607 , test loss : 2.210200\n",
      "epoch = 279 train_loss : 2.302067 , test loss : 2.206020\n",
      "epoch = 280 train_loss : 2.297449 , test loss : 2.201964\n",
      "epoch = 281 train_loss : 2.292975 , test loss : 2.197749\n",
      "epoch = 282 train_loss : 2.288409 , test loss : 2.194287\n",
      "epoch = 283 train_loss : 2.283901 , test loss : 2.189793\n",
      "epoch = 284 train_loss : 2.279458 , test loss : 2.185664\n",
      "epoch = 285 train_loss : 2.274987 , test loss : 2.181627\n",
      "epoch = 286 train_loss : 2.270492 , test loss : 2.177595\n",
      "epoch = 287 train_loss : 2.265936 , test loss : 2.173380\n",
      "epoch = 288 train_loss : 2.261459 , test loss : 2.169469\n",
      "epoch = 289 train_loss : 2.257092 , test loss : 2.165690\n",
      "epoch = 290 train_loss : 2.252684 , test loss : 2.161918\n",
      "epoch = 291 train_loss : 2.248228 , test loss : 2.157650\n",
      "epoch = 292 train_loss : 2.243785 , test loss : 2.153407\n",
      "epoch = 293 train_loss : 2.239298 , test loss : 2.149191\n",
      "epoch = 294 train_loss : 2.234852 , test loss : 2.145146\n",
      "epoch = 295 train_loss : 2.230501 , test loss : 2.141456\n",
      "epoch = 296 train_loss : 2.226004 , test loss : 2.137668\n",
      "epoch = 297 train_loss : 2.221646 , test loss : 2.133553\n",
      "epoch = 298 train_loss : 2.217248 , test loss : 2.129490\n",
      "epoch = 299 train_loss : 2.212784 , test loss : 2.125806\n",
      "epoch = 300 train_loss : 2.208421 , test loss : 2.121640\n",
      "epoch = 301 train_loss : 2.204072 , test loss : 2.117949\n",
      "epoch = 302 train_loss : 2.199658 , test loss : 2.113463\n",
      "epoch = 303 train_loss : 2.195251 , test loss : 2.109771\n",
      "epoch = 304 train_loss : 2.190999 , test loss : 2.105687\n",
      "epoch = 305 train_loss : 2.186545 , test loss : 2.101802\n",
      "epoch = 306 train_loss : 2.182136 , test loss : 2.097952\n",
      "epoch = 307 train_loss : 2.177840 , test loss : 2.094238\n",
      "epoch = 308 train_loss : 2.173457 , test loss : 2.090207\n",
      "epoch = 309 train_loss : 2.169113 , test loss : 2.086480\n",
      "epoch = 310 train_loss : 2.164750 , test loss : 2.082826\n",
      "epoch = 311 train_loss : 2.160453 , test loss : 2.078755\n",
      "epoch = 312 train_loss : 2.156224 , test loss : 2.074870\n",
      "epoch = 313 train_loss : 2.151883 , test loss : 2.071352\n",
      "epoch = 314 train_loss : 2.147661 , test loss : 2.067259\n",
      "epoch = 315 train_loss : 2.143346 , test loss : 2.063389\n",
      "epoch = 316 train_loss : 2.139094 , test loss : 2.059527\n",
      "epoch = 317 train_loss : 2.134954 , test loss : 2.055779\n",
      "epoch = 318 train_loss : 2.130684 , test loss : 2.052144\n",
      "epoch = 319 train_loss : 2.126409 , test loss : 2.048343\n",
      "epoch = 320 train_loss : 2.122204 , test loss : 2.044283\n",
      "epoch = 321 train_loss : 2.118105 , test loss : 2.040470\n",
      "epoch = 322 train_loss : 2.113889 , test loss : 2.036924\n",
      "epoch = 323 train_loss : 2.109687 , test loss : 2.033596\n",
      "epoch = 324 train_loss : 2.105476 , test loss : 2.029070\n",
      "epoch = 325 train_loss : 2.101339 , test loss : 2.025647\n",
      "epoch = 326 train_loss : 2.097081 , test loss : 2.022034\n",
      "epoch = 327 train_loss : 2.092895 , test loss : 2.018373\n",
      "epoch = 328 train_loss : 2.088707 , test loss : 2.014518\n",
      "epoch = 329 train_loss : 2.084544 , test loss : 2.011090\n",
      "epoch = 330 train_loss : 2.080289 , test loss : 2.007236\n",
      "epoch = 331 train_loss : 2.076252 , test loss : 2.003601\n",
      "epoch = 332 train_loss : 2.072038 , test loss : 2.000015\n",
      "epoch = 333 train_loss : 2.067862 , test loss : 1.996142\n",
      "epoch = 334 train_loss : 2.063818 , test loss : 1.992189\n",
      "epoch = 335 train_loss : 2.059613 , test loss : 1.988554\n",
      "epoch = 336 train_loss : 2.055505 , test loss : 1.985081\n",
      "epoch = 337 train_loss : 2.051474 , test loss : 1.981332\n",
      "epoch = 338 train_loss : 2.047375 , test loss : 1.977604\n",
      "epoch = 339 train_loss : 2.043304 , test loss : 1.973895\n",
      "epoch = 340 train_loss : 2.039242 , test loss : 1.970444\n",
      "epoch = 341 train_loss : 2.035172 , test loss : 1.966722\n",
      "epoch = 342 train_loss : 2.031158 , test loss : 1.963334\n",
      "epoch = 343 train_loss : 2.027013 , test loss : 1.959762\n",
      "epoch = 344 train_loss : 2.022956 , test loss : 1.956633\n",
      "epoch = 345 train_loss : 2.018871 , test loss : 1.952309\n",
      "epoch = 346 train_loss : 2.014833 , test loss : 1.949063\n",
      "epoch = 347 train_loss : 2.010816 , test loss : 1.945327\n",
      "epoch = 348 train_loss : 2.006799 , test loss : 1.941702\n",
      "epoch = 349 train_loss : 2.002785 , test loss : 1.938276\n",
      "epoch = 350 train_loss : 1.998790 , test loss : 1.934710\n",
      "epoch = 351 train_loss : 1.994864 , test loss : 1.931579\n",
      "epoch = 352 train_loss : 1.990898 , test loss : 1.928078\n",
      "epoch = 353 train_loss : 1.986938 , test loss : 1.924487\n",
      "epoch = 354 train_loss : 1.982990 , test loss : 1.920533\n",
      "epoch = 355 train_loss : 1.979109 , test loss : 1.917635\n",
      "epoch = 356 train_loss : 1.975101 , test loss : 1.913974\n",
      "epoch = 357 train_loss : 1.971180 , test loss : 1.910340\n",
      "epoch = 358 train_loss : 1.967232 , test loss : 1.906744\n",
      "epoch = 359 train_loss : 1.963359 , test loss : 1.903511\n",
      "epoch = 360 train_loss : 1.959423 , test loss : 1.899954\n",
      "epoch = 361 train_loss : 1.955554 , test loss : 1.896311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 362 train_loss : 1.951626 , test loss : 1.892648\n",
      "epoch = 363 train_loss : 1.947769 , test loss : 1.889984\n",
      "epoch = 364 train_loss : 1.943872 , test loss : 1.885786\n",
      "epoch = 365 train_loss : 1.940012 , test loss : 1.882592\n",
      "epoch = 366 train_loss : 1.936133 , test loss : 1.879353\n",
      "epoch = 367 train_loss : 1.932352 , test loss : 1.875930\n",
      "epoch = 368 train_loss : 1.928420 , test loss : 1.873242\n",
      "epoch = 369 train_loss : 1.924564 , test loss : 1.869446\n",
      "epoch = 370 train_loss : 1.920776 , test loss : 1.866362\n",
      "epoch = 371 train_loss : 1.916942 , test loss : 1.863049\n",
      "epoch = 372 train_loss : 1.913096 , test loss : 1.859247\n",
      "epoch = 373 train_loss : 1.909305 , test loss : 1.855655\n",
      "epoch = 374 train_loss : 1.905504 , test loss : 1.852167\n",
      "epoch = 375 train_loss : 1.901743 , test loss : 1.848727\n",
      "epoch = 376 train_loss : 1.897906 , test loss : 1.845694\n",
      "epoch = 377 train_loss : 1.894130 , test loss : 1.842262\n",
      "epoch = 378 train_loss : 1.890366 , test loss : 1.839064\n",
      "epoch = 379 train_loss : 1.886614 , test loss : 1.835990\n",
      "epoch = 380 train_loss : 1.882810 , test loss : 1.832467\n",
      "epoch = 381 train_loss : 1.879130 , test loss : 1.828825\n",
      "epoch = 382 train_loss : 1.875414 , test loss : 1.825573\n",
      "epoch = 383 train_loss : 1.871616 , test loss : 1.822545\n",
      "epoch = 384 train_loss : 1.867905 , test loss : 1.819343\n",
      "epoch = 385 train_loss : 1.864191 , test loss : 1.815819\n",
      "epoch = 386 train_loss : 1.860469 , test loss : 1.812867\n",
      "epoch = 387 train_loss : 1.856763 , test loss : 1.809719\n",
      "epoch = 388 train_loss : 1.853131 , test loss : 1.806827\n",
      "epoch = 389 train_loss : 1.849390 , test loss : 1.802496\n",
      "epoch = 390 train_loss : 1.845671 , test loss : 1.799757\n",
      "epoch = 391 train_loss : 1.842071 , test loss : 1.796573\n",
      "epoch = 392 train_loss : 1.838411 , test loss : 1.793543\n",
      "epoch = 393 train_loss : 1.834902 , test loss : 1.790607\n",
      "epoch = 394 train_loss : 1.831249 , test loss : 1.787002\n",
      "epoch = 395 train_loss : 1.827642 , test loss : 1.783514\n",
      "epoch = 396 train_loss : 1.824072 , test loss : 1.780552\n",
      "epoch = 397 train_loss : 1.820502 , test loss : 1.777725\n",
      "epoch = 398 train_loss : 1.816919 , test loss : 1.774431\n",
      "epoch = 399 train_loss : 1.813399 , test loss : 1.771694\n",
      "epoch = 400 train_loss : 1.809803 , test loss : 1.768714\n",
      "epoch = 401 train_loss : 1.806281 , test loss : 1.765277\n",
      "epoch = 402 train_loss : 1.802774 , test loss : 1.762107\n",
      "epoch = 403 train_loss : 1.799240 , test loss : 1.759170\n",
      "epoch = 404 train_loss : 1.795717 , test loss : 1.756281\n",
      "epoch = 405 train_loss : 1.792253 , test loss : 1.753101\n",
      "epoch = 406 train_loss : 1.788733 , test loss : 1.749895\n",
      "epoch = 407 train_loss : 1.785231 , test loss : 1.746852\n",
      "epoch = 408 train_loss : 1.781732 , test loss : 1.743842\n",
      "epoch = 409 train_loss : 1.778236 , test loss : 1.740427\n",
      "epoch = 410 train_loss : 1.774809 , test loss : 1.737595\n",
      "epoch = 411 train_loss : 1.771336 , test loss : 1.734400\n",
      "epoch = 412 train_loss : 1.767893 , test loss : 1.731479\n",
      "epoch = 413 train_loss : 1.764509 , test loss : 1.728444\n",
      "epoch = 414 train_loss : 1.761105 , test loss : 1.725232\n",
      "epoch = 415 train_loss : 1.757718 , test loss : 1.722683\n",
      "epoch = 416 train_loss : 1.754308 , test loss : 1.719609\n",
      "epoch = 417 train_loss : 1.750949 , test loss : 1.717111\n",
      "epoch = 418 train_loss : 1.747542 , test loss : 1.714154\n",
      "epoch = 419 train_loss : 1.744198 , test loss : 1.711082\n",
      "epoch = 420 train_loss : 1.740811 , test loss : 1.707964\n",
      "epoch = 421 train_loss : 1.737459 , test loss : 1.705113\n",
      "epoch = 422 train_loss : 1.734154 , test loss : 1.702022\n",
      "epoch = 423 train_loss : 1.730820 , test loss : 1.699194\n",
      "epoch = 424 train_loss : 1.727538 , test loss : 1.696225\n",
      "epoch = 425 train_loss : 1.724188 , test loss : 1.692947\n",
      "epoch = 426 train_loss : 1.720884 , test loss : 1.690163\n",
      "epoch = 427 train_loss : 1.717617 , test loss : 1.687908\n",
      "epoch = 428 train_loss : 1.714323 , test loss : 1.684582\n",
      "epoch = 429 train_loss : 1.711082 , test loss : 1.681345\n",
      "epoch = 430 train_loss : 1.707821 , test loss : 1.678929\n",
      "epoch = 431 train_loss : 1.704532 , test loss : 1.676013\n",
      "epoch = 432 train_loss : 1.701306 , test loss : 1.673223\n",
      "epoch = 433 train_loss : 1.698031 , test loss : 1.669997\n",
      "epoch = 434 train_loss : 1.694865 , test loss : 1.667506\n",
      "epoch = 435 train_loss : 1.691662 , test loss : 1.664673\n",
      "epoch = 436 train_loss : 1.688473 , test loss : 1.662761\n",
      "epoch = 437 train_loss : 1.685301 , test loss : 1.659998\n",
      "epoch = 438 train_loss : 1.682119 , test loss : 1.656489\n",
      "epoch = 439 train_loss : 1.678997 , test loss : 1.654048\n",
      "epoch = 440 train_loss : 1.675913 , test loss : 1.651197\n",
      "epoch = 441 train_loss : 1.672705 , test loss : 1.648624\n",
      "epoch = 442 train_loss : 1.669582 , test loss : 1.646250\n",
      "epoch = 443 train_loss : 1.666483 , test loss : 1.642973\n",
      "epoch = 444 train_loss : 1.663295 , test loss : 1.640477\n",
      "epoch = 445 train_loss : 1.660206 , test loss : 1.637113\n",
      "epoch = 446 train_loss : 1.657120 , test loss : 1.634988\n",
      "epoch = 447 train_loss : 1.654027 , test loss : 1.632331\n",
      "epoch = 448 train_loss : 1.650958 , test loss : 1.629270\n",
      "epoch = 449 train_loss : 1.647932 , test loss : 1.627052\n",
      "epoch = 450 train_loss : 1.644858 , test loss : 1.624249\n",
      "epoch = 451 train_loss : 1.641808 , test loss : 1.621294\n",
      "epoch = 452 train_loss : 1.638723 , test loss : 1.618804\n",
      "epoch = 453 train_loss : 1.635678 , test loss : 1.615578\n",
      "epoch = 454 train_loss : 1.632633 , test loss : 1.613588\n",
      "epoch = 455 train_loss : 1.629641 , test loss : 1.610950\n",
      "epoch = 456 train_loss : 1.626658 , test loss : 1.607977\n",
      "epoch = 457 train_loss : 1.623631 , test loss : 1.605458\n",
      "epoch = 458 train_loss : 1.620663 , test loss : 1.603110\n",
      "epoch = 459 train_loss : 1.617693 , test loss : 1.600857\n",
      "epoch = 460 train_loss : 1.614771 , test loss : 1.597451\n",
      "epoch = 461 train_loss : 1.611808 , test loss : 1.595394\n",
      "epoch = 462 train_loss : 1.608878 , test loss : 1.593413\n",
      "epoch = 463 train_loss : 1.605925 , test loss : 1.590642\n",
      "epoch = 464 train_loss : 1.603010 , test loss : 1.588411\n",
      "epoch = 465 train_loss : 1.600143 , test loss : 1.585621\n",
      "epoch = 466 train_loss : 1.597233 , test loss : 1.582728\n",
      "epoch = 467 train_loss : 1.594378 , test loss : 1.580905\n",
      "epoch = 468 train_loss : 1.591491 , test loss : 1.578119\n",
      "epoch = 469 train_loss : 1.588684 , test loss : 1.575621\n",
      "epoch = 470 train_loss : 1.585860 , test loss : 1.573351\n",
      "epoch = 471 train_loss : 1.583047 , test loss : 1.571453\n",
      "epoch = 472 train_loss : 1.580177 , test loss : 1.568296\n",
      "epoch = 473 train_loss : 1.577396 , test loss : 1.566206\n",
      "epoch = 474 train_loss : 1.574612 , test loss : 1.563172\n",
      "epoch = 475 train_loss : 1.571781 , test loss : 1.561088\n",
      "epoch = 476 train_loss : 1.569030 , test loss : 1.558460\n",
      "epoch = 477 train_loss : 1.566234 , test loss : 1.556425\n",
      "epoch = 478 train_loss : 1.563520 , test loss : 1.553751\n",
      "epoch = 479 train_loss : 1.560762 , test loss : 1.551927\n",
      "epoch = 480 train_loss : 1.558037 , test loss : 1.549462\n",
      "epoch = 481 train_loss : 1.555341 , test loss : 1.547388\n",
      "epoch = 482 train_loss : 1.552582 , test loss : 1.544579\n",
      "epoch = 483 train_loss : 1.549848 , test loss : 1.542259\n",
      "epoch = 484 train_loss : 1.547209 , test loss : 1.538989\n",
      "epoch = 485 train_loss : 1.544410 , test loss : 1.537763\n",
      "epoch = 486 train_loss : 1.541745 , test loss : 1.535131\n",
      "epoch = 487 train_loss : 1.539050 , test loss : 1.533230\n",
      "epoch = 488 train_loss : 1.536388 , test loss : 1.530867\n",
      "epoch = 489 train_loss : 1.533789 , test loss : 1.528478\n",
      "epoch = 490 train_loss : 1.531084 , test loss : 1.525651\n",
      "epoch = 491 train_loss : 1.528377 , test loss : 1.524146\n",
      "epoch = 492 train_loss : 1.525768 , test loss : 1.521664\n",
      "epoch = 493 train_loss : 1.523134 , test loss : 1.519304\n",
      "epoch = 494 train_loss : 1.520494 , test loss : 1.517424\n",
      "epoch = 495 train_loss : 1.517916 , test loss : 1.514694\n",
      "epoch = 496 train_loss : 1.515303 , test loss : 1.513096\n",
      "epoch = 497 train_loss : 1.512747 , test loss : 1.510467\n",
      "epoch = 498 train_loss : 1.510197 , test loss : 1.508318\n",
      "epoch = 499 train_loss : 1.507576 , test loss : 1.506036\n",
      "epoch = 500 train_loss : 1.505091 , test loss : 1.504125\n",
      "epoch = 501 train_loss : 1.502418 , test loss : 1.501562\n",
      "epoch = 502 train_loss : 1.499922 , test loss : 1.499506\n",
      "epoch = 503 train_loss : 1.497460 , test loss : 1.497077\n",
      "epoch = 504 train_loss : 1.494940 , test loss : 1.495492\n",
      "epoch = 505 train_loss : 1.492421 , test loss : 1.492718\n",
      "epoch = 506 train_loss : 1.489950 , test loss : 1.490759\n",
      "epoch = 507 train_loss : 1.487437 , test loss : 1.488573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 508 train_loss : 1.484958 , test loss : 1.486590\n",
      "epoch = 509 train_loss : 1.482587 , test loss : 1.484067\n",
      "epoch = 510 train_loss : 1.480094 , test loss : 1.482762\n",
      "epoch = 511 train_loss : 1.477722 , test loss : 1.480338\n",
      "epoch = 512 train_loss : 1.475287 , test loss : 1.478077\n",
      "epoch = 513 train_loss : 1.472803 , test loss : 1.475718\n",
      "epoch = 514 train_loss : 1.470441 , test loss : 1.473735\n",
      "epoch = 515 train_loss : 1.468085 , test loss : 1.471686\n",
      "epoch = 516 train_loss : 1.465698 , test loss : 1.469947\n",
      "epoch = 517 train_loss : 1.463323 , test loss : 1.467722\n",
      "epoch = 518 train_loss : 1.460927 , test loss : 1.465344\n",
      "epoch = 519 train_loss : 1.458640 , test loss : 1.463812\n",
      "epoch = 520 train_loss : 1.456264 , test loss : 1.461625\n",
      "epoch = 521 train_loss : 1.453915 , test loss : 1.459991\n",
      "epoch = 522 train_loss : 1.451617 , test loss : 1.457601\n",
      "epoch = 523 train_loss : 1.449349 , test loss : 1.455890\n",
      "epoch = 524 train_loss : 1.447102 , test loss : 1.453829\n",
      "epoch = 525 train_loss : 1.444804 , test loss : 1.451501\n",
      "epoch = 526 train_loss : 1.442499 , test loss : 1.449793\n",
      "epoch = 527 train_loss : 1.440304 , test loss : 1.448949\n",
      "epoch = 528 train_loss : 1.437995 , test loss : 1.446454\n",
      "epoch = 529 train_loss : 1.435853 , test loss : 1.443945\n",
      "epoch = 530 train_loss : 1.433576 , test loss : 1.442591\n",
      "epoch = 531 train_loss : 1.431388 , test loss : 1.440683\n",
      "epoch = 532 train_loss : 1.429212 , test loss : 1.438792\n",
      "epoch = 533 train_loss : 1.427061 , test loss : 1.437166\n",
      "epoch = 534 train_loss : 1.424905 , test loss : 1.434978\n",
      "epoch = 535 train_loss : 1.422770 , test loss : 1.433795\n",
      "epoch = 536 train_loss : 1.420605 , test loss : 1.431725\n",
      "epoch = 537 train_loss : 1.418455 , test loss : 1.429351\n",
      "epoch = 538 train_loss : 1.416342 , test loss : 1.427750\n",
      "epoch = 539 train_loss : 1.414209 , test loss : 1.426463\n",
      "epoch = 540 train_loss : 1.412060 , test loss : 1.424092\n",
      "epoch = 541 train_loss : 1.409950 , test loss : 1.422437\n",
      "epoch = 542 train_loss : 1.407866 , test loss : 1.420960\n",
      "epoch = 543 train_loss : 1.405807 , test loss : 1.419210\n",
      "epoch = 544 train_loss : 1.403713 , test loss : 1.417056\n",
      "epoch = 545 train_loss : 1.401657 , test loss : 1.415518\n",
      "epoch = 546 train_loss : 1.399585 , test loss : 1.413985\n",
      "epoch = 547 train_loss : 1.397554 , test loss : 1.411978\n",
      "epoch = 548 train_loss : 1.395545 , test loss : 1.411070\n",
      "epoch = 549 train_loss : 1.393485 , test loss : 1.408372\n",
      "epoch = 550 train_loss : 1.391455 , test loss : 1.406643\n",
      "epoch = 551 train_loss : 1.389466 , test loss : 1.405352\n",
      "epoch = 552 train_loss : 1.387489 , test loss : 1.403608\n",
      "epoch = 553 train_loss : 1.385511 , test loss : 1.402258\n",
      "epoch = 554 train_loss : 1.383453 , test loss : 1.400113\n",
      "epoch = 555 train_loss : 1.381459 , test loss : 1.398835\n",
      "epoch = 556 train_loss : 1.379504 , test loss : 1.397001\n",
      "epoch = 557 train_loss : 1.377563 , test loss : 1.395110\n",
      "epoch = 558 train_loss : 1.375574 , test loss : 1.393723\n",
      "epoch = 559 train_loss : 1.373644 , test loss : 1.391612\n",
      "epoch = 560 train_loss : 1.371699 , test loss : 1.390115\n",
      "epoch = 561 train_loss : 1.369711 , test loss : 1.389181\n",
      "epoch = 562 train_loss : 1.367810 , test loss : 1.387592\n",
      "epoch = 563 train_loss : 1.365897 , test loss : 1.386101\n",
      "epoch = 564 train_loss : 1.364001 , test loss : 1.384156\n",
      "epoch = 565 train_loss : 1.362020 , test loss : 1.382707\n",
      "epoch = 566 train_loss : 1.360167 , test loss : 1.380999\n",
      "epoch = 567 train_loss : 1.358251 , test loss : 1.379450\n",
      "epoch = 568 train_loss : 1.356364 , test loss : 1.377302\n",
      "epoch = 569 train_loss : 1.354442 , test loss : 1.375791\n",
      "epoch = 570 train_loss : 1.352595 , test loss : 1.374503\n",
      "epoch = 571 train_loss : 1.350781 , test loss : 1.372422\n",
      "epoch = 572 train_loss : 1.348876 , test loss : 1.372157\n",
      "epoch = 573 train_loss : 1.347018 , test loss : 1.370293\n",
      "epoch = 574 train_loss : 1.345141 , test loss : 1.368355\n",
      "epoch = 575 train_loss : 1.343349 , test loss : 1.366696\n",
      "epoch = 576 train_loss : 1.341501 , test loss : 1.365649\n",
      "epoch = 577 train_loss : 1.339680 , test loss : 1.364218\n",
      "epoch = 578 train_loss : 1.337864 , test loss : 1.362540\n",
      "epoch = 579 train_loss : 1.336077 , test loss : 1.360596\n",
      "epoch = 580 train_loss : 1.334278 , test loss : 1.359169\n",
      "epoch = 581 train_loss : 1.332451 , test loss : 1.358002\n",
      "epoch = 582 train_loss : 1.330733 , test loss : 1.356457\n",
      "epoch = 583 train_loss : 1.328959 , test loss : 1.354790\n",
      "epoch = 584 train_loss : 1.327192 , test loss : 1.353560\n",
      "epoch = 585 train_loss : 1.325407 , test loss : 1.352011\n",
      "epoch = 586 train_loss : 1.323701 , test loss : 1.350720\n",
      "epoch = 587 train_loss : 1.321920 , test loss : 1.348680\n",
      "epoch = 588 train_loss : 1.320232 , test loss : 1.348338\n",
      "epoch = 589 train_loss : 1.318489 , test loss : 1.346362\n",
      "epoch = 590 train_loss : 1.316763 , test loss : 1.344926\n",
      "epoch = 591 train_loss : 1.315048 , test loss : 1.343594\n",
      "epoch = 592 train_loss : 1.313397 , test loss : 1.342120\n",
      "epoch = 593 train_loss : 1.311730 , test loss : 1.340666\n",
      "epoch = 594 train_loss : 1.310067 , test loss : 1.339224\n",
      "epoch = 595 train_loss : 1.308420 , test loss : 1.338178\n",
      "epoch = 596 train_loss : 1.306778 , test loss : 1.336461\n",
      "epoch = 597 train_loss : 1.305164 , test loss : 1.335431\n",
      "epoch = 598 train_loss : 1.303566 , test loss : 1.334007\n",
      "epoch = 599 train_loss : 1.301928 , test loss : 1.332373\n",
      "epoch = 600 train_loss : 1.300294 , test loss : 1.330731\n",
      "epoch = 601 train_loss : 1.298743 , test loss : 1.330463\n",
      "epoch = 602 train_loss : 1.297121 , test loss : 1.329298\n",
      "epoch = 603 train_loss : 1.295548 , test loss : 1.327433\n",
      "epoch = 604 train_loss : 1.293922 , test loss : 1.326043\n",
      "epoch = 605 train_loss : 1.292384 , test loss : 1.325757\n",
      "epoch = 606 train_loss : 1.290771 , test loss : 1.323463\n",
      "epoch = 607 train_loss : 1.289204 , test loss : 1.322750\n",
      "epoch = 608 train_loss : 1.287668 , test loss : 1.321086\n",
      "epoch = 609 train_loss : 1.286102 , test loss : 1.320208\n",
      "epoch = 610 train_loss : 1.284681 , test loss : 1.318078\n",
      "epoch = 611 train_loss : 1.283023 , test loss : 1.317313\n",
      "epoch = 612 train_loss : 1.281512 , test loss : 1.316472\n",
      "epoch = 613 train_loss : 1.280059 , test loss : 1.315027\n",
      "epoch = 614 train_loss : 1.278497 , test loss : 1.314221\n",
      "epoch = 615 train_loss : 1.277017 , test loss : 1.312248\n",
      "epoch = 616 train_loss : 1.275517 , test loss : 1.311103\n",
      "epoch = 617 train_loss : 1.274016 , test loss : 1.310516\n",
      "epoch = 618 train_loss : 1.272524 , test loss : 1.309129\n",
      "epoch = 619 train_loss : 1.271092 , test loss : 1.307457\n",
      "epoch = 620 train_loss : 1.269624 , test loss : 1.306417\n",
      "epoch = 621 train_loss : 1.268146 , test loss : 1.305348\n",
      "epoch = 622 train_loss : 1.266742 , test loss : 1.304101\n",
      "epoch = 623 train_loss : 1.265254 , test loss : 1.303111\n",
      "epoch = 624 train_loss : 1.263806 , test loss : 1.302331\n",
      "epoch = 625 train_loss : 1.262401 , test loss : 1.300590\n",
      "epoch = 626 train_loss : 1.260992 , test loss : 1.299708\n",
      "epoch = 627 train_loss : 1.259668 , test loss : 1.297938\n",
      "epoch = 628 train_loss : 1.258161 , test loss : 1.297342\n",
      "epoch = 629 train_loss : 1.256775 , test loss : 1.296953\n",
      "epoch = 630 train_loss : 1.255361 , test loss : 1.295398\n",
      "epoch = 631 train_loss : 1.253929 , test loss : 1.294088\n",
      "epoch = 632 train_loss : 1.252647 , test loss : 1.292542\n",
      "epoch = 633 train_loss : 1.251217 , test loss : 1.292332\n",
      "epoch = 634 train_loss : 1.249937 , test loss : 1.291405\n",
      "epoch = 635 train_loss : 1.248515 , test loss : 1.289820\n",
      "epoch = 636 train_loss : 1.247137 , test loss : 1.288696\n",
      "epoch = 637 train_loss : 1.245948 , test loss : 1.286665\n",
      "epoch = 638 train_loss : 1.244473 , test loss : 1.286369\n",
      "epoch = 639 train_loss : 1.243171 , test loss : 1.285990\n",
      "epoch = 640 train_loss : 1.241808 , test loss : 1.284258\n",
      "epoch = 641 train_loss : 1.240502 , test loss : 1.282784\n",
      "epoch = 642 train_loss : 1.239145 , test loss : 1.282249\n",
      "epoch = 643 train_loss : 1.237945 , test loss : 1.281818\n",
      "epoch = 644 train_loss : 1.236656 , test loss : 1.280067\n",
      "epoch = 645 train_loss : 1.235321 , test loss : 1.279886\n",
      "epoch = 646 train_loss : 1.233969 , test loss : 1.278286\n",
      "epoch = 647 train_loss : 1.232739 , test loss : 1.276816\n",
      "epoch = 648 train_loss : 1.231469 , test loss : 1.276498\n",
      "epoch = 649 train_loss : 1.230145 , test loss : 1.274629\n",
      "epoch = 650 train_loss : 1.228889 , test loss : 1.274108\n",
      "epoch = 651 train_loss : 1.227620 , test loss : 1.272971\n",
      "epoch = 652 train_loss : 1.226377 , test loss : 1.272325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 653 train_loss : 1.225119 , test loss : 1.270556\n",
      "epoch = 654 train_loss : 1.223896 , test loss : 1.269820\n",
      "epoch = 655 train_loss : 1.222624 , test loss : 1.269078\n",
      "epoch = 656 train_loss : 1.221428 , test loss : 1.267976\n",
      "epoch = 657 train_loss : 1.220164 , test loss : 1.267207\n",
      "epoch = 658 train_loss : 1.218965 , test loss : 1.266989\n",
      "epoch = 659 train_loss : 1.217731 , test loss : 1.265864\n",
      "epoch = 660 train_loss : 1.216522 , test loss : 1.264452\n",
      "epoch = 661 train_loss : 1.215306 , test loss : 1.263650\n",
      "epoch = 662 train_loss : 1.214098 , test loss : 1.262387\n",
      "epoch = 663 train_loss : 1.212912 , test loss : 1.261691\n",
      "epoch = 664 train_loss : 1.211765 , test loss : 1.260482\n",
      "epoch = 665 train_loss : 1.210521 , test loss : 1.259484\n",
      "epoch = 666 train_loss : 1.209369 , test loss : 1.259161\n",
      "epoch = 667 train_loss : 1.208180 , test loss : 1.258232\n",
      "epoch = 668 train_loss : 1.207039 , test loss : 1.257702\n",
      "epoch = 669 train_loss : 1.205859 , test loss : 1.256323\n",
      "epoch = 670 train_loss : 1.204711 , test loss : 1.255493\n",
      "epoch = 671 train_loss : 1.203568 , test loss : 1.254081\n",
      "epoch = 672 train_loss : 1.202369 , test loss : 1.253111\n",
      "epoch = 673 train_loss : 1.201235 , test loss : 1.252913\n",
      "epoch = 674 train_loss : 1.200107 , test loss : 1.251953\n",
      "epoch = 675 train_loss : 1.199004 , test loss : 1.250210\n",
      "epoch = 676 train_loss : 1.197852 , test loss : 1.250109\n",
      "epoch = 677 train_loss : 1.196789 , test loss : 1.249297\n",
      "epoch = 678 train_loss : 1.195619 , test loss : 1.248516\n",
      "epoch = 679 train_loss : 1.194530 , test loss : 1.247612\n",
      "epoch = 680 train_loss : 1.193405 , test loss : 1.246930\n",
      "epoch = 681 train_loss : 1.192307 , test loss : 1.245687\n",
      "epoch = 682 train_loss : 1.191195 , test loss : 1.245625\n",
      "epoch = 683 train_loss : 1.190122 , test loss : 1.244118\n",
      "epoch = 684 train_loss : 1.189029 , test loss : 1.243200\n",
      "epoch = 685 train_loss : 1.187952 , test loss : 1.243070\n",
      "epoch = 686 train_loss : 1.186934 , test loss : 1.241820\n",
      "epoch = 687 train_loss : 1.185873 , test loss : 1.240583\n",
      "epoch = 688 train_loss : 1.184782 , test loss : 1.239808\n",
      "epoch = 690 train_loss : 1.182641 , test loss : 1.238507\n",
      "epoch = 691 train_loss : 1.181601 , test loss : 1.237377\n",
      "epoch = 692 train_loss : 1.180547 , test loss : 1.236725\n",
      "epoch = 693 train_loss : 1.179541 , test loss : 1.236073\n",
      "epoch = 694 train_loss : 1.178463 , test loss : 1.235040\n",
      "epoch = 695 train_loss : 1.177427 , test loss : 1.234462\n",
      "epoch = 696 train_loss : 1.176386 , test loss : 1.233340\n",
      "epoch = 697 train_loss : 1.175338 , test loss : 1.232679\n",
      "epoch = 698 train_loss : 1.174340 , test loss : 1.232076\n",
      "epoch = 699 train_loss : 1.173333 , test loss : 1.231133\n",
      "epoch = 701 train_loss : 1.171353 , test loss : 1.229581\n",
      "epoch = 702 train_loss : 1.170289 , test loss : 1.229441\n",
      "epoch = 703 train_loss : 1.169303 , test loss : 1.228252\n",
      "epoch = 704 train_loss : 1.168311 , test loss : 1.227600\n",
      "epoch = 705 train_loss : 1.167324 , test loss : 1.226600\n",
      "epoch = 706 train_loss : 1.166381 , test loss : 1.225786\n",
      "epoch = 707 train_loss : 1.165352 , test loss : 1.225612\n",
      "epoch = 708 train_loss : 1.164376 , test loss : 1.224852\n",
      "epoch = 709 train_loss : 1.163383 , test loss : 1.223823\n",
      "epoch = 710 train_loss : 1.162420 , test loss : 1.223210\n",
      "epoch = 711 train_loss : 1.161445 , test loss : 1.222488\n",
      "epoch = 712 train_loss : 1.160478 , test loss : 1.221536\n",
      "epoch = 713 train_loss : 1.159534 , test loss : 1.221082\n",
      "epoch = 714 train_loss : 1.158565 , test loss : 1.220600\n",
      "epoch = 715 train_loss : 1.157621 , test loss : 1.219710\n",
      "epoch = 716 train_loss : 1.156646 , test loss : 1.219186\n",
      "epoch = 717 train_loss : 1.155734 , test loss : 1.218327\n",
      "epoch = 718 train_loss : 1.154775 , test loss : 1.217517\n",
      "epoch = 719 train_loss : 1.153823 , test loss : 1.216637\n",
      "epoch = 720 train_loss : 1.152921 , test loss : 1.215856\n",
      "epoch = 722 train_loss : 1.151055 , test loss : 1.214369\n",
      "epoch = 723 train_loss : 1.150155 , test loss : 1.213807\n",
      "epoch = 724 train_loss : 1.149211 , test loss : 1.213261\n",
      "epoch = 725 train_loss : 1.148321 , test loss : 1.212843\n",
      "epoch = 726 train_loss : 1.147381 , test loss : 1.211685\n",
      "epoch = 727 train_loss : 1.146562 , test loss : 1.210997\n",
      "epoch = 728 train_loss : 1.145564 , test loss : 1.210665\n",
      "epoch = 729 train_loss : 1.144700 , test loss : 1.210168\n",
      "epoch = 730 train_loss : 1.143779 , test loss : 1.209193\n",
      "epoch = 731 train_loss : 1.142897 , test loss : 1.208851\n",
      "epoch = 732 train_loss : 1.142023 , test loss : 1.207784\n",
      "epoch = 733 train_loss : 1.141121 , test loss : 1.207500\n",
      "epoch = 734 train_loss : 1.140252 , test loss : 1.206610\n",
      "epoch = 735 train_loss : 1.139390 , test loss : 1.205955\n",
      "epoch = 737 train_loss : 1.137649 , test loss : 1.204952\n",
      "epoch = 738 train_loss : 1.136737 , test loss : 1.204031\n",
      "epoch = 739 train_loss : 1.135873 , test loss : 1.203761\n",
      "epoch = 740 train_loss : 1.135015 , test loss : 1.203185\n",
      "epoch = 741 train_loss : 1.134167 , test loss : 1.202341\n",
      "epoch = 742 train_loss : 1.133318 , test loss : 1.201856\n",
      "epoch = 743 train_loss : 1.132465 , test loss : 1.200573\n",
      "epoch = 744 train_loss : 1.131605 , test loss : 1.200022\n",
      "epoch = 745 train_loss : 1.130767 , test loss : 1.199625\n",
      "epoch = 746 train_loss : 1.129920 , test loss : 1.199009\n",
      "epoch = 747 train_loss : 1.129133 , test loss : 1.198993\n",
      "epoch = 748 train_loss : 1.128251 , test loss : 1.197532\n",
      "epoch = 749 train_loss : 1.127445 , test loss : 1.197245\n",
      "epoch = 751 train_loss : 1.125776 , test loss : 1.196060\n",
      "epoch = 753 train_loss : 1.124127 , test loss : 1.195154\n",
      "epoch = 754 train_loss : 1.123342 , test loss : 1.194175\n",
      "epoch = 755 train_loss : 1.122491 , test loss : 1.193291\n",
      "epoch = 757 train_loss : 1.120866 , test loss : 1.192594\n",
      "epoch = 758 train_loss : 1.120085 , test loss : 1.192303\n",
      "epoch = 759 train_loss : 1.119287 , test loss : 1.191301\n",
      "epoch = 760 train_loss : 1.118459 , test loss : 1.191211\n",
      "epoch = 761 train_loss : 1.117666 , test loss : 1.190199\n",
      "epoch = 762 train_loss : 1.116876 , test loss : 1.189838\n",
      "epoch = 763 train_loss : 1.116092 , test loss : 1.189330\n",
      "epoch = 764 train_loss : 1.115320 , test loss : 1.188712\n",
      "epoch = 765 train_loss : 1.114518 , test loss : 1.188199\n",
      "epoch = 766 train_loss : 1.113776 , test loss : 1.186822\n",
      "epoch = 768 train_loss : 1.112188 , test loss : 1.186772\n",
      "epoch = 769 train_loss : 1.111431 , test loss : 1.185982\n",
      "epoch = 770 train_loss : 1.110654 , test loss : 1.184866\n",
      "epoch = 772 train_loss : 1.109165 , test loss : 1.183805\n",
      "epoch = 773 train_loss : 1.108378 , test loss : 1.183080\n",
      "epoch = 774 train_loss : 1.107631 , test loss : 1.182893\n",
      "epoch = 776 train_loss : 1.106146 , test loss : 1.182855\n",
      "epoch = 777 train_loss : 1.105381 , test loss : 1.181608\n",
      "epoch = 778 train_loss : 1.104646 , test loss : 1.181037\n",
      "epoch = 780 train_loss : 1.103154 , test loss : 1.180236\n",
      "epoch = 781 train_loss : 1.102456 , test loss : 1.179520\n",
      "epoch = 783 train_loss : 1.100979 , test loss : 1.178320\n",
      "epoch = 784 train_loss : 1.100223 , test loss : 1.177896\n",
      "epoch = 785 train_loss : 1.099496 , test loss : 1.177743\n",
      "epoch = 786 train_loss : 1.098797 , test loss : 1.177207\n",
      "epoch = 787 train_loss : 1.098073 , test loss : 1.176910\n",
      "epoch = 788 train_loss : 1.097338 , test loss : 1.176419\n",
      "epoch = 789 train_loss : 1.096650 , test loss : 1.175458\n",
      "epoch = 791 train_loss : 1.095236 , test loss : 1.174905\n",
      "epoch = 792 train_loss : 1.094523 , test loss : 1.174022\n",
      "epoch = 793 train_loss : 1.093825 , test loss : 1.173564\n",
      "epoch = 794 train_loss : 1.093114 , test loss : 1.173268\n",
      "epoch = 795 train_loss : 1.092442 , test loss : 1.173032\n",
      "epoch = 796 train_loss : 1.091707 , test loss : 1.172554\n",
      "epoch = 797 train_loss : 1.091011 , test loss : 1.172175\n",
      "epoch = 798 train_loss : 1.090329 , test loss : 1.171803\n",
      "epoch = 799 train_loss : 1.089735 , test loss : 1.170840\n",
      "epoch = 801 train_loss : 1.088321 , test loss : 1.170110\n",
      "epoch = 802 train_loss : 1.087587 , test loss : 1.169866\n",
      "epoch = 803 train_loss : 1.086922 , test loss : 1.169460\n",
      "epoch = 805 train_loss : 1.085588 , test loss : 1.168493\n",
      "epoch = 806 train_loss : 1.084935 , test loss : 1.167243\n",
      "epoch = 808 train_loss : 1.083590 , test loss : 1.166858\n",
      "epoch = 809 train_loss : 1.082934 , test loss : 1.166592\n",
      "epoch = 810 train_loss : 1.082256 , test loss : 1.165961\n",
      "epoch = 812 train_loss : 1.080940 , test loss : 1.165438\n",
      "epoch = 813 train_loss : 1.080303 , test loss : 1.164321\n",
      "epoch = 814 train_loss : 1.079641 , test loss : 1.163716\n",
      "epoch = 815 train_loss : 1.078998 , test loss : 1.163476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 816 train_loss : 1.078328 , test loss : 1.163398\n",
      "epoch = 817 train_loss : 1.077692 , test loss : 1.162786\n",
      "epoch = 818 train_loss : 1.077077 , test loss : 1.162132\n",
      "epoch = 819 train_loss : 1.076422 , test loss : 1.162005\n",
      "epoch = 820 train_loss : 1.075774 , test loss : 1.161522\n",
      "epoch = 821 train_loss : 1.075150 , test loss : 1.161097\n",
      "epoch = 823 train_loss : 1.073925 , test loss : 1.160390\n",
      "epoch = 824 train_loss : 1.073329 , test loss : 1.159900\n",
      "epoch = 825 train_loss : 1.072665 , test loss : 1.159509\n",
      "epoch = 826 train_loss : 1.072063 , test loss : 1.158854\n",
      "epoch = 827 train_loss : 1.071430 , test loss : 1.158599\n",
      "epoch = 829 train_loss : 1.070168 , test loss : 1.158265\n",
      "epoch = 830 train_loss : 1.069584 , test loss : 1.157671\n",
      "epoch = 831 train_loss : 1.068948 , test loss : 1.157107\n",
      "epoch = 832 train_loss : 1.068326 , test loss : 1.156975\n",
      "epoch = 834 train_loss : 1.067127 , test loss : 1.155833\n",
      "epoch = 835 train_loss : 1.066534 , test loss : 1.155565\n",
      "epoch = 836 train_loss : 1.065903 , test loss : 1.155283\n",
      "epoch = 838 train_loss : 1.064711 , test loss : 1.155008\n",
      "epoch = 839 train_loss : 1.064121 , test loss : 1.154058\n",
      "epoch = 840 train_loss : 1.063516 , test loss : 1.153697\n",
      "epoch = 841 train_loss : 1.062944 , test loss : 1.153166\n",
      "epoch = 842 train_loss : 1.062399 , test loss : 1.152638\n",
      "epoch = 844 train_loss : 1.061168 , test loss : 1.152294\n",
      "epoch = 845 train_loss : 1.060618 , test loss : 1.151562\n",
      "epoch = 846 train_loss : 1.059983 , test loss : 1.151309\n",
      "epoch = 847 train_loss : 1.059402 , test loss : 1.150982\n",
      "epoch = 849 train_loss : 1.058258 , test loss : 1.150591\n",
      "epoch = 850 train_loss : 1.057684 , test loss : 1.150103\n",
      "epoch = 851 train_loss : 1.057132 , test loss : 1.149657\n",
      "epoch = 852 train_loss : 1.056575 , test loss : 1.149090\n",
      "epoch = 854 train_loss : 1.055386 , test loss : 1.148963\n",
      "epoch = 855 train_loss : 1.054828 , test loss : 1.148568\n",
      "epoch = 856 train_loss : 1.054250 , test loss : 1.148175\n",
      "epoch = 858 train_loss : 1.053114 , test loss : 1.147259\n",
      "epoch = 860 train_loss : 1.051987 , test loss : 1.147041\n",
      "epoch = 861 train_loss : 1.051414 , test loss : 1.146870\n",
      "epoch = 862 train_loss : 1.050868 , test loss : 1.146407\n",
      "epoch = 864 train_loss : 1.049774 , test loss : 1.145436\n",
      "epoch = 865 train_loss : 1.049223 , test loss : 1.145032\n",
      "epoch = 867 train_loss : 1.048144 , test loss : 1.144520\n",
      "epoch = 868 train_loss : 1.047548 , test loss : 1.144225\n",
      "epoch = 869 train_loss : 1.047035 , test loss : 1.143750\n",
      "epoch = 870 train_loss : 1.046470 , test loss : 1.143636\n",
      "epoch = 871 train_loss : 1.045915 , test loss : 1.142979\n",
      "epoch = 873 train_loss : 1.044823 , test loss : 1.142926\n",
      "epoch = 874 train_loss : 1.044307 , test loss : 1.142109\n",
      "epoch = 875 train_loss : 1.043783 , test loss : 1.141288\n",
      "epoch = 877 train_loss : 1.042710 , test loss : 1.141236\n",
      "epoch = 878 train_loss : 1.042185 , test loss : 1.141024\n",
      "epoch = 880 train_loss : 1.041124 , test loss : 1.140720\n",
      "epoch = 881 train_loss : 1.040564 , test loss : 1.139816\n",
      "epoch = 882 train_loss : 1.040043 , test loss : 1.139733\n",
      "epoch = 883 train_loss : 1.039604 , test loss : 1.139041\n",
      "epoch = 886 train_loss : 1.038002 , test loss : 1.138429\n",
      "epoch = 887 train_loss : 1.037479 , test loss : 1.138110\n",
      "epoch = 890 train_loss : 1.035920 , test loss : 1.137926\n",
      "epoch = 891 train_loss : 1.035380 , test loss : 1.137447\n",
      "epoch = 892 train_loss : 1.034895 , test loss : 1.136534\n",
      "epoch = 893 train_loss : 1.034397 , test loss : 1.136408\n",
      "epoch = 895 train_loss : 1.033359 , test loss : 1.136267\n",
      "epoch = 897 train_loss : 1.032363 , test loss : 1.135699\n",
      "epoch = 898 train_loss : 1.031850 , test loss : 1.135211\n",
      "epoch = 899 train_loss : 1.031357 , test loss : 1.134549\n",
      "epoch = 900 train_loss : 1.030851 , test loss : 1.134451\n",
      "epoch = 902 train_loss : 1.029867 , test loss : 1.134141\n",
      "epoch = 904 train_loss : 1.028864 , test loss : 1.133858\n",
      "epoch = 905 train_loss : 1.028397 , test loss : 1.133107\n",
      "epoch = 906 train_loss : 1.027924 , test loss : 1.132980\n",
      "epoch = 908 train_loss : 1.026933 , test loss : 1.132880\n",
      "epoch = 909 train_loss : 1.026438 , test loss : 1.132683\n",
      "epoch = 910 train_loss : 1.025932 , test loss : 1.131902\n",
      "epoch = 911 train_loss : 1.025470 , test loss : 1.131806\n",
      "epoch = 912 train_loss : 1.024952 , test loss : 1.131404\n",
      "epoch = 913 train_loss : 1.024519 , test loss : 1.130475\n",
      "epoch = 917 train_loss : 1.022576 , test loss : 1.130280\n",
      "epoch = 918 train_loss : 1.022082 , test loss : 1.129922\n",
      "epoch = 920 train_loss : 1.021145 , test loss : 1.129389\n",
      "epoch = 922 train_loss : 1.020203 , test loss : 1.129024\n",
      "epoch = 923 train_loss : 1.019730 , test loss : 1.128531\n",
      "epoch = 924 train_loss : 1.019295 , test loss : 1.128150\n",
      "epoch = 926 train_loss : 1.018341 , test loss : 1.128091\n",
      "epoch = 927 train_loss : 1.017862 , test loss : 1.127714\n",
      "epoch = 928 train_loss : 1.017386 , test loss : 1.127116\n",
      "epoch = 929 train_loss : 1.016936 , test loss : 1.126855\n",
      "epoch = 931 train_loss : 1.016006 , test loss : 1.126823\n",
      "epoch = 932 train_loss : 1.015558 , test loss : 1.126471\n",
      "epoch = 933 train_loss : 1.015106 , test loss : 1.126128\n",
      "epoch = 936 train_loss : 1.013742 , test loss : 1.125369\n",
      "epoch = 939 train_loss : 1.012351 , test loss : 1.124911\n",
      "epoch = 940 train_loss : 1.011904 , test loss : 1.124432\n",
      "epoch = 941 train_loss : 1.011443 , test loss : 1.124431\n",
      "epoch = 942 train_loss : 1.011029 , test loss : 1.124102\n",
      "epoch = 944 train_loss : 1.010100 , test loss : 1.123506\n",
      "epoch = 945 train_loss : 1.009662 , test loss : 1.123464\n",
      "epoch = 946 train_loss : 1.009210 , test loss : 1.123058\n",
      "epoch = 947 train_loss : 1.008771 , test loss : 1.122770\n",
      "epoch = 949 train_loss : 1.007885 , test loss : 1.122165\n",
      "epoch = 951 train_loss : 1.006978 , test loss : 1.122097\n",
      "epoch = 952 train_loss : 1.006524 , test loss : 1.121812\n",
      "epoch = 955 train_loss : 1.005194 , test loss : 1.120753\n",
      "epoch = 959 train_loss : 1.003422 , test loss : 1.120583\n",
      "epoch = 960 train_loss : 1.003014 , test loss : 1.120112\n",
      "epoch = 962 train_loss : 1.002120 , test loss : 1.120109\n",
      "epoch = 963 train_loss : 1.001669 , test loss : 1.119459\n",
      "epoch = 964 train_loss : 1.001242 , test loss : 1.119454\n",
      "epoch = 965 train_loss : 1.000805 , test loss : 1.119333\n",
      "epoch = 966 train_loss : 1.000426 , test loss : 1.119293\n",
      "epoch = 969 train_loss : 0.999098 , test loss : 1.118341\n",
      "epoch = 970 train_loss : 0.998672 , test loss : 1.118265\n",
      "epoch = 971 train_loss : 0.998260 , test loss : 1.117821\n",
      "epoch = 972 train_loss : 0.997813 , test loss : 1.117599\n",
      "epoch = 976 train_loss : 0.996126 , test loss : 1.116646\n",
      "epoch = 980 train_loss : 0.994456 , test loss : 1.115943\n",
      "epoch = 984 train_loss : 0.992800 , test loss : 1.115087\n",
      "epoch = 986 train_loss : 0.991981 , test loss : 1.114796\n",
      "epoch = 988 train_loss : 0.991175 , test loss : 1.114785\n",
      "epoch = 989 train_loss : 0.990779 , test loss : 1.113931\n",
      "epoch = 995 train_loss : 0.988321 , test loss : 1.113577\n",
      "epoch = 996 train_loss : 0.987921 , test loss : 1.113060\n",
      "epoch = 997 train_loss : 0.987545 , test loss : 1.112690\n",
      "epoch = 1001 train_loss : 0.985935 , test loss : 1.112253\n",
      "epoch = 1004 train_loss : 0.984747 , test loss : 1.111760\n",
      "epoch = 1005 train_loss : 0.984375 , test loss : 1.111526\n",
      "epoch = 1007 train_loss : 0.983625 , test loss : 1.111110\n",
      "epoch = 1008 train_loss : 0.983188 , test loss : 1.111073\n",
      "epoch = 1011 train_loss : 0.982031 , test loss : 1.110904\n",
      "epoch = 1012 train_loss : 0.981640 , test loss : 1.110745\n",
      "epoch = 1013 train_loss : 0.981309 , test loss : 1.109913\n",
      "epoch = 1016 train_loss : 0.980188 , test loss : 1.109837\n",
      "epoch = 1020 train_loss : 0.978571 , test loss : 1.109058\n",
      "epoch = 1023 train_loss : 0.977461 , test loss : 1.108819\n",
      "epoch = 1025 train_loss : 0.976708 , test loss : 1.108749\n",
      "epoch = 1026 train_loss : 0.976321 , test loss : 1.108109\n",
      "epoch = 1027 train_loss : 0.975940 , test loss : 1.107921\n",
      "epoch = 1030 train_loss : 0.974793 , test loss : 1.107915\n",
      "epoch = 1031 train_loss : 0.974434 , test loss : 1.107649\n",
      "epoch = 1033 train_loss : 0.973709 , test loss : 1.107475\n",
      "epoch = 1035 train_loss : 0.972998 , test loss : 1.106768\n",
      "epoch = 1039 train_loss : 0.971473 , test loss : 1.106402\n",
      "epoch = 1041 train_loss : 0.970716 , test loss : 1.106107\n",
      "epoch = 1043 train_loss : 0.969991 , test loss : 1.105658\n",
      "epoch = 1045 train_loss : 0.969258 , test loss : 1.105537\n",
      "epoch = 1047 train_loss : 0.968573 , test loss : 1.105019\n",
      "epoch = 1048 train_loss : 0.968207 , test loss : 1.104760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1054 train_loss : 0.965986 , test loss : 1.104574\n",
      "epoch = 1055 train_loss : 0.965617 , test loss : 1.104346\n",
      "epoch = 1056 train_loss : 0.965263 , test loss : 1.103967\n",
      "epoch = 1060 train_loss : 0.963912 , test loss : 1.103021\n",
      "epoch = 1068 train_loss : 0.961030 , test loss : 1.102408\n",
      "epoch = 1074 train_loss : 0.958901 , test loss : 1.102131\n",
      "epoch = 1076 train_loss : 0.958220 , test loss : 1.101920\n",
      "epoch = 1080 train_loss : 0.956813 , test loss : 1.101699\n",
      "epoch = 1081 train_loss : 0.956516 , test loss : 1.101006\n",
      "epoch = 1086 train_loss : 0.954819 , test loss : 1.100489\n",
      "epoch = 1089 train_loss : 0.953894 , test loss : 1.099829\n",
      "epoch = 1099 train_loss : 0.950410 , test loss : 1.099779\n",
      "epoch = 1100 train_loss : 0.950062 , test loss : 1.099276\n",
      "epoch = 1103 train_loss : 0.949055 , test loss : 1.099245\n",
      "epoch = 1104 train_loss : 0.948701 , test loss : 1.099200\n",
      "epoch = 1106 train_loss : 0.948040 , test loss : 1.099047\n",
      "epoch = 1107 train_loss : 0.947760 , test loss : 1.098664\n",
      "epoch = 1109 train_loss : 0.947099 , test loss : 1.098220\n",
      "epoch = 1112 train_loss : 0.946114 , test loss : 1.097908\n",
      "epoch = 1115 train_loss : 0.945303 , test loss : 1.097572\n",
      "epoch = 1124 train_loss : 0.942172 , test loss : 1.097559\n",
      "epoch = 1125 train_loss : 0.941895 , test loss : 1.097421\n",
      "epoch = 1127 train_loss : 0.941265 , test loss : 1.097002\n",
      "epoch = 1131 train_loss : 0.939979 , test loss : 1.096923\n",
      "epoch = 1133 train_loss : 0.939318 , test loss : 1.096768\n",
      "epoch = 1134 train_loss : 0.938988 , test loss : 1.096637\n",
      "epoch = 1137 train_loss : 0.938176 , test loss : 1.095834\n",
      "epoch = 1146 train_loss : 0.935225 , test loss : 1.095732\n",
      "epoch = 1150 train_loss : 0.934004 , test loss : 1.095689\n",
      "epoch = 1153 train_loss : 0.933137 , test loss : 1.095121\n",
      "epoch = 1163 train_loss : 0.930056 , test loss : 1.094699\n",
      "epoch = 1166 train_loss : 0.929212 , test loss : 1.094263\n",
      "epoch = 1176 train_loss : 0.926160 , test loss : 1.093855\n",
      "epoch = 1183 train_loss : 0.924065 , test loss : 1.093713\n",
      "epoch = 1185 train_loss : 0.923509 , test loss : 1.093411\n",
      "epoch = 1191 train_loss : 0.921753 , test loss : 1.092894\n",
      "epoch = 1204 train_loss : 0.918042 , test loss : 1.092654\n",
      "epoch = 1214 train_loss : 0.915090 , test loss : 1.092456\n",
      "epoch = 1216 train_loss : 0.914482 , test loss : 1.092427\n",
      "epoch = 1217 train_loss : 0.914195 , test loss : 1.092371\n",
      "epoch = 1221 train_loss : 0.913087 , test loss : 1.092164\n",
      "epoch = 1224 train_loss : 0.912211 , test loss : 1.091798\n",
      "epoch = 1225 train_loss : 0.911925 , test loss : 1.091780\n",
      "epoch = 1229 train_loss : 0.910895 , test loss : 1.091111\n",
      "epoch = 1233 train_loss : 0.909722 , test loss : 1.091083\n",
      "epoch = 1240 train_loss : 0.907790 , test loss : 1.091045\n",
      "epoch = 1248 train_loss : 0.905526 , test loss : 1.090687\n",
      "epoch = 1258 train_loss : 0.902790 , test loss : 1.090332\n",
      "epoch = 1269 train_loss : 0.899738 , test loss : 1.090206\n",
      "epoch = 1271 train_loss : 0.899189 , test loss : 1.090145\n",
      "epoch = 1272 train_loss : 0.898925 , test loss : 1.090033\n",
      "epoch = 1284 train_loss : 0.895741 , test loss : 1.089768\n",
      "epoch = 1297 train_loss : 0.892252 , test loss : 1.089766\n",
      "epoch = 1298 train_loss : 0.892034 , test loss : 1.089291\n",
      "epoch = 1306 train_loss : 0.889920 , test loss : 1.089200\n",
      "epoch = 1310 train_loss : 0.888865 , test loss : 1.089001\n",
      "epoch = 1317 train_loss : 0.887250 , test loss : 1.088645\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.887250,test loss : 1.088645\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.795560,total test loss mean : 1.116120 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],128),nn.ReLU(),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,5000,0.00001,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:50:45.792774Z",
     "start_time": "2021-12-30T06:46:47.604151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 4.921469 , test loss : 4.919907\n",
      "epoch = 2 train_loss : 2.872569 , test loss : 3.079181\n",
      "epoch = 3 train_loss : 2.350341 , test loss : 2.482507\n",
      "epoch = 4 train_loss : 2.115571 , test loss : 2.280147\n",
      "epoch = 5 train_loss : 1.976397 , test loss : 2.119133\n",
      "epoch = 6 train_loss : 1.844471 , test loss : 1.997985\n",
      "epoch = 7 train_loss : 1.744152 , test loss : 1.909790\n",
      "epoch = 8 train_loss : 1.643218 , test loss : 1.785140\n",
      "epoch = 9 train_loss : 1.580176 , test loss : 1.726007\n",
      "epoch = 10 train_loss : 1.501081 , test loss : 1.637497\n",
      "epoch = 11 train_loss : 1.450005 , test loss : 1.569525\n",
      "epoch = 12 train_loss : 1.401940 , test loss : 1.510709\n",
      "epoch = 13 train_loss : 1.357637 , test loss : 1.468948\n",
      "epoch = 14 train_loss : 1.309911 , test loss : 1.408424\n",
      "epoch = 16 train_loss : 1.256314 , test loss : 1.354624\n",
      "epoch = 17 train_loss : 1.239250 , test loss : 1.341222\n",
      "epoch = 18 train_loss : 1.212507 , test loss : 1.312310\n",
      "epoch = 19 train_loss : 1.208245 , test loss : 1.294210\n",
      "epoch = 21 train_loss : 1.175361 , test loss : 1.262374\n",
      "epoch = 23 train_loss : 1.140709 , test loss : 1.229440\n",
      "epoch = 24 train_loss : 1.125766 , test loss : 1.197588\n",
      "epoch = 27 train_loss : 1.107769 , test loss : 1.181500\n",
      "epoch = 31 train_loss : 1.085106 , test loss : 1.172055\n",
      "epoch = 33 train_loss : 1.082396 , test loss : 1.167913\n",
      "epoch = 34 train_loss : 1.092562 , test loss : 1.153345\n",
      "epoch = 37 train_loss : 1.064428 , test loss : 1.142428\n",
      "epoch = 41 train_loss : 1.056643 , test loss : 1.135416\n",
      "epoch = 45 train_loss : 1.043004 , test loss : 1.126740\n",
      "epoch = 46 train_loss : 1.041544 , test loss : 1.120840\n",
      "epoch = 51 train_loss : 1.032904 , test loss : 1.105004\n",
      "epoch = 160 train_loss : 1.016805 , test loss : 1.104766\n",
      "epoch = 164 train_loss : 1.023460 , test loss : 1.103805\n",
      "epoch = 197 train_loss : 1.022406 , test loss : 1.102376\n",
      "epoch = 290 train_loss : 1.016094 , test loss : 1.100874\n",
      "epoch = 292 train_loss : 1.019110 , test loss : 1.099152\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 1.019110,test loss : 1.099152\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 4.250223 , test loss : 4.620215\n",
      "epoch = 2 train_loss : 2.648348 , test loss : 2.948425\n",
      "epoch = 3 train_loss : 2.210908 , test loss : 2.519535\n",
      "epoch = 4 train_loss : 2.024412 , test loss : 2.324180\n",
      "epoch = 5 train_loss : 1.825195 , test loss : 2.138355\n",
      "epoch = 6 train_loss : 1.703978 , test loss : 1.994613\n",
      "epoch = 7 train_loss : 1.565340 , test loss : 1.861626\n",
      "epoch = 8 train_loss : 1.494229 , test loss : 1.780517\n",
      "epoch = 9 train_loss : 1.399122 , test loss : 1.698498\n",
      "epoch = 10 train_loss : 1.352056 , test loss : 1.629172\n",
      "epoch = 11 train_loss : 1.319113 , test loss : 1.579117\n",
      "epoch = 13 train_loss : 1.223672 , test loss : 1.502789\n",
      "epoch = 14 train_loss : 1.208355 , test loss : 1.461935\n",
      "epoch = 16 train_loss : 1.162894 , test loss : 1.397809\n",
      "epoch = 18 train_loss : 1.140358 , test loss : 1.375180\n",
      "epoch = 19 train_loss : 1.110907 , test loss : 1.366429\n",
      "epoch = 20 train_loss : 1.098815 , test loss : 1.346547\n",
      "epoch = 22 train_loss : 1.121754 , test loss : 1.331480\n",
      "epoch = 23 train_loss : 1.089964 , test loss : 1.294662\n",
      "epoch = 28 train_loss : 1.051135 , test loss : 1.261843\n",
      "epoch = 29 train_loss : 1.053688 , test loss : 1.260200\n",
      "epoch = 33 train_loss : 1.035256 , test loss : 1.236511\n",
      "epoch = 37 train_loss : 1.027890 , test loss : 1.209985\n",
      "epoch = 42 train_loss : 1.046792 , test loss : 1.207103\n",
      "epoch = 53 train_loss : 1.024455 , test loss : 1.205142\n",
      "epoch = 56 train_loss : 1.025361 , test loss : 1.190151\n",
      "epoch = 73 train_loss : 1.016802 , test loss : 1.187779\n",
      "epoch = 79 train_loss : 1.011231 , test loss : 1.181589\n",
      "epoch = 97 train_loss : 1.011162 , test loss : 1.180787\n",
      "epoch = 127 train_loss : 1.008049 , test loss : 1.174483\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 1.008049,test loss : 1.174483\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 5.104630 , test loss : 4.844357\n",
      "epoch = 2 train_loss : 2.844180 , test loss : 2.631221\n",
      "epoch = 3 train_loss : 2.414256 , test loss : 2.291463\n",
      "epoch = 4 train_loss : 2.176631 , test loss : 2.051809\n",
      "epoch = 5 train_loss : 2.028564 , test loss : 1.901653\n",
      "epoch = 6 train_loss : 1.864321 , test loss : 1.782643\n",
      "epoch = 7 train_loss : 1.736966 , test loss : 1.660460\n",
      "epoch = 8 train_loss : 1.639637 , test loss : 1.571709\n",
      "epoch = 9 train_loss : 1.542371 , test loss : 1.472421\n",
      "epoch = 10 train_loss : 1.449286 , test loss : 1.421056\n",
      "epoch = 11 train_loss : 1.403185 , test loss : 1.373128\n",
      "epoch = 12 train_loss : 1.363914 , test loss : 1.347451\n",
      "epoch = 13 train_loss : 1.312269 , test loss : 1.321115\n",
      "epoch = 14 train_loss : 1.280337 , test loss : 1.271520\n",
      "epoch = 15 train_loss : 1.259474 , test loss : 1.264085\n",
      "epoch = 16 train_loss : 1.223190 , test loss : 1.257657\n",
      "epoch = 17 train_loss : 1.202809 , test loss : 1.217238\n",
      "epoch = 18 train_loss : 1.189657 , test loss : 1.216877\n",
      "epoch = 19 train_loss : 1.155928 , test loss : 1.184136\n",
      "epoch = 21 train_loss : 1.139389 , test loss : 1.183570\n",
      "epoch = 22 train_loss : 1.144824 , test loss : 1.175295\n",
      "epoch = 24 train_loss : 1.124333 , test loss : 1.167792\n",
      "epoch = 25 train_loss : 1.109390 , test loss : 1.154841\n",
      "epoch = 26 train_loss : 1.097374 , test loss : 1.144307\n",
      "epoch = 29 train_loss : 1.081875 , test loss : 1.138563\n",
      "epoch = 37 train_loss : 1.066265 , test loss : 1.129498\n",
      "epoch = 40 train_loss : 1.043237 , test loss : 1.108649\n",
      "epoch = 54 train_loss : 1.040641 , test loss : 1.108029\n",
      "epoch = 69 train_loss : 1.025992 , test loss : 1.102349\n",
      "epoch = 113 train_loss : 1.026236 , test loss : 1.101776\n",
      "epoch = 119 train_loss : 1.022509 , test loss : 1.100576\n",
      "epoch = 148 train_loss : 1.022659 , test loss : 1.100225\n",
      "epoch = 155 train_loss : 1.025616 , test loss : 1.099706\n",
      "epoch = 158 train_loss : 1.023031 , test loss : 1.098549\n",
      "epoch = 175 train_loss : 1.028143 , test loss : 1.098202\n",
      "epoch = 205 train_loss : 1.025343 , test loss : 1.097291\n",
      "epoch = 215 train_loss : 1.021768 , test loss : 1.094540\n",
      "epoch = 304 train_loss : 1.017218 , test loss : 1.092496\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 1.017218,test loss : 1.092496\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 4.993168 , test loss : 4.878818\n",
      "epoch = 2 train_loss : 2.865231 , test loss : 3.005386\n",
      "epoch = 3 train_loss : 2.336038 , test loss : 2.388070\n",
      "epoch = 4 train_loss : 2.141834 , test loss : 2.213869\n",
      "epoch = 5 train_loss : 1.975695 , test loss : 2.045572\n",
      "epoch = 6 train_loss : 1.853294 , test loss : 1.929373\n",
      "epoch = 7 train_loss : 1.745599 , test loss : 1.815091\n",
      "epoch = 8 train_loss : 1.662185 , test loss : 1.746928\n",
      "epoch = 9 train_loss : 1.574370 , test loss : 1.647881\n",
      "epoch = 10 train_loss : 1.508828 , test loss : 1.571035\n",
      "epoch = 11 train_loss : 1.447499 , test loss : 1.511983\n",
      "epoch = 12 train_loss : 1.392801 , test loss : 1.462343\n",
      "epoch = 13 train_loss : 1.350306 , test loss : 1.416666\n",
      "epoch = 14 train_loss : 1.322226 , test loss : 1.369419\n",
      "epoch = 15 train_loss : 1.297979 , test loss : 1.356324\n",
      "epoch = 16 train_loss : 1.260882 , test loss : 1.331050\n",
      "epoch = 17 train_loss : 1.268691 , test loss : 1.306140\n",
      "epoch = 18 train_loss : 1.252620 , test loss : 1.298494\n",
      "epoch = 20 train_loss : 1.228168 , test loss : 1.258481\n",
      "epoch = 21 train_loss : 1.175938 , test loss : 1.202868\n",
      "epoch = 23 train_loss : 1.154344 , test loss : 1.187229\n",
      "epoch = 25 train_loss : 1.153794 , test loss : 1.162327\n",
      "epoch = 26 train_loss : 1.121660 , test loss : 1.160120\n",
      "epoch = 28 train_loss : 1.113636 , test loss : 1.156050\n",
      "epoch = 29 train_loss : 1.109900 , test loss : 1.131333\n",
      "epoch = 31 train_loss : 1.111844 , test loss : 1.126390\n",
      "epoch = 32 train_loss : 1.093632 , test loss : 1.115956\n",
      "epoch = 37 train_loss : 1.084173 , test loss : 1.102378\n",
      "epoch = 40 train_loss : 1.087929 , test loss : 1.098954\n",
      "epoch = 46 train_loss : 1.056719 , test loss : 1.085691\n",
      "epoch = 47 train_loss : 1.063230 , test loss : 1.081452\n",
      "epoch = 54 train_loss : 1.064107 , test loss : 1.069726\n",
      "epoch = 64 train_loss : 1.048458 , test loss : 1.069682\n",
      "epoch = 66 train_loss : 1.066547 , test loss : 1.066305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 82 train_loss : 1.073255 , test loss : 1.058329\n",
      "epoch = 109 train_loss : 1.059421 , test loss : 1.049953\n",
      "epoch = 145 train_loss : 1.037277 , test loss : 1.048532\n",
      "epoch = 150 train_loss : 1.045511 , test loss : 1.047668\n",
      "epoch = 219 train_loss : 1.038063 , test loss : 1.040263\n",
      "epoch = 327 train_loss : 1.043767 , test loss : 1.038450\n",
      "epoch = 538 train_loss : 1.049942 , test loss : 1.037423\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 1.049942,test loss : 1.037423\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 4.383550 , test loss : 4.105916\n",
      "epoch = 2 train_loss : 2.618942 , test loss : 2.440706\n",
      "epoch = 3 train_loss : 2.279776 , test loss : 2.201206\n",
      "epoch = 4 train_loss : 2.084721 , test loss : 1.933570\n",
      "epoch = 5 train_loss : 1.969985 , test loss : 1.857982\n",
      "epoch = 6 train_loss : 1.867330 , test loss : 1.759669\n",
      "epoch = 7 train_loss : 1.782368 , test loss : 1.666252\n",
      "epoch = 8 train_loss : 1.701496 , test loss : 1.616136\n",
      "epoch = 9 train_loss : 1.629551 , test loss : 1.521363\n",
      "epoch = 10 train_loss : 1.559525 , test loss : 1.462996\n",
      "epoch = 11 train_loss : 1.504511 , test loss : 1.410214\n",
      "epoch = 12 train_loss : 1.446919 , test loss : 1.375554\n",
      "epoch = 13 train_loss : 1.415960 , test loss : 1.361122\n",
      "epoch = 14 train_loss : 1.369903 , test loss : 1.305364\n",
      "epoch = 15 train_loss : 1.347190 , test loss : 1.274212\n",
      "epoch = 16 train_loss : 1.312767 , test loss : 1.238369\n",
      "epoch = 19 train_loss : 1.238991 , test loss : 1.190820\n",
      "epoch = 20 train_loss : 1.218249 , test loss : 1.178203\n",
      "epoch = 21 train_loss : 1.210159 , test loss : 1.163855\n",
      "epoch = 22 train_loss : 1.181272 , test loss : 1.148483\n",
      "epoch = 24 train_loss : 1.158128 , test loss : 1.142606\n",
      "epoch = 25 train_loss : 1.155684 , test loss : 1.131233\n",
      "epoch = 29 train_loss : 1.118081 , test loss : 1.095710\n",
      "epoch = 33 train_loss : 1.108557 , test loss : 1.085510\n",
      "epoch = 34 train_loss : 1.102971 , test loss : 1.074326\n",
      "epoch = 42 train_loss : 1.066801 , test loss : 1.066780\n",
      "epoch = 54 train_loss : 1.080656 , test loss : 1.063378\n",
      "epoch = 55 train_loss : 1.055161 , test loss : 1.062592\n",
      "epoch = 68 train_loss : 1.051610 , test loss : 1.059734\n",
      "epoch = 69 train_loss : 1.050791 , test loss : 1.043056\n",
      "epoch = 132 train_loss : 1.038166 , test loss : 1.039401\n",
      "epoch = 154 train_loss : 1.034232 , test loss : 1.037823\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 1.034232,test loss : 1.037823\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 1.025710,total test loss mean : 1.088275 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],256),nn.Linear(256,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:06:53.264111Z",
     "start_time": "2021-12-30T07:02:44.480881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 29.429476 , test loss : 29.217377\n",
      "epoch = 2 train_loss : 20.798487 , test loss : 20.792294\n",
      "epoch = 3 train_loss : 13.962105 , test loss : 14.135642\n",
      "epoch = 4 train_loss : 8.656483 , test loss : 8.936952\n",
      "epoch = 5 train_loss : 5.232327 , test loss : 5.536167\n",
      "epoch = 6 train_loss : 3.610189 , test loss : 3.881304\n",
      "epoch = 7 train_loss : 3.067370 , test loss : 3.301517\n",
      "epoch = 8 train_loss : 2.914636 , test loss : 3.125934\n",
      "epoch = 9 train_loss : 2.833570 , test loss : 3.036701\n",
      "epoch = 10 train_loss : 2.774008 , test loss : 2.973697\n",
      "epoch = 11 train_loss : 2.719606 , test loss : 2.921455\n",
      "epoch = 12 train_loss : 2.672846 , test loss : 2.877495\n",
      "epoch = 13 train_loss : 2.632305 , test loss : 2.841449\n",
      "epoch = 14 train_loss : 2.593929 , test loss : 2.805087\n",
      "epoch = 15 train_loss : 2.558807 , test loss : 2.773671\n",
      "epoch = 16 train_loss : 2.527799 , test loss : 2.748186\n",
      "epoch = 17 train_loss : 2.495615 , test loss : 2.713878\n",
      "epoch = 18 train_loss : 2.467134 , test loss : 2.694268\n",
      "epoch = 19 train_loss : 2.438320 , test loss : 2.661191\n",
      "epoch = 20 train_loss : 2.410819 , test loss : 2.641043\n",
      "epoch = 21 train_loss : 2.384577 , test loss : 2.617418\n",
      "epoch = 22 train_loss : 2.358960 , test loss : 2.592740\n",
      "epoch = 23 train_loss : 2.334884 , test loss : 2.571957\n",
      "epoch = 24 train_loss : 2.310753 , test loss : 2.541131\n",
      "epoch = 25 train_loss : 2.287719 , test loss : 2.531278\n",
      "epoch = 26 train_loss : 2.263331 , test loss : 2.498117\n",
      "epoch = 27 train_loss : 2.239423 , test loss : 2.478717\n",
      "epoch = 28 train_loss : 2.216899 , test loss : 2.459449\n",
      "epoch = 29 train_loss : 2.194274 , test loss : 2.436196\n",
      "epoch = 30 train_loss : 2.171980 , test loss : 2.413140\n",
      "epoch = 31 train_loss : 2.150238 , test loss : 2.391710\n",
      "epoch = 32 train_loss : 2.129298 , test loss : 2.373525\n",
      "epoch = 33 train_loss : 2.106898 , test loss : 2.350559\n",
      "epoch = 34 train_loss : 2.086309 , test loss : 2.323359\n",
      "epoch = 35 train_loss : 2.064554 , test loss : 2.307452\n",
      "epoch = 36 train_loss : 2.044628 , test loss : 2.284363\n",
      "epoch = 37 train_loss : 2.022985 , test loss : 2.265597\n",
      "epoch = 38 train_loss : 2.002307 , test loss : 2.240141\n",
      "epoch = 39 train_loss : 1.982497 , test loss : 2.222410\n",
      "epoch = 40 train_loss : 1.962029 , test loss : 2.196419\n",
      "epoch = 41 train_loss : 1.942071 , test loss : 2.176302\n",
      "epoch = 42 train_loss : 1.922764 , test loss : 2.160424\n",
      "epoch = 43 train_loss : 1.901713 , test loss : 2.132845\n",
      "epoch = 44 train_loss : 1.882569 , test loss : 2.112718\n",
      "epoch = 45 train_loss : 1.865232 , test loss : 2.096248\n",
      "epoch = 46 train_loss : 1.843902 , test loss : 2.069457\n",
      "epoch = 47 train_loss : 1.824976 , test loss : 2.042662\n",
      "epoch = 48 train_loss : 1.805855 , test loss : 2.021449\n",
      "epoch = 49 train_loss : 1.787558 , test loss : 2.009904\n",
      "epoch = 50 train_loss : 1.768419 , test loss : 1.985350\n",
      "epoch = 51 train_loss : 1.749922 , test loss : 1.959939\n",
      "epoch = 52 train_loss : 1.731788 , test loss : 1.941794\n",
      "epoch = 53 train_loss : 1.714504 , test loss : 1.922101\n",
      "epoch = 54 train_loss : 1.696731 , test loss : 1.901309\n",
      "epoch = 55 train_loss : 1.679316 , test loss : 1.878630\n",
      "epoch = 56 train_loss : 1.662195 , test loss : 1.856062\n",
      "epoch = 57 train_loss : 1.644769 , test loss : 1.839614\n",
      "epoch = 58 train_loss : 1.629085 , test loss : 1.817516\n",
      "epoch = 59 train_loss : 1.612477 , test loss : 1.799742\n",
      "epoch = 60 train_loss : 1.601268 , test loss : 1.784592\n",
      "epoch = 61 train_loss : 1.580211 , test loss : 1.763372\n",
      "epoch = 62 train_loss : 1.564595 , test loss : 1.741950\n",
      "epoch = 63 train_loss : 1.549454 , test loss : 1.723630\n",
      "epoch = 64 train_loss : 1.535125 , test loss : 1.705252\n",
      "epoch = 65 train_loss : 1.521651 , test loss : 1.692466\n",
      "epoch = 66 train_loss : 1.507296 , test loss : 1.668251\n",
      "epoch = 67 train_loss : 1.492063 , test loss : 1.654083\n",
      "epoch = 68 train_loss : 1.486511 , test loss : 1.648511\n",
      "epoch = 69 train_loss : 1.466906 , test loss : 1.622943\n",
      "epoch = 70 train_loss : 1.453202 , test loss : 1.606434\n",
      "epoch = 71 train_loss : 1.442746 , test loss : 1.590974\n",
      "epoch = 72 train_loss : 1.428435 , test loss : 1.578907\n",
      "epoch = 73 train_loss : 1.416944 , test loss : 1.560658\n",
      "epoch = 74 train_loss : 1.405316 , test loss : 1.545463\n",
      "epoch = 75 train_loss : 1.393986 , test loss : 1.532782\n",
      "epoch = 76 train_loss : 1.384069 , test loss : 1.520429\n",
      "epoch = 77 train_loss : 1.374729 , test loss : 1.507953\n",
      "epoch = 78 train_loss : 1.363341 , test loss : 1.494904\n",
      "epoch = 79 train_loss : 1.352135 , test loss : 1.483106\n",
      "epoch = 80 train_loss : 1.350318 , test loss : 1.473070\n",
      "epoch = 81 train_loss : 1.333002 , test loss : 1.459135\n",
      "epoch = 82 train_loss : 1.325681 , test loss : 1.453557\n",
      "epoch = 83 train_loss : 1.316370 , test loss : 1.437488\n",
      "epoch = 84 train_loss : 1.308702 , test loss : 1.432501\n",
      "epoch = 85 train_loss : 1.298142 , test loss : 1.417627\n",
      "epoch = 86 train_loss : 1.290699 , test loss : 1.404694\n",
      "epoch = 87 train_loss : 1.283021 , test loss : 1.401136\n",
      "epoch = 88 train_loss : 1.277255 , test loss : 1.388961\n",
      "epoch = 89 train_loss : 1.270175 , test loss : 1.388026\n",
      "epoch = 90 train_loss : 1.262866 , test loss : 1.369974\n",
      "epoch = 91 train_loss : 1.254558 , test loss : 1.358620\n",
      "epoch = 93 train_loss : 1.244598 , test loss : 1.345812\n",
      "epoch = 94 train_loss : 1.233618 , test loss : 1.340776\n",
      "epoch = 95 train_loss : 1.229230 , test loss : 1.332302\n",
      "epoch = 97 train_loss : 1.216137 , test loss : 1.321815\n",
      "epoch = 98 train_loss : 1.213297 , test loss : 1.310437\n",
      "epoch = 100 train_loss : 1.203341 , test loss : 1.309252\n",
      "epoch = 101 train_loss : 1.197456 , test loss : 1.295077\n",
      "epoch = 102 train_loss : 1.189808 , test loss : 1.285591\n",
      "epoch = 103 train_loss : 1.185282 , test loss : 1.283339\n",
      "epoch = 104 train_loss : 1.180372 , test loss : 1.279760\n",
      "epoch = 105 train_loss : 1.175600 , test loss : 1.271899\n",
      "epoch = 106 train_loss : 1.170996 , test loss : 1.267989\n",
      "epoch = 107 train_loss : 1.168175 , test loss : 1.257891\n",
      "epoch = 108 train_loss : 1.168463 , test loss : 1.255759\n",
      "epoch = 109 train_loss : 1.158655 , test loss : 1.251954\n",
      "epoch = 110 train_loss : 1.159161 , test loss : 1.250611\n",
      "epoch = 111 train_loss : 1.153916 , test loss : 1.246836\n",
      "epoch = 112 train_loss : 1.147530 , test loss : 1.239922\n",
      "epoch = 113 train_loss : 1.145471 , test loss : 1.232707\n",
      "epoch = 114 train_loss : 1.142039 , test loss : 1.231390\n",
      "epoch = 115 train_loss : 1.143508 , test loss : 1.226972\n",
      "epoch = 116 train_loss : 1.135198 , test loss : 1.223994\n",
      "epoch = 117 train_loss : 1.132045 , test loss : 1.218829\n",
      "epoch = 119 train_loss : 1.127646 , test loss : 1.217989\n",
      "epoch = 120 train_loss : 1.124510 , test loss : 1.216141\n",
      "epoch = 121 train_loss : 1.125503 , test loss : 1.207128\n",
      "epoch = 122 train_loss : 1.119082 , test loss : 1.206508\n",
      "epoch = 124 train_loss : 1.115091 , test loss : 1.200258\n",
      "epoch = 125 train_loss : 1.110607 , test loss : 1.199144\n",
      "epoch = 126 train_loss : 1.107510 , test loss : 1.193828\n",
      "epoch = 127 train_loss : 1.105184 , test loss : 1.188156\n",
      "epoch = 128 train_loss : 1.102665 , test loss : 1.187373\n",
      "epoch = 129 train_loss : 1.104587 , test loss : 1.183991\n",
      "epoch = 130 train_loss : 1.103530 , test loss : 1.183882\n",
      "epoch = 131 train_loss : 1.101948 , test loss : 1.181645\n",
      "epoch = 132 train_loss : 1.094711 , test loss : 1.176811\n",
      "epoch = 135 train_loss : 1.089843 , test loss : 1.168012\n",
      "epoch = 139 train_loss : 1.088532 , test loss : 1.162277\n",
      "epoch = 140 train_loss : 1.082045 , test loss : 1.159374\n",
      "epoch = 142 train_loss : 1.076453 , test loss : 1.157441\n",
      "epoch = 145 train_loss : 1.074404 , test loss : 1.154993\n",
      "epoch = 147 train_loss : 1.072786 , test loss : 1.152686\n",
      "epoch = 148 train_loss : 1.069184 , test loss : 1.147608\n",
      "epoch = 150 train_loss : 1.066211 , test loss : 1.145353\n",
      "epoch = 152 train_loss : 1.064357 , test loss : 1.143945\n",
      "epoch = 153 train_loss : 1.062083 , test loss : 1.143618\n",
      "epoch = 154 train_loss : 1.061655 , test loss : 1.143012\n",
      "epoch = 155 train_loss : 1.061094 , test loss : 1.139356\n",
      "epoch = 157 train_loss : 1.060512 , test loss : 1.138688\n",
      "epoch = 158 train_loss : 1.056109 , test loss : 1.135999\n",
      "epoch = 163 train_loss : 1.055710 , test loss : 1.131329\n",
      "epoch = 166 train_loss : 1.051630 , test loss : 1.127992\n",
      "epoch = 172 train_loss : 1.047537 , test loss : 1.122807\n",
      "epoch = 177 train_loss : 1.040056 , test loss : 1.120573\n",
      "epoch = 181 train_loss : 1.038022 , test loss : 1.119093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 185 train_loss : 1.035675 , test loss : 1.115247\n",
      "epoch = 193 train_loss : 1.032451 , test loss : 1.112947\n",
      "epoch = 194 train_loss : 1.030535 , test loss : 1.112938\n",
      "epoch = 196 train_loss : 1.030076 , test loss : 1.112435\n",
      "epoch = 199 train_loss : 1.027870 , test loss : 1.109674\n",
      "epoch = 203 train_loss : 1.026814 , test loss : 1.108513\n",
      "epoch = 210 train_loss : 1.024773 , test loss : 1.107450\n",
      "epoch = 219 train_loss : 1.023927 , test loss : 1.107180\n",
      "epoch = 220 train_loss : 1.026241 , test loss : 1.105543\n",
      "epoch = 227 train_loss : 1.022438 , test loss : 1.104954\n",
      "epoch = 235 train_loss : 1.026826 , test loss : 1.104779\n",
      "epoch = 247 train_loss : 1.019828 , test loss : 1.101305\n",
      "epoch = 262 train_loss : 1.019404 , test loss : 1.101021\n",
      "epoch = 324 train_loss : 1.015704 , test loss : 1.100865\n",
      "epoch = 333 train_loss : 1.015042 , test loss : 1.100596\n",
      "epoch = 478 train_loss : 1.015296 , test loss : 1.099682\n",
      "epoch = 953 train_loss : 1.014807 , test loss : 1.099665\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 1.014807,test loss : 1.099665\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 29.396370 , test loss : 28.670723\n",
      "epoch = 2 train_loss : 19.430376 , test loss : 19.046322\n",
      "epoch = 3 train_loss : 11.964695 , test loss : 11.887539\n",
      "epoch = 4 train_loss : 6.898979 , test loss : 6.991429\n",
      "epoch = 5 train_loss : 4.112637 , test loss : 4.310024\n",
      "epoch = 6 train_loss : 2.982738 , test loss : 3.258095\n",
      "epoch = 7 train_loss : 2.668219 , test loss : 2.989613\n",
      "epoch = 8 train_loss : 2.576046 , test loss : 2.918401\n",
      "epoch = 9 train_loss : 2.523889 , test loss : 2.874201\n",
      "epoch = 10 train_loss : 2.476915 , test loss : 2.831574\n",
      "epoch = 11 train_loss : 2.438076 , test loss : 2.788627\n",
      "epoch = 12 train_loss : 2.402073 , test loss : 2.759754\n",
      "epoch = 13 train_loss : 2.370881 , test loss : 2.729710\n",
      "epoch = 14 train_loss : 2.340289 , test loss : 2.698150\n",
      "epoch = 15 train_loss : 2.312001 , test loss : 2.677997\n",
      "epoch = 16 train_loss : 2.284585 , test loss : 2.643923\n",
      "epoch = 17 train_loss : 2.257946 , test loss : 2.625392\n",
      "epoch = 18 train_loss : 2.233005 , test loss : 2.592059\n",
      "epoch = 19 train_loss : 2.207801 , test loss : 2.577497\n",
      "epoch = 20 train_loss : 2.182250 , test loss : 2.546975\n",
      "epoch = 21 train_loss : 2.157227 , test loss : 2.524554\n",
      "epoch = 22 train_loss : 2.132945 , test loss : 2.496201\n",
      "epoch = 23 train_loss : 2.108947 , test loss : 2.473015\n",
      "epoch = 24 train_loss : 2.084556 , test loss : 2.451906\n",
      "epoch = 25 train_loss : 2.060602 , test loss : 2.424580\n",
      "epoch = 26 train_loss : 2.037277 , test loss : 2.394490\n",
      "epoch = 27 train_loss : 2.013138 , test loss : 2.374882\n",
      "epoch = 28 train_loss : 1.988698 , test loss : 2.351132\n",
      "epoch = 29 train_loss : 1.964494 , test loss : 2.327071\n",
      "epoch = 30 train_loss : 1.941722 , test loss : 2.301476\n",
      "epoch = 31 train_loss : 1.917596 , test loss : 2.274571\n",
      "epoch = 32 train_loss : 1.893977 , test loss : 2.251660\n",
      "epoch = 33 train_loss : 1.870418 , test loss : 2.226460\n",
      "epoch = 34 train_loss : 1.847521 , test loss : 2.206899\n",
      "epoch = 35 train_loss : 1.824948 , test loss : 2.175688\n",
      "epoch = 36 train_loss : 1.801612 , test loss : 2.153161\n",
      "epoch = 37 train_loss : 1.779056 , test loss : 2.131369\n",
      "epoch = 38 train_loss : 1.758579 , test loss : 2.105816\n",
      "epoch = 39 train_loss : 1.735479 , test loss : 2.082041\n",
      "epoch = 40 train_loss : 1.715454 , test loss : 2.061803\n",
      "epoch = 41 train_loss : 1.692406 , test loss : 2.036450\n",
      "epoch = 42 train_loss : 1.675092 , test loss : 2.018813\n",
      "epoch = 43 train_loss : 1.652192 , test loss : 1.991187\n",
      "epoch = 44 train_loss : 1.632911 , test loss : 1.978476\n",
      "epoch = 45 train_loss : 1.614510 , test loss : 1.951237\n",
      "epoch = 46 train_loss : 1.595931 , test loss : 1.931911\n",
      "epoch = 47 train_loss : 1.577265 , test loss : 1.911469\n",
      "epoch = 48 train_loss : 1.559252 , test loss : 1.892375\n",
      "epoch = 49 train_loss : 1.541873 , test loss : 1.876273\n",
      "epoch = 50 train_loss : 1.526221 , test loss : 1.860820\n",
      "epoch = 51 train_loss : 1.511567 , test loss : 1.840534\n",
      "epoch = 52 train_loss : 1.496997 , test loss : 1.830501\n",
      "epoch = 53 train_loss : 1.478979 , test loss : 1.808060\n",
      "epoch = 54 train_loss : 1.466130 , test loss : 1.787467\n",
      "epoch = 55 train_loss : 1.453151 , test loss : 1.780196\n",
      "epoch = 56 train_loss : 1.438035 , test loss : 1.762148\n",
      "epoch = 57 train_loss : 1.424914 , test loss : 1.745327\n",
      "epoch = 58 train_loss : 1.412452 , test loss : 1.735032\n",
      "epoch = 59 train_loss : 1.400797 , test loss : 1.719438\n",
      "epoch = 60 train_loss : 1.389336 , test loss : 1.701769\n",
      "epoch = 61 train_loss : 1.377836 , test loss : 1.696592\n",
      "epoch = 62 train_loss : 1.366597 , test loss : 1.683913\n",
      "epoch = 63 train_loss : 1.355986 , test loss : 1.673679\n",
      "epoch = 64 train_loss : 1.347003 , test loss : 1.651755\n",
      "epoch = 65 train_loss : 1.337595 , test loss : 1.645170\n",
      "epoch = 66 train_loss : 1.327022 , test loss : 1.630961\n",
      "epoch = 67 train_loss : 1.319539 , test loss : 1.629550\n",
      "epoch = 68 train_loss : 1.310697 , test loss : 1.611579\n",
      "epoch = 70 train_loss : 1.291804 , test loss : 1.592423\n",
      "epoch = 72 train_loss : 1.277636 , test loss : 1.582192\n",
      "epoch = 73 train_loss : 1.271290 , test loss : 1.565093\n",
      "epoch = 74 train_loss : 1.262919 , test loss : 1.559786\n",
      "epoch = 75 train_loss : 1.254936 , test loss : 1.551096\n",
      "epoch = 77 train_loss : 1.243422 , test loss : 1.542144\n",
      "epoch = 78 train_loss : 1.237017 , test loss : 1.534748\n",
      "epoch = 79 train_loss : 1.229189 , test loss : 1.519164\n",
      "epoch = 80 train_loss : 1.223601 , test loss : 1.517256\n",
      "epoch = 81 train_loss : 1.222291 , test loss : 1.497532\n",
      "epoch = 83 train_loss : 1.209456 , test loss : 1.490662\n",
      "epoch = 84 train_loss : 1.204542 , test loss : 1.488168\n",
      "epoch = 85 train_loss : 1.197579 , test loss : 1.473719\n",
      "epoch = 88 train_loss : 1.182584 , test loss : 1.464799\n",
      "epoch = 89 train_loss : 1.177759 , test loss : 1.453144\n",
      "epoch = 90 train_loss : 1.180867 , test loss : 1.451644\n",
      "epoch = 91 train_loss : 1.169376 , test loss : 1.449905\n",
      "epoch = 92 train_loss : 1.166036 , test loss : 1.434370\n",
      "epoch = 95 train_loss : 1.157953 , test loss : 1.428489\n",
      "epoch = 96 train_loss : 1.152439 , test loss : 1.426306\n",
      "epoch = 98 train_loss : 1.143575 , test loss : 1.405704\n",
      "epoch = 100 train_loss : 1.140753 , test loss : 1.399161\n",
      "epoch = 102 train_loss : 1.132947 , test loss : 1.386216\n",
      "epoch = 104 train_loss : 1.131354 , test loss : 1.385178\n",
      "epoch = 107 train_loss : 1.119183 , test loss : 1.367188\n",
      "epoch = 110 train_loss : 1.112458 , test loss : 1.363903\n",
      "epoch = 111 train_loss : 1.107907 , test loss : 1.362446\n",
      "epoch = 112 train_loss : 1.105281 , test loss : 1.356822\n",
      "epoch = 114 train_loss : 1.108859 , test loss : 1.348095\n",
      "epoch = 117 train_loss : 1.096389 , test loss : 1.338178\n",
      "epoch = 119 train_loss : 1.089545 , test loss : 1.337379\n",
      "epoch = 120 train_loss : 1.088622 , test loss : 1.335110\n",
      "epoch = 121 train_loss : 1.086234 , test loss : 1.324891\n",
      "epoch = 122 train_loss : 1.084958 , test loss : 1.323063\n",
      "epoch = 123 train_loss : 1.082001 , test loss : 1.321074\n",
      "epoch = 126 train_loss : 1.079720 , test loss : 1.306869\n",
      "epoch = 129 train_loss : 1.077696 , test loss : 1.296734\n",
      "epoch = 132 train_loss : 1.073044 , test loss : 1.290542\n",
      "epoch = 133 train_loss : 1.069694 , test loss : 1.287902\n",
      "epoch = 135 train_loss : 1.065253 , test loss : 1.284906\n",
      "epoch = 138 train_loss : 1.069423 , test loss : 1.279180\n",
      "epoch = 142 train_loss : 1.058556 , test loss : 1.272850\n",
      "epoch = 144 train_loss : 1.051563 , test loss : 1.272388\n",
      "epoch = 146 train_loss : 1.050315 , test loss : 1.268966\n",
      "epoch = 148 train_loss : 1.053882 , test loss : 1.261761\n",
      "epoch = 151 train_loss : 1.046319 , test loss : 1.253820\n",
      "epoch = 154 train_loss : 1.042080 , test loss : 1.251253\n",
      "epoch = 157 train_loss : 1.042451 , test loss : 1.243058\n",
      "epoch = 166 train_loss : 1.033993 , test loss : 1.242241\n",
      "epoch = 168 train_loss : 1.032401 , test loss : 1.237997\n",
      "epoch = 169 train_loss : 1.031439 , test loss : 1.234211\n",
      "epoch = 171 train_loss : 1.031652 , test loss : 1.233312\n",
      "epoch = 172 train_loss : 1.038311 , test loss : 1.229227\n",
      "epoch = 175 train_loss : 1.030648 , test loss : 1.222260\n",
      "epoch = 180 train_loss : 1.024300 , test loss : 1.218370\n",
      "epoch = 184 train_loss : 1.024319 , test loss : 1.209231\n",
      "epoch = 192 train_loss : 1.016469 , test loss : 1.207786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 204 train_loss : 1.011558 , test loss : 1.207150\n",
      "epoch = 205 train_loss : 1.021814 , test loss : 1.199568\n",
      "epoch = 215 train_loss : 1.010930 , test loss : 1.199278\n",
      "epoch = 216 train_loss : 1.018770 , test loss : 1.198159\n",
      "epoch = 219 train_loss : 1.009864 , test loss : 1.196284\n",
      "epoch = 222 train_loss : 1.006395 , test loss : 1.193571\n",
      "epoch = 224 train_loss : 1.007661 , test loss : 1.191528\n",
      "epoch = 239 train_loss : 1.009641 , test loss : 1.185154\n",
      "epoch = 240 train_loss : 1.006247 , test loss : 1.184316\n",
      "epoch = 245 train_loss : 1.015837 , test loss : 1.181342\n",
      "epoch = 257 train_loss : 1.005673 , test loss : 1.178969\n",
      "epoch = 281 train_loss : 1.002747 , test loss : 1.177975\n",
      "epoch = 282 train_loss : 1.001215 , test loss : 1.175273\n",
      "epoch = 304 train_loss : 1.007938 , test loss : 1.174254\n",
      "epoch = 341 train_loss : 1.004914 , test loss : 1.173163\n",
      "epoch = 426 train_loss : 1.001552 , test loss : 1.172058\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 1.001552,test loss : 1.172058\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 22.182125 , test loss : 22.752155\n",
      "epoch = 2 train_loss : 12.089033 , test loss : 12.212997\n",
      "epoch = 3 train_loss : 6.337962 , test loss : 6.247351\n",
      "epoch = 4 train_loss : 3.583158 , test loss : 3.430624\n",
      "epoch = 5 train_loss : 2.739280 , test loss : 2.570509\n",
      "epoch = 6 train_loss : 2.569953 , test loss : 2.395420\n",
      "epoch = 7 train_loss : 2.507482 , test loss : 2.339947\n",
      "epoch = 8 train_loss : 2.459452 , test loss : 2.298671\n",
      "epoch = 9 train_loss : 2.415527 , test loss : 2.262949\n",
      "epoch = 10 train_loss : 2.380403 , test loss : 2.224690\n",
      "epoch = 11 train_loss : 2.348331 , test loss : 2.205937\n",
      "epoch = 12 train_loss : 2.317670 , test loss : 2.180092\n",
      "epoch = 13 train_loss : 2.290959 , test loss : 2.154134\n",
      "epoch = 14 train_loss : 2.265029 , test loss : 2.130860\n",
      "epoch = 15 train_loss : 2.240861 , test loss : 2.114923\n",
      "epoch = 16 train_loss : 2.216721 , test loss : 2.096802\n",
      "epoch = 17 train_loss : 2.194009 , test loss : 2.077166\n",
      "epoch = 18 train_loss : 2.170956 , test loss : 2.057244\n",
      "epoch = 19 train_loss : 2.148489 , test loss : 2.038176\n",
      "epoch = 20 train_loss : 2.126534 , test loss : 2.021189\n",
      "epoch = 21 train_loss : 2.104930 , test loss : 1.998614\n",
      "epoch = 22 train_loss : 2.083916 , test loss : 1.982671\n",
      "epoch = 23 train_loss : 2.063095 , test loss : 1.959508\n",
      "epoch = 24 train_loss : 2.041498 , test loss : 1.949123\n",
      "epoch = 25 train_loss : 2.021586 , test loss : 1.924532\n",
      "epoch = 26 train_loss : 2.001228 , test loss : 1.911523\n",
      "epoch = 27 train_loss : 1.981510 , test loss : 1.890542\n",
      "epoch = 28 train_loss : 1.960929 , test loss : 1.875814\n",
      "epoch = 29 train_loss : 1.942962 , test loss : 1.860290\n",
      "epoch = 30 train_loss : 1.922411 , test loss : 1.845513\n",
      "epoch = 31 train_loss : 1.904547 , test loss : 1.827029\n",
      "epoch = 32 train_loss : 1.884602 , test loss : 1.809259\n",
      "epoch = 33 train_loss : 1.866080 , test loss : 1.792138\n",
      "epoch = 34 train_loss : 1.848731 , test loss : 1.778444\n",
      "epoch = 35 train_loss : 1.829187 , test loss : 1.760828\n",
      "epoch = 36 train_loss : 1.810831 , test loss : 1.741899\n",
      "epoch = 37 train_loss : 1.792865 , test loss : 1.730131\n",
      "epoch = 38 train_loss : 1.776071 , test loss : 1.710161\n",
      "epoch = 39 train_loss : 1.758567 , test loss : 1.699968\n",
      "epoch = 40 train_loss : 1.741493 , test loss : 1.681868\n",
      "epoch = 41 train_loss : 1.724499 , test loss : 1.671284\n",
      "epoch = 42 train_loss : 1.707628 , test loss : 1.655596\n",
      "epoch = 43 train_loss : 1.693825 , test loss : 1.644289\n",
      "epoch = 44 train_loss : 1.677858 , test loss : 1.626314\n",
      "epoch = 45 train_loss : 1.661572 , test loss : 1.617161\n",
      "epoch = 46 train_loss : 1.643100 , test loss : 1.601180\n",
      "epoch = 47 train_loss : 1.627721 , test loss : 1.585907\n",
      "epoch = 48 train_loss : 1.613036 , test loss : 1.575693\n",
      "epoch = 49 train_loss : 1.598133 , test loss : 1.561306\n",
      "epoch = 50 train_loss : 1.583353 , test loss : 1.548636\n",
      "epoch = 51 train_loss : 1.569129 , test loss : 1.534029\n",
      "epoch = 52 train_loss : 1.557144 , test loss : 1.525553\n",
      "epoch = 53 train_loss : 1.542367 , test loss : 1.507480\n",
      "epoch = 54 train_loss : 1.528676 , test loss : 1.507044\n",
      "epoch = 55 train_loss : 1.515748 , test loss : 1.492579\n",
      "epoch = 56 train_loss : 1.504818 , test loss : 1.477501\n",
      "epoch = 57 train_loss : 1.492418 , test loss : 1.471791\n",
      "epoch = 58 train_loss : 1.478472 , test loss : 1.453675\n",
      "epoch = 60 train_loss : 1.454927 , test loss : 1.434449\n",
      "epoch = 61 train_loss : 1.446541 , test loss : 1.431894\n",
      "epoch = 62 train_loss : 1.434058 , test loss : 1.426336\n",
      "epoch = 63 train_loss : 1.422851 , test loss : 1.401636\n",
      "epoch = 66 train_loss : 1.390786 , test loss : 1.383111\n",
      "epoch = 67 train_loss : 1.381319 , test loss : 1.376337\n",
      "epoch = 68 train_loss : 1.371882 , test loss : 1.370906\n",
      "epoch = 69 train_loss : 1.371607 , test loss : 1.361928\n",
      "epoch = 70 train_loss : 1.358216 , test loss : 1.351164\n",
      "epoch = 71 train_loss : 1.347016 , test loss : 1.349376\n",
      "epoch = 72 train_loss : 1.339766 , test loss : 1.345061\n",
      "epoch = 73 train_loss : 1.329936 , test loss : 1.334748\n",
      "epoch = 74 train_loss : 1.321129 , test loss : 1.327367\n",
      "epoch = 76 train_loss : 1.305635 , test loss : 1.314211\n",
      "epoch = 77 train_loss : 1.298584 , test loss : 1.308726\n",
      "epoch = 78 train_loss : 1.291920 , test loss : 1.298159\n",
      "epoch = 79 train_loss : 1.284635 , test loss : 1.295884\n",
      "epoch = 80 train_loss : 1.278828 , test loss : 1.295733\n",
      "epoch = 82 train_loss : 1.264657 , test loss : 1.272603\n",
      "epoch = 86 train_loss : 1.244872 , test loss : 1.262506\n",
      "epoch = 87 train_loss : 1.238719 , test loss : 1.253302\n",
      "epoch = 89 train_loss : 1.222941 , test loss : 1.240840\n",
      "epoch = 90 train_loss : 1.218690 , test loss : 1.237761\n",
      "epoch = 91 train_loss : 1.215082 , test loss : 1.234262\n",
      "epoch = 92 train_loss : 1.217498 , test loss : 1.233676\n",
      "epoch = 93 train_loss : 1.203051 , test loss : 1.227523\n",
      "epoch = 94 train_loss : 1.199410 , test loss : 1.222845\n",
      "epoch = 95 train_loss : 1.195727 , test loss : 1.218311\n",
      "epoch = 96 train_loss : 1.190286 , test loss : 1.214131\n",
      "epoch = 98 train_loss : 1.183457 , test loss : 1.209885\n",
      "epoch = 99 train_loss : 1.177082 , test loss : 1.202836\n",
      "epoch = 102 train_loss : 1.165355 , test loss : 1.196113\n",
      "epoch = 103 train_loss : 1.161367 , test loss : 1.191439\n",
      "epoch = 104 train_loss : 1.158526 , test loss : 1.189957\n",
      "epoch = 106 train_loss : 1.153482 , test loss : 1.185954\n",
      "epoch = 107 train_loss : 1.147542 , test loss : 1.181752\n",
      "epoch = 109 train_loss : 1.142799 , test loss : 1.174778\n",
      "epoch = 111 train_loss : 1.135587 , test loss : 1.171709\n",
      "epoch = 112 train_loss : 1.132486 , test loss : 1.170765\n",
      "epoch = 113 train_loss : 1.129899 , test loss : 1.169966\n",
      "epoch = 115 train_loss : 1.124762 , test loss : 1.161274\n",
      "epoch = 121 train_loss : 1.113189 , test loss : 1.158036\n",
      "epoch = 123 train_loss : 1.106031 , test loss : 1.151742\n",
      "epoch = 124 train_loss : 1.104428 , test loss : 1.149422\n",
      "epoch = 125 train_loss : 1.100802 , test loss : 1.143696\n",
      "epoch = 126 train_loss : 1.100713 , test loss : 1.140674\n",
      "epoch = 134 train_loss : 1.084111 , test loss : 1.135283\n",
      "epoch = 136 train_loss : 1.080608 , test loss : 1.133255\n",
      "epoch = 140 train_loss : 1.082847 , test loss : 1.129664\n",
      "epoch = 143 train_loss : 1.071435 , test loss : 1.127788\n",
      "epoch = 145 train_loss : 1.071227 , test loss : 1.126166\n",
      "epoch = 146 train_loss : 1.072551 , test loss : 1.125966\n",
      "epoch = 147 train_loss : 1.065347 , test loss : 1.124903\n",
      "epoch = 148 train_loss : 1.065113 , test loss : 1.121095\n",
      "epoch = 149 train_loss : 1.064279 , test loss : 1.119891\n",
      "epoch = 150 train_loss : 1.061225 , test loss : 1.117610\n",
      "epoch = 153 train_loss : 1.059790 , test loss : 1.114555\n",
      "epoch = 157 train_loss : 1.054942 , test loss : 1.109679\n",
      "epoch = 169 train_loss : 1.043238 , test loss : 1.107602\n",
      "epoch = 176 train_loss : 1.036472 , test loss : 1.107597\n",
      "epoch = 177 train_loss : 1.041356 , test loss : 1.106007\n",
      "epoch = 180 train_loss : 1.034884 , test loss : 1.101986\n",
      "epoch = 188 train_loss : 1.030857 , test loss : 1.100069\n",
      "epoch = 208 train_loss : 1.023677 , test loss : 1.099461\n",
      "epoch = 219 train_loss : 1.022706 , test loss : 1.095331\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 1.022706,test loss : 1.095331\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 23.374483 , test loss : 23.564320\n",
      "epoch = 2 train_loss : 13.754076 , test loss : 13.757482\n",
      "epoch = 3 train_loss : 7.528051 , test loss : 7.567341\n",
      "epoch = 4 train_loss : 4.279425 , test loss : 4.351912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5 train_loss : 3.095401 , test loss : 3.175659\n",
      "epoch = 6 train_loss : 2.785105 , test loss : 2.868351\n",
      "epoch = 7 train_loss : 2.689273 , test loss : 2.770549\n",
      "epoch = 8 train_loss : 2.620661 , test loss : 2.699888\n",
      "epoch = 9 train_loss : 2.563167 , test loss : 2.640698\n",
      "epoch = 10 train_loss : 2.514401 , test loss : 2.591420\n",
      "epoch = 11 train_loss : 2.469127 , test loss : 2.542197\n",
      "epoch = 12 train_loss : 2.429186 , test loss : 2.504494\n",
      "epoch = 13 train_loss : 2.393510 , test loss : 2.469057\n",
      "epoch = 14 train_loss : 2.359518 , test loss : 2.436006\n",
      "epoch = 15 train_loss : 2.328230 , test loss : 2.406213\n",
      "epoch = 16 train_loss : 2.297984 , test loss : 2.376942\n",
      "epoch = 17 train_loss : 2.269131 , test loss : 2.349148\n",
      "epoch = 18 train_loss : 2.241991 , test loss : 2.325038\n",
      "epoch = 19 train_loss : 2.215110 , test loss : 2.296282\n",
      "epoch = 20 train_loss : 2.189407 , test loss : 2.268466\n",
      "epoch = 21 train_loss : 2.164435 , test loss : 2.249209\n",
      "epoch = 22 train_loss : 2.139199 , test loss : 2.222811\n",
      "epoch = 23 train_loss : 2.115137 , test loss : 2.199043\n",
      "epoch = 24 train_loss : 2.091255 , test loss : 2.178818\n",
      "epoch = 25 train_loss : 2.068333 , test loss : 2.152374\n",
      "epoch = 26 train_loss : 2.045414 , test loss : 2.134161\n",
      "epoch = 27 train_loss : 2.023706 , test loss : 2.112304\n",
      "epoch = 28 train_loss : 2.002631 , test loss : 2.089165\n",
      "epoch = 29 train_loss : 1.981888 , test loss : 2.072628\n",
      "epoch = 30 train_loss : 1.959411 , test loss : 2.051375\n",
      "epoch = 31 train_loss : 1.939027 , test loss : 2.026754\n",
      "epoch = 32 train_loss : 1.918890 , test loss : 2.007022\n",
      "epoch = 33 train_loss : 1.900071 , test loss : 1.986484\n",
      "epoch = 34 train_loss : 1.880068 , test loss : 1.969437\n",
      "epoch = 35 train_loss : 1.860817 , test loss : 1.950968\n",
      "epoch = 36 train_loss : 1.841673 , test loss : 1.928552\n",
      "epoch = 37 train_loss : 1.823089 , test loss : 1.910735\n",
      "epoch = 38 train_loss : 1.806292 , test loss : 1.894440\n",
      "epoch = 39 train_loss : 1.788757 , test loss : 1.882059\n",
      "epoch = 40 train_loss : 1.770054 , test loss : 1.857754\n",
      "epoch = 41 train_loss : 1.753480 , test loss : 1.844994\n",
      "epoch = 42 train_loss : 1.736942 , test loss : 1.821063\n",
      "epoch = 43 train_loss : 1.719449 , test loss : 1.804527\n",
      "epoch = 44 train_loss : 1.703624 , test loss : 1.789977\n",
      "epoch = 45 train_loss : 1.688152 , test loss : 1.776964\n",
      "epoch = 46 train_loss : 1.675623 , test loss : 1.764640\n",
      "epoch = 47 train_loss : 1.657357 , test loss : 1.744345\n",
      "epoch = 48 train_loss : 1.643794 , test loss : 1.724071\n",
      "epoch = 49 train_loss : 1.628349 , test loss : 1.714230\n",
      "epoch = 50 train_loss : 1.614971 , test loss : 1.695129\n",
      "epoch = 51 train_loss : 1.600883 , test loss : 1.684047\n",
      "epoch = 52 train_loss : 1.587997 , test loss : 1.673425\n",
      "epoch = 53 train_loss : 1.574632 , test loss : 1.650994\n",
      "epoch = 54 train_loss : 1.563559 , test loss : 1.650163\n",
      "epoch = 55 train_loss : 1.551373 , test loss : 1.628698\n",
      "epoch = 56 train_loss : 1.537688 , test loss : 1.617956\n",
      "epoch = 57 train_loss : 1.526745 , test loss : 1.609215\n",
      "epoch = 58 train_loss : 1.516904 , test loss : 1.600611\n",
      "epoch = 59 train_loss : 1.502764 , test loss : 1.580439\n",
      "epoch = 60 train_loss : 1.494207 , test loss : 1.571096\n",
      "epoch = 61 train_loss : 1.486001 , test loss : 1.557639\n",
      "epoch = 62 train_loss : 1.471580 , test loss : 1.548020\n",
      "epoch = 63 train_loss : 1.461135 , test loss : 1.537088\n",
      "epoch = 65 train_loss : 1.445300 , test loss : 1.519228\n",
      "epoch = 66 train_loss : 1.434698 , test loss : 1.512861\n",
      "epoch = 67 train_loss : 1.424512 , test loss : 1.499539\n",
      "epoch = 68 train_loss : 1.416196 , test loss : 1.492924\n",
      "epoch = 69 train_loss : 1.411389 , test loss : 1.479709\n",
      "epoch = 70 train_loss : 1.400742 , test loss : 1.476076\n",
      "epoch = 71 train_loss : 1.391346 , test loss : 1.463491\n",
      "epoch = 72 train_loss : 1.383803 , test loss : 1.450490\n",
      "epoch = 73 train_loss : 1.375526 , test loss : 1.445776\n",
      "epoch = 74 train_loss : 1.369644 , test loss : 1.440384\n",
      "epoch = 75 train_loss : 1.360621 , test loss : 1.427488\n",
      "epoch = 76 train_loss : 1.352926 , test loss : 1.420822\n",
      "epoch = 77 train_loss : 1.346240 , test loss : 1.413819\n",
      "epoch = 78 train_loss : 1.341398 , test loss : 1.401812\n",
      "epoch = 79 train_loss : 1.332621 , test loss : 1.392789\n",
      "epoch = 81 train_loss : 1.320988 , test loss : 1.381757\n",
      "epoch = 82 train_loss : 1.315006 , test loss : 1.379273\n",
      "epoch = 84 train_loss : 1.304090 , test loss : 1.374898\n",
      "epoch = 85 train_loss : 1.301364 , test loss : 1.355067\n",
      "epoch = 86 train_loss : 1.291636 , test loss : 1.350839\n",
      "epoch = 88 train_loss : 1.283184 , test loss : 1.349680\n",
      "epoch = 89 train_loss : 1.275076 , test loss : 1.338837\n",
      "epoch = 90 train_loss : 1.271822 , test loss : 1.333721\n",
      "epoch = 91 train_loss : 1.265754 , test loss : 1.323293\n",
      "epoch = 92 train_loss : 1.261509 , test loss : 1.311966\n",
      "epoch = 94 train_loss : 1.251031 , test loss : 1.304431\n",
      "epoch = 96 train_loss : 1.241651 , test loss : 1.294199\n",
      "epoch = 98 train_loss : 1.232617 , test loss : 1.291343\n",
      "epoch = 99 train_loss : 1.226841 , test loss : 1.284093\n",
      "epoch = 100 train_loss : 1.226656 , test loss : 1.283725\n",
      "epoch = 101 train_loss : 1.220978 , test loss : 1.272996\n",
      "epoch = 102 train_loss : 1.218095 , test loss : 1.269683\n",
      "epoch = 103 train_loss : 1.212968 , test loss : 1.265645\n",
      "epoch = 104 train_loss : 1.207702 , test loss : 1.262107\n",
      "epoch = 105 train_loss : 1.206662 , test loss : 1.260509\n",
      "epoch = 107 train_loss : 1.197096 , test loss : 1.257650\n",
      "epoch = 108 train_loss : 1.193775 , test loss : 1.249626\n",
      "epoch = 110 train_loss : 1.188733 , test loss : 1.232170\n",
      "epoch = 112 train_loss : 1.180099 , test loss : 1.229184\n",
      "epoch = 114 train_loss : 1.174955 , test loss : 1.227819\n",
      "epoch = 116 train_loss : 1.166899 , test loss : 1.217425\n",
      "epoch = 117 train_loss : 1.165626 , test loss : 1.215020\n",
      "epoch = 120 train_loss : 1.154345 , test loss : 1.207711\n",
      "epoch = 121 train_loss : 1.155273 , test loss : 1.199511\n",
      "epoch = 124 train_loss : 1.144575 , test loss : 1.190570\n",
      "epoch = 126 train_loss : 1.138759 , test loss : 1.188086\n",
      "epoch = 128 train_loss : 1.139053 , test loss : 1.175289\n",
      "epoch = 133 train_loss : 1.126908 , test loss : 1.163110\n",
      "epoch = 134 train_loss : 1.122644 , test loss : 1.160104\n",
      "epoch = 140 train_loss : 1.113755 , test loss : 1.156715\n",
      "epoch = 141 train_loss : 1.106294 , test loss : 1.149160\n",
      "epoch = 144 train_loss : 1.103652 , test loss : 1.146128\n",
      "epoch = 145 train_loss : 1.103649 , test loss : 1.142813\n",
      "epoch = 146 train_loss : 1.098751 , test loss : 1.140494\n",
      "epoch = 149 train_loss : 1.094931 , test loss : 1.135381\n",
      "epoch = 151 train_loss : 1.092916 , test loss : 1.132039\n",
      "epoch = 153 train_loss : 1.087916 , test loss : 1.124100\n",
      "epoch = 159 train_loss : 1.086535 , test loss : 1.118467\n",
      "epoch = 160 train_loss : 1.089133 , test loss : 1.114086\n",
      "epoch = 165 train_loss : 1.078197 , test loss : 1.113225\n",
      "epoch = 168 train_loss : 1.070429 , test loss : 1.104177\n",
      "epoch = 170 train_loss : 1.071190 , test loss : 1.101869\n",
      "epoch = 173 train_loss : 1.069539 , test loss : 1.100953\n",
      "epoch = 179 train_loss : 1.065927 , test loss : 1.093688\n",
      "epoch = 180 train_loss : 1.065270 , test loss : 1.089692\n",
      "epoch = 185 train_loss : 1.058201 , test loss : 1.089543\n",
      "epoch = 186 train_loss : 1.055793 , test loss : 1.086115\n",
      "epoch = 187 train_loss : 1.055884 , test loss : 1.085779\n",
      "epoch = 189 train_loss : 1.061342 , test loss : 1.079212\n",
      "epoch = 196 train_loss : 1.050610 , test loss : 1.079008\n",
      "epoch = 199 train_loss : 1.053159 , test loss : 1.069188\n",
      "epoch = 200 train_loss : 1.052219 , test loss : 1.066303\n",
      "epoch = 217 train_loss : 1.041671 , test loss : 1.063571\n",
      "epoch = 220 train_loss : 1.047795 , test loss : 1.062295\n",
      "epoch = 221 train_loss : 1.041556 , test loss : 1.060709\n",
      "epoch = 230 train_loss : 1.040569 , test loss : 1.059680\n",
      "epoch = 233 train_loss : 1.042539 , test loss : 1.058936\n",
      "epoch = 238 train_loss : 1.046198 , test loss : 1.053397\n",
      "epoch = 239 train_loss : 1.045435 , test loss : 1.053106\n",
      "epoch = 246 train_loss : 1.037190 , test loss : 1.052439\n",
      "epoch = 256 train_loss : 1.040171 , test loss : 1.046414\n",
      "epoch = 294 train_loss : 1.037223 , test loss : 1.044611\n",
      "epoch = 394 train_loss : 1.034401 , test loss : 1.043836\n",
      "epoch = 442 train_loss : 1.035205 , test loss : 1.043546\n",
      "epoch = 464 train_loss : 1.038538 , test loss : 1.043180\n",
      "epoch = 522 train_loss : 1.034885 , test loss : 1.040403\n",
      "epoch = 992 train_loss : 1.037103 , test loss : 1.039922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 1.037103,test loss : 1.039922\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 22.617085 , test loss : 22.733805\n",
      "epoch = 2 train_loss : 14.247381 , test loss : 14.500608\n",
      "epoch = 3 train_loss : 8.609718 , test loss : 8.742831\n",
      "epoch = 4 train_loss : 5.159454 , test loss : 5.154177\n",
      "epoch = 5 train_loss : 3.578047 , test loss : 3.488376\n",
      "epoch = 6 train_loss : 3.058806 , test loss : 2.906221\n",
      "epoch = 7 train_loss : 2.905034 , test loss : 2.723767\n",
      "epoch = 8 train_loss : 2.829329 , test loss : 2.646892\n",
      "epoch = 9 train_loss : 2.765854 , test loss : 2.591650\n",
      "epoch = 10 train_loss : 2.712929 , test loss : 2.548832\n",
      "epoch = 11 train_loss : 2.667200 , test loss : 2.503513\n",
      "epoch = 12 train_loss : 2.625030 , test loss : 2.468183\n",
      "epoch = 13 train_loss : 2.586268 , test loss : 2.433995\n",
      "epoch = 14 train_loss : 2.550821 , test loss : 2.399791\n",
      "epoch = 15 train_loss : 2.516664 , test loss : 2.370488\n",
      "epoch = 16 train_loss : 2.484756 , test loss : 2.333568\n",
      "epoch = 17 train_loss : 2.454616 , test loss : 2.312610\n",
      "epoch = 18 train_loss : 2.425921 , test loss : 2.276463\n",
      "epoch = 19 train_loss : 2.396791 , test loss : 2.262336\n",
      "epoch = 20 train_loss : 2.370028 , test loss : 2.230069\n",
      "epoch = 21 train_loss : 2.343088 , test loss : 2.206670\n",
      "epoch = 22 train_loss : 2.316749 , test loss : 2.179720\n",
      "epoch = 23 train_loss : 2.291441 , test loss : 2.158935\n",
      "epoch = 24 train_loss : 2.265795 , test loss : 2.138419\n",
      "epoch = 25 train_loss : 2.241233 , test loss : 2.108488\n",
      "epoch = 26 train_loss : 2.217047 , test loss : 2.090089\n",
      "epoch = 27 train_loss : 2.193199 , test loss : 2.065290\n",
      "epoch = 28 train_loss : 2.168867 , test loss : 2.047009\n",
      "epoch = 29 train_loss : 2.146307 , test loss : 2.019988\n",
      "epoch = 30 train_loss : 2.123423 , test loss : 1.998250\n",
      "epoch = 31 train_loss : 2.100191 , test loss : 1.982171\n",
      "epoch = 32 train_loss : 2.077991 , test loss : 1.958167\n",
      "epoch = 33 train_loss : 2.055709 , test loss : 1.940522\n",
      "epoch = 34 train_loss : 2.034919 , test loss : 1.918387\n",
      "epoch = 35 train_loss : 2.013302 , test loss : 1.902472\n",
      "epoch = 36 train_loss : 1.991476 , test loss : 1.880895\n",
      "epoch = 37 train_loss : 1.970879 , test loss : 1.857293\n",
      "epoch = 38 train_loss : 1.951434 , test loss : 1.855279\n",
      "epoch = 39 train_loss : 1.929574 , test loss : 1.819379\n",
      "epoch = 40 train_loss : 1.910183 , test loss : 1.804698\n",
      "epoch = 41 train_loss : 1.890024 , test loss : 1.783068\n",
      "epoch = 42 train_loss : 1.873035 , test loss : 1.776476\n",
      "epoch = 43 train_loss : 1.850324 , test loss : 1.748874\n",
      "epoch = 44 train_loss : 1.831265 , test loss : 1.734327\n",
      "epoch = 45 train_loss : 1.813037 , test loss : 1.718630\n",
      "epoch = 46 train_loss : 1.795271 , test loss : 1.708458\n",
      "epoch = 47 train_loss : 1.776610 , test loss : 1.677801\n",
      "epoch = 48 train_loss : 1.759986 , test loss : 1.671023\n",
      "epoch = 49 train_loss : 1.741098 , test loss : 1.651755\n",
      "epoch = 50 train_loss : 1.724241 , test loss : 1.628075\n",
      "epoch = 51 train_loss : 1.707234 , test loss : 1.625683\n",
      "epoch = 52 train_loss : 1.690279 , test loss : 1.605978\n",
      "epoch = 53 train_loss : 1.677028 , test loss : 1.588774\n",
      "epoch = 54 train_loss : 1.658697 , test loss : 1.579799\n",
      "epoch = 55 train_loss : 1.643036 , test loss : 1.565694\n",
      "epoch = 56 train_loss : 1.627589 , test loss : 1.543375\n",
      "epoch = 58 train_loss : 1.598574 , test loss : 1.523205\n",
      "epoch = 59 train_loss : 1.585163 , test loss : 1.507309\n",
      "epoch = 60 train_loss : 1.569389 , test loss : 1.494467\n",
      "epoch = 61 train_loss : 1.556244 , test loss : 1.481723\n",
      "epoch = 62 train_loss : 1.542478 , test loss : 1.466892\n",
      "epoch = 64 train_loss : 1.517052 , test loss : 1.443165\n",
      "epoch = 65 train_loss : 1.504101 , test loss : 1.440768\n",
      "epoch = 66 train_loss : 1.493862 , test loss : 1.430697\n",
      "epoch = 67 train_loss : 1.480521 , test loss : 1.417066\n",
      "epoch = 68 train_loss : 1.468591 , test loss : 1.404421\n",
      "epoch = 69 train_loss : 1.457343 , test loss : 1.394454\n",
      "epoch = 70 train_loss : 1.449595 , test loss : 1.393468\n",
      "epoch = 71 train_loss : 1.435992 , test loss : 1.373913\n",
      "epoch = 72 train_loss : 1.425406 , test loss : 1.365443\n",
      "epoch = 73 train_loss : 1.414237 , test loss : 1.353870\n",
      "epoch = 75 train_loss : 1.394632 , test loss : 1.338961\n",
      "epoch = 76 train_loss : 1.389363 , test loss : 1.324365\n",
      "epoch = 77 train_loss : 1.376890 , test loss : 1.323849\n",
      "epoch = 78 train_loss : 1.368878 , test loss : 1.311492\n",
      "epoch = 79 train_loss : 1.359057 , test loss : 1.303424\n",
      "epoch = 80 train_loss : 1.351092 , test loss : 1.292937\n",
      "epoch = 81 train_loss : 1.341803 , test loss : 1.288674\n",
      "epoch = 82 train_loss : 1.332708 , test loss : 1.286506\n",
      "epoch = 83 train_loss : 1.325795 , test loss : 1.277344\n",
      "epoch = 84 train_loss : 1.316013 , test loss : 1.274949\n",
      "epoch = 85 train_loss : 1.308195 , test loss : 1.255826\n",
      "epoch = 87 train_loss : 1.297178 , test loss : 1.242639\n",
      "epoch = 89 train_loss : 1.279370 , test loss : 1.237159\n",
      "epoch = 90 train_loss : 1.272002 , test loss : 1.234019\n",
      "epoch = 91 train_loss : 1.267803 , test loss : 1.223813\n",
      "epoch = 92 train_loss : 1.259922 , test loss : 1.210971\n",
      "epoch = 93 train_loss : 1.252534 , test loss : 1.210340\n",
      "epoch = 95 train_loss : 1.248028 , test loss : 1.208518\n",
      "epoch = 96 train_loss : 1.243165 , test loss : 1.207837\n",
      "epoch = 97 train_loss : 1.231639 , test loss : 1.197481\n",
      "epoch = 98 train_loss : 1.224775 , test loss : 1.182653\n",
      "epoch = 100 train_loss : 1.214467 , test loss : 1.174500\n",
      "epoch = 103 train_loss : 1.198771 , test loss : 1.168699\n",
      "epoch = 104 train_loss : 1.195039 , test loss : 1.163283\n",
      "epoch = 106 train_loss : 1.187200 , test loss : 1.148162\n",
      "epoch = 109 train_loss : 1.177738 , test loss : 1.143897\n",
      "epoch = 112 train_loss : 1.171339 , test loss : 1.137823\n",
      "epoch = 116 train_loss : 1.148995 , test loss : 1.133081\n",
      "epoch = 117 train_loss : 1.142852 , test loss : 1.124590\n",
      "epoch = 120 train_loss : 1.142776 , test loss : 1.122325\n",
      "epoch = 121 train_loss : 1.131953 , test loss : 1.119457\n",
      "epoch = 122 train_loss : 1.129362 , test loss : 1.109243\n",
      "epoch = 126 train_loss : 1.119655 , test loss : 1.106065\n",
      "epoch = 128 train_loss : 1.118557 , test loss : 1.098834\n",
      "epoch = 131 train_loss : 1.107308 , test loss : 1.097617\n",
      "epoch = 132 train_loss : 1.105338 , test loss : 1.095447\n",
      "epoch = 134 train_loss : 1.103883 , test loss : 1.089055\n",
      "epoch = 137 train_loss : 1.098059 , test loss : 1.081103\n",
      "epoch = 139 train_loss : 1.092601 , test loss : 1.080822\n",
      "epoch = 148 train_loss : 1.086059 , test loss : 1.078736\n",
      "epoch = 149 train_loss : 1.077966 , test loss : 1.072714\n",
      "epoch = 159 train_loss : 1.068371 , test loss : 1.067329\n",
      "epoch = 168 train_loss : 1.069699 , test loss : 1.065112\n",
      "epoch = 170 train_loss : 1.066602 , test loss : 1.064855\n",
      "epoch = 175 train_loss : 1.054073 , test loss : 1.062847\n",
      "epoch = 177 train_loss : 1.054290 , test loss : 1.061288\n",
      "epoch = 189 train_loss : 1.046199 , test loss : 1.056841\n",
      "epoch = 191 train_loss : 1.047019 , test loss : 1.053760\n",
      "epoch = 201 train_loss : 1.044179 , test loss : 1.050434\n",
      "epoch = 241 train_loss : 1.039193 , test loss : 1.047107\n",
      "epoch = 263 train_loss : 1.035977 , test loss : 1.045588\n",
      "epoch = 532 train_loss : 1.030702 , test loss : 1.044735\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 1.030702,test loss : 1.044735\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 1.021374,total test loss mean : 1.090342 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],16),nn.Linear(16,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.0005,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:56:09.978810Z",
     "start_time": "2021-12-29T06:53:03.206128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.381629 , test loss : 0.399963\n",
      "epoch = 2 train_loss : 0.293572 , test loss : 0.312060\n",
      "epoch = 3 train_loss : 0.261381 , test loss : 0.282909\n",
      "epoch = 4 train_loss : 0.237863 , test loss : 0.260051\n",
      "epoch = 5 train_loss : 0.221804 , test loss : 0.240736\n",
      "epoch = 6 train_loss : 0.207388 , test loss : 0.226529\n",
      "epoch = 7 train_loss : 0.201104 , test loss : 0.221888\n",
      "epoch = 8 train_loss : 0.187545 , test loss : 0.205953\n",
      "epoch = 9 train_loss : 0.179314 , test loss : 0.197147\n",
      "epoch = 10 train_loss : 0.175913 , test loss : 0.189993\n",
      "epoch = 12 train_loss : 0.167336 , test loss : 0.185310\n",
      "epoch = 13 train_loss : 0.159530 , test loss : 0.175348\n",
      "epoch = 14 train_loss : 0.156213 , test loss : 0.170752\n",
      "epoch = 15 train_loss : 0.153288 , test loss : 0.166733\n",
      "epoch = 16 train_loss : 0.151911 , test loss : 0.164389\n",
      "epoch = 18 train_loss : 0.147388 , test loss : 0.159558\n",
      "epoch = 19 train_loss : 0.146350 , test loss : 0.159420\n",
      "epoch = 22 train_loss : 0.149217 , test loss : 0.159242\n",
      "epoch = 23 train_loss : 0.146371 , test loss : 0.157109\n",
      "epoch = 27 train_loss : 0.142368 , test loss : 0.155817\n",
      "epoch = 29 train_loss : 0.141419 , test loss : 0.153098\n",
      "epoch = 30 train_loss : 0.140114 , test loss : 0.152056\n",
      "epoch = 33 train_loss : 0.138962 , test loss : 0.150826\n",
      "epoch = 39 train_loss : 0.138964 , test loss : 0.150812\n",
      "epoch = 42 train_loss : 0.139567 , test loss : 0.150649\n",
      "epoch = 58 train_loss : 0.138480 , test loss : 0.149837\n",
      "epoch = 63 train_loss : 0.138885 , test loss : 0.149149\n",
      "epoch = 90 train_loss : 0.137783 , test loss : 0.148392\n",
      "epoch = 334 train_loss : 0.137025 , test loss : 0.148039\n",
      "epoch = 470 train_loss : 0.136937 , test loss : 0.148016\n",
      "epoch = 519 train_loss : 0.136725 , test loss : 0.148001\n",
      "epoch = 536 train_loss : 0.137219 , test loss : 0.147929\n",
      "epoch = 972 train_loss : 0.136580 , test loss : 0.147884\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.136580,test loss : 0.147884\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.405299 , test loss : 0.466230\n",
      "epoch = 2 train_loss : 0.340223 , test loss : 0.396715\n",
      "epoch = 3 train_loss : 0.291525 , test loss : 0.346468\n",
      "epoch = 4 train_loss : 0.265463 , test loss : 0.321199\n",
      "epoch = 5 train_loss : 0.246682 , test loss : 0.303268\n",
      "epoch = 6 train_loss : 0.230925 , test loss : 0.285337\n",
      "epoch = 7 train_loss : 0.215813 , test loss : 0.267678\n",
      "epoch = 8 train_loss : 0.203798 , test loss : 0.254424\n",
      "epoch = 9 train_loss : 0.195732 , test loss : 0.244741\n",
      "epoch = 10 train_loss : 0.186440 , test loss : 0.234258\n",
      "epoch = 11 train_loss : 0.186108 , test loss : 0.227451\n",
      "epoch = 12 train_loss : 0.176361 , test loss : 0.216925\n",
      "epoch = 13 train_loss : 0.168913 , test loss : 0.212470\n",
      "epoch = 14 train_loss : 0.166522 , test loss : 0.207643\n",
      "epoch = 15 train_loss : 0.161435 , test loss : 0.203901\n",
      "epoch = 16 train_loss : 0.156560 , test loss : 0.196267\n",
      "epoch = 18 train_loss : 0.155022 , test loss : 0.187318\n",
      "epoch = 21 train_loss : 0.147615 , test loss : 0.182454\n",
      "epoch = 22 train_loss : 0.148538 , test loss : 0.180545\n",
      "epoch = 23 train_loss : 0.146285 , test loss : 0.179824\n",
      "epoch = 24 train_loss : 0.145527 , test loss : 0.176799\n",
      "epoch = 25 train_loss : 0.142347 , test loss : 0.173485\n",
      "epoch = 26 train_loss : 0.145132 , test loss : 0.172957\n",
      "epoch = 27 train_loss : 0.141913 , test loss : 0.170541\n",
      "epoch = 29 train_loss : 0.141462 , test loss : 0.168398\n",
      "epoch = 33 train_loss : 0.139792 , test loss : 0.166374\n",
      "epoch = 34 train_loss : 0.139913 , test loss : 0.166070\n",
      "epoch = 35 train_loss : 0.140014 , test loss : 0.162241\n",
      "epoch = 46 train_loss : 0.137512 , test loss : 0.161882\n",
      "epoch = 47 train_loss : 0.136747 , test loss : 0.159532\n",
      "epoch = 70 train_loss : 0.136854 , test loss : 0.159082\n",
      "epoch = 108 train_loss : 0.136004 , test loss : 0.157958\n",
      "epoch = 140 train_loss : 0.136468 , test loss : 0.157827\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.136468,test loss : 0.157827\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.413448 , test loss : 0.388998\n",
      "epoch = 2 train_loss : 0.328863 , test loss : 0.313426\n",
      "epoch = 3 train_loss : 0.287716 , test loss : 0.267641\n",
      "epoch = 4 train_loss : 0.262512 , test loss : 0.248872\n",
      "epoch = 5 train_loss : 0.240911 , test loss : 0.226793\n",
      "epoch = 6 train_loss : 0.227201 , test loss : 0.218545\n",
      "epoch = 7 train_loss : 0.217104 , test loss : 0.207669\n",
      "epoch = 8 train_loss : 0.199465 , test loss : 0.192032\n",
      "epoch = 9 train_loss : 0.191204 , test loss : 0.184602\n",
      "epoch = 10 train_loss : 0.182834 , test loss : 0.176813\n",
      "epoch = 11 train_loss : 0.174256 , test loss : 0.173964\n",
      "epoch = 12 train_loss : 0.171772 , test loss : 0.172609\n",
      "epoch = 13 train_loss : 0.164493 , test loss : 0.165393\n",
      "epoch = 14 train_loss : 0.164225 , test loss : 0.162427\n",
      "epoch = 15 train_loss : 0.160285 , test loss : 0.158258\n",
      "epoch = 18 train_loss : 0.150694 , test loss : 0.153327\n",
      "epoch = 21 train_loss : 0.146541 , test loss : 0.150208\n",
      "epoch = 26 train_loss : 0.142281 , test loss : 0.149501\n",
      "epoch = 30 train_loss : 0.142499 , test loss : 0.148818\n",
      "epoch = 33 train_loss : 0.139623 , test loss : 0.148071\n",
      "epoch = 39 train_loss : 0.139948 , test loss : 0.147778\n",
      "epoch = 160 train_loss : 0.137494 , test loss : 0.147307\n",
      "epoch = 211 train_loss : 0.138482 , test loss : 0.147185\n",
      "epoch = 250 train_loss : 0.137832 , test loss : 0.147184\n",
      "epoch = 310 train_loss : 0.138991 , test loss : 0.147033\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.138991,test loss : 0.147033\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.397581 , test loss : 0.399014\n",
      "epoch = 2 train_loss : 0.325679 , test loss : 0.325460\n",
      "epoch = 3 train_loss : 0.285662 , test loss : 0.289245\n",
      "epoch = 4 train_loss : 0.261975 , test loss : 0.268303\n",
      "epoch = 5 train_loss : 0.241702 , test loss : 0.249571\n",
      "epoch = 6 train_loss : 0.221355 , test loss : 0.229925\n",
      "epoch = 7 train_loss : 0.206709 , test loss : 0.211003\n",
      "epoch = 8 train_loss : 0.196700 , test loss : 0.208316\n",
      "epoch = 9 train_loss : 0.186048 , test loss : 0.192384\n",
      "epoch = 10 train_loss : 0.178818 , test loss : 0.185392\n",
      "epoch = 11 train_loss : 0.172808 , test loss : 0.176525\n",
      "epoch = 12 train_loss : 0.166990 , test loss : 0.172511\n",
      "epoch = 13 train_loss : 0.162237 , test loss : 0.171741\n",
      "epoch = 14 train_loss : 0.157474 , test loss : 0.164053\n",
      "epoch = 15 train_loss : 0.156641 , test loss : 0.160786\n",
      "epoch = 17 train_loss : 0.153024 , test loss : 0.159408\n",
      "epoch = 19 train_loss : 0.149703 , test loss : 0.156888\n",
      "epoch = 20 train_loss : 0.149852 , test loss : 0.155460\n",
      "epoch = 23 train_loss : 0.148570 , test loss : 0.149491\n",
      "epoch = 24 train_loss : 0.145893 , test loss : 0.149340\n",
      "epoch = 29 train_loss : 0.142834 , test loss : 0.149134\n",
      "epoch = 30 train_loss : 0.146570 , test loss : 0.148815\n",
      "epoch = 34 train_loss : 0.145123 , test loss : 0.145689\n",
      "epoch = 36 train_loss : 0.140984 , test loss : 0.142644\n",
      "epoch = 37 train_loss : 0.141802 , test loss : 0.142560\n",
      "epoch = 50 train_loss : 0.140593 , test loss : 0.142220\n",
      "epoch = 58 train_loss : 0.142020 , test loss : 0.142016\n",
      "epoch = 70 train_loss : 0.140941 , test loss : 0.141286\n",
      "epoch = 79 train_loss : 0.141075 , test loss : 0.141237\n",
      "epoch = 122 train_loss : 0.141704 , test loss : 0.140673\n",
      "epoch = 133 train_loss : 0.142227 , test loss : 0.139208\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.142227,test loss : 0.139208\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.452395 , test loss : 0.458837\n",
      "epoch = 2 train_loss : 0.366324 , test loss : 0.343785\n",
      "epoch = 3 train_loss : 0.320331 , test loss : 0.315227\n",
      "epoch = 4 train_loss : 0.289558 , test loss : 0.279279\n",
      "epoch = 5 train_loss : 0.269844 , test loss : 0.260561\n",
      "epoch = 6 train_loss : 0.255504 , test loss : 0.251920\n",
      "epoch = 7 train_loss : 0.240548 , test loss : 0.230533\n",
      "epoch = 8 train_loss : 0.225676 , test loss : 0.219779\n",
      "epoch = 9 train_loss : 0.218097 , test loss : 0.212251\n",
      "epoch = 10 train_loss : 0.204871 , test loss : 0.202157\n",
      "epoch = 11 train_loss : 0.194176 , test loss : 0.186594\n",
      "epoch = 13 train_loss : 0.180412 , test loss : 0.174407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 14 train_loss : 0.175547 , test loss : 0.167802\n",
      "epoch = 16 train_loss : 0.166967 , test loss : 0.162763\n",
      "epoch = 17 train_loss : 0.162563 , test loss : 0.158650\n",
      "epoch = 18 train_loss : 0.157606 , test loss : 0.154868\n",
      "epoch = 19 train_loss : 0.159768 , test loss : 0.151749\n",
      "epoch = 22 train_loss : 0.152614 , test loss : 0.148502\n",
      "epoch = 23 train_loss : 0.149784 , test loss : 0.147605\n",
      "epoch = 26 train_loss : 0.149103 , test loss : 0.147063\n",
      "epoch = 27 train_loss : 0.150687 , test loss : 0.147041\n",
      "epoch = 29 train_loss : 0.145986 , test loss : 0.144530\n",
      "epoch = 44 train_loss : 0.142213 , test loss : 0.141785\n",
      "epoch = 65 train_loss : 0.140175 , test loss : 0.141721\n",
      "epoch = 70 train_loss : 0.140223 , test loss : 0.141248\n",
      "epoch = 73 train_loss : 0.140910 , test loss : 0.141089\n",
      "epoch = 83 train_loss : 0.140804 , test loss : 0.139512\n",
      "epoch = 378 train_loss : 0.140996 , test loss : 0.139362\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.140996,test loss : 0.139362\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.139052,total test loss mean : 0.146263 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],32),nn.Linear(32,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:05:00.556991Z",
     "start_time": "2021-12-28T07:05:00.534989Z"
    }
   },
   "source": [
    "#### set lr = 0.0001 , batch_size = 64 , test loss <=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T06:09:48.800243Z",
     "start_time": "2021-12-30T06:04:55.671477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 35.977432 , test loss : 35.725063\n",
      "epoch = 2 train_loss : 28.226198 , test loss : 28.058767\n",
      "epoch = 3 train_loss : 20.995371 , test loss : 20.925306\n",
      "epoch = 4 train_loss : 14.726070 , test loss : 14.775249\n",
      "epoch = 5 train_loss : 9.885094 , test loss : 9.996122\n",
      "epoch = 6 train_loss : 6.756429 , test loss : 6.909353\n",
      "epoch = 7 train_loss : 4.945567 , test loss : 5.114060\n",
      "epoch = 8 train_loss : 3.969896 , test loss : 4.148422\n",
      "epoch = 9 train_loss : 3.457125 , test loss : 3.637757\n",
      "epoch = 10 train_loss : 3.160943 , test loss : 3.344415\n",
      "epoch = 11 train_loss : 2.986933 , test loss : 3.176252\n",
      "epoch = 12 train_loss : 2.872469 , test loss : 3.067549\n",
      "epoch = 13 train_loss : 2.785807 , test loss : 2.987186\n",
      "epoch = 14 train_loss : 2.712818 , test loss : 2.922814\n",
      "epoch = 15 train_loss : 2.647378 , test loss : 2.863000\n",
      "epoch = 16 train_loss : 2.586798 , test loss : 2.805517\n",
      "epoch = 17 train_loss : 2.529670 , test loss : 2.752616\n",
      "epoch = 18 train_loss : 2.474979 , test loss : 2.696851\n",
      "epoch = 19 train_loss : 2.422246 , test loss : 2.644543\n",
      "epoch = 20 train_loss : 2.370919 , test loss : 2.594342\n",
      "epoch = 21 train_loss : 2.324775 , test loss : 2.549371\n",
      "epoch = 22 train_loss : 2.279002 , test loss : 2.504047\n",
      "epoch = 23 train_loss : 2.237063 , test loss : 2.464312\n",
      "epoch = 24 train_loss : 2.197309 , test loss : 2.425841\n",
      "epoch = 25 train_loss : 2.158362 , test loss : 2.387259\n",
      "epoch = 26 train_loss : 2.122136 , test loss : 2.351228\n",
      "epoch = 27 train_loss : 2.087291 , test loss : 2.315221\n",
      "epoch = 28 train_loss : 2.053895 , test loss : 2.282567\n",
      "epoch = 29 train_loss : 2.021163 , test loss : 2.251114\n",
      "epoch = 30 train_loss : 1.990527 , test loss : 2.220292\n",
      "epoch = 31 train_loss : 1.960779 , test loss : 2.191454\n",
      "epoch = 32 train_loss : 1.931881 , test loss : 2.161654\n",
      "epoch = 33 train_loss : 1.904166 , test loss : 2.132483\n",
      "epoch = 34 train_loss : 1.878411 , test loss : 2.105838\n",
      "epoch = 35 train_loss : 1.851664 , test loss : 2.079643\n",
      "epoch = 36 train_loss : 1.827601 , test loss : 2.055202\n",
      "epoch = 37 train_loss : 1.803102 , test loss : 2.030860\n",
      "epoch = 38 train_loss : 1.780405 , test loss : 2.005675\n",
      "epoch = 39 train_loss : 1.757917 , test loss : 1.983853\n",
      "epoch = 40 train_loss : 1.735507 , test loss : 1.961070\n",
      "epoch = 41 train_loss : 1.714108 , test loss : 1.938600\n",
      "epoch = 42 train_loss : 1.693339 , test loss : 1.917853\n",
      "epoch = 43 train_loss : 1.672342 , test loss : 1.895973\n",
      "epoch = 44 train_loss : 1.652570 , test loss : 1.875347\n",
      "epoch = 45 train_loss : 1.632871 , test loss : 1.856021\n",
      "epoch = 46 train_loss : 1.613851 , test loss : 1.834752\n",
      "epoch = 47 train_loss : 1.595942 , test loss : 1.815763\n",
      "epoch = 48 train_loss : 1.578048 , test loss : 1.797513\n",
      "epoch = 49 train_loss : 1.559639 , test loss : 1.779378\n",
      "epoch = 50 train_loss : 1.543473 , test loss : 1.760735\n",
      "epoch = 51 train_loss : 1.526538 , test loss : 1.744085\n",
      "epoch = 52 train_loss : 1.510544 , test loss : 1.727914\n",
      "epoch = 53 train_loss : 1.494863 , test loss : 1.710905\n",
      "epoch = 54 train_loss : 1.479336 , test loss : 1.695302\n",
      "epoch = 55 train_loss : 1.465177 , test loss : 1.679171\n",
      "epoch = 56 train_loss : 1.451377 , test loss : 1.665586\n",
      "epoch = 57 train_loss : 1.436199 , test loss : 1.647919\n",
      "epoch = 58 train_loss : 1.424311 , test loss : 1.635579\n",
      "epoch = 59 train_loss : 1.409620 , test loss : 1.619631\n",
      "epoch = 60 train_loss : 1.397227 , test loss : 1.605303\n",
      "epoch = 61 train_loss : 1.384761 , test loss : 1.592128\n",
      "epoch = 62 train_loss : 1.372204 , test loss : 1.579142\n",
      "epoch = 63 train_loss : 1.362499 , test loss : 1.567953\n",
      "epoch = 64 train_loss : 1.349391 , test loss : 1.554221\n",
      "epoch = 65 train_loss : 1.338019 , test loss : 1.540646\n",
      "epoch = 66 train_loss : 1.326939 , test loss : 1.528856\n",
      "epoch = 67 train_loss : 1.315715 , test loss : 1.516942\n",
      "epoch = 68 train_loss : 1.305208 , test loss : 1.505905\n",
      "epoch = 69 train_loss : 1.296946 , test loss : 1.497706\n",
      "epoch = 70 train_loss : 1.286834 , test loss : 1.484764\n",
      "epoch = 71 train_loss : 1.276881 , test loss : 1.475494\n",
      "epoch = 72 train_loss : 1.267757 , test loss : 1.462203\n",
      "epoch = 73 train_loss : 1.258195 , test loss : 1.452215\n",
      "epoch = 74 train_loss : 1.248232 , test loss : 1.443805\n",
      "epoch = 75 train_loss : 1.239722 , test loss : 1.431904\n",
      "epoch = 76 train_loss : 1.232725 , test loss : 1.423877\n",
      "epoch = 77 train_loss : 1.223652 , test loss : 1.414188\n",
      "epoch = 78 train_loss : 1.217478 , test loss : 1.406416\n",
      "epoch = 79 train_loss : 1.209511 , test loss : 1.401698\n",
      "epoch = 80 train_loss : 1.201352 , test loss : 1.392149\n",
      "epoch = 81 train_loss : 1.193610 , test loss : 1.382929\n",
      "epoch = 82 train_loss : 1.186329 , test loss : 1.374795\n",
      "epoch = 83 train_loss : 1.179920 , test loss : 1.368518\n",
      "epoch = 84 train_loss : 1.174152 , test loss : 1.363077\n",
      "epoch = 85 train_loss : 1.168126 , test loss : 1.356761\n",
      "epoch = 86 train_loss : 1.162369 , test loss : 1.350221\n",
      "epoch = 87 train_loss : 1.155681 , test loss : 1.342452\n",
      "epoch = 88 train_loss : 1.149122 , test loss : 1.336561\n",
      "epoch = 89 train_loss : 1.142908 , test loss : 1.330006\n",
      "epoch = 90 train_loss : 1.139397 , test loss : 1.327456\n",
      "epoch = 91 train_loss : 1.133659 , test loss : 1.322109\n",
      "epoch = 92 train_loss : 1.127037 , test loss : 1.315648\n",
      "epoch = 93 train_loss : 1.123890 , test loss : 1.310335\n",
      "epoch = 94 train_loss : 1.116678 , test loss : 1.305559\n",
      "epoch = 95 train_loss : 1.115681 , test loss : 1.305046\n",
      "epoch = 96 train_loss : 1.107875 , test loss : 1.296229\n",
      "epoch = 97 train_loss : 1.102661 , test loss : 1.290923\n",
      "epoch = 99 train_loss : 1.094085 , test loss : 1.283073\n",
      "epoch = 100 train_loss : 1.089487 , test loss : 1.279514\n",
      "epoch = 101 train_loss : 1.086579 , test loss : 1.277930\n",
      "epoch = 102 train_loss : 1.085450 , test loss : 1.276106\n",
      "epoch = 103 train_loss : 1.078183 , test loss : 1.267665\n",
      "epoch = 104 train_loss : 1.075712 , test loss : 1.264254\n",
      "epoch = 105 train_loss : 1.071975 , test loss : 1.261942\n",
      "epoch = 106 train_loss : 1.067251 , test loss : 1.258101\n",
      "epoch = 108 train_loss : 1.061637 , test loss : 1.252371\n",
      "epoch = 109 train_loss : 1.057584 , test loss : 1.249696\n",
      "epoch = 110 train_loss : 1.054934 , test loss : 1.246679\n",
      "epoch = 111 train_loss : 1.050282 , test loss : 1.242129\n",
      "epoch = 112 train_loss : 1.048550 , test loss : 1.241631\n",
      "epoch = 114 train_loss : 1.043476 , test loss : 1.238941\n",
      "epoch = 115 train_loss : 1.039102 , test loss : 1.234197\n",
      "epoch = 117 train_loss : 1.032873 , test loss : 1.227696\n",
      "epoch = 118 train_loss : 1.030875 , test loss : 1.224643\n",
      "epoch = 119 train_loss : 1.028484 , test loss : 1.224629\n",
      "epoch = 120 train_loss : 1.025400 , test loss : 1.221293\n",
      "epoch = 122 train_loss : 1.021038 , test loss : 1.218670\n",
      "epoch = 123 train_loss : 1.018144 , test loss : 1.215460\n",
      "epoch = 124 train_loss : 1.015950 , test loss : 1.213696\n",
      "epoch = 125 train_loss : 1.013538 , test loss : 1.213095\n",
      "epoch = 127 train_loss : 1.009420 , test loss : 1.208422\n",
      "epoch = 129 train_loss : 1.004523 , test loss : 1.206102\n",
      "epoch = 131 train_loss : 1.001332 , test loss : 1.203231\n",
      "epoch = 132 train_loss : 0.997794 , test loss : 1.201428\n",
      "epoch = 133 train_loss : 0.995539 , test loss : 1.199695\n",
      "epoch = 135 train_loss : 0.991575 , test loss : 1.196100\n",
      "epoch = 136 train_loss : 0.990099 , test loss : 1.195033\n",
      "epoch = 137 train_loss : 0.989596 , test loss : 1.194912\n",
      "epoch = 140 train_loss : 0.981939 , test loss : 1.190492\n",
      "epoch = 142 train_loss : 0.978362 , test loss : 1.189321\n",
      "epoch = 143 train_loss : 0.976343 , test loss : 1.186324\n",
      "epoch = 145 train_loss : 0.972640 , test loss : 1.184468\n",
      "epoch = 148 train_loss : 0.968271 , test loss : 1.182309\n",
      "epoch = 149 train_loss : 0.966742 , test loss : 1.182257\n",
      "epoch = 150 train_loss : 0.964727 , test loss : 1.181864\n",
      "epoch = 151 train_loss : 0.962967 , test loss : 1.179506\n",
      "epoch = 152 train_loss : 0.961389 , test loss : 1.179397\n",
      "epoch = 153 train_loss : 0.960198 , test loss : 1.177755\n",
      "epoch = 156 train_loss : 0.954941 , test loss : 1.177052\n",
      "epoch = 158 train_loss : 0.953590 , test loss : 1.174638\n",
      "epoch = 159 train_loss : 0.950474 , test loss : 1.173322\n",
      "epoch = 160 train_loss : 0.948988 , test loss : 1.172837\n",
      "epoch = 164 train_loss : 0.944464 , test loss : 1.172630\n",
      "epoch = 165 train_loss : 0.942758 , test loss : 1.170136\n",
      "epoch = 167 train_loss : 0.940681 , test loss : 1.168028\n",
      "epoch = 171 train_loss : 0.935843 , test loss : 1.166263\n",
      "epoch = 172 train_loss : 0.933628 , test loss : 1.165975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 175 train_loss : 0.929864 , test loss : 1.163999\n",
      "epoch = 181 train_loss : 0.923071 , test loss : 1.162490\n",
      "epoch = 184 train_loss : 0.918723 , test loss : 1.161473\n",
      "epoch = 186 train_loss : 0.917282 , test loss : 1.161312\n",
      "epoch = 187 train_loss : 0.915423 , test loss : 1.160603\n",
      "epoch = 192 train_loss : 0.910512 , test loss : 1.160073\n",
      "epoch = 194 train_loss : 0.908575 , test loss : 1.159787\n",
      "epoch = 199 train_loss : 0.903627 , test loss : 1.159747\n",
      "epoch = 200 train_loss : 0.902779 , test loss : 1.158864\n",
      "epoch = 204 train_loss : 0.897900 , test loss : 1.157972\n",
      "epoch = 206 train_loss : 0.896437 , test loss : 1.157889\n",
      "epoch = 214 train_loss : 0.888295 , test loss : 1.156815\n",
      "epoch = 216 train_loss : 0.887091 , test loss : 1.156575\n",
      "epoch = 229 train_loss : 0.876224 , test loss : 1.156421\n",
      "epoch = 232 train_loss : 0.873713 , test loss : 1.156375\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.873713,test loss : 1.156375\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 33.753365 , test loss : 32.878643\n",
      "epoch = 2 train_loss : 28.356684 , test loss : 27.599579\n",
      "epoch = 3 train_loss : 21.807564 , test loss : 21.161989\n",
      "epoch = 4 train_loss : 14.783728 , test loss : 14.370565\n",
      "epoch = 5 train_loss : 9.236149 , test loss : 9.059698\n",
      "epoch = 6 train_loss : 5.837419 , test loss : 5.846956\n",
      "epoch = 7 train_loss : 4.153890 , test loss : 4.292858\n",
      "epoch = 8 train_loss : 3.376998 , test loss : 3.601829\n",
      "epoch = 9 train_loss : 3.012611 , test loss : 3.284141\n",
      "epoch = 10 train_loss : 2.829041 , test loss : 3.124301\n",
      "epoch = 11 train_loss : 2.724487 , test loss : 3.030949\n",
      "epoch = 12 train_loss : 2.658828 , test loss : 2.970470\n",
      "epoch = 13 train_loss : 2.607552 , test loss : 2.919483\n",
      "epoch = 14 train_loss : 2.563723 , test loss : 2.878132\n",
      "epoch = 15 train_loss : 2.521606 , test loss : 2.832468\n",
      "epoch = 16 train_loss : 2.480470 , test loss : 2.792704\n",
      "epoch = 17 train_loss : 2.441616 , test loss : 2.752695\n",
      "epoch = 18 train_loss : 2.401720 , test loss : 2.709929\n",
      "epoch = 19 train_loss : 2.361570 , test loss : 2.671148\n",
      "epoch = 20 train_loss : 2.312951 , test loss : 2.611878\n",
      "epoch = 21 train_loss : 2.262169 , test loss : 2.556862\n",
      "epoch = 22 train_loss : 2.214598 , test loss : 2.510807\n",
      "epoch = 23 train_loss : 2.169232 , test loss : 2.469144\n",
      "epoch = 24 train_loss : 2.128576 , test loss : 2.430595\n",
      "epoch = 25 train_loss : 2.090716 , test loss : 2.388680\n",
      "epoch = 26 train_loss : 2.055584 , test loss : 2.354652\n",
      "epoch = 27 train_loss : 2.021458 , test loss : 2.318976\n",
      "epoch = 28 train_loss : 1.989299 , test loss : 2.286465\n",
      "epoch = 29 train_loss : 1.957700 , test loss : 2.257298\n",
      "epoch = 30 train_loss : 1.927279 , test loss : 2.228470\n",
      "epoch = 31 train_loss : 1.898989 , test loss : 2.199484\n",
      "epoch = 32 train_loss : 1.871405 , test loss : 2.171219\n",
      "epoch = 33 train_loss : 1.845050 , test loss : 2.143134\n",
      "epoch = 34 train_loss : 1.819283 , test loss : 2.117944\n",
      "epoch = 35 train_loss : 1.794975 , test loss : 2.094070\n",
      "epoch = 36 train_loss : 1.770974 , test loss : 2.071621\n",
      "epoch = 37 train_loss : 1.747712 , test loss : 2.047929\n",
      "epoch = 38 train_loss : 1.725084 , test loss : 2.027343\n",
      "epoch = 39 train_loss : 1.702652 , test loss : 2.008139\n",
      "epoch = 40 train_loss : 1.681737 , test loss : 1.983622\n",
      "epoch = 41 train_loss : 1.660538 , test loss : 1.965647\n",
      "epoch = 42 train_loss : 1.641047 , test loss : 1.945155\n",
      "epoch = 43 train_loss : 1.620719 , test loss : 1.921965\n",
      "epoch = 44 train_loss : 1.600999 , test loss : 1.905803\n",
      "epoch = 45 train_loss : 1.582166 , test loss : 1.891087\n",
      "epoch = 46 train_loss : 1.563913 , test loss : 1.871531\n",
      "epoch = 47 train_loss : 1.547307 , test loss : 1.855918\n",
      "epoch = 48 train_loss : 1.531679 , test loss : 1.834128\n",
      "epoch = 49 train_loss : 1.514050 , test loss : 1.822493\n",
      "epoch = 50 train_loss : 1.496344 , test loss : 1.804806\n",
      "epoch = 51 train_loss : 1.480133 , test loss : 1.790724\n",
      "epoch = 52 train_loss : 1.464823 , test loss : 1.774834\n",
      "epoch = 53 train_loss : 1.450792 , test loss : 1.760539\n",
      "epoch = 54 train_loss : 1.435306 , test loss : 1.744023\n",
      "epoch = 55 train_loss : 1.420518 , test loss : 1.732924\n",
      "epoch = 56 train_loss : 1.409925 , test loss : 1.726748\n",
      "epoch = 57 train_loss : 1.393947 , test loss : 1.711400\n",
      "epoch = 58 train_loss : 1.379173 , test loss : 1.689139\n",
      "epoch = 59 train_loss : 1.368363 , test loss : 1.679930\n",
      "epoch = 60 train_loss : 1.353573 , test loss : 1.664274\n",
      "epoch = 61 train_loss : 1.341731 , test loss : 1.651817\n",
      "epoch = 62 train_loss : 1.329741 , test loss : 1.639968\n",
      "epoch = 63 train_loss : 1.320458 , test loss : 1.637931\n",
      "epoch = 64 train_loss : 1.307372 , test loss : 1.618130\n",
      "epoch = 65 train_loss : 1.296953 , test loss : 1.613683\n",
      "epoch = 66 train_loss : 1.285832 , test loss : 1.598930\n",
      "epoch = 67 train_loss : 1.275669 , test loss : 1.587491\n",
      "epoch = 68 train_loss : 1.265999 , test loss : 1.575430\n",
      "epoch = 69 train_loss : 1.255941 , test loss : 1.566245\n",
      "epoch = 70 train_loss : 1.246939 , test loss : 1.556501\n",
      "epoch = 71 train_loss : 1.237637 , test loss : 1.548777\n",
      "epoch = 72 train_loss : 1.229081 , test loss : 1.543929\n",
      "epoch = 73 train_loss : 1.221062 , test loss : 1.525378\n",
      "epoch = 74 train_loss : 1.211034 , test loss : 1.518443\n",
      "epoch = 75 train_loss : 1.202464 , test loss : 1.510903\n",
      "epoch = 77 train_loss : 1.186875 , test loss : 1.498501\n",
      "epoch = 78 train_loss : 1.178948 , test loss : 1.491105\n",
      "epoch = 79 train_loss : 1.171596 , test loss : 1.483971\n",
      "epoch = 80 train_loss : 1.164002 , test loss : 1.478624\n",
      "epoch = 81 train_loss : 1.157800 , test loss : 1.467901\n",
      "epoch = 82 train_loss : 1.151754 , test loss : 1.463473\n",
      "epoch = 83 train_loss : 1.144619 , test loss : 1.458951\n",
      "epoch = 84 train_loss : 1.139200 , test loss : 1.454957\n",
      "epoch = 85 train_loss : 1.133164 , test loss : 1.448934\n",
      "epoch = 86 train_loss : 1.127471 , test loss : 1.444176\n",
      "epoch = 87 train_loss : 1.122267 , test loss : 1.430911\n",
      "epoch = 88 train_loss : 1.116710 , test loss : 1.426718\n",
      "epoch = 89 train_loss : 1.110978 , test loss : 1.425730\n",
      "epoch = 90 train_loss : 1.106030 , test loss : 1.417912\n",
      "epoch = 91 train_loss : 1.101540 , test loss : 1.411647\n",
      "epoch = 92 train_loss : 1.097803 , test loss : 1.406176\n",
      "epoch = 93 train_loss : 1.092554 , test loss : 1.401827\n",
      "epoch = 94 train_loss : 1.090229 , test loss : 1.399552\n",
      "epoch = 95 train_loss : 1.084933 , test loss : 1.396017\n",
      "epoch = 96 train_loss : 1.081512 , test loss : 1.391090\n",
      "epoch = 98 train_loss : 1.073485 , test loss : 1.377142\n",
      "epoch = 99 train_loss : 1.069610 , test loss : 1.376608\n",
      "epoch = 101 train_loss : 1.062159 , test loss : 1.372549\n",
      "epoch = 102 train_loss : 1.059544 , test loss : 1.369392\n",
      "epoch = 103 train_loss : 1.057017 , test loss : 1.359954\n",
      "epoch = 104 train_loss : 1.052630 , test loss : 1.355755\n",
      "epoch = 105 train_loss : 1.049085 , test loss : 1.354694\n",
      "epoch = 106 train_loss : 1.047096 , test loss : 1.351364\n",
      "epoch = 108 train_loss : 1.040725 , test loss : 1.341836\n",
      "epoch = 113 train_loss : 1.027884 , test loss : 1.324368\n",
      "epoch = 116 train_loss : 1.018690 , test loss : 1.324162\n",
      "epoch = 120 train_loss : 1.009598 , test loss : 1.317122\n",
      "epoch = 121 train_loss : 1.006975 , test loss : 1.314561\n",
      "epoch = 122 train_loss : 1.006019 , test loss : 1.313154\n",
      "epoch = 123 train_loss : 1.004057 , test loss : 1.312132\n",
      "epoch = 124 train_loss : 1.002313 , test loss : 1.311166\n",
      "epoch = 125 train_loss : 1.000903 , test loss : 1.299707\n",
      "epoch = 126 train_loss : 0.998223 , test loss : 1.295821\n",
      "epoch = 129 train_loss : 0.991865 , test loss : 1.292082\n",
      "epoch = 131 train_loss : 0.988012 , test loss : 1.286676\n",
      "epoch = 136 train_loss : 0.977701 , test loss : 1.283920\n",
      "epoch = 138 train_loss : 0.975426 , test loss : 1.282890\n",
      "epoch = 140 train_loss : 0.971382 , test loss : 1.276024\n",
      "epoch = 143 train_loss : 0.967508 , test loss : 1.271839\n",
      "epoch = 146 train_loss : 0.962547 , test loss : 1.267819\n",
      "epoch = 150 train_loss : 0.957658 , test loss : 1.261808\n",
      "epoch = 156 train_loss : 0.948815 , test loss : 1.259411\n",
      "epoch = 158 train_loss : 0.946495 , test loss : 1.257065\n",
      "epoch = 160 train_loss : 0.943485 , test loss : 1.251535\n",
      "epoch = 166 train_loss : 0.936027 , test loss : 1.247940\n",
      "epoch = 171 train_loss : 0.929731 , test loss : 1.245207\n",
      "epoch = 174 train_loss : 0.926145 , test loss : 1.244030\n",
      "epoch = 175 train_loss : 0.925244 , test loss : 1.240626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 178 train_loss : 0.924017 , test loss : 1.240018\n",
      "epoch = 180 train_loss : 0.921031 , test loss : 1.236791\n",
      "epoch = 187 train_loss : 0.914181 , test loss : 1.230346\n",
      "epoch = 194 train_loss : 0.908686 , test loss : 1.226394\n",
      "epoch = 204 train_loss : 0.899199 , test loss : 1.224338\n",
      "epoch = 214 train_loss : 0.891127 , test loss : 1.220303\n",
      "epoch = 218 train_loss : 0.886876 , test loss : 1.219941\n",
      "epoch = 220 train_loss : 0.888782 , test loss : 1.218590\n",
      "epoch = 229 train_loss : 0.883253 , test loss : 1.218327\n",
      "epoch = 233 train_loss : 0.875532 , test loss : 1.216247\n",
      "epoch = 235 train_loss : 0.874757 , test loss : 1.213621\n",
      "epoch = 246 train_loss : 0.867305 , test loss : 1.212289\n",
      "epoch = 268 train_loss : 0.852641 , test loss : 1.212011\n",
      "epoch = 277 train_loss : 0.850171 , test loss : 1.210638\n",
      "epoch = 284 train_loss : 0.843895 , test loss : 1.207991\n",
      "epoch = 352 train_loss : 0.811162 , test loss : 1.207732\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.811162,test loss : 1.207732\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 37.416195 , test loss : 38.272133\n",
      "epoch = 2 train_loss : 31.228672 , test loss : 31.948929\n",
      "epoch = 3 train_loss : 25.452696 , test loss : 26.023188\n",
      "epoch = 4 train_loss : 20.061407 , test loss : 20.484421\n",
      "epoch = 5 train_loss : 15.485948 , test loss : 15.779355\n",
      "epoch = 6 train_loss : 11.805591 , test loss : 11.985270\n",
      "epoch = 7 train_loss : 9.087151 , test loss : 9.167240\n",
      "epoch = 8 train_loss : 7.124959 , test loss : 7.115366\n",
      "epoch = 9 train_loss : 5.738865 , test loss : 5.659001\n",
      "epoch = 10 train_loss : 4.762552 , test loss : 4.627439\n",
      "epoch = 11 train_loss : 4.071613 , test loss : 3.900852\n",
      "epoch = 12 train_loss : 3.606787 , test loss : 3.417249\n",
      "epoch = 13 train_loss : 3.296351 , test loss : 3.095863\n",
      "epoch = 14 train_loss : 3.095492 , test loss : 2.890769\n",
      "epoch = 15 train_loss : 2.962085 , test loss : 2.755668\n",
      "epoch = 16 train_loss : 2.873784 , test loss : 2.669798\n",
      "epoch = 17 train_loss : 2.811307 , test loss : 2.605730\n",
      "epoch = 18 train_loss : 2.761861 , test loss : 2.560092\n",
      "epoch = 19 train_loss : 2.722980 , test loss : 2.525088\n",
      "epoch = 20 train_loss : 2.688331 , test loss : 2.494603\n",
      "epoch = 21 train_loss : 2.656665 , test loss : 2.465785\n",
      "epoch = 22 train_loss : 2.625780 , test loss : 2.439369\n",
      "epoch = 23 train_loss : 2.595224 , test loss : 2.413490\n",
      "epoch = 24 train_loss : 2.562257 , test loss : 2.385264\n",
      "epoch = 25 train_loss : 2.530361 , test loss : 2.359542\n",
      "epoch = 26 train_loss : 2.498468 , test loss : 2.333486\n",
      "epoch = 27 train_loss : 2.465825 , test loss : 2.308236\n",
      "epoch = 28 train_loss : 2.433322 , test loss : 2.276388\n",
      "epoch = 29 train_loss : 2.400928 , test loss : 2.250647\n",
      "epoch = 30 train_loss : 2.368496 , test loss : 2.221107\n",
      "epoch = 31 train_loss : 2.335451 , test loss : 2.195399\n",
      "epoch = 32 train_loss : 2.299948 , test loss : 2.162316\n",
      "epoch = 33 train_loss : 2.265295 , test loss : 2.135318\n",
      "epoch = 34 train_loss : 2.230937 , test loss : 2.105639\n",
      "epoch = 35 train_loss : 2.196205 , test loss : 2.072783\n",
      "epoch = 36 train_loss : 2.161514 , test loss : 2.045973\n",
      "epoch = 37 train_loss : 2.127569 , test loss : 2.016517\n",
      "epoch = 38 train_loss : 2.093405 , test loss : 1.990053\n",
      "epoch = 39 train_loss : 2.059291 , test loss : 1.958952\n",
      "epoch = 40 train_loss : 2.026482 , test loss : 1.928931\n",
      "epoch = 41 train_loss : 1.992465 , test loss : 1.901534\n",
      "epoch = 42 train_loss : 1.960447 , test loss : 1.875329\n",
      "epoch = 43 train_loss : 1.923254 , test loss : 1.841296\n",
      "epoch = 44 train_loss : 1.889246 , test loss : 1.810976\n",
      "epoch = 45 train_loss : 1.856437 , test loss : 1.785289\n",
      "epoch = 46 train_loss : 1.822525 , test loss : 1.750983\n",
      "epoch = 47 train_loss : 1.789716 , test loss : 1.723423\n",
      "epoch = 48 train_loss : 1.759135 , test loss : 1.700741\n",
      "epoch = 49 train_loss : 1.729636 , test loss : 1.672696\n",
      "epoch = 50 train_loss : 1.700648 , test loss : 1.645001\n",
      "epoch = 51 train_loss : 1.674211 , test loss : 1.626182\n",
      "epoch = 52 train_loss : 1.647181 , test loss : 1.598207\n",
      "epoch = 53 train_loss : 1.621946 , test loss : 1.577934\n",
      "epoch = 54 train_loss : 1.597628 , test loss : 1.555195\n",
      "epoch = 55 train_loss : 1.574703 , test loss : 1.537902\n",
      "epoch = 56 train_loss : 1.551960 , test loss : 1.519149\n",
      "epoch = 57 train_loss : 1.530818 , test loss : 1.499209\n",
      "epoch = 58 train_loss : 1.510880 , test loss : 1.485515\n",
      "epoch = 59 train_loss : 1.490438 , test loss : 1.463003\n",
      "epoch = 60 train_loss : 1.472783 , test loss : 1.445181\n",
      "epoch = 61 train_loss : 1.455397 , test loss : 1.435624\n",
      "epoch = 62 train_loss : 1.437117 , test loss : 1.417807\n",
      "epoch = 63 train_loss : 1.419660 , test loss : 1.404167\n",
      "epoch = 64 train_loss : 1.405321 , test loss : 1.390552\n",
      "epoch = 65 train_loss : 1.388874 , test loss : 1.375698\n",
      "epoch = 66 train_loss : 1.374541 , test loss : 1.362748\n",
      "epoch = 67 train_loss : 1.361460 , test loss : 1.352595\n",
      "epoch = 68 train_loss : 1.348032 , test loss : 1.340861\n",
      "epoch = 69 train_loss : 1.334845 , test loss : 1.333370\n",
      "epoch = 70 train_loss : 1.323152 , test loss : 1.323989\n",
      "epoch = 71 train_loss : 1.310820 , test loss : 1.311380\n",
      "epoch = 72 train_loss : 1.301805 , test loss : 1.305909\n",
      "epoch = 73 train_loss : 1.288777 , test loss : 1.292668\n",
      "epoch = 74 train_loss : 1.279269 , test loss : 1.286394\n",
      "epoch = 75 train_loss : 1.268727 , test loss : 1.277497\n",
      "epoch = 76 train_loss : 1.259022 , test loss : 1.268627\n",
      "epoch = 77 train_loss : 1.249778 , test loss : 1.261700\n",
      "epoch = 78 train_loss : 1.241198 , test loss : 1.252234\n",
      "epoch = 79 train_loss : 1.233807 , test loss : 1.249734\n",
      "epoch = 80 train_loss : 1.225456 , test loss : 1.239222\n",
      "epoch = 81 train_loss : 1.216087 , test loss : 1.235915\n",
      "epoch = 82 train_loss : 1.208438 , test loss : 1.227641\n",
      "epoch = 83 train_loss : 1.203434 , test loss : 1.224194\n",
      "epoch = 84 train_loss : 1.195775 , test loss : 1.219661\n",
      "epoch = 85 train_loss : 1.188081 , test loss : 1.212146\n",
      "epoch = 86 train_loss : 1.181496 , test loss : 1.208902\n",
      "epoch = 87 train_loss : 1.177639 , test loss : 1.205092\n",
      "epoch = 88 train_loss : 1.169218 , test loss : 1.198796\n",
      "epoch = 89 train_loss : 1.162211 , test loss : 1.191703\n",
      "epoch = 90 train_loss : 1.155815 , test loss : 1.188340\n",
      "epoch = 91 train_loss : 1.152129 , test loss : 1.184225\n",
      "epoch = 92 train_loss : 1.146591 , test loss : 1.182054\n",
      "epoch = 93 train_loss : 1.139210 , test loss : 1.176237\n",
      "epoch = 95 train_loss : 1.129049 , test loss : 1.170382\n",
      "epoch = 97 train_loss : 1.119528 , test loss : 1.163740\n",
      "epoch = 98 train_loss : 1.120364 , test loss : 1.163395\n",
      "epoch = 99 train_loss : 1.109752 , test loss : 1.157035\n",
      "epoch = 100 train_loss : 1.105551 , test loss : 1.153309\n",
      "epoch = 101 train_loss : 1.101509 , test loss : 1.152680\n",
      "epoch = 102 train_loss : 1.097575 , test loss : 1.150292\n",
      "epoch = 103 train_loss : 1.093793 , test loss : 1.146850\n",
      "epoch = 105 train_loss : 1.085582 , test loss : 1.143155\n",
      "epoch = 106 train_loss : 1.085208 , test loss : 1.142265\n",
      "epoch = 108 train_loss : 1.074652 , test loss : 1.136935\n",
      "epoch = 110 train_loss : 1.069335 , test loss : 1.136016\n",
      "epoch = 111 train_loss : 1.065197 , test loss : 1.134467\n",
      "epoch = 112 train_loss : 1.061779 , test loss : 1.130775\n",
      "epoch = 114 train_loss : 1.054007 , test loss : 1.127453\n",
      "epoch = 115 train_loss : 1.051285 , test loss : 1.125185\n",
      "epoch = 117 train_loss : 1.045446 , test loss : 1.123041\n",
      "epoch = 119 train_loss : 1.041052 , test loss : 1.122070\n",
      "epoch = 120 train_loss : 1.038666 , test loss : 1.120303\n",
      "epoch = 121 train_loss : 1.034154 , test loss : 1.117906\n",
      "epoch = 122 train_loss : 1.031553 , test loss : 1.117331\n",
      "epoch = 125 train_loss : 1.029415 , test loss : 1.116049\n",
      "epoch = 127 train_loss : 1.019629 , test loss : 1.115072\n",
      "epoch = 128 train_loss : 1.016904 , test loss : 1.112645\n",
      "epoch = 130 train_loss : 1.011847 , test loss : 1.110717\n",
      "epoch = 132 train_loss : 1.009106 , test loss : 1.109825\n",
      "epoch = 133 train_loss : 1.005228 , test loss : 1.109527\n",
      "epoch = 134 train_loss : 1.003353 , test loss : 1.108190\n",
      "epoch = 136 train_loss : 0.999622 , test loss : 1.105583\n",
      "epoch = 137 train_loss : 0.997694 , test loss : 1.105383\n",
      "epoch = 140 train_loss : 0.991899 , test loss : 1.104547\n",
      "epoch = 143 train_loss : 0.986839 , test loss : 1.103664\n",
      "epoch = 144 train_loss : 0.983733 , test loss : 1.101924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 151 train_loss : 0.971274 , test loss : 1.101601\n",
      "epoch = 153 train_loss : 0.969425 , test loss : 1.101459\n",
      "epoch = 154 train_loss : 0.966510 , test loss : 1.099747\n",
      "epoch = 158 train_loss : 0.960972 , test loss : 1.099727\n",
      "epoch = 164 train_loss : 0.951931 , test loss : 1.099564\n",
      "epoch = 166 train_loss : 0.949511 , test loss : 1.099137\n",
      "epoch = 168 train_loss : 0.949242 , test loss : 1.098027\n",
      "epoch = 170 train_loss : 0.947598 , test loss : 1.096480\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.947598,test loss : 1.096480\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 33.532787 , test loss : 34.258457\n",
      "epoch = 2 train_loss : 28.135048 , test loss : 28.775078\n",
      "epoch = 3 train_loss : 23.515177 , test loss : 24.080605\n",
      "epoch = 4 train_loss : 19.190063 , test loss : 19.570787\n",
      "epoch = 5 train_loss : 15.382458 , test loss : 15.608493\n",
      "epoch = 6 train_loss : 12.210268 , test loss : 12.320921\n",
      "epoch = 7 train_loss : 9.719098 , test loss : 9.762858\n",
      "epoch = 8 train_loss : 7.812058 , test loss : 7.828127\n",
      "epoch = 9 train_loss : 6.393195 , test loss : 6.409768\n",
      "epoch = 10 train_loss : 5.340435 , test loss : 5.364978\n",
      "epoch = 11 train_loss : 4.559391 , test loss : 4.590361\n",
      "epoch = 12 train_loss : 3.987142 , test loss : 4.023916\n",
      "epoch = 13 train_loss : 3.585238 , test loss : 3.626270\n",
      "epoch = 14 train_loss : 3.301548 , test loss : 3.345278\n",
      "epoch = 15 train_loss : 3.106337 , test loss : 3.151446\n",
      "epoch = 16 train_loss : 2.976400 , test loss : 3.022206\n",
      "epoch = 17 train_loss : 2.883766 , test loss : 2.928675\n",
      "epoch = 18 train_loss : 2.816137 , test loss : 2.860068\n",
      "epoch = 19 train_loss : 2.765954 , test loss : 2.810902\n",
      "epoch = 20 train_loss : 2.725619 , test loss : 2.771254\n",
      "epoch = 21 train_loss : 2.690489 , test loss : 2.737895\n",
      "epoch = 22 train_loss : 2.659141 , test loss : 2.709045\n",
      "epoch = 23 train_loss : 2.630651 , test loss : 2.681842\n",
      "epoch = 24 train_loss : 2.604022 , test loss : 2.656431\n",
      "epoch = 25 train_loss : 2.578230 , test loss : 2.632357\n",
      "epoch = 26 train_loss : 2.553542 , test loss : 2.608479\n",
      "epoch = 27 train_loss : 2.529228 , test loss : 2.584590\n",
      "epoch = 28 train_loss : 2.504869 , test loss : 2.562516\n",
      "epoch = 29 train_loss : 2.480840 , test loss : 2.538875\n",
      "epoch = 30 train_loss : 2.457631 , test loss : 2.516615\n",
      "epoch = 31 train_loss : 2.434949 , test loss : 2.494221\n",
      "epoch = 32 train_loss : 2.411565 , test loss : 2.470779\n",
      "epoch = 33 train_loss : 2.388754 , test loss : 2.448188\n",
      "epoch = 34 train_loss : 2.366240 , test loss : 2.425953\n",
      "epoch = 35 train_loss : 2.343846 , test loss : 2.403803\n",
      "epoch = 36 train_loss : 2.321574 , test loss : 2.381059\n",
      "epoch = 37 train_loss : 2.299542 , test loss : 2.360170\n",
      "epoch = 38 train_loss : 2.278054 , test loss : 2.337365\n",
      "epoch = 39 train_loss : 2.255939 , test loss : 2.318439\n",
      "epoch = 40 train_loss : 2.234047 , test loss : 2.295929\n",
      "epoch = 41 train_loss : 2.212633 , test loss : 2.274979\n",
      "epoch = 42 train_loss : 2.190870 , test loss : 2.252774\n",
      "epoch = 43 train_loss : 2.169777 , test loss : 2.233459\n",
      "epoch = 44 train_loss : 2.148270 , test loss : 2.211221\n",
      "epoch = 45 train_loss : 2.126917 , test loss : 2.189957\n",
      "epoch = 46 train_loss : 2.105507 , test loss : 2.169250\n",
      "epoch = 47 train_loss : 2.084019 , test loss : 2.148297\n",
      "epoch = 48 train_loss : 2.062865 , test loss : 2.128317\n",
      "epoch = 49 train_loss : 2.040568 , test loss : 2.104771\n",
      "epoch = 50 train_loss : 2.018494 , test loss : 2.083275\n",
      "epoch = 51 train_loss : 1.995929 , test loss : 2.061154\n",
      "epoch = 52 train_loss : 1.973996 , test loss : 2.038499\n",
      "epoch = 53 train_loss : 1.952332 , test loss : 2.017339\n",
      "epoch = 54 train_loss : 1.930191 , test loss : 1.996565\n",
      "epoch = 55 train_loss : 1.908838 , test loss : 1.975502\n",
      "epoch = 56 train_loss : 1.886555 , test loss : 1.952792\n",
      "epoch = 57 train_loss : 1.865888 , test loss : 1.932330\n",
      "epoch = 58 train_loss : 1.844182 , test loss : 1.910797\n",
      "epoch = 59 train_loss : 1.823660 , test loss : 1.892135\n",
      "epoch = 60 train_loss : 1.803697 , test loss : 1.871616\n",
      "epoch = 61 train_loss : 1.782509 , test loss : 1.848557\n",
      "epoch = 62 train_loss : 1.762488 , test loss : 1.830612\n",
      "epoch = 63 train_loss : 1.742719 , test loss : 1.810187\n",
      "epoch = 64 train_loss : 1.724891 , test loss : 1.792899\n",
      "epoch = 65 train_loss : 1.705483 , test loss : 1.773545\n",
      "epoch = 66 train_loss : 1.686203 , test loss : 1.754776\n",
      "epoch = 67 train_loss : 1.668984 , test loss : 1.737877\n",
      "epoch = 68 train_loss : 1.650730 , test loss : 1.720533\n",
      "epoch = 69 train_loss : 1.633619 , test loss : 1.705128\n",
      "epoch = 70 train_loss : 1.616689 , test loss : 1.686623\n",
      "epoch = 71 train_loss : 1.599128 , test loss : 1.671049\n",
      "epoch = 72 train_loss : 1.582707 , test loss : 1.654021\n",
      "epoch = 73 train_loss : 1.567104 , test loss : 1.638266\n",
      "epoch = 74 train_loss : 1.551954 , test loss : 1.623460\n",
      "epoch = 75 train_loss : 1.536917 , test loss : 1.609740\n",
      "epoch = 76 train_loss : 1.522722 , test loss : 1.598404\n",
      "epoch = 77 train_loss : 1.508129 , test loss : 1.582114\n",
      "epoch = 78 train_loss : 1.494102 , test loss : 1.568799\n",
      "epoch = 79 train_loss : 1.480668 , test loss : 1.556790\n",
      "epoch = 80 train_loss : 1.469682 , test loss : 1.547207\n",
      "epoch = 81 train_loss : 1.455103 , test loss : 1.530071\n",
      "epoch = 82 train_loss : 1.443126 , test loss : 1.518410\n",
      "epoch = 83 train_loss : 1.430665 , test loss : 1.509162\n",
      "epoch = 84 train_loss : 1.418768 , test loss : 1.494509\n",
      "epoch = 85 train_loss : 1.407039 , test loss : 1.484215\n",
      "epoch = 86 train_loss : 1.396444 , test loss : 1.476874\n",
      "epoch = 87 train_loss : 1.385172 , test loss : 1.464157\n",
      "epoch = 88 train_loss : 1.375522 , test loss : 1.454136\n",
      "epoch = 89 train_loss : 1.364744 , test loss : 1.445507\n",
      "epoch = 90 train_loss : 1.356645 , test loss : 1.436615\n",
      "epoch = 91 train_loss : 1.346276 , test loss : 1.424279\n",
      "epoch = 92 train_loss : 1.337231 , test loss : 1.415327\n",
      "epoch = 93 train_loss : 1.327638 , test loss : 1.406042\n",
      "epoch = 94 train_loss : 1.318782 , test loss : 1.397185\n",
      "epoch = 95 train_loss : 1.310441 , test loss : 1.390211\n",
      "epoch = 96 train_loss : 1.302265 , test loss : 1.381585\n",
      "epoch = 97 train_loss : 1.294157 , test loss : 1.376277\n",
      "epoch = 98 train_loss : 1.286984 , test loss : 1.368115\n",
      "epoch = 99 train_loss : 1.278790 , test loss : 1.360624\n",
      "epoch = 100 train_loss : 1.271162 , test loss : 1.353579\n",
      "epoch = 101 train_loss : 1.265638 , test loss : 1.348413\n",
      "epoch = 102 train_loss : 1.256628 , test loss : 1.339508\n",
      "epoch = 103 train_loss : 1.249938 , test loss : 1.333984\n",
      "epoch = 104 train_loss : 1.243430 , test loss : 1.327532\n",
      "epoch = 105 train_loss : 1.236374 , test loss : 1.320608\n",
      "epoch = 106 train_loss : 1.230054 , test loss : 1.316438\n",
      "epoch = 107 train_loss : 1.224076 , test loss : 1.310653\n",
      "epoch = 108 train_loss : 1.218463 , test loss : 1.303960\n",
      "epoch = 109 train_loss : 1.212457 , test loss : 1.298518\n",
      "epoch = 110 train_loss : 1.208605 , test loss : 1.298038\n",
      "epoch = 111 train_loss : 1.202260 , test loss : 1.288786\n",
      "epoch = 112 train_loss : 1.199082 , test loss : 1.285998\n",
      "epoch = 113 train_loss : 1.193681 , test loss : 1.282650\n",
      "epoch = 114 train_loss : 1.185598 , test loss : 1.278811\n",
      "epoch = 115 train_loss : 1.181031 , test loss : 1.272940\n",
      "epoch = 116 train_loss : 1.174995 , test loss : 1.267647\n",
      "epoch = 117 train_loss : 1.170300 , test loss : 1.262799\n",
      "epoch = 118 train_loss : 1.165315 , test loss : 1.261324\n",
      "epoch = 119 train_loss : 1.162337 , test loss : 1.256360\n",
      "epoch = 120 train_loss : 1.155777 , test loss : 1.251321\n",
      "epoch = 122 train_loss : 1.146981 , test loss : 1.243041\n",
      "epoch = 123 train_loss : 1.142836 , test loss : 1.241333\n",
      "epoch = 124 train_loss : 1.138347 , test loss : 1.238589\n",
      "epoch = 125 train_loss : 1.134631 , test loss : 1.233407\n",
      "epoch = 126 train_loss : 1.130488 , test loss : 1.232939\n",
      "epoch = 127 train_loss : 1.126695 , test loss : 1.225798\n",
      "epoch = 128 train_loss : 1.122362 , test loss : 1.224562\n",
      "epoch = 129 train_loss : 1.118562 , test loss : 1.222815\n",
      "epoch = 130 train_loss : 1.116113 , test loss : 1.220871\n",
      "epoch = 132 train_loss : 1.108453 , test loss : 1.216385\n",
      "epoch = 133 train_loss : 1.103418 , test loss : 1.211758\n",
      "epoch = 134 train_loss : 1.099946 , test loss : 1.208276\n",
      "epoch = 135 train_loss : 1.096536 , test loss : 1.205022\n",
      "epoch = 136 train_loss : 1.093314 , test loss : 1.204391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 137 train_loss : 1.089967 , test loss : 1.199132\n",
      "epoch = 138 train_loss : 1.085932 , test loss : 1.197716\n",
      "epoch = 140 train_loss : 1.080681 , test loss : 1.191108\n",
      "epoch = 143 train_loss : 1.069649 , test loss : 1.187753\n",
      "epoch = 145 train_loss : 1.064135 , test loss : 1.186512\n",
      "epoch = 146 train_loss : 1.060761 , test loss : 1.181631\n",
      "epoch = 147 train_loss : 1.057981 , test loss : 1.181506\n",
      "epoch = 149 train_loss : 1.052368 , test loss : 1.179517\n",
      "epoch = 150 train_loss : 1.049320 , test loss : 1.174841\n",
      "epoch = 153 train_loss : 1.041127 , test loss : 1.171629\n",
      "epoch = 154 train_loss : 1.040525 , test loss : 1.170136\n",
      "epoch = 155 train_loss : 1.036570 , test loss : 1.168693\n",
      "epoch = 156 train_loss : 1.034562 , test loss : 1.165048\n",
      "epoch = 157 train_loss : 1.031248 , test loss : 1.162846\n",
      "epoch = 160 train_loss : 1.024320 , test loss : 1.162739\n",
      "epoch = 161 train_loss : 1.021193 , test loss : 1.158589\n",
      "epoch = 163 train_loss : 1.020260 , test loss : 1.158560\n",
      "epoch = 164 train_loss : 1.014587 , test loss : 1.156534\n",
      "epoch = 165 train_loss : 1.012377 , test loss : 1.153705\n",
      "epoch = 167 train_loss : 1.008081 , test loss : 1.151762\n",
      "epoch = 169 train_loss : 1.003412 , test loss : 1.149672\n",
      "epoch = 173 train_loss : 0.995532 , test loss : 1.148063\n",
      "epoch = 174 train_loss : 0.993269 , test loss : 1.146634\n",
      "epoch = 175 train_loss : 0.991452 , test loss : 1.145969\n",
      "epoch = 176 train_loss : 0.989987 , test loss : 1.145805\n",
      "epoch = 177 train_loss : 0.987491 , test loss : 1.142869\n",
      "epoch = 178 train_loss : 0.988691 , test loss : 1.142491\n",
      "epoch = 181 train_loss : 0.980192 , test loss : 1.138180\n",
      "epoch = 186 train_loss : 0.971148 , test loss : 1.138005\n",
      "epoch = 188 train_loss : 0.967940 , test loss : 1.136681\n",
      "epoch = 190 train_loss : 0.964838 , test loss : 1.136672\n",
      "epoch = 191 train_loss : 0.964077 , test loss : 1.135735\n",
      "epoch = 192 train_loss : 0.963376 , test loss : 1.135493\n",
      "epoch = 193 train_loss : 0.959742 , test loss : 1.132234\n",
      "epoch = 194 train_loss : 0.958397 , test loss : 1.130928\n",
      "epoch = 201 train_loss : 0.947037 , test loss : 1.128217\n",
      "epoch = 203 train_loss : 0.944180 , test loss : 1.125417\n",
      "epoch = 218 train_loss : 0.923337 , test loss : 1.122902\n",
      "epoch = 230 train_loss : 0.909209 , test loss : 1.121364\n",
      "epoch = 247 train_loss : 0.889139 , test loss : 1.117910\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.889139,test loss : 1.117910\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 27.813148 , test loss : 27.544498\n",
      "epoch = 2 train_loss : 22.938124 , test loss : 22.830864\n",
      "epoch = 3 train_loss : 18.308739 , test loss : 18.324942\n",
      "epoch = 4 train_loss : 14.351450 , test loss : 14.423079\n",
      "epoch = 5 train_loss : 11.258547 , test loss : 11.322991\n",
      "epoch = 6 train_loss : 8.912189 , test loss : 8.932357\n",
      "epoch = 7 train_loss : 7.158707 , test loss : 7.116357\n",
      "epoch = 8 train_loss : 5.815646 , test loss : 5.718457\n",
      "epoch = 9 train_loss : 4.806370 , test loss : 4.669333\n",
      "epoch = 10 train_loss : 4.085357 , test loss : 3.919535\n",
      "epoch = 11 train_loss : 3.600046 , test loss : 3.421568\n",
      "epoch = 12 train_loss : 3.281026 , test loss : 3.092712\n",
      "epoch = 13 train_loss : 3.081527 , test loss : 2.886097\n",
      "epoch = 14 train_loss : 2.957761 , test loss : 2.761531\n",
      "epoch = 15 train_loss : 2.875631 , test loss : 2.680024\n",
      "epoch = 16 train_loss : 2.816658 , test loss : 2.626202\n",
      "epoch = 17 train_loss : 2.771934 , test loss : 2.585742\n",
      "epoch = 18 train_loss : 2.733387 , test loss : 2.552237\n",
      "epoch = 19 train_loss : 2.698811 , test loss : 2.519206\n",
      "epoch = 20 train_loss : 2.667606 , test loss : 2.494202\n",
      "epoch = 21 train_loss : 2.634807 , test loss : 2.468204\n",
      "epoch = 22 train_loss : 2.600484 , test loss : 2.441011\n",
      "epoch = 23 train_loss : 2.565910 , test loss : 2.411926\n",
      "epoch = 24 train_loss : 2.532667 , test loss : 2.384314\n",
      "epoch = 25 train_loss : 2.498080 , test loss : 2.355387\n",
      "epoch = 26 train_loss : 2.463919 , test loss : 2.323099\n",
      "epoch = 27 train_loss : 2.427998 , test loss : 2.290909\n",
      "epoch = 28 train_loss : 2.392879 , test loss : 2.258994\n",
      "epoch = 29 train_loss : 2.358806 , test loss : 2.228316\n",
      "epoch = 30 train_loss : 2.323077 , test loss : 2.197261\n",
      "epoch = 31 train_loss : 2.289301 , test loss : 2.162484\n",
      "epoch = 32 train_loss : 2.255496 , test loss : 2.133795\n",
      "epoch = 33 train_loss : 2.216705 , test loss : 2.096160\n",
      "epoch = 34 train_loss : 2.171994 , test loss : 2.055829\n",
      "epoch = 35 train_loss : 2.131293 , test loss : 2.024308\n",
      "epoch = 36 train_loss : 2.086863 , test loss : 1.987347\n",
      "epoch = 37 train_loss : 2.047610 , test loss : 1.950258\n",
      "epoch = 38 train_loss : 2.009173 , test loss : 1.915809\n",
      "epoch = 39 train_loss : 1.970699 , test loss : 1.882113\n",
      "epoch = 40 train_loss : 1.936043 , test loss : 1.847124\n",
      "epoch = 41 train_loss : 1.901218 , test loss : 1.820015\n",
      "epoch = 42 train_loss : 1.868432 , test loss : 1.788419\n",
      "epoch = 43 train_loss : 1.837917 , test loss : 1.760752\n",
      "epoch = 44 train_loss : 1.809159 , test loss : 1.737442\n",
      "epoch = 45 train_loss : 1.781247 , test loss : 1.707852\n",
      "epoch = 46 train_loss : 1.754613 , test loss : 1.687290\n",
      "epoch = 47 train_loss : 1.729183 , test loss : 1.662915\n",
      "epoch = 48 train_loss : 1.704702 , test loss : 1.639025\n",
      "epoch = 49 train_loss : 1.681371 , test loss : 1.619463\n",
      "epoch = 50 train_loss : 1.661094 , test loss : 1.596825\n",
      "epoch = 51 train_loss : 1.639992 , test loss : 1.582558\n",
      "epoch = 52 train_loss : 1.620706 , test loss : 1.569152\n",
      "epoch = 53 train_loss : 1.598092 , test loss : 1.542829\n",
      "epoch = 54 train_loss : 1.579519 , test loss : 1.523820\n",
      "epoch = 55 train_loss : 1.563087 , test loss : 1.514927\n",
      "epoch = 56 train_loss : 1.544224 , test loss : 1.496231\n",
      "epoch = 57 train_loss : 1.526272 , test loss : 1.479619\n",
      "epoch = 58 train_loss : 1.510321 , test loss : 1.462209\n",
      "epoch = 59 train_loss : 1.494858 , test loss : 1.449378\n",
      "epoch = 60 train_loss : 1.482158 , test loss : 1.439714\n",
      "epoch = 61 train_loss : 1.465847 , test loss : 1.425970\n",
      "epoch = 62 train_loss : 1.451817 , test loss : 1.414574\n",
      "epoch = 63 train_loss : 1.438042 , test loss : 1.401964\n",
      "epoch = 64 train_loss : 1.425819 , test loss : 1.388469\n",
      "epoch = 65 train_loss : 1.416821 , test loss : 1.385581\n",
      "epoch = 66 train_loss : 1.402080 , test loss : 1.374408\n",
      "epoch = 67 train_loss : 1.388234 , test loss : 1.362458\n",
      "epoch = 68 train_loss : 1.376670 , test loss : 1.353302\n",
      "epoch = 69 train_loss : 1.365432 , test loss : 1.339025\n",
      "epoch = 70 train_loss : 1.353662 , test loss : 1.332228\n",
      "epoch = 71 train_loss : 1.342974 , test loss : 1.325088\n",
      "epoch = 72 train_loss : 1.330881 , test loss : 1.312007\n",
      "epoch = 73 train_loss : 1.321432 , test loss : 1.305880\n",
      "epoch = 74 train_loss : 1.310922 , test loss : 1.297383\n",
      "epoch = 75 train_loss : 1.302361 , test loss : 1.289903\n",
      "epoch = 76 train_loss : 1.291340 , test loss : 1.280105\n",
      "epoch = 77 train_loss : 1.283530 , test loss : 1.273387\n",
      "epoch = 78 train_loss : 1.273879 , test loss : 1.266667\n",
      "epoch = 79 train_loss : 1.266107 , test loss : 1.261837\n",
      "epoch = 80 train_loss : 1.257743 , test loss : 1.254201\n",
      "epoch = 81 train_loss : 1.249253 , test loss : 1.246400\n",
      "epoch = 82 train_loss : 1.242589 , test loss : 1.241636\n",
      "epoch = 83 train_loss : 1.233149 , test loss : 1.235099\n",
      "epoch = 84 train_loss : 1.227272 , test loss : 1.226812\n",
      "epoch = 85 train_loss : 1.219004 , test loss : 1.219366\n",
      "epoch = 87 train_loss : 1.205978 , test loss : 1.217486\n",
      "epoch = 88 train_loss : 1.201405 , test loss : 1.202573\n",
      "epoch = 89 train_loss : 1.195851 , test loss : 1.202380\n",
      "epoch = 90 train_loss : 1.186639 , test loss : 1.198326\n",
      "epoch = 91 train_loss : 1.182588 , test loss : 1.191441\n",
      "epoch = 92 train_loss : 1.176175 , test loss : 1.185341\n",
      "epoch = 93 train_loss : 1.173790 , test loss : 1.183950\n",
      "epoch = 95 train_loss : 1.161063 , test loss : 1.180210\n",
      "epoch = 96 train_loss : 1.155039 , test loss : 1.173599\n",
      "epoch = 97 train_loss : 1.154894 , test loss : 1.167766\n",
      "epoch = 98 train_loss : 1.144809 , test loss : 1.164674\n",
      "epoch = 99 train_loss : 1.140391 , test loss : 1.158863\n",
      "epoch = 101 train_loss : 1.131555 , test loss : 1.156435\n",
      "epoch = 102 train_loss : 1.132635 , test loss : 1.155748\n",
      "epoch = 103 train_loss : 1.123674 , test loss : 1.151600\n",
      "epoch = 104 train_loss : 1.120488 , test loss : 1.147348\n",
      "epoch = 105 train_loss : 1.115967 , test loss : 1.144773\n",
      "epoch = 106 train_loss : 1.114543 , test loss : 1.138478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 107 train_loss : 1.107563 , test loss : 1.138319\n",
      "epoch = 108 train_loss : 1.105234 , test loss : 1.138299\n",
      "epoch = 109 train_loss : 1.102060 , test loss : 1.134519\n",
      "epoch = 110 train_loss : 1.097492 , test loss : 1.133236\n",
      "epoch = 111 train_loss : 1.093621 , test loss : 1.127738\n",
      "epoch = 113 train_loss : 1.089188 , test loss : 1.122647\n",
      "epoch = 115 train_loss : 1.083413 , test loss : 1.120764\n",
      "epoch = 116 train_loss : 1.078716 , test loss : 1.120117\n",
      "epoch = 117 train_loss : 1.077386 , test loss : 1.115804\n",
      "epoch = 118 train_loss : 1.072981 , test loss : 1.114126\n",
      "epoch = 119 train_loss : 1.070804 , test loss : 1.113457\n",
      "epoch = 121 train_loss : 1.066787 , test loss : 1.108396\n",
      "epoch = 124 train_loss : 1.056933 , test loss : 1.105683\n",
      "epoch = 126 train_loss : 1.052956 , test loss : 1.103752\n",
      "epoch = 127 train_loss : 1.050530 , test loss : 1.103088\n",
      "epoch = 128 train_loss : 1.047311 , test loss : 1.102895\n",
      "epoch = 129 train_loss : 1.045855 , test loss : 1.098170\n",
      "epoch = 134 train_loss : 1.034792 , test loss : 1.095487\n",
      "epoch = 135 train_loss : 1.032925 , test loss : 1.094390\n",
      "epoch = 136 train_loss : 1.032505 , test loss : 1.091305\n",
      "epoch = 138 train_loss : 1.028726 , test loss : 1.090407\n",
      "epoch = 141 train_loss : 1.020855 , test loss : 1.089478\n",
      "epoch = 143 train_loss : 1.017512 , test loss : 1.087581\n",
      "epoch = 145 train_loss : 1.014887 , test loss : 1.083950\n",
      "epoch = 150 train_loss : 1.006315 , test loss : 1.083318\n",
      "epoch = 151 train_loss : 1.004541 , test loss : 1.080441\n",
      "epoch = 159 train_loss : 0.991443 , test loss : 1.079292\n",
      "epoch = 166 train_loss : 0.982163 , test loss : 1.075808\n",
      "epoch = 172 train_loss : 0.973494 , test loss : 1.074904\n",
      "epoch = 176 train_loss : 0.968621 , test loss : 1.071505\n",
      "epoch = 187 train_loss : 0.956862 , test loss : 1.071029\n",
      "epoch = 190 train_loss : 0.955284 , test loss : 1.070945\n",
      "epoch = 201 train_loss : 0.939992 , test loss : 1.068413\n",
      "epoch = 217 train_loss : 0.924858 , test loss : 1.068221\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.924858,test loss : 1.068221\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.889294,total test loss mean : 1.129344 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],16),nn.ReLU(),nn.Linear(16,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,5000,0.0001,5,x44,y44,64,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T07:04:34.344658Z",
     "start_time": "2021-12-29T07:00:12.549685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.703851 , test loss : 0.723326\n",
      "epoch = 2 train_loss : 0.561331 , test loss : 0.585175\n",
      "epoch = 3 train_loss : 0.492634 , test loss : 0.519692\n",
      "epoch = 4 train_loss : 0.454616 , test loss : 0.483981\n",
      "epoch = 5 train_loss : 0.429250 , test loss : 0.460158\n",
      "epoch = 6 train_loss : 0.409460 , test loss : 0.441180\n",
      "epoch = 7 train_loss : 0.393354 , test loss : 0.425830\n",
      "epoch = 8 train_loss : 0.379418 , test loss : 0.412674\n",
      "epoch = 9 train_loss : 0.367053 , test loss : 0.401016\n",
      "epoch = 10 train_loss : 0.355819 , test loss : 0.390081\n",
      "epoch = 11 train_loss : 0.345574 , test loss : 0.380364\n",
      "epoch = 12 train_loss : 0.336413 , test loss : 0.371739\n",
      "epoch = 13 train_loss : 0.327649 , test loss : 0.362754\n",
      "epoch = 14 train_loss : 0.319542 , test loss : 0.354904\n",
      "epoch = 15 train_loss : 0.311942 , test loss : 0.347495\n",
      "epoch = 16 train_loss : 0.304844 , test loss : 0.340931\n",
      "epoch = 17 train_loss : 0.298329 , test loss : 0.334615\n",
      "epoch = 18 train_loss : 0.292040 , test loss : 0.328828\n",
      "epoch = 19 train_loss : 0.286258 , test loss : 0.323299\n",
      "epoch = 20 train_loss : 0.280959 , test loss : 0.318136\n",
      "epoch = 21 train_loss : 0.275972 , test loss : 0.313222\n",
      "epoch = 22 train_loss : 0.271344 , test loss : 0.308853\n",
      "epoch = 23 train_loss : 0.266869 , test loss : 0.304793\n",
      "epoch = 24 train_loss : 0.262491 , test loss : 0.300259\n",
      "epoch = 25 train_loss : 0.258394 , test loss : 0.296279\n",
      "epoch = 26 train_loss : 0.254417 , test loss : 0.292826\n",
      "epoch = 27 train_loss : 0.250532 , test loss : 0.288868\n",
      "epoch = 28 train_loss : 0.246815 , test loss : 0.285264\n",
      "epoch = 29 train_loss : 0.243348 , test loss : 0.281852\n",
      "epoch = 30 train_loss : 0.239997 , test loss : 0.278616\n",
      "epoch = 31 train_loss : 0.236755 , test loss : 0.275463\n",
      "epoch = 32 train_loss : 0.233638 , test loss : 0.272543\n",
      "epoch = 33 train_loss : 0.230561 , test loss : 0.269201\n",
      "epoch = 34 train_loss : 0.227750 , test loss : 0.266428\n",
      "epoch = 35 train_loss : 0.224956 , test loss : 0.263875\n",
      "epoch = 36 train_loss : 0.222363 , test loss : 0.261243\n",
      "epoch = 37 train_loss : 0.219622 , test loss : 0.258631\n",
      "epoch = 38 train_loss : 0.217082 , test loss : 0.256156\n",
      "epoch = 39 train_loss : 0.214596 , test loss : 0.253452\n",
      "epoch = 40 train_loss : 0.212199 , test loss : 0.251033\n",
      "epoch = 41 train_loss : 0.209796 , test loss : 0.248949\n",
      "epoch = 42 train_loss : 0.207530 , test loss : 0.246487\n",
      "epoch = 43 train_loss : 0.205343 , test loss : 0.244534\n",
      "epoch = 44 train_loss : 0.203227 , test loss : 0.242242\n",
      "epoch = 45 train_loss : 0.201222 , test loss : 0.240174\n",
      "epoch = 46 train_loss : 0.199220 , test loss : 0.238101\n",
      "epoch = 47 train_loss : 0.197273 , test loss : 0.236107\n",
      "epoch = 48 train_loss : 0.195430 , test loss : 0.234202\n",
      "epoch = 49 train_loss : 0.193517 , test loss : 0.232171\n",
      "epoch = 50 train_loss : 0.191695 , test loss : 0.230682\n",
      "epoch = 51 train_loss : 0.189938 , test loss : 0.228850\n",
      "epoch = 52 train_loss : 0.188224 , test loss : 0.227007\n",
      "epoch = 53 train_loss : 0.186678 , test loss : 0.225507\n",
      "epoch = 54 train_loss : 0.184820 , test loss : 0.223560\n",
      "epoch = 55 train_loss : 0.183222 , test loss : 0.222090\n",
      "epoch = 56 train_loss : 0.181611 , test loss : 0.220500\n",
      "epoch = 57 train_loss : 0.180110 , test loss : 0.219211\n",
      "epoch = 58 train_loss : 0.178695 , test loss : 0.217585\n",
      "epoch = 59 train_loss : 0.177210 , test loss : 0.216143\n",
      "epoch = 60 train_loss : 0.175843 , test loss : 0.214910\n",
      "epoch = 61 train_loss : 0.174509 , test loss : 0.213876\n",
      "epoch = 62 train_loss : 0.173184 , test loss : 0.212594\n",
      "epoch = 63 train_loss : 0.171732 , test loss : 0.210720\n",
      "epoch = 64 train_loss : 0.170404 , test loss : 0.209659\n",
      "epoch = 65 train_loss : 0.169294 , test loss : 0.208530\n",
      "epoch = 66 train_loss : 0.167988 , test loss : 0.207363\n",
      "epoch = 67 train_loss : 0.166918 , test loss : 0.206224\n",
      "epoch = 68 train_loss : 0.165622 , test loss : 0.204695\n",
      "epoch = 69 train_loss : 0.164766 , test loss : 0.203584\n",
      "epoch = 70 train_loss : 0.163434 , test loss : 0.202465\n",
      "epoch = 71 train_loss : 0.162406 , test loss : 0.201241\n",
      "epoch = 72 train_loss : 0.161425 , test loss : 0.200291\n",
      "epoch = 73 train_loss : 0.160325 , test loss : 0.199607\n",
      "epoch = 74 train_loss : 0.159481 , test loss : 0.198114\n",
      "epoch = 75 train_loss : 0.158358 , test loss : 0.197487\n",
      "epoch = 76 train_loss : 0.157428 , test loss : 0.196482\n",
      "epoch = 77 train_loss : 0.156507 , test loss : 0.195660\n",
      "epoch = 78 train_loss : 0.155649 , test loss : 0.194427\n",
      "epoch = 79 train_loss : 0.154754 , test loss : 0.193706\n",
      "epoch = 80 train_loss : 0.153875 , test loss : 0.193102\n",
      "epoch = 81 train_loss : 0.153114 , test loss : 0.192111\n",
      "epoch = 82 train_loss : 0.152431 , test loss : 0.191623\n",
      "epoch = 83 train_loss : 0.151508 , test loss : 0.191110\n",
      "epoch = 84 train_loss : 0.150859 , test loss : 0.190451\n",
      "epoch = 85 train_loss : 0.150027 , test loss : 0.189052\n",
      "epoch = 86 train_loss : 0.149250 , test loss : 0.188311\n",
      "epoch = 87 train_loss : 0.148594 , test loss : 0.187939\n",
      "epoch = 88 train_loss : 0.147920 , test loss : 0.186972\n",
      "epoch = 89 train_loss : 0.147618 , test loss : 0.186673\n",
      "epoch = 90 train_loss : 0.146652 , test loss : 0.185556\n",
      "epoch = 91 train_loss : 0.145940 , test loss : 0.185019\n",
      "epoch = 92 train_loss : 0.145363 , test loss : 0.184354\n",
      "epoch = 93 train_loss : 0.144772 , test loss : 0.183802\n",
      "epoch = 94 train_loss : 0.144183 , test loss : 0.183499\n",
      "epoch = 95 train_loss : 0.143750 , test loss : 0.182439\n",
      "epoch = 96 train_loss : 0.142997 , test loss : 0.182066\n",
      "epoch = 97 train_loss : 0.142504 , test loss : 0.181363\n",
      "epoch = 98 train_loss : 0.142132 , test loss : 0.180983\n",
      "epoch = 99 train_loss : 0.141512 , test loss : 0.180379\n",
      "epoch = 100 train_loss : 0.140963 , test loss : 0.180259\n",
      "epoch = 101 train_loss : 0.140674 , test loss : 0.179541\n",
      "epoch = 102 train_loss : 0.139918 , test loss : 0.178970\n",
      "epoch = 104 train_loss : 0.139028 , test loss : 0.178211\n",
      "epoch = 105 train_loss : 0.138629 , test loss : 0.178045\n",
      "epoch = 106 train_loss : 0.138120 , test loss : 0.177295\n",
      "epoch = 107 train_loss : 0.137749 , test loss : 0.177227\n",
      "epoch = 108 train_loss : 0.137365 , test loss : 0.176804\n",
      "epoch = 109 train_loss : 0.136801 , test loss : 0.175882\n",
      "epoch = 110 train_loss : 0.136436 , test loss : 0.175310\n",
      "epoch = 111 train_loss : 0.136036 , test loss : 0.175061\n",
      "epoch = 112 train_loss : 0.135629 , test loss : 0.174784\n",
      "epoch = 113 train_loss : 0.135220 , test loss : 0.174143\n",
      "epoch = 115 train_loss : 0.134431 , test loss : 0.173381\n",
      "epoch = 117 train_loss : 0.133647 , test loss : 0.172619\n",
      "epoch = 119 train_loss : 0.132965 , test loss : 0.171981\n",
      "epoch = 121 train_loss : 0.132253 , test loss : 0.171365\n",
      "epoch = 122 train_loss : 0.131924 , test loss : 0.171015\n",
      "epoch = 125 train_loss : 0.130912 , test loss : 0.170062\n",
      "epoch = 126 train_loss : 0.130601 , test loss : 0.169884\n",
      "epoch = 128 train_loss : 0.130009 , test loss : 0.169748\n",
      "epoch = 130 train_loss : 0.129377 , test loss : 0.169332\n",
      "epoch = 131 train_loss : 0.129254 , test loss : 0.168677\n",
      "epoch = 133 train_loss : 0.128665 , test loss : 0.168512\n",
      "epoch = 134 train_loss : 0.128311 , test loss : 0.167982\n",
      "epoch = 136 train_loss : 0.127786 , test loss : 0.167861\n",
      "epoch = 139 train_loss : 0.127092 , test loss : 0.167470\n",
      "epoch = 140 train_loss : 0.126742 , test loss : 0.167193\n",
      "epoch = 143 train_loss : 0.126268 , test loss : 0.166746\n",
      "epoch = 145 train_loss : 0.125661 , test loss : 0.166418\n",
      "epoch = 146 train_loss : 0.125397 , test loss : 0.166136\n",
      "epoch = 151 train_loss : 0.124315 , test loss : 0.165885\n",
      "epoch = 152 train_loss : 0.124214 , test loss : 0.165641\n",
      "epoch = 154 train_loss : 0.123726 , test loss : 0.165317\n",
      "epoch = 156 train_loss : 0.123350 , test loss : 0.165308\n",
      "epoch = 158 train_loss : 0.123045 , test loss : 0.164762\n",
      "epoch = 160 train_loss : 0.122607 , test loss : 0.164620\n",
      "epoch = 161 train_loss : 0.122955 , test loss : 0.164210\n",
      "epoch = 165 train_loss : 0.121854 , test loss : 0.163967\n",
      "epoch = 167 train_loss : 0.121488 , test loss : 0.163882\n",
      "epoch = 169 train_loss : 0.121197 , test loss : 0.163796\n",
      "epoch = 170 train_loss : 0.120962 , test loss : 0.163671\n",
      "epoch = 175 train_loss : 0.120222 , test loss : 0.163513\n",
      "epoch = 176 train_loss : 0.120186 , test loss : 0.163334\n",
      "epoch = 179 train_loss : 0.119980 , test loss : 0.163310\n",
      "epoch = 183 train_loss : 0.119256 , test loss : 0.162889\n",
      "epoch = 187 train_loss : 0.118714 , test loss : 0.162706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 194 train_loss : 0.117731 , test loss : 0.162437\n",
      "epoch = 197 train_loss : 0.117568 , test loss : 0.161968\n",
      "epoch = 211 train_loss : 0.116103 , test loss : 0.161848\n",
      "epoch = 216 train_loss : 0.115401 , test loss : 0.161605\n",
      "epoch = 218 train_loss : 0.115328 , test loss : 0.161537\n",
      "epoch = 220 train_loss : 0.115236 , test loss : 0.161385\n",
      "epoch = 224 train_loss : 0.114628 , test loss : 0.161285\n",
      "epoch = 227 train_loss : 0.114350 , test loss : 0.161242\n",
      "epoch = 232 train_loss : 0.113871 , test loss : 0.161222\n",
      "epoch = 242 train_loss : 0.113008 , test loss : 0.161131\n",
      "epoch = 245 train_loss : 0.112759 , test loss : 0.161078\n",
      "epoch = 272 train_loss : 0.111313 , test loss : 0.160960\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.111313,test loss : 0.160960\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.630170 , test loss : 0.641322\n",
      "epoch = 2 train_loss : 0.523336 , test loss : 0.542347\n",
      "epoch = 3 train_loss : 0.468554 , test loss : 0.493001\n",
      "epoch = 4 train_loss : 0.435521 , test loss : 0.463704\n",
      "epoch = 5 train_loss : 0.412775 , test loss : 0.443994\n",
      "epoch = 6 train_loss : 0.394898 , test loss : 0.428254\n",
      "epoch = 7 train_loss : 0.380448 , test loss : 0.415180\n",
      "epoch = 8 train_loss : 0.367718 , test loss : 0.404546\n",
      "epoch = 9 train_loss : 0.356242 , test loss : 0.395064\n",
      "epoch = 10 train_loss : 0.345954 , test loss : 0.386104\n",
      "epoch = 11 train_loss : 0.336721 , test loss : 0.378343\n",
      "epoch = 12 train_loss : 0.327981 , test loss : 0.370221\n",
      "epoch = 13 train_loss : 0.320164 , test loss : 0.363833\n",
      "epoch = 14 train_loss : 0.312543 , test loss : 0.357128\n",
      "epoch = 15 train_loss : 0.305409 , test loss : 0.350788\n",
      "epoch = 16 train_loss : 0.298509 , test loss : 0.344561\n",
      "epoch = 17 train_loss : 0.291957 , test loss : 0.339340\n",
      "epoch = 18 train_loss : 0.285802 , test loss : 0.333881\n",
      "epoch = 19 train_loss : 0.279887 , test loss : 0.329064\n",
      "epoch = 20 train_loss : 0.274342 , test loss : 0.324748\n",
      "epoch = 21 train_loss : 0.268941 , test loss : 0.319979\n",
      "epoch = 22 train_loss : 0.263847 , test loss : 0.315405\n",
      "epoch = 23 train_loss : 0.259237 , test loss : 0.311154\n",
      "epoch = 24 train_loss : 0.254518 , test loss : 0.307661\n",
      "epoch = 25 train_loss : 0.250162 , test loss : 0.303851\n",
      "epoch = 26 train_loss : 0.245676 , test loss : 0.299998\n",
      "epoch = 27 train_loss : 0.241666 , test loss : 0.296509\n",
      "epoch = 28 train_loss : 0.237844 , test loss : 0.293537\n",
      "epoch = 29 train_loss : 0.234203 , test loss : 0.289817\n",
      "epoch = 30 train_loss : 0.230390 , test loss : 0.286823\n",
      "epoch = 31 train_loss : 0.227014 , test loss : 0.283478\n",
      "epoch = 32 train_loss : 0.223593 , test loss : 0.280534\n",
      "epoch = 33 train_loss : 0.220403 , test loss : 0.277829\n",
      "epoch = 34 train_loss : 0.217374 , test loss : 0.274774\n",
      "epoch = 35 train_loss : 0.214322 , test loss : 0.271712\n",
      "epoch = 36 train_loss : 0.211602 , test loss : 0.269605\n",
      "epoch = 37 train_loss : 0.208663 , test loss : 0.267275\n",
      "epoch = 38 train_loss : 0.206062 , test loss : 0.263391\n",
      "epoch = 39 train_loss : 0.203478 , test loss : 0.260894\n",
      "epoch = 40 train_loss : 0.200877 , test loss : 0.258845\n",
      "epoch = 41 train_loss : 0.198319 , test loss : 0.256792\n",
      "epoch = 42 train_loss : 0.195986 , test loss : 0.254528\n",
      "epoch = 43 train_loss : 0.193840 , test loss : 0.252496\n",
      "epoch = 44 train_loss : 0.191557 , test loss : 0.249750\n",
      "epoch = 45 train_loss : 0.189486 , test loss : 0.247806\n",
      "epoch = 46 train_loss : 0.187481 , test loss : 0.245991\n",
      "epoch = 47 train_loss : 0.185458 , test loss : 0.243129\n",
      "epoch = 48 train_loss : 0.183464 , test loss : 0.241795\n",
      "epoch = 49 train_loss : 0.181657 , test loss : 0.239807\n",
      "epoch = 50 train_loss : 0.179850 , test loss : 0.238271\n",
      "epoch = 51 train_loss : 0.178140 , test loss : 0.236405\n",
      "epoch = 52 train_loss : 0.176448 , test loss : 0.234487\n",
      "epoch = 53 train_loss : 0.174860 , test loss : 0.233240\n",
      "epoch = 54 train_loss : 0.173264 , test loss : 0.232246\n",
      "epoch = 55 train_loss : 0.171755 , test loss : 0.230635\n",
      "epoch = 56 train_loss : 0.170309 , test loss : 0.228550\n",
      "epoch = 57 train_loss : 0.168931 , test loss : 0.227225\n",
      "epoch = 58 train_loss : 0.167594 , test loss : 0.226277\n",
      "epoch = 59 train_loss : 0.166444 , test loss : 0.225220\n",
      "epoch = 60 train_loss : 0.165088 , test loss : 0.223214\n",
      "epoch = 61 train_loss : 0.163801 , test loss : 0.221774\n",
      "epoch = 62 train_loss : 0.162742 , test loss : 0.220612\n",
      "epoch = 63 train_loss : 0.161471 , test loss : 0.219512\n",
      "epoch = 64 train_loss : 0.160359 , test loss : 0.218104\n",
      "epoch = 65 train_loss : 0.159287 , test loss : 0.217263\n",
      "epoch = 66 train_loss : 0.158239 , test loss : 0.215761\n",
      "epoch = 67 train_loss : 0.157218 , test loss : 0.215177\n",
      "epoch = 68 train_loss : 0.156210 , test loss : 0.213930\n",
      "epoch = 69 train_loss : 0.155359 , test loss : 0.211759\n",
      "epoch = 70 train_loss : 0.154320 , test loss : 0.211395\n",
      "epoch = 71 train_loss : 0.153449 , test loss : 0.210661\n",
      "epoch = 72 train_loss : 0.152657 , test loss : 0.209508\n",
      "epoch = 73 train_loss : 0.151895 , test loss : 0.209069\n",
      "epoch = 74 train_loss : 0.151028 , test loss : 0.206872\n",
      "epoch = 75 train_loss : 0.150075 , test loss : 0.206305\n",
      "epoch = 76 train_loss : 0.149353 , test loss : 0.206221\n",
      "epoch = 77 train_loss : 0.148525 , test loss : 0.204625\n",
      "epoch = 78 train_loss : 0.147790 , test loss : 0.204409\n",
      "epoch = 79 train_loss : 0.147157 , test loss : 0.204073\n",
      "epoch = 80 train_loss : 0.146596 , test loss : 0.202385\n",
      "epoch = 82 train_loss : 0.144993 , test loss : 0.201016\n",
      "epoch = 83 train_loss : 0.144363 , test loss : 0.200148\n",
      "epoch = 85 train_loss : 0.143506 , test loss : 0.199851\n",
      "epoch = 86 train_loss : 0.142549 , test loss : 0.198345\n",
      "epoch = 88 train_loss : 0.141419 , test loss : 0.196765\n",
      "epoch = 89 train_loss : 0.141079 , test loss : 0.196388\n",
      "epoch = 91 train_loss : 0.139853 , test loss : 0.196187\n",
      "epoch = 92 train_loss : 0.139198 , test loss : 0.195148\n",
      "epoch = 93 train_loss : 0.138735 , test loss : 0.193908\n",
      "epoch = 94 train_loss : 0.138342 , test loss : 0.192955\n",
      "epoch = 96 train_loss : 0.137297 , test loss : 0.192546\n",
      "epoch = 97 train_loss : 0.136934 , test loss : 0.192221\n",
      "epoch = 99 train_loss : 0.135895 , test loss : 0.191938\n",
      "epoch = 100 train_loss : 0.135681 , test loss : 0.191483\n",
      "epoch = 101 train_loss : 0.135167 , test loss : 0.191256\n",
      "epoch = 102 train_loss : 0.134553 , test loss : 0.189953\n",
      "epoch = 103 train_loss : 0.134168 , test loss : 0.189605\n",
      "epoch = 105 train_loss : 0.133464 , test loss : 0.188399\n",
      "epoch = 107 train_loss : 0.132600 , test loss : 0.188363\n",
      "epoch = 108 train_loss : 0.132172 , test loss : 0.188033\n",
      "epoch = 109 train_loss : 0.131840 , test loss : 0.186925\n",
      "epoch = 110 train_loss : 0.131381 , test loss : 0.186652\n",
      "epoch = 111 train_loss : 0.131063 , test loss : 0.186432\n",
      "epoch = 112 train_loss : 0.130803 , test loss : 0.185421\n",
      "epoch = 115 train_loss : 0.129846 , test loss : 0.184405\n",
      "epoch = 116 train_loss : 0.129360 , test loss : 0.184015\n",
      "epoch = 117 train_loss : 0.129156 , test loss : 0.183454\n",
      "epoch = 120 train_loss : 0.128139 , test loss : 0.182784\n",
      "epoch = 122 train_loss : 0.127611 , test loss : 0.182300\n",
      "epoch = 124 train_loss : 0.127014 , test loss : 0.181734\n",
      "epoch = 126 train_loss : 0.126479 , test loss : 0.180912\n",
      "epoch = 128 train_loss : 0.126351 , test loss : 0.179939\n",
      "epoch = 131 train_loss : 0.125214 , test loss : 0.179580\n",
      "epoch = 132 train_loss : 0.125107 , test loss : 0.179404\n",
      "epoch = 133 train_loss : 0.124709 , test loss : 0.179372\n",
      "epoch = 134 train_loss : 0.124645 , test loss : 0.178538\n",
      "epoch = 136 train_loss : 0.124395 , test loss : 0.178350\n",
      "epoch = 137 train_loss : 0.124056 , test loss : 0.177986\n",
      "epoch = 140 train_loss : 0.123173 , test loss : 0.177791\n",
      "epoch = 141 train_loss : 0.122938 , test loss : 0.177633\n",
      "epoch = 142 train_loss : 0.122846 , test loss : 0.177607\n",
      "epoch = 143 train_loss : 0.122586 , test loss : 0.176997\n",
      "epoch = 144 train_loss : 0.122567 , test loss : 0.176251\n",
      "epoch = 145 train_loss : 0.122267 , test loss : 0.176196\n",
      "epoch = 150 train_loss : 0.121406 , test loss : 0.175133\n",
      "epoch = 152 train_loss : 0.121083 , test loss : 0.174865\n",
      "epoch = 154 train_loss : 0.120648 , test loss : 0.174824\n",
      "epoch = 156 train_loss : 0.120419 , test loss : 0.174500\n",
      "epoch = 160 train_loss : 0.119678 , test loss : 0.173894\n",
      "epoch = 167 train_loss : 0.118557 , test loss : 0.173703\n",
      "epoch = 168 train_loss : 0.119282 , test loss : 0.173236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 172 train_loss : 0.117997 , test loss : 0.172827\n",
      "epoch = 174 train_loss : 0.117630 , test loss : 0.172819\n",
      "epoch = 181 train_loss : 0.116951 , test loss : 0.172752\n",
      "epoch = 182 train_loss : 0.116715 , test loss : 0.172351\n",
      "epoch = 184 train_loss : 0.117295 , test loss : 0.172228\n",
      "epoch = 185 train_loss : 0.116256 , test loss : 0.172043\n",
      "epoch = 186 train_loss : 0.116300 , test loss : 0.171440\n",
      "epoch = 194 train_loss : 0.115404 , test loss : 0.170744\n",
      "epoch = 211 train_loss : 0.113645 , test loss : 0.170540\n",
      "epoch = 213 train_loss : 0.113665 , test loss : 0.170418\n",
      "epoch = 219 train_loss : 0.113181 , test loss : 0.169849\n",
      "epoch = 235 train_loss : 0.111848 , test loss : 0.169648\n",
      "epoch = 270 train_loss : 0.109707 , test loss : 0.169623\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.109707,test loss : 0.169623\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.846754 , test loss : 0.858632\n",
      "epoch = 2 train_loss : 0.733749 , test loss : 0.745467\n",
      "epoch = 3 train_loss : 0.639501 , test loss : 0.649520\n",
      "epoch = 4 train_loss : 0.569314 , test loss : 0.576006\n",
      "epoch = 5 train_loss : 0.520318 , test loss : 0.522567\n",
      "epoch = 6 train_loss : 0.486856 , test loss : 0.484024\n",
      "epoch = 7 train_loss : 0.461672 , test loss : 0.453829\n",
      "epoch = 8 train_loss : 0.443087 , test loss : 0.430827\n",
      "epoch = 9 train_loss : 0.427535 , test loss : 0.411739\n",
      "epoch = 10 train_loss : 0.415090 , test loss : 0.396425\n",
      "epoch = 11 train_loss : 0.404465 , test loss : 0.383788\n",
      "epoch = 12 train_loss : 0.395296 , test loss : 0.373343\n",
      "epoch = 13 train_loss : 0.387236 , test loss : 0.364341\n",
      "epoch = 14 train_loss : 0.379226 , test loss : 0.355372\n",
      "epoch = 15 train_loss : 0.372164 , test loss : 0.348162\n",
      "epoch = 16 train_loss : 0.365639 , test loss : 0.341809\n",
      "epoch = 17 train_loss : 0.359550 , test loss : 0.335748\n",
      "epoch = 18 train_loss : 0.353694 , test loss : 0.330571\n",
      "epoch = 19 train_loss : 0.348039 , test loss : 0.325063\n",
      "epoch = 20 train_loss : 0.342587 , test loss : 0.319952\n",
      "epoch = 21 train_loss : 0.337470 , test loss : 0.315211\n",
      "epoch = 22 train_loss : 0.332404 , test loss : 0.310592\n",
      "epoch = 23 train_loss : 0.327591 , test loss : 0.306334\n",
      "epoch = 24 train_loss : 0.322905 , test loss : 0.301901\n",
      "epoch = 25 train_loss : 0.318324 , test loss : 0.297789\n",
      "epoch = 26 train_loss : 0.313836 , test loss : 0.293541\n",
      "epoch = 27 train_loss : 0.309513 , test loss : 0.290314\n",
      "epoch = 28 train_loss : 0.305238 , test loss : 0.286228\n",
      "epoch = 29 train_loss : 0.301175 , test loss : 0.283131\n",
      "epoch = 30 train_loss : 0.297178 , test loss : 0.279605\n",
      "epoch = 31 train_loss : 0.293455 , test loss : 0.276658\n",
      "epoch = 32 train_loss : 0.289721 , test loss : 0.273428\n",
      "epoch = 33 train_loss : 0.286062 , test loss : 0.270144\n",
      "epoch = 34 train_loss : 0.282537 , test loss : 0.267286\n",
      "epoch = 35 train_loss : 0.279016 , test loss : 0.263983\n",
      "epoch = 36 train_loss : 0.275773 , test loss : 0.261377\n",
      "epoch = 37 train_loss : 0.272399 , test loss : 0.258948\n",
      "epoch = 38 train_loss : 0.269057 , test loss : 0.255958\n",
      "epoch = 39 train_loss : 0.265807 , test loss : 0.253117\n",
      "epoch = 40 train_loss : 0.262566 , test loss : 0.250778\n",
      "epoch = 41 train_loss : 0.259502 , test loss : 0.248109\n",
      "epoch = 42 train_loss : 0.256441 , test loss : 0.245891\n",
      "epoch = 43 train_loss : 0.253396 , test loss : 0.243634\n",
      "epoch = 44 train_loss : 0.250448 , test loss : 0.241425\n",
      "epoch = 45 train_loss : 0.247573 , test loss : 0.239307\n",
      "epoch = 46 train_loss : 0.244753 , test loss : 0.237216\n",
      "epoch = 47 train_loss : 0.242055 , test loss : 0.234887\n",
      "epoch = 48 train_loss : 0.239478 , test loss : 0.233441\n",
      "epoch = 49 train_loss : 0.236820 , test loss : 0.231214\n",
      "epoch = 50 train_loss : 0.234421 , test loss : 0.228965\n",
      "epoch = 51 train_loss : 0.231784 , test loss : 0.227311\n",
      "epoch = 52 train_loss : 0.229262 , test loss : 0.225833\n",
      "epoch = 53 train_loss : 0.226889 , test loss : 0.224127\n",
      "epoch = 54 train_loss : 0.224575 , test loss : 0.222804\n",
      "epoch = 55 train_loss : 0.222271 , test loss : 0.220656\n",
      "epoch = 56 train_loss : 0.220077 , test loss : 0.219653\n",
      "epoch = 57 train_loss : 0.217830 , test loss : 0.217817\n",
      "epoch = 58 train_loss : 0.215724 , test loss : 0.216490\n",
      "epoch = 59 train_loss : 0.213807 , test loss : 0.215578\n",
      "epoch = 60 train_loss : 0.211603 , test loss : 0.213247\n",
      "epoch = 61 train_loss : 0.209625 , test loss : 0.211775\n",
      "epoch = 62 train_loss : 0.207762 , test loss : 0.210140\n",
      "epoch = 63 train_loss : 0.205851 , test loss : 0.209131\n",
      "epoch = 64 train_loss : 0.203961 , test loss : 0.207787\n",
      "epoch = 65 train_loss : 0.202196 , test loss : 0.206756\n",
      "epoch = 66 train_loss : 0.200425 , test loss : 0.205480\n",
      "epoch = 67 train_loss : 0.198914 , test loss : 0.204107\n",
      "epoch = 68 train_loss : 0.196982 , test loss : 0.203262\n",
      "epoch = 69 train_loss : 0.195329 , test loss : 0.201941\n",
      "epoch = 70 train_loss : 0.193571 , test loss : 0.200591\n",
      "epoch = 71 train_loss : 0.192067 , test loss : 0.199459\n",
      "epoch = 72 train_loss : 0.190443 , test loss : 0.198920\n",
      "epoch = 73 train_loss : 0.188797 , test loss : 0.197320\n",
      "epoch = 74 train_loss : 0.187315 , test loss : 0.196374\n",
      "epoch = 75 train_loss : 0.185860 , test loss : 0.194972\n",
      "epoch = 76 train_loss : 0.184252 , test loss : 0.194062\n",
      "epoch = 77 train_loss : 0.182798 , test loss : 0.193046\n",
      "epoch = 78 train_loss : 0.181407 , test loss : 0.192439\n",
      "epoch = 79 train_loss : 0.180081 , test loss : 0.191398\n",
      "epoch = 80 train_loss : 0.178727 , test loss : 0.190136\n",
      "epoch = 81 train_loss : 0.177439 , test loss : 0.189984\n",
      "epoch = 82 train_loss : 0.176086 , test loss : 0.188212\n",
      "epoch = 83 train_loss : 0.174843 , test loss : 0.187814\n",
      "epoch = 84 train_loss : 0.173567 , test loss : 0.186560\n",
      "epoch = 85 train_loss : 0.172467 , test loss : 0.186168\n",
      "epoch = 86 train_loss : 0.171476 , test loss : 0.186121\n",
      "epoch = 87 train_loss : 0.170118 , test loss : 0.184212\n",
      "epoch = 88 train_loss : 0.169041 , test loss : 0.183671\n",
      "epoch = 89 train_loss : 0.167953 , test loss : 0.182715\n",
      "epoch = 90 train_loss : 0.166994 , test loss : 0.182337\n",
      "epoch = 91 train_loss : 0.165823 , test loss : 0.181802\n",
      "epoch = 92 train_loss : 0.164838 , test loss : 0.180325\n",
      "epoch = 94 train_loss : 0.162928 , test loss : 0.179443\n",
      "epoch = 95 train_loss : 0.162002 , test loss : 0.178566\n",
      "epoch = 96 train_loss : 0.161055 , test loss : 0.178266\n",
      "epoch = 97 train_loss : 0.160174 , test loss : 0.177645\n",
      "epoch = 98 train_loss : 0.159341 , test loss : 0.177300\n",
      "epoch = 99 train_loss : 0.158436 , test loss : 0.176193\n",
      "epoch = 100 train_loss : 0.157583 , test loss : 0.175559\n",
      "epoch = 101 train_loss : 0.156812 , test loss : 0.175405\n",
      "epoch = 103 train_loss : 0.155210 , test loss : 0.174102\n",
      "epoch = 105 train_loss : 0.153660 , test loss : 0.173196\n",
      "epoch = 106 train_loss : 0.152899 , test loss : 0.172801\n",
      "epoch = 107 train_loss : 0.152167 , test loss : 0.172125\n",
      "epoch = 108 train_loss : 0.151459 , test loss : 0.171824\n",
      "epoch = 109 train_loss : 0.150756 , test loss : 0.171389\n",
      "epoch = 110 train_loss : 0.150114 , test loss : 0.170885\n",
      "epoch = 111 train_loss : 0.149432 , test loss : 0.170440\n",
      "epoch = 112 train_loss : 0.148745 , test loss : 0.170243\n",
      "epoch = 113 train_loss : 0.148232 , test loss : 0.170048\n",
      "epoch = 115 train_loss : 0.147005 , test loss : 0.168684\n",
      "epoch = 116 train_loss : 0.146293 , test loss : 0.168610\n",
      "epoch = 117 train_loss : 0.145698 , test loss : 0.168119\n",
      "epoch = 118 train_loss : 0.145241 , test loss : 0.167905\n",
      "epoch = 119 train_loss : 0.144547 , test loss : 0.167511\n",
      "epoch = 121 train_loss : 0.143440 , test loss : 0.167220\n",
      "epoch = 123 train_loss : 0.142322 , test loss : 0.166618\n",
      "epoch = 124 train_loss : 0.141777 , test loss : 0.166456\n",
      "epoch = 126 train_loss : 0.140784 , test loss : 0.165972\n",
      "epoch = 127 train_loss : 0.140301 , test loss : 0.165696\n",
      "epoch = 128 train_loss : 0.139878 , test loss : 0.165260\n",
      "epoch = 129 train_loss : 0.139380 , test loss : 0.165049\n",
      "epoch = 131 train_loss : 0.138480 , test loss : 0.164865\n",
      "epoch = 132 train_loss : 0.138118 , test loss : 0.164328\n",
      "epoch = 133 train_loss : 0.137629 , test loss : 0.164206\n",
      "epoch = 134 train_loss : 0.137246 , test loss : 0.163697\n",
      "epoch = 135 train_loss : 0.136831 , test loss : 0.163608\n",
      "epoch = 137 train_loss : 0.135965 , test loss : 0.163595\n",
      "epoch = 139 train_loss : 0.135228 , test loss : 0.163041\n",
      "epoch = 140 train_loss : 0.134857 , test loss : 0.163004\n",
      "epoch = 142 train_loss : 0.134049 , test loss : 0.162551\n",
      "epoch = 143 train_loss : 0.133669 , test loss : 0.162512\n",
      "epoch = 144 train_loss : 0.133330 , test loss : 0.162453\n",
      "epoch = 146 train_loss : 0.132590 , test loss : 0.162045\n",
      "epoch = 147 train_loss : 0.132381 , test loss : 0.162038\n",
      "epoch = 148 train_loss : 0.131989 , test loss : 0.161893\n",
      "epoch = 149 train_loss : 0.131601 , test loss : 0.161414\n",
      "epoch = 151 train_loss : 0.131002 , test loss : 0.161107\n",
      "epoch = 152 train_loss : 0.130663 , test loss : 0.160944\n",
      "epoch = 154 train_loss : 0.130073 , test loss : 0.160933\n",
      "epoch = 155 train_loss : 0.129781 , test loss : 0.160507\n",
      "epoch = 159 train_loss : 0.128650 , test loss : 0.160163\n",
      "epoch = 162 train_loss : 0.127967 , test loss : 0.160125\n",
      "epoch = 163 train_loss : 0.127570 , test loss : 0.159851\n",
      "epoch = 164 train_loss : 0.127346 , test loss : 0.159665\n",
      "epoch = 166 train_loss : 0.127006 , test loss : 0.159170\n",
      "epoch = 173 train_loss : 0.125247 , test loss : 0.159020\n",
      "epoch = 177 train_loss : 0.124438 , test loss : 0.158881\n",
      "epoch = 186 train_loss : 0.122662 , test loss : 0.158874\n",
      "epoch = 187 train_loss : 0.122561 , test loss : 0.158775\n",
      "epoch = 188 train_loss : 0.122493 , test loss : 0.158638\n",
      "epoch = 189 train_loss : 0.122289 , test loss : 0.158465\n",
      "epoch = 190 train_loss : 0.122047 , test loss : 0.158346\n",
      "epoch = 194 train_loss : 0.121349 , test loss : 0.158280\n",
      "epoch = 203 train_loss : 0.119991 , test loss : 0.157930\n",
      "epoch = 218 train_loss : 0.117987 , test loss : 0.157926\n",
      "epoch = 219 train_loss : 0.117905 , test loss : 0.157803\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.117905,test loss : 0.157803\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.717966 , test loss : 0.688274\n",
      "epoch = 2 train_loss : 0.584517 , test loss : 0.559378\n",
      "epoch = 3 train_loss : 0.512192 , test loss : 0.492005\n",
      "epoch = 4 train_loss : 0.467697 , test loss : 0.449717\n",
      "epoch = 5 train_loss : 0.438204 , test loss : 0.421020\n",
      "epoch = 6 train_loss : 0.415634 , test loss : 0.399061\n",
      "epoch = 7 train_loss : 0.397822 , test loss : 0.382137\n",
      "epoch = 8 train_loss : 0.383133 , test loss : 0.368415\n",
      "epoch = 9 train_loss : 0.370371 , test loss : 0.356898\n",
      "epoch = 10 train_loss : 0.358797 , test loss : 0.346597\n",
      "epoch = 11 train_loss : 0.348383 , test loss : 0.337464\n",
      "epoch = 12 train_loss : 0.339016 , test loss : 0.329865\n",
      "epoch = 13 train_loss : 0.330068 , test loss : 0.322575\n",
      "epoch = 14 train_loss : 0.321947 , test loss : 0.316028\n",
      "epoch = 15 train_loss : 0.314427 , test loss : 0.309922\n",
      "epoch = 16 train_loss : 0.307239 , test loss : 0.304360\n",
      "epoch = 17 train_loss : 0.300688 , test loss : 0.299252\n",
      "epoch = 18 train_loss : 0.294515 , test loss : 0.294577\n",
      "epoch = 19 train_loss : 0.288534 , test loss : 0.289728\n",
      "epoch = 20 train_loss : 0.283187 , test loss : 0.285616\n",
      "epoch = 21 train_loss : 0.278156 , test loss : 0.281444\n",
      "epoch = 22 train_loss : 0.273319 , test loss : 0.277630\n",
      "epoch = 23 train_loss : 0.268758 , test loss : 0.274286\n",
      "epoch = 24 train_loss : 0.264392 , test loss : 0.270581\n",
      "epoch = 25 train_loss : 0.260132 , test loss : 0.267174\n",
      "epoch = 26 train_loss : 0.256026 , test loss : 0.263800\n",
      "epoch = 27 train_loss : 0.252147 , test loss : 0.260653\n",
      "epoch = 28 train_loss : 0.248419 , test loss : 0.257612\n",
      "epoch = 29 train_loss : 0.244810 , test loss : 0.254665\n",
      "epoch = 30 train_loss : 0.241559 , test loss : 0.252262\n",
      "epoch = 31 train_loss : 0.238153 , test loss : 0.249253\n",
      "epoch = 32 train_loss : 0.234836 , test loss : 0.246536\n",
      "epoch = 33 train_loss : 0.231717 , test loss : 0.243585\n",
      "epoch = 34 train_loss : 0.228948 , test loss : 0.242053\n",
      "epoch = 35 train_loss : 0.225911 , test loss : 0.239013\n",
      "epoch = 36 train_loss : 0.223012 , test loss : 0.236937\n",
      "epoch = 37 train_loss : 0.220238 , test loss : 0.234705\n",
      "epoch = 38 train_loss : 0.217663 , test loss : 0.232556\n",
      "epoch = 39 train_loss : 0.215041 , test loss : 0.230465\n",
      "epoch = 40 train_loss : 0.212598 , test loss : 0.228677\n",
      "epoch = 41 train_loss : 0.210225 , test loss : 0.226536\n",
      "epoch = 42 train_loss : 0.207945 , test loss : 0.224768\n",
      "epoch = 43 train_loss : 0.205534 , test loss : 0.222799\n",
      "epoch = 44 train_loss : 0.203260 , test loss : 0.220805\n",
      "epoch = 45 train_loss : 0.201081 , test loss : 0.219022\n",
      "epoch = 46 train_loss : 0.199007 , test loss : 0.217295\n",
      "epoch = 47 train_loss : 0.196967 , test loss : 0.215739\n",
      "epoch = 48 train_loss : 0.195135 , test loss : 0.214030\n",
      "epoch = 49 train_loss : 0.192976 , test loss : 0.212642\n",
      "epoch = 50 train_loss : 0.191061 , test loss : 0.211428\n",
      "epoch = 51 train_loss : 0.189261 , test loss : 0.209941\n",
      "epoch = 52 train_loss : 0.187419 , test loss : 0.208049\n",
      "epoch = 53 train_loss : 0.185691 , test loss : 0.207202\n",
      "epoch = 54 train_loss : 0.183968 , test loss : 0.205484\n",
      "epoch = 55 train_loss : 0.182392 , test loss : 0.204258\n",
      "epoch = 56 train_loss : 0.180880 , test loss : 0.202699\n",
      "epoch = 57 train_loss : 0.179369 , test loss : 0.201741\n",
      "epoch = 58 train_loss : 0.177817 , test loss : 0.199847\n",
      "epoch = 59 train_loss : 0.176685 , test loss : 0.199667\n",
      "epoch = 60 train_loss : 0.174991 , test loss : 0.198365\n",
      "epoch = 61 train_loss : 0.173600 , test loss : 0.197002\n",
      "epoch = 62 train_loss : 0.172329 , test loss : 0.196108\n",
      "epoch = 63 train_loss : 0.170981 , test loss : 0.195230\n",
      "epoch = 64 train_loss : 0.169769 , test loss : 0.194440\n",
      "epoch = 65 train_loss : 0.168501 , test loss : 0.193271\n",
      "epoch = 66 train_loss : 0.167363 , test loss : 0.192574\n",
      "epoch = 67 train_loss : 0.166268 , test loss : 0.191454\n",
      "epoch = 68 train_loss : 0.165161 , test loss : 0.190771\n",
      "epoch = 69 train_loss : 0.164085 , test loss : 0.189900\n",
      "epoch = 70 train_loss : 0.162978 , test loss : 0.188975\n",
      "epoch = 71 train_loss : 0.162030 , test loss : 0.188634\n",
      "epoch = 72 train_loss : 0.160966 , test loss : 0.187828\n",
      "epoch = 73 train_loss : 0.160064 , test loss : 0.186796\n",
      "epoch = 74 train_loss : 0.159179 , test loss : 0.186777\n",
      "epoch = 75 train_loss : 0.158038 , test loss : 0.185586\n",
      "epoch = 76 train_loss : 0.157221 , test loss : 0.184925\n",
      "epoch = 77 train_loss : 0.156376 , test loss : 0.184466\n",
      "epoch = 78 train_loss : 0.155448 , test loss : 0.183889\n",
      "epoch = 79 train_loss : 0.154993 , test loss : 0.182717\n",
      "epoch = 80 train_loss : 0.153693 , test loss : 0.182458\n",
      "epoch = 81 train_loss : 0.152961 , test loss : 0.182116\n",
      "epoch = 82 train_loss : 0.152317 , test loss : 0.181374\n",
      "epoch = 83 train_loss : 0.151462 , test loss : 0.180181\n",
      "epoch = 85 train_loss : 0.150051 , test loss : 0.179759\n",
      "epoch = 86 train_loss : 0.149299 , test loss : 0.179524\n",
      "epoch = 87 train_loss : 0.148571 , test loss : 0.178734\n",
      "epoch = 88 train_loss : 0.147949 , test loss : 0.178411\n",
      "epoch = 90 train_loss : 0.146588 , test loss : 0.177079\n",
      "epoch = 92 train_loss : 0.145612 , test loss : 0.176421\n",
      "epoch = 94 train_loss : 0.144235 , test loss : 0.175408\n",
      "epoch = 96 train_loss : 0.143238 , test loss : 0.174198\n",
      "epoch = 98 train_loss : 0.142217 , test loss : 0.173273\n",
      "epoch = 100 train_loss : 0.140966 , test loss : 0.172799\n",
      "epoch = 102 train_loss : 0.139960 , test loss : 0.172068\n",
      "epoch = 104 train_loss : 0.139079 , test loss : 0.172008\n",
      "epoch = 105 train_loss : 0.138596 , test loss : 0.171614\n",
      "epoch = 106 train_loss : 0.138172 , test loss : 0.170727\n",
      "epoch = 108 train_loss : 0.137649 , test loss : 0.170427\n",
      "epoch = 110 train_loss : 0.136763 , test loss : 0.169811\n",
      "epoch = 111 train_loss : 0.136158 , test loss : 0.169673\n",
      "epoch = 112 train_loss : 0.135854 , test loss : 0.169290\n",
      "epoch = 114 train_loss : 0.135269 , test loss : 0.168954\n",
      "epoch = 115 train_loss : 0.134700 , test loss : 0.168447\n",
      "epoch = 117 train_loss : 0.133971 , test loss : 0.168345\n",
      "epoch = 118 train_loss : 0.133607 , test loss : 0.168187\n",
      "epoch = 120 train_loss : 0.133462 , test loss : 0.167222\n",
      "epoch = 122 train_loss : 0.132392 , test loss : 0.166676\n",
      "epoch = 123 train_loss : 0.132126 , test loss : 0.166620\n",
      "epoch = 125 train_loss : 0.131580 , test loss : 0.166532\n",
      "epoch = 126 train_loss : 0.131279 , test loss : 0.166313\n",
      "epoch = 127 train_loss : 0.130838 , test loss : 0.166006\n",
      "epoch = 128 train_loss : 0.130892 , test loss : 0.165918\n",
      "epoch = 130 train_loss : 0.130064 , test loss : 0.165661\n",
      "epoch = 131 train_loss : 0.129686 , test loss : 0.165167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 135 train_loss : 0.128916 , test loss : 0.165151\n",
      "epoch = 136 train_loss : 0.128497 , test loss : 0.164958\n",
      "epoch = 137 train_loss : 0.128157 , test loss : 0.164678\n",
      "epoch = 139 train_loss : 0.127695 , test loss : 0.163780\n",
      "epoch = 140 train_loss : 0.127509 , test loss : 0.163505\n",
      "epoch = 141 train_loss : 0.127251 , test loss : 0.163357\n",
      "epoch = 145 train_loss : 0.126415 , test loss : 0.163124\n",
      "epoch = 146 train_loss : 0.126099 , test loss : 0.163027\n",
      "epoch = 148 train_loss : 0.125832 , test loss : 0.162584\n",
      "epoch = 149 train_loss : 0.125787 , test loss : 0.162564\n",
      "epoch = 150 train_loss : 0.125745 , test loss : 0.162313\n",
      "epoch = 154 train_loss : 0.124483 , test loss : 0.161981\n",
      "epoch = 155 train_loss : 0.124475 , test loss : 0.161489\n",
      "epoch = 158 train_loss : 0.124135 , test loss : 0.161389\n",
      "epoch = 168 train_loss : 0.122041 , test loss : 0.161278\n",
      "epoch = 170 train_loss : 0.121886 , test loss : 0.161270\n",
      "epoch = 171 train_loss : 0.121670 , test loss : 0.160916\n",
      "epoch = 172 train_loss : 0.121543 , test loss : 0.160575\n",
      "epoch = 178 train_loss : 0.120576 , test loss : 0.160354\n",
      "epoch = 182 train_loss : 0.120070 , test loss : 0.160215\n",
      "epoch = 191 train_loss : 0.118753 , test loss : 0.160057\n",
      "epoch = 197 train_loss : 0.118301 , test loss : 0.159923\n",
      "epoch = 204 train_loss : 0.117359 , test loss : 0.159765\n",
      "epoch = 220 train_loss : 0.115704 , test loss : 0.159389\n",
      "epoch = 232 train_loss : 0.114775 , test loss : 0.159315\n",
      "epoch = 242 train_loss : 0.114160 , test loss : 0.159310\n",
      "epoch = 284 train_loss : 0.111101 , test loss : 0.159269\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.111101,test loss : 0.159269\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.841372 , test loss : 0.786004\n",
      "epoch = 2 train_loss : 0.658155 , test loss : 0.607908\n",
      "epoch = 3 train_loss : 0.565964 , test loss : 0.521886\n",
      "epoch = 4 train_loss : 0.511629 , test loss : 0.474230\n",
      "epoch = 5 train_loss : 0.475533 , test loss : 0.444290\n",
      "epoch = 6 train_loss : 0.449563 , test loss : 0.423449\n",
      "epoch = 7 train_loss : 0.431114 , test loss : 0.408771\n",
      "epoch = 8 train_loss : 0.416406 , test loss : 0.396520\n",
      "epoch = 9 train_loss : 0.403801 , test loss : 0.385454\n",
      "epoch = 10 train_loss : 0.392648 , test loss : 0.376067\n",
      "epoch = 11 train_loss : 0.382625 , test loss : 0.366928\n",
      "epoch = 12 train_loss : 0.373280 , test loss : 0.358353\n",
      "epoch = 13 train_loss : 0.364500 , test loss : 0.350425\n",
      "epoch = 14 train_loss : 0.355934 , test loss : 0.342292\n",
      "epoch = 15 train_loss : 0.347716 , test loss : 0.334762\n",
      "epoch = 16 train_loss : 0.340009 , test loss : 0.327633\n",
      "epoch = 17 train_loss : 0.332428 , test loss : 0.320746\n",
      "epoch = 18 train_loss : 0.325393 , test loss : 0.314170\n",
      "epoch = 19 train_loss : 0.318296 , test loss : 0.307985\n",
      "epoch = 20 train_loss : 0.311556 , test loss : 0.302361\n",
      "epoch = 21 train_loss : 0.305285 , test loss : 0.297201\n",
      "epoch = 22 train_loss : 0.299394 , test loss : 0.292299\n",
      "epoch = 23 train_loss : 0.293752 , test loss : 0.287347\n",
      "epoch = 24 train_loss : 0.288397 , test loss : 0.282882\n",
      "epoch = 25 train_loss : 0.283448 , test loss : 0.279260\n",
      "epoch = 26 train_loss : 0.278660 , test loss : 0.274794\n",
      "epoch = 27 train_loss : 0.274266 , test loss : 0.271010\n",
      "epoch = 28 train_loss : 0.269788 , test loss : 0.267568\n",
      "epoch = 29 train_loss : 0.265639 , test loss : 0.263944\n",
      "epoch = 30 train_loss : 0.261835 , test loss : 0.260415\n",
      "epoch = 31 train_loss : 0.257862 , test loss : 0.257526\n",
      "epoch = 32 train_loss : 0.254274 , test loss : 0.254746\n",
      "epoch = 33 train_loss : 0.250540 , test loss : 0.251399\n",
      "epoch = 34 train_loss : 0.247115 , test loss : 0.248515\n",
      "epoch = 35 train_loss : 0.244008 , test loss : 0.245871\n",
      "epoch = 36 train_loss : 0.240475 , test loss : 0.243189\n",
      "epoch = 37 train_loss : 0.237389 , test loss : 0.240693\n",
      "epoch = 38 train_loss : 0.234395 , test loss : 0.238484\n",
      "epoch = 39 train_loss : 0.231429 , test loss : 0.236112\n",
      "epoch = 40 train_loss : 0.228537 , test loss : 0.233616\n",
      "epoch = 41 train_loss : 0.225824 , test loss : 0.231485\n",
      "epoch = 42 train_loss : 0.223274 , test loss : 0.229702\n",
      "epoch = 43 train_loss : 0.220591 , test loss : 0.227346\n",
      "epoch = 44 train_loss : 0.218101 , test loss : 0.225334\n",
      "epoch = 45 train_loss : 0.215603 , test loss : 0.223585\n",
      "epoch = 46 train_loss : 0.213228 , test loss : 0.221239\n",
      "epoch = 47 train_loss : 0.210942 , test loss : 0.219120\n",
      "epoch = 48 train_loss : 0.208693 , test loss : 0.217757\n",
      "epoch = 49 train_loss : 0.206529 , test loss : 0.215951\n",
      "epoch = 50 train_loss : 0.204382 , test loss : 0.214138\n",
      "epoch = 51 train_loss : 0.202260 , test loss : 0.212416\n",
      "epoch = 52 train_loss : 0.200229 , test loss : 0.210932\n",
      "epoch = 53 train_loss : 0.198261 , test loss : 0.209267\n",
      "epoch = 54 train_loss : 0.196402 , test loss : 0.207647\n",
      "epoch = 55 train_loss : 0.194530 , test loss : 0.206549\n",
      "epoch = 56 train_loss : 0.192728 , test loss : 0.204793\n",
      "epoch = 57 train_loss : 0.191004 , test loss : 0.203635\n",
      "epoch = 58 train_loss : 0.189305 , test loss : 0.202176\n",
      "epoch = 59 train_loss : 0.187763 , test loss : 0.200956\n",
      "epoch = 60 train_loss : 0.186058 , test loss : 0.199437\n",
      "epoch = 61 train_loss : 0.184817 , test loss : 0.199298\n",
      "epoch = 62 train_loss : 0.183093 , test loss : 0.197099\n",
      "epoch = 63 train_loss : 0.181498 , test loss : 0.195918\n",
      "epoch = 64 train_loss : 0.180333 , test loss : 0.194875\n",
      "epoch = 65 train_loss : 0.178663 , test loss : 0.194036\n",
      "epoch = 66 train_loss : 0.177313 , test loss : 0.193134\n",
      "epoch = 67 train_loss : 0.175925 , test loss : 0.191284\n",
      "epoch = 68 train_loss : 0.174668 , test loss : 0.190297\n",
      "epoch = 69 train_loss : 0.173355 , test loss : 0.189659\n",
      "epoch = 70 train_loss : 0.172215 , test loss : 0.188469\n",
      "epoch = 71 train_loss : 0.170836 , test loss : 0.187301\n",
      "epoch = 72 train_loss : 0.169627 , test loss : 0.186291\n",
      "epoch = 74 train_loss : 0.167558 , test loss : 0.184969\n",
      "epoch = 75 train_loss : 0.166469 , test loss : 0.183874\n",
      "epoch = 76 train_loss : 0.165117 , test loss : 0.183275\n",
      "epoch = 77 train_loss : 0.164088 , test loss : 0.181665\n",
      "epoch = 78 train_loss : 0.163061 , test loss : 0.181518\n",
      "epoch = 79 train_loss : 0.161972 , test loss : 0.180668\n",
      "epoch = 80 train_loss : 0.161061 , test loss : 0.179864\n",
      "epoch = 81 train_loss : 0.160035 , test loss : 0.178658\n",
      "epoch = 82 train_loss : 0.159094 , test loss : 0.178039\n",
      "epoch = 83 train_loss : 0.158196 , test loss : 0.177168\n",
      "epoch = 84 train_loss : 0.157392 , test loss : 0.176668\n",
      "epoch = 85 train_loss : 0.156392 , test loss : 0.175711\n",
      "epoch = 86 train_loss : 0.155639 , test loss : 0.175103\n",
      "epoch = 87 train_loss : 0.154734 , test loss : 0.174837\n",
      "epoch = 88 train_loss : 0.153830 , test loss : 0.174028\n",
      "epoch = 89 train_loss : 0.153174 , test loss : 0.173653\n",
      "epoch = 90 train_loss : 0.152596 , test loss : 0.173164\n",
      "epoch = 91 train_loss : 0.151709 , test loss : 0.172109\n",
      "epoch = 92 train_loss : 0.150779 , test loss : 0.171733\n",
      "epoch = 93 train_loss : 0.150024 , test loss : 0.171097\n",
      "epoch = 94 train_loss : 0.149365 , test loss : 0.170353\n",
      "epoch = 95 train_loss : 0.148629 , test loss : 0.170200\n",
      "epoch = 96 train_loss : 0.148131 , test loss : 0.169788\n",
      "epoch = 97 train_loss : 0.147698 , test loss : 0.169351\n",
      "epoch = 98 train_loss : 0.146634 , test loss : 0.168139\n",
      "epoch = 99 train_loss : 0.145988 , test loss : 0.167857\n",
      "epoch = 101 train_loss : 0.144887 , test loss : 0.167819\n",
      "epoch = 102 train_loss : 0.144259 , test loss : 0.167251\n",
      "epoch = 103 train_loss : 0.143772 , test loss : 0.166306\n",
      "epoch = 104 train_loss : 0.143029 , test loss : 0.166087\n",
      "epoch = 105 train_loss : 0.142475 , test loss : 0.165744\n",
      "epoch = 106 train_loss : 0.141987 , test loss : 0.165457\n",
      "epoch = 107 train_loss : 0.141382 , test loss : 0.164757\n",
      "epoch = 109 train_loss : 0.140349 , test loss : 0.164636\n",
      "epoch = 110 train_loss : 0.139929 , test loss : 0.163941\n",
      "epoch = 112 train_loss : 0.138979 , test loss : 0.163404\n",
      "epoch = 113 train_loss : 0.138404 , test loss : 0.163244\n",
      "epoch = 114 train_loss : 0.137912 , test loss : 0.163006\n",
      "epoch = 115 train_loss : 0.137471 , test loss : 0.162700\n",
      "epoch = 116 train_loss : 0.137216 , test loss : 0.162575\n",
      "epoch = 117 train_loss : 0.136606 , test loss : 0.162529\n",
      "epoch = 118 train_loss : 0.136263 , test loss : 0.162169\n",
      "epoch = 120 train_loss : 0.135501 , test loss : 0.162001\n",
      "epoch = 121 train_loss : 0.135124 , test loss : 0.161694\n",
      "epoch = 122 train_loss : 0.134698 , test loss : 0.161269\n",
      "epoch = 123 train_loss : 0.134302 , test loss : 0.161229\n",
      "epoch = 124 train_loss : 0.133910 , test loss : 0.160825\n",
      "epoch = 126 train_loss : 0.133208 , test loss : 0.160482\n",
      "epoch = 128 train_loss : 0.132529 , test loss : 0.160385\n",
      "epoch = 129 train_loss : 0.132239 , test loss : 0.160047\n",
      "epoch = 130 train_loss : 0.131765 , test loss : 0.159411\n",
      "epoch = 133 train_loss : 0.130776 , test loss : 0.159378\n",
      "epoch = 134 train_loss : 0.130498 , test loss : 0.159164\n",
      "epoch = 135 train_loss : 0.130298 , test loss : 0.158759\n",
      "epoch = 137 train_loss : 0.129770 , test loss : 0.158475\n",
      "epoch = 139 train_loss : 0.129033 , test loss : 0.158359\n",
      "epoch = 140 train_loss : 0.128901 , test loss : 0.158010\n",
      "epoch = 145 train_loss : 0.127688 , test loss : 0.157730\n",
      "epoch = 148 train_loss : 0.126830 , test loss : 0.157322\n",
      "epoch = 149 train_loss : 0.126496 , test loss : 0.157250\n",
      "epoch = 154 train_loss : 0.125512 , test loss : 0.157169\n",
      "epoch = 156 train_loss : 0.125002 , test loss : 0.156679\n",
      "epoch = 163 train_loss : 0.123704 , test loss : 0.156576\n",
      "epoch = 169 train_loss : 0.122748 , test loss : 0.156387\n",
      "epoch = 179 train_loss : 0.121148 , test loss : 0.156383\n",
      "epoch = 182 train_loss : 0.120397 , test loss : 0.156209\n",
      "epoch = 189 train_loss : 0.119613 , test loss : 0.156079\n",
      "epoch = 222 train_loss : 0.115879 , test loss : 0.156049\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.115879,test loss : 0.156049\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.113181,total test loss mean : 0.160741 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],8),nn.ReLU(),nn.Linear(8,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,5000,0.0001,5,x44,y44,64,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear function  test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:07:56.948753Z",
     "start_time": "2021-12-30T07:07:56.943753Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_cv(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x4)\n",
    "    rmse=np.sqrt(-cross_val_score(model,x4,y4,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:08:03.042102Z",
     "start_time": "2021-12-30T07:07:58.680852Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 1.0530 (0.0612)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.0005,random_state=1))\n",
    "score=rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:08:12.793660Z",
     "start_time": "2021-12-30T07:08:08.455411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " enet score: 1.0530 (0.0612)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enet=make_pipeline(RobustScaler(),ElasticNet(alpha=0.0005,l1_ratio=0.9))\n",
    "scoreo=rmsle_cv(enet)\n",
    "print(\"\\n enet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:08:18.071961Z",
     "start_time": "2021-12-30T07:08:17.695940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ridge score: 1.0563 (0.0612)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge=make_pipeline(RobustScaler(),Ridge(alpha=0.5))\n",
    "score=rmsle_cv(ridge)\n",
    "print(\"\\n ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:08:26.331434Z",
     "start_time": "2021-12-30T07:08:25.958412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ridge score: 1.0564 (0.0612)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge=make_pipeline(Ridge(alpha=0.5))\n",
    "score=rmsle_cv(ridge)\n",
    "print(\"\\n ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:09:53.373412Z",
     "start_time": "2021-12-30T07:08:27.447498Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 1.2025 (0.0807)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000,\n",
    "                                   learning_rate=0.05,\n",
    "                                   max_depth=4,\n",
    "                                   max_features='sqrt',\n",
    "                                   min_samples_leaf=15,\n",
    "                                   min_samples_split=10,\n",
    "                                   loss='huber',\n",
    "                                   random_state=5)\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:13:24.133467Z",
     "start_time": "2021-12-30T07:11:06.824614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:11:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:12:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:12:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:12:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Xgboost score: 1.1317 (0.0673)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:13:35.138097Z",
     "start_time": "2021-12-30T07:13:24.137467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 1.1382 (0.0710)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-24T09:33:30.208720Z",
     "start_time": "2021-12-24T09:33:28.560626Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x4_cxv=pd.DataFrame(x4.reshape(-1,9))\n",
    "# x4_cxv.to_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\wx_x_cxv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:16.613496Z",
     "start_time": "2021-12-30T02:13:16.604495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79645675, -0.60553382, -1.27240954, -1.8175533 , -1.8175533 ,\n",
       "       -0.90134018,  0.3641883 ,  1.00139281,  1.48322449, -0.25412602])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-5,81:91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:17.163527Z",
     "start_time": "2021-12-30T02:13:17.153527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.60553382, -1.27240954, -1.8175533 , -1.8175533 , -0.90134018,\n",
       "        0.3641883 ,  1.00139281,  1.48322449,  1.00139281, -0.25412602])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-4,81:91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:17.621554Z",
     "start_time": "2021-12-30T02:13:17.614553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.27240954, -1.8175533 , -1.8175533 , -0.90134018,  0.3641883 ,\n",
       "        1.00139281,  1.48322449,  1.00139281,  0.57751679, -0.25412602])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-3,81:91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:18.119582Z",
     "start_time": "2021-12-30T02:13:18.112582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00139281],\n",
       "       [ 0.57751679],\n",
       "       [-0.06379855],\n",
       "       [ 0.3641883 ],\n",
       "       [ 0.6281137 ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:13:35.230102Z",
     "start_time": "2021-12-30T07:13:35.143097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.019875e-13</td>\n",
       "      <td>-5.144712e-14</td>\n",
       "      <td>6.653925e-14</td>\n",
       "      <td>2.549689e-14</td>\n",
       "      <td>2.334629e-15</td>\n",
       "      <td>-6.727368e-14</td>\n",
       "      <td>-4.221841e-14</td>\n",
       "      <td>2.062856e-15</td>\n",
       "      <td>5.215490e-14</td>\n",
       "      <td>5.756380</td>\n",
       "      <td>-1.659610e-15</td>\n",
       "      <td>6.245795e-14</td>\n",
       "      <td>-9.682569e-15</td>\n",
       "      <td>-1.537578e-14</td>\n",
       "      <td>1.616595e-14</td>\n",
       "      <td>-8.086471e-15</td>\n",
       "      <td>3.354384e-14</td>\n",
       "      <td>3.181464e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.725299</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.255345e+00</td>\n",
       "      <td>-5.306764e+00</td>\n",
       "      <td>-2.846587e+00</td>\n",
       "      <td>-2.447008e+00</td>\n",
       "      <td>-3.818917e+00</td>\n",
       "      <td>-4.363104e+00</td>\n",
       "      <td>-3.808196e+00</td>\n",
       "      <td>-3.063532e+00</td>\n",
       "      <td>-2.833784e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-2.286725e+00</td>\n",
       "      <td>-3.466795e+00</td>\n",
       "      <td>-7.641412e+00</td>\n",
       "      <td>-3.527271e+00</td>\n",
       "      <td>-3.868786e+00</td>\n",
       "      <td>-3.965265e+00</td>\n",
       "      <td>-2.782619e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.027755e-01</td>\n",
       "      <td>-1.199461e+00</td>\n",
       "      <td>-6.693840e-01</td>\n",
       "      <td>-7.516859e-01</td>\n",
       "      <td>-6.222681e-01</td>\n",
       "      <td>-6.602794e-01</td>\n",
       "      <td>-6.587790e-01</td>\n",
       "      <td>-6.921282e-01</td>\n",
       "      <td>-6.450364e-01</td>\n",
       "      <td>3.853588</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-8.022974e-01</td>\n",
       "      <td>-6.567335e-01</td>\n",
       "      <td>-8.957229e-01</td>\n",
       "      <td>-8.471015e-01</td>\n",
       "      <td>-8.284860e-01</td>\n",
       "      <td>-7.175293e-01</td>\n",
       "      <td>-7.554874e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.868283e-03</td>\n",
       "      <td>-1.540203e-01</td>\n",
       "      <td>5.390355e-02</td>\n",
       "      <td>-8.905258e-02</td>\n",
       "      <td>2.767230e-03</td>\n",
       "      <td>-2.466757e-02</td>\n",
       "      <td>-6.652185e-02</td>\n",
       "      <td>9.398760e-03</td>\n",
       "      <td>-1.337080e-02</td>\n",
       "      <td>5.763730</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.566150e-03</td>\n",
       "      <td>-5.175865e-02</td>\n",
       "      <td>-2.955772e-01</td>\n",
       "      <td>-1.955858e-01</td>\n",
       "      <td>-1.918681e-01</td>\n",
       "      <td>-1.644871e-02</td>\n",
       "      <td>1.601343e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.085792e-01</td>\n",
       "      <td>1.103605e+00</td>\n",
       "      <td>6.987095e-01</td>\n",
       "      <td>7.299705e-01</td>\n",
       "      <td>5.875442e-01</td>\n",
       "      <td>7.024097e-01</td>\n",
       "      <td>6.728357e-01</td>\n",
       "      <td>6.640201e-01</td>\n",
       "      <td>6.670347e-01</td>\n",
       "      <td>7.603404</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.107297e-01</td>\n",
       "      <td>6.329803e-01</td>\n",
       "      <td>3.274645e-01</td>\n",
       "      <td>7.160547e-01</td>\n",
       "      <td>7.535070e-01</td>\n",
       "      <td>7.077023e-01</td>\n",
       "      <td>7.440291e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.465256e+00</td>\n",
       "      <td>4.391621e+00</td>\n",
       "      <td>2.890982e+00</td>\n",
       "      <td>2.483615e+00</td>\n",
       "      <td>2.956513e+00</td>\n",
       "      <td>3.042810e+00</td>\n",
       "      <td>3.154037e+00</td>\n",
       "      <td>5.440292e+00</td>\n",
       "      <td>3.461476e+00</td>\n",
       "      <td>14.709463</td>\n",
       "      <td>4.321989e+00</td>\n",
       "      <td>2.443003e+00</td>\n",
       "      <td>3.760984e+00</td>\n",
       "      <td>8.702351e+00</td>\n",
       "      <td>1.710428e+00</td>\n",
       "      <td>1.698787e+00</td>\n",
       "      <td>3.054866e+00</td>\n",
       "      <td>2.753135e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean   1.019875e-13 -5.144712e-14  6.653925e-14  2.549689e-14  2.334629e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.255345e+00 -5.306764e+00 -2.846587e+00 -2.447008e+00 -3.818917e+00   \n",
       "25%   -8.027755e-01 -1.199461e+00 -6.693840e-01 -7.516859e-01 -6.222681e-01   \n",
       "50%    3.868283e-03 -1.540203e-01  5.390355e-02 -8.905258e-02  2.767230e-03   \n",
       "75%    7.085792e-01  1.103605e+00  6.987095e-01  7.299705e-01  5.875442e-01   \n",
       "max    2.465256e+00  4.391621e+00  2.890982e+00  2.483615e+00  2.956513e+00   \n",
       "\n",
       "                 5             6             7             8            9   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5760.000000   \n",
       "mean  -6.727368e-14 -4.221841e-14  2.062856e-15  5.215490e-14     5.756380   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00     2.725299   \n",
       "min   -4.363104e+00 -3.808196e+00 -3.063532e+00 -2.833784e+00     0.000000   \n",
       "25%   -6.602794e-01 -6.587790e-01 -6.921282e-01 -6.450364e-01     3.853588   \n",
       "50%   -2.466757e-02 -6.652185e-02  9.398760e-03 -1.337080e-02     5.763730   \n",
       "75%    7.024097e-01  6.728357e-01  6.640201e-01  6.670347e-01     7.603404   \n",
       "max    3.042810e+00  3.154037e+00  5.440292e+00  3.461476e+00    14.709463   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean  -1.659610e-15  6.245795e-14 -9.682569e-15 -1.537578e-14  1.616595e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.541260e-01 -2.286725e+00 -3.466795e+00 -7.641412e+00 -3.527271e+00   \n",
       "25%   -2.541260e-01 -8.022974e-01 -6.567335e-01 -8.957229e-01 -8.471015e-01   \n",
       "50%   -2.541260e-01  8.566150e-03 -5.175865e-02 -2.955772e-01 -1.955858e-01   \n",
       "75%   -2.541260e-01  8.107297e-01  6.329803e-01  3.274645e-01  7.160547e-01   \n",
       "max    4.321989e+00  2.443003e+00  3.760984e+00  8.702351e+00  1.710428e+00   \n",
       "\n",
       "                 15            16            17  \n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  \n",
       "mean  -8.086471e-15  3.354384e-14  3.181464e-15  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -3.868786e+00 -3.965265e+00 -2.782619e+00  \n",
       "25%   -8.284860e-01 -7.175293e-01 -7.554874e-01  \n",
       "50%   -1.918681e-01 -1.644871e-02  1.601343e-02  \n",
       "75%    7.535070e-01  7.077023e-01  7.440291e-01  \n",
       "max    1.698787e+00  3.054866e+00  2.753135e+00  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:02.102098Z",
     "start_time": "2021-12-30T02:14:02.093097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4681776384963"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 0.6281137*2.725299+5.756380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:24:38.452036Z",
     "start_time": "2021-12-30T07:24:38.445036Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import inv_boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:03.244163Z",
     "start_time": "2021-12-30T02:14:03.236163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.999999855599405"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 0.6281137*2.725299+5.756380\n",
    "inv_boxcox1p(7.4681776384963,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:04.158215Z",
     "start_time": "2021-12-30T02:14:04.148215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5825098754835505"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.06379855*2.725299+5.756380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:06.111327Z",
     "start_time": "2021-12-30T02:14:06.099326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.000000800694327"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox1p(5.5825098754835505,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:07.613413Z",
     "start_time": "2021-12-30T02:14:07.603412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1444"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.38*0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:02.245533Z",
     "start_time": "2021-12-30T07:23:02.229532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4521\n"
     ]
    }
   ],
   "source": [
    "x4_len=x4.shape[0]\n",
    "print(int(0.8*x4_len))\n",
    "x4_train=x4[:int(0.8*x4_len),:]\n",
    "y4_train=y4[:int(0.8*x4_len),:]\n",
    "x4_test=x4[int(0.8*x4_len):,:]\n",
    "y4_test=y4[int(0.8*x4_len):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:07.151814Z",
     "start_time": "2021-12-30T07:23:07.139813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 162)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:07.664843Z",
     "start_time": "2021-12-30T07:23:07.656843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:40.511722Z",
     "start_time": "2021-12-30T07:23:39.817682Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso=Lasso(alpha=0.0005,random_state=1)\n",
    "lasso.fit(x4_train,y4_train)\n",
    "y4_hat=lasso.predict(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:42.684846Z",
     "start_time": "2021-12-30T07:23:42.679846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.90944759, 7.92873243, 6.45371003, 5.93095807, 6.70817544])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_hat[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:44.275937Z",
     "start_time": "2021-12-30T07:23:44.266937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.4854749 ],\n",
       "       [7.33028592],\n",
       "       [5.58250973],\n",
       "       [6.74890197],\n",
       "       [7.46817766]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_test[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:22.110242Z",
     "start_time": "2021-12-30T02:14:22.099241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.87925650986765"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.04508735*2.725299+5.756380\n",
    "\n",
    "inv_boxcox1p(5.87925650986765,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:57.003665Z",
     "start_time": "2021-12-30T07:23:56.995665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:23:58.917775Z",
     "start_time": "2021-12-30T07:23:58.906774Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_cv_predict(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x4_train)\n",
    "    rmse=np.sqrt(-cross_val_predict(model,x4_train,y4_train,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:24:00.694876Z",
     "start_time": "2021-12-30T07:23:59.883830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.08220714])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso=Lasso(alpha=0.0005,random_state=1)\n",
    "lasso.fit(x4_train,y4_train)\n",
    "y4_hat=lasso.predict(x4_test).reshape(-1,1)\n",
    "np.sqrt(np.sum(np.power(y4_hat-y4_test,2),axis=0)/y4_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:26:23.094021Z",
     "start_time": "2021-12-30T07:26:23.077020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.532536460979065"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_hat_orig=y4_hat\n",
    "y4_test_orig=y4_test\n",
    "y4_hat_orig=inv_boxcox1p(y4_hat_orig,0.4145678510523434)\n",
    "y4_test_orig=inv_boxcox1p(y4_test_orig,0.4145678510523434)\n",
    "np.sqrt(mean_squared_error(y4_hat_orig,y4_test_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T07:24:55.726024Z",
     "start_time": "2021-12-30T07:24:55.715023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3909286462303396"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox1p(1.05,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:37:28.812408Z",
     "start_time": "2021-12-29T09:37:28.656399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge=Ridge(alpha=0.5)\n",
    "ridge.fit(x4_train,y4_train)\n",
    "y_hat=ridge.predict(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:37:41.302122Z",
     "start_time": "2021-12-29T09:37:41.294122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16289152],\n",
       "       [0.78155887],\n",
       "       [0.25523402],\n",
       "       [0.07791427],\n",
       "       [0.35014741]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:52:27.554813Z",
     "start_time": "2021-12-29T09:52:27.537812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x44_train=torch.Tensor(x4_train)\n",
    "y44_train=torch.Tensor(y4_train)\n",
    "x44_test=torch.Tensor(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:52:29.186906Z",
     "start_time": "2021-12-29T09:52:29.136904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold_pred(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd,test_features):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    preds=net(test_features).detach().numpy()\n",
    "    print('pred :\\n', preds[-5:])\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:57:40.688723Z",
     "start_time": "2021-12-29T09:52:37.955408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.974191 , test loss : 0.991456\n",
      "epoch = 2 train_loss : 0.741834 , test loss : 0.757175\n",
      "epoch = 3 train_loss : 0.601612 , test loss : 0.618431\n",
      "epoch = 4 train_loss : 0.526269 , test loss : 0.546513\n",
      "epoch = 5 train_loss : 0.484943 , test loss : 0.508254\n",
      "epoch = 6 train_loss : 0.456718 , test loss : 0.482930\n",
      "epoch = 7 train_loss : 0.434904 , test loss : 0.463773\n",
      "epoch = 8 train_loss : 0.417073 , test loss : 0.447909\n",
      "epoch = 9 train_loss : 0.401582 , test loss : 0.433991\n",
      "epoch = 10 train_loss : 0.387928 , test loss : 0.421180\n",
      "epoch = 11 train_loss : 0.376064 , test loss : 0.409798\n",
      "epoch = 12 train_loss : 0.365388 , test loss : 0.399940\n",
      "epoch = 13 train_loss : 0.355818 , test loss : 0.390764\n",
      "epoch = 14 train_loss : 0.346839 , test loss : 0.382016\n",
      "epoch = 15 train_loss : 0.338422 , test loss : 0.373656\n",
      "epoch = 16 train_loss : 0.330679 , test loss : 0.366201\n",
      "epoch = 17 train_loss : 0.323433 , test loss : 0.359235\n",
      "epoch = 18 train_loss : 0.316660 , test loss : 0.352880\n",
      "epoch = 19 train_loss : 0.310033 , test loss : 0.346734\n",
      "epoch = 20 train_loss : 0.303927 , test loss : 0.340848\n",
      "epoch = 21 train_loss : 0.297967 , test loss : 0.335151\n",
      "epoch = 22 train_loss : 0.292399 , test loss : 0.329497\n",
      "epoch = 23 train_loss : 0.286885 , test loss : 0.324540\n",
      "epoch = 24 train_loss : 0.281678 , test loss : 0.319288\n",
      "epoch = 25 train_loss : 0.276744 , test loss : 0.314681\n",
      "epoch = 26 train_loss : 0.271906 , test loss : 0.309983\n",
      "epoch = 27 train_loss : 0.267282 , test loss : 0.305389\n",
      "epoch = 28 train_loss : 0.262815 , test loss : 0.301027\n",
      "epoch = 29 train_loss : 0.258399 , test loss : 0.296615\n",
      "epoch = 30 train_loss : 0.254181 , test loss : 0.292465\n",
      "epoch = 31 train_loss : 0.249947 , test loss : 0.288378\n",
      "epoch = 32 train_loss : 0.246053 , test loss : 0.284895\n",
      "epoch = 33 train_loss : 0.242065 , test loss : 0.280817\n",
      "epoch = 34 train_loss : 0.238323 , test loss : 0.277058\n",
      "epoch = 35 train_loss : 0.234833 , test loss : 0.273443\n",
      "epoch = 36 train_loss : 0.231370 , test loss : 0.269999\n",
      "epoch = 37 train_loss : 0.227820 , test loss : 0.266658\n",
      "epoch = 38 train_loss : 0.224514 , test loss : 0.263339\n",
      "epoch = 39 train_loss : 0.221381 , test loss : 0.259840\n",
      "epoch = 40 train_loss : 0.218319 , test loss : 0.256822\n",
      "epoch = 41 train_loss : 0.215339 , test loss : 0.253966\n",
      "epoch = 42 train_loss : 0.212285 , test loss : 0.250863\n",
      "epoch = 43 train_loss : 0.209421 , test loss : 0.247899\n",
      "epoch = 44 train_loss : 0.206692 , test loss : 0.245298\n",
      "epoch = 45 train_loss : 0.204186 , test loss : 0.242565\n",
      "epoch = 46 train_loss : 0.201724 , test loss : 0.240088\n",
      "epoch = 47 train_loss : 0.199198 , test loss : 0.237672\n",
      "epoch = 48 train_loss : 0.196972 , test loss : 0.235029\n",
      "epoch = 49 train_loss : 0.194721 , test loss : 0.232793\n",
      "epoch = 50 train_loss : 0.192571 , test loss : 0.230813\n",
      "epoch = 51 train_loss : 0.190481 , test loss : 0.228488\n",
      "epoch = 52 train_loss : 0.188513 , test loss : 0.226509\n",
      "epoch = 53 train_loss : 0.186500 , test loss : 0.224612\n",
      "epoch = 54 train_loss : 0.184655 , test loss : 0.222812\n",
      "epoch = 55 train_loss : 0.182736 , test loss : 0.220610\n",
      "epoch = 56 train_loss : 0.181004 , test loss : 0.219083\n",
      "epoch = 57 train_loss : 0.179196 , test loss : 0.217022\n",
      "epoch = 58 train_loss : 0.177692 , test loss : 0.215164\n",
      "epoch = 59 train_loss : 0.176148 , test loss : 0.213946\n",
      "epoch = 60 train_loss : 0.174379 , test loss : 0.212040\n",
      "epoch = 61 train_loss : 0.172854 , test loss : 0.210500\n",
      "epoch = 62 train_loss : 0.171455 , test loss : 0.208963\n",
      "epoch = 63 train_loss : 0.170030 , test loss : 0.207974\n",
      "epoch = 64 train_loss : 0.168624 , test loss : 0.206187\n",
      "epoch = 65 train_loss : 0.167228 , test loss : 0.204762\n",
      "epoch = 66 train_loss : 0.166019 , test loss : 0.203583\n",
      "epoch = 67 train_loss : 0.164644 , test loss : 0.202302\n",
      "epoch = 68 train_loss : 0.163524 , test loss : 0.200794\n",
      "epoch = 69 train_loss : 0.162281 , test loss : 0.199852\n",
      "epoch = 70 train_loss : 0.161408 , test loss : 0.198209\n",
      "epoch = 71 train_loss : 0.160270 , test loss : 0.198172\n",
      "epoch = 72 train_loss : 0.159398 , test loss : 0.196293\n",
      "epoch = 73 train_loss : 0.158136 , test loss : 0.195570\n",
      "epoch = 74 train_loss : 0.157132 , test loss : 0.194273\n",
      "epoch = 75 train_loss : 0.155804 , test loss : 0.193161\n",
      "epoch = 76 train_loss : 0.154862 , test loss : 0.192204\n",
      "epoch = 77 train_loss : 0.153869 , test loss : 0.191184\n",
      "epoch = 78 train_loss : 0.152999 , test loss : 0.190291\n",
      "epoch = 79 train_loss : 0.152056 , test loss : 0.189614\n",
      "epoch = 80 train_loss : 0.151104 , test loss : 0.188552\n",
      "epoch = 81 train_loss : 0.150329 , test loss : 0.187881\n",
      "epoch = 82 train_loss : 0.149421 , test loss : 0.186787\n",
      "epoch = 83 train_loss : 0.148604 , test loss : 0.185932\n",
      "epoch = 84 train_loss : 0.147796 , test loss : 0.185429\n",
      "epoch = 85 train_loss : 0.147371 , test loss : 0.184554\n",
      "epoch = 86 train_loss : 0.146549 , test loss : 0.183929\n",
      "epoch = 87 train_loss : 0.145626 , test loss : 0.183323\n",
      "epoch = 88 train_loss : 0.144868 , test loss : 0.182527\n",
      "epoch = 89 train_loss : 0.144131 , test loss : 0.181867\n",
      "epoch = 91 train_loss : 0.142890 , test loss : 0.180839\n",
      "epoch = 92 train_loss : 0.142418 , test loss : 0.180370\n",
      "epoch = 94 train_loss : 0.141026 , test loss : 0.179450\n",
      "epoch = 95 train_loss : 0.140431 , test loss : 0.178630\n",
      "epoch = 96 train_loss : 0.139779 , test loss : 0.178187\n",
      "epoch = 98 train_loss : 0.138844 , test loss : 0.177374\n",
      "epoch = 99 train_loss : 0.138313 , test loss : 0.176994\n",
      "epoch = 100 train_loss : 0.137664 , test loss : 0.176498\n",
      "epoch = 101 train_loss : 0.137234 , test loss : 0.176068\n",
      "epoch = 102 train_loss : 0.136632 , test loss : 0.175473\n",
      "epoch = 103 train_loss : 0.136132 , test loss : 0.175195\n",
      "epoch = 104 train_loss : 0.135734 , test loss : 0.174936\n",
      "epoch = 105 train_loss : 0.135386 , test loss : 0.174194\n",
      "epoch = 107 train_loss : 0.134300 , test loss : 0.173860\n",
      "epoch = 108 train_loss : 0.133866 , test loss : 0.173593\n",
      "epoch = 109 train_loss : 0.133405 , test loss : 0.173067\n",
      "epoch = 110 train_loss : 0.133035 , test loss : 0.173060\n",
      "epoch = 111 train_loss : 0.132646 , test loss : 0.172833\n",
      "epoch = 112 train_loss : 0.132402 , test loss : 0.172267\n",
      "epoch = 113 train_loss : 0.131734 , test loss : 0.171859\n",
      "epoch = 116 train_loss : 0.130680 , test loss : 0.171281\n",
      "epoch = 118 train_loss : 0.129926 , test loss : 0.170648\n",
      "epoch = 120 train_loss : 0.129238 , test loss : 0.169971\n",
      "epoch = 121 train_loss : 0.128997 , test loss : 0.169786\n",
      "epoch = 122 train_loss : 0.128844 , test loss : 0.169761\n",
      "epoch = 124 train_loss : 0.127943 , test loss : 0.169355\n",
      "epoch = 125 train_loss : 0.127773 , test loss : 0.168844\n",
      "epoch = 126 train_loss : 0.127380 , test loss : 0.168588\n",
      "epoch = 127 train_loss : 0.127190 , test loss : 0.168460\n",
      "epoch = 129 train_loss : 0.126559 , test loss : 0.167892\n",
      "epoch = 130 train_loss : 0.126498 , test loss : 0.167823\n",
      "epoch = 131 train_loss : 0.125967 , test loss : 0.167599\n",
      "epoch = 134 train_loss : 0.125068 , test loss : 0.167527\n",
      "epoch = 137 train_loss : 0.124270 , test loss : 0.167130\n",
      "epoch = 140 train_loss : 0.123578 , test loss : 0.166824\n",
      "epoch = 142 train_loss : 0.123050 , test loss : 0.166598\n",
      "epoch = 144 train_loss : 0.122881 , test loss : 0.166262\n",
      "epoch = 146 train_loss : 0.122448 , test loss : 0.165993\n",
      "epoch = 148 train_loss : 0.121904 , test loss : 0.165624\n",
      "epoch = 153 train_loss : 0.120611 , test loss : 0.165417\n",
      "epoch = 154 train_loss : 0.120501 , test loss : 0.165328\n",
      "epoch = 155 train_loss : 0.120550 , test loss : 0.164811\n",
      "epoch = 161 train_loss : 0.119324 , test loss : 0.164385\n",
      "epoch = 162 train_loss : 0.119113 , test loss : 0.164303\n",
      "epoch = 165 train_loss : 0.118803 , test loss : 0.164034\n",
      "epoch = 172 train_loss : 0.117515 , test loss : 0.163601\n",
      "epoch = 182 train_loss : 0.116310 , test loss : 0.163468\n",
      "epoch = 186 train_loss : 0.115626 , test loss : 0.163413\n",
      "epoch = 189 train_loss : 0.115277 , test loss : 0.163191\n",
      "epoch = 190 train_loss : 0.115505 , test loss : 0.163025\n",
      "epoch = 195 train_loss : 0.114742 , test loss : 0.162958\n",
      "epoch = 202 train_loss : 0.114389 , test loss : 0.162894\n",
      "epoch = 207 train_loss : 0.113531 , test loss : 0.162795\n",
      "epoch = 210 train_loss : 0.113296 , test loss : 0.162738\n",
      "epoch = 213 train_loss : 0.112877 , test loss : 0.162706\n",
      "epoch = 229 train_loss : 0.112205 , test loss : 0.162703\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.112205,test loss : 0.162703\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.940339 , test loss : 1.001383\n",
      "epoch = 2 train_loss : 0.710311 , test loss : 0.767712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3 train_loss : 0.583636 , test loss : 0.643681\n",
      "epoch = 4 train_loss : 0.513431 , test loss : 0.575133\n",
      "epoch = 5 train_loss : 0.473913 , test loss : 0.537210\n",
      "epoch = 6 train_loss : 0.449237 , test loss : 0.513542\n",
      "epoch = 7 train_loss : 0.431348 , test loss : 0.496913\n",
      "epoch = 8 train_loss : 0.416752 , test loss : 0.483396\n",
      "epoch = 9 train_loss : 0.404074 , test loss : 0.471418\n",
      "epoch = 10 train_loss : 0.392451 , test loss : 0.459390\n",
      "epoch = 11 train_loss : 0.382106 , test loss : 0.449323\n",
      "epoch = 12 train_loss : 0.372442 , test loss : 0.439136\n",
      "epoch = 13 train_loss : 0.363195 , test loss : 0.429782\n",
      "epoch = 14 train_loss : 0.354842 , test loss : 0.421697\n",
      "epoch = 15 train_loss : 0.347060 , test loss : 0.414091\n",
      "epoch = 16 train_loss : 0.339808 , test loss : 0.407107\n",
      "epoch = 17 train_loss : 0.333109 , test loss : 0.400208\n",
      "epoch = 18 train_loss : 0.326489 , test loss : 0.394170\n",
      "epoch = 19 train_loss : 0.320287 , test loss : 0.387891\n",
      "epoch = 20 train_loss : 0.314319 , test loss : 0.381793\n",
      "epoch = 21 train_loss : 0.308702 , test loss : 0.377100\n",
      "epoch = 22 train_loss : 0.303206 , test loss : 0.371790\n",
      "epoch = 23 train_loss : 0.297984 , test loss : 0.366543\n",
      "epoch = 24 train_loss : 0.292944 , test loss : 0.361850\n",
      "epoch = 25 train_loss : 0.288048 , test loss : 0.357753\n",
      "epoch = 26 train_loss : 0.283408 , test loss : 0.353488\n",
      "epoch = 27 train_loss : 0.278932 , test loss : 0.348970\n",
      "epoch = 28 train_loss : 0.274581 , test loss : 0.344649\n",
      "epoch = 29 train_loss : 0.270433 , test loss : 0.340516\n",
      "epoch = 30 train_loss : 0.266347 , test loss : 0.337068\n",
      "epoch = 31 train_loss : 0.262394 , test loss : 0.332831\n",
      "epoch = 32 train_loss : 0.258760 , test loss : 0.329317\n",
      "epoch = 33 train_loss : 0.254931 , test loss : 0.326375\n",
      "epoch = 34 train_loss : 0.251641 , test loss : 0.323262\n",
      "epoch = 35 train_loss : 0.248098 , test loss : 0.319069\n",
      "epoch = 36 train_loss : 0.244889 , test loss : 0.316251\n",
      "epoch = 37 train_loss : 0.241833 , test loss : 0.312937\n",
      "epoch = 38 train_loss : 0.238732 , test loss : 0.309571\n",
      "epoch = 39 train_loss : 0.235720 , test loss : 0.306926\n",
      "epoch = 40 train_loss : 0.232774 , test loss : 0.303703\n",
      "epoch = 41 train_loss : 0.229952 , test loss : 0.301060\n",
      "epoch = 42 train_loss : 0.227149 , test loss : 0.298021\n",
      "epoch = 43 train_loss : 0.224380 , test loss : 0.295154\n",
      "epoch = 44 train_loss : 0.221740 , test loss : 0.292490\n",
      "epoch = 45 train_loss : 0.219272 , test loss : 0.290040\n",
      "epoch = 46 train_loss : 0.216925 , test loss : 0.287401\n",
      "epoch = 47 train_loss : 0.214336 , test loss : 0.285164\n",
      "epoch = 48 train_loss : 0.212054 , test loss : 0.282911\n",
      "epoch = 49 train_loss : 0.209716 , test loss : 0.280922\n",
      "epoch = 50 train_loss : 0.207527 , test loss : 0.277962\n",
      "epoch = 51 train_loss : 0.205337 , test loss : 0.275892\n",
      "epoch = 52 train_loss : 0.203232 , test loss : 0.273666\n",
      "epoch = 53 train_loss : 0.201147 , test loss : 0.271307\n",
      "epoch = 54 train_loss : 0.199091 , test loss : 0.270129\n",
      "epoch = 55 train_loss : 0.197204 , test loss : 0.267647\n",
      "epoch = 56 train_loss : 0.195190 , test loss : 0.265448\n",
      "epoch = 57 train_loss : 0.193401 , test loss : 0.263149\n",
      "epoch = 58 train_loss : 0.191542 , test loss : 0.261561\n",
      "epoch = 59 train_loss : 0.189806 , test loss : 0.259556\n",
      "epoch = 60 train_loss : 0.188048 , test loss : 0.258432\n",
      "epoch = 61 train_loss : 0.186399 , test loss : 0.256418\n",
      "epoch = 62 train_loss : 0.184701 , test loss : 0.255147\n",
      "epoch = 63 train_loss : 0.183077 , test loss : 0.253179\n",
      "epoch = 64 train_loss : 0.181481 , test loss : 0.251573\n",
      "epoch = 65 train_loss : 0.179992 , test loss : 0.250446\n",
      "epoch = 66 train_loss : 0.178565 , test loss : 0.248512\n",
      "epoch = 67 train_loss : 0.177097 , test loss : 0.248109\n",
      "epoch = 68 train_loss : 0.175547 , test loss : 0.246200\n",
      "epoch = 69 train_loss : 0.174118 , test loss : 0.244145\n",
      "epoch = 70 train_loss : 0.172831 , test loss : 0.243477\n",
      "epoch = 71 train_loss : 0.171447 , test loss : 0.241012\n",
      "epoch = 72 train_loss : 0.170173 , test loss : 0.240400\n",
      "epoch = 73 train_loss : 0.168871 , test loss : 0.239311\n",
      "epoch = 74 train_loss : 0.167607 , test loss : 0.237736\n",
      "epoch = 75 train_loss : 0.166358 , test loss : 0.236200\n",
      "epoch = 76 train_loss : 0.165193 , test loss : 0.235215\n",
      "epoch = 77 train_loss : 0.164114 , test loss : 0.233101\n",
      "epoch = 78 train_loss : 0.163306 , test loss : 0.232534\n",
      "epoch = 79 train_loss : 0.162017 , test loss : 0.232178\n",
      "epoch = 80 train_loss : 0.160934 , test loss : 0.230560\n",
      "epoch = 81 train_loss : 0.159797 , test loss : 0.229230\n",
      "epoch = 82 train_loss : 0.158870 , test loss : 0.227869\n",
      "epoch = 83 train_loss : 0.157969 , test loss : 0.227379\n",
      "epoch = 84 train_loss : 0.157036 , test loss : 0.226048\n",
      "epoch = 85 train_loss : 0.156070 , test loss : 0.225206\n",
      "epoch = 86 train_loss : 0.155050 , test loss : 0.223489\n",
      "epoch = 87 train_loss : 0.154154 , test loss : 0.222733\n",
      "epoch = 88 train_loss : 0.153374 , test loss : 0.222290\n",
      "epoch = 89 train_loss : 0.152484 , test loss : 0.220616\n",
      "epoch = 90 train_loss : 0.151696 , test loss : 0.219551\n",
      "epoch = 91 train_loss : 0.150934 , test loss : 0.218471\n",
      "epoch = 92 train_loss : 0.150085 , test loss : 0.217826\n",
      "epoch = 93 train_loss : 0.149451 , test loss : 0.216300\n",
      "epoch = 94 train_loss : 0.148606 , test loss : 0.215885\n",
      "epoch = 95 train_loss : 0.147893 , test loss : 0.215380\n",
      "epoch = 96 train_loss : 0.147136 , test loss : 0.214741\n",
      "epoch = 97 train_loss : 0.146448 , test loss : 0.213705\n",
      "epoch = 98 train_loss : 0.145711 , test loss : 0.212965\n",
      "epoch = 99 train_loss : 0.145231 , test loss : 0.212350\n",
      "epoch = 100 train_loss : 0.144592 , test loss : 0.211932\n",
      "epoch = 101 train_loss : 0.143825 , test loss : 0.211346\n",
      "epoch = 102 train_loss : 0.143131 , test loss : 0.210322\n",
      "epoch = 103 train_loss : 0.142476 , test loss : 0.209912\n",
      "epoch = 104 train_loss : 0.141890 , test loss : 0.208921\n",
      "epoch = 106 train_loss : 0.140771 , test loss : 0.208347\n",
      "epoch = 107 train_loss : 0.140226 , test loss : 0.207164\n",
      "epoch = 108 train_loss : 0.139674 , test loss : 0.206727\n",
      "epoch = 109 train_loss : 0.139071 , test loss : 0.205856\n",
      "epoch = 110 train_loss : 0.138612 , test loss : 0.205163\n",
      "epoch = 112 train_loss : 0.137670 , test loss : 0.204399\n",
      "epoch = 113 train_loss : 0.137182 , test loss : 0.204081\n",
      "epoch = 114 train_loss : 0.136727 , test loss : 0.203903\n",
      "epoch = 115 train_loss : 0.136364 , test loss : 0.203694\n",
      "epoch = 116 train_loss : 0.135860 , test loss : 0.201587\n",
      "epoch = 118 train_loss : 0.134895 , test loss : 0.201410\n",
      "epoch = 119 train_loss : 0.134532 , test loss : 0.200583\n",
      "epoch = 120 train_loss : 0.134024 , test loss : 0.200536\n",
      "epoch = 121 train_loss : 0.133793 , test loss : 0.199891\n",
      "epoch = 122 train_loss : 0.133297 , test loss : 0.199624\n",
      "epoch = 123 train_loss : 0.133140 , test loss : 0.199246\n",
      "epoch = 125 train_loss : 0.132352 , test loss : 0.198358\n",
      "epoch = 126 train_loss : 0.131806 , test loss : 0.197645\n",
      "epoch = 128 train_loss : 0.131205 , test loss : 0.197195\n",
      "epoch = 129 train_loss : 0.130875 , test loss : 0.197068\n",
      "epoch = 130 train_loss : 0.130522 , test loss : 0.196426\n",
      "epoch = 131 train_loss : 0.130338 , test loss : 0.195857\n",
      "epoch = 133 train_loss : 0.129662 , test loss : 0.194935\n",
      "epoch = 136 train_loss : 0.128770 , test loss : 0.194219\n",
      "epoch = 139 train_loss : 0.127828 , test loss : 0.193848\n",
      "epoch = 140 train_loss : 0.127500 , test loss : 0.193175\n",
      "epoch = 142 train_loss : 0.127222 , test loss : 0.192975\n",
      "epoch = 144 train_loss : 0.126555 , test loss : 0.192367\n",
      "epoch = 145 train_loss : 0.126354 , test loss : 0.191871\n",
      "epoch = 147 train_loss : 0.125968 , test loss : 0.191461\n",
      "epoch = 149 train_loss : 0.125335 , test loss : 0.191021\n",
      "epoch = 151 train_loss : 0.125183 , test loss : 0.190822\n",
      "epoch = 152 train_loss : 0.124631 , test loss : 0.190582\n",
      "epoch = 154 train_loss : 0.124261 , test loss : 0.190534\n",
      "epoch = 155 train_loss : 0.124132 , test loss : 0.189561\n",
      "epoch = 156 train_loss : 0.124034 , test loss : 0.189367\n",
      "epoch = 158 train_loss : 0.123578 , test loss : 0.189175\n",
      "epoch = 161 train_loss : 0.122876 , test loss : 0.189119\n",
      "epoch = 162 train_loss : 0.122653 , test loss : 0.188638\n",
      "epoch = 163 train_loss : 0.122471 , test loss : 0.187950\n",
      "epoch = 164 train_loss : 0.122277 , test loss : 0.187859\n",
      "epoch = 165 train_loss : 0.122106 , test loss : 0.187823\n",
      "epoch = 166 train_loss : 0.122113 , test loss : 0.187596\n",
      "epoch = 168 train_loss : 0.121595 , test loss : 0.187596\n",
      "epoch = 170 train_loss : 0.121344 , test loss : 0.186680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 172 train_loss : 0.120981 , test loss : 0.185920\n",
      "epoch = 174 train_loss : 0.120641 , test loss : 0.185668\n",
      "epoch = 176 train_loss : 0.120437 , test loss : 0.185454\n",
      "epoch = 181 train_loss : 0.119484 , test loss : 0.185201\n",
      "epoch = 184 train_loss : 0.119030 , test loss : 0.184822\n",
      "epoch = 187 train_loss : 0.118621 , test loss : 0.184799\n",
      "epoch = 189 train_loss : 0.118542 , test loss : 0.184041\n",
      "epoch = 192 train_loss : 0.117912 , test loss : 0.183725\n",
      "epoch = 197 train_loss : 0.117262 , test loss : 0.183299\n",
      "epoch = 198 train_loss : 0.117197 , test loss : 0.182915\n",
      "epoch = 207 train_loss : 0.115993 , test loss : 0.182638\n",
      "epoch = 208 train_loss : 0.115840 , test loss : 0.182569\n",
      "epoch = 209 train_loss : 0.116011 , test loss : 0.182203\n",
      "epoch = 212 train_loss : 0.115482 , test loss : 0.182177\n",
      "epoch = 216 train_loss : 0.115066 , test loss : 0.182146\n",
      "epoch = 218 train_loss : 0.115089 , test loss : 0.181773\n",
      "epoch = 221 train_loss : 0.114529 , test loss : 0.181560\n",
      "epoch = 226 train_loss : 0.114002 , test loss : 0.181319\n",
      "epoch = 236 train_loss : 0.113086 , test loss : 0.180694\n",
      "epoch = 238 train_loss : 0.112917 , test loss : 0.180646\n",
      "epoch = 239 train_loss : 0.113000 , test loss : 0.180199\n",
      "epoch = 248 train_loss : 0.112418 , test loss : 0.179733\n",
      "epoch = 249 train_loss : 0.112480 , test loss : 0.179491\n",
      "epoch = 251 train_loss : 0.111921 , test loss : 0.179397\n",
      "epoch = 259 train_loss : 0.111392 , test loss : 0.179032\n",
      "epoch = 262 train_loss : 0.111064 , test loss : 0.179024\n",
      "epoch = 265 train_loss : 0.110872 , test loss : 0.178936\n",
      "epoch = 266 train_loss : 0.110810 , test loss : 0.178773\n",
      "epoch = 271 train_loss : 0.110470 , test loss : 0.178636\n",
      "epoch = 280 train_loss : 0.110040 , test loss : 0.178594\n",
      "epoch = 286 train_loss : 0.109543 , test loss : 0.178239\n",
      "epoch = 296 train_loss : 0.108857 , test loss : 0.178190\n",
      "epoch = 297 train_loss : 0.109046 , test loss : 0.178015\n",
      "epoch = 307 train_loss : 0.108472 , test loss : 0.177559\n",
      "epoch = 325 train_loss : 0.107422 , test loss : 0.177427\n",
      "epoch = 344 train_loss : 0.106736 , test loss : 0.176958\n",
      "epoch = 354 train_loss : 0.106428 , test loss : 0.176818\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.106428,test loss : 0.176818\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.744787 , test loss : 0.770667\n",
      "epoch = 2 train_loss : 0.595239 , test loss : 0.615533\n",
      "epoch = 3 train_loss : 0.527985 , test loss : 0.539540\n",
      "epoch = 4 train_loss : 0.489996 , test loss : 0.494104\n",
      "epoch = 5 train_loss : 0.463723 , test loss : 0.462035\n",
      "epoch = 6 train_loss : 0.443705 , test loss : 0.437558\n",
      "epoch = 7 train_loss : 0.428694 , test loss : 0.420214\n",
      "epoch = 8 train_loss : 0.415552 , test loss : 0.404427\n",
      "epoch = 9 train_loss : 0.404503 , test loss : 0.392562\n",
      "epoch = 10 train_loss : 0.394481 , test loss : 0.381667\n",
      "epoch = 11 train_loss : 0.385393 , test loss : 0.371911\n",
      "epoch = 12 train_loss : 0.376840 , test loss : 0.362666\n",
      "epoch = 13 train_loss : 0.368548 , test loss : 0.354917\n",
      "epoch = 14 train_loss : 0.360787 , test loss : 0.346830\n",
      "epoch = 15 train_loss : 0.353474 , test loss : 0.339295\n",
      "epoch = 16 train_loss : 0.346418 , test loss : 0.332695\n",
      "epoch = 17 train_loss : 0.339794 , test loss : 0.325712\n",
      "epoch = 18 train_loss : 0.333368 , test loss : 0.319912\n",
      "epoch = 19 train_loss : 0.327254 , test loss : 0.313528\n",
      "epoch = 20 train_loss : 0.321433 , test loss : 0.307719\n",
      "epoch = 21 train_loss : 0.315885 , test loss : 0.302671\n",
      "epoch = 22 train_loss : 0.310450 , test loss : 0.297126\n",
      "epoch = 23 train_loss : 0.305369 , test loss : 0.292436\n",
      "epoch = 24 train_loss : 0.300319 , test loss : 0.287812\n",
      "epoch = 25 train_loss : 0.295508 , test loss : 0.283368\n",
      "epoch = 26 train_loss : 0.290842 , test loss : 0.279442\n",
      "epoch = 27 train_loss : 0.286449 , test loss : 0.275586\n",
      "epoch = 28 train_loss : 0.282387 , test loss : 0.271984\n",
      "epoch = 29 train_loss : 0.278119 , test loss : 0.268049\n",
      "epoch = 30 train_loss : 0.274261 , test loss : 0.264545\n",
      "epoch = 31 train_loss : 0.270592 , test loss : 0.262166\n",
      "epoch = 32 train_loss : 0.266879 , test loss : 0.258900\n",
      "epoch = 33 train_loss : 0.263234 , test loss : 0.255964\n",
      "epoch = 34 train_loss : 0.259847 , test loss : 0.252842\n",
      "epoch = 35 train_loss : 0.256522 , test loss : 0.250060\n",
      "epoch = 36 train_loss : 0.253256 , test loss : 0.247581\n",
      "epoch = 37 train_loss : 0.249949 , test loss : 0.245284\n",
      "epoch = 38 train_loss : 0.246893 , test loss : 0.242367\n",
      "epoch = 39 train_loss : 0.243759 , test loss : 0.239895\n",
      "epoch = 40 train_loss : 0.240875 , test loss : 0.237788\n",
      "epoch = 41 train_loss : 0.237862 , test loss : 0.235447\n",
      "epoch = 42 train_loss : 0.235059 , test loss : 0.233063\n",
      "epoch = 43 train_loss : 0.232258 , test loss : 0.231078\n",
      "epoch = 44 train_loss : 0.229617 , test loss : 0.229298\n",
      "epoch = 45 train_loss : 0.227019 , test loss : 0.226640\n",
      "epoch = 46 train_loss : 0.224436 , test loss : 0.224556\n",
      "epoch = 47 train_loss : 0.221881 , test loss : 0.222988\n",
      "epoch = 48 train_loss : 0.219582 , test loss : 0.221327\n",
      "epoch = 49 train_loss : 0.217099 , test loss : 0.219456\n",
      "epoch = 50 train_loss : 0.214846 , test loss : 0.217755\n",
      "epoch = 51 train_loss : 0.212479 , test loss : 0.216118\n",
      "epoch = 52 train_loss : 0.210246 , test loss : 0.214651\n",
      "epoch = 53 train_loss : 0.208157 , test loss : 0.212647\n",
      "epoch = 54 train_loss : 0.206010 , test loss : 0.211567\n",
      "epoch = 55 train_loss : 0.203977 , test loss : 0.210072\n",
      "epoch = 56 train_loss : 0.201994 , test loss : 0.208260\n",
      "epoch = 57 train_loss : 0.199962 , test loss : 0.207062\n",
      "epoch = 58 train_loss : 0.197991 , test loss : 0.205669\n",
      "epoch = 59 train_loss : 0.196171 , test loss : 0.204527\n",
      "epoch = 60 train_loss : 0.194395 , test loss : 0.203212\n",
      "epoch = 61 train_loss : 0.192456 , test loss : 0.201484\n",
      "epoch = 62 train_loss : 0.190687 , test loss : 0.200135\n",
      "epoch = 63 train_loss : 0.188878 , test loss : 0.198949\n",
      "epoch = 64 train_loss : 0.187190 , test loss : 0.198040\n",
      "epoch = 65 train_loss : 0.185699 , test loss : 0.197253\n",
      "epoch = 66 train_loss : 0.183893 , test loss : 0.195277\n",
      "epoch = 67 train_loss : 0.182227 , test loss : 0.194278\n",
      "epoch = 68 train_loss : 0.180743 , test loss : 0.192959\n",
      "epoch = 69 train_loss : 0.179182 , test loss : 0.191777\n",
      "epoch = 70 train_loss : 0.177788 , test loss : 0.190898\n",
      "epoch = 71 train_loss : 0.176309 , test loss : 0.190041\n",
      "epoch = 72 train_loss : 0.174798 , test loss : 0.188873\n",
      "epoch = 73 train_loss : 0.173458 , test loss : 0.187507\n",
      "epoch = 74 train_loss : 0.172083 , test loss : 0.187016\n",
      "epoch = 75 train_loss : 0.170884 , test loss : 0.185711\n",
      "epoch = 76 train_loss : 0.169456 , test loss : 0.185019\n",
      "epoch = 77 train_loss : 0.168190 , test loss : 0.184446\n",
      "epoch = 78 train_loss : 0.166844 , test loss : 0.183153\n",
      "epoch = 79 train_loss : 0.165692 , test loss : 0.182285\n",
      "epoch = 80 train_loss : 0.164467 , test loss : 0.181402\n",
      "epoch = 81 train_loss : 0.163538 , test loss : 0.181260\n",
      "epoch = 82 train_loss : 0.162215 , test loss : 0.179803\n",
      "epoch = 83 train_loss : 0.161059 , test loss : 0.178926\n",
      "epoch = 84 train_loss : 0.160146 , test loss : 0.178306\n",
      "epoch = 85 train_loss : 0.158951 , test loss : 0.177625\n",
      "epoch = 86 train_loss : 0.158181 , test loss : 0.176476\n",
      "epoch = 87 train_loss : 0.157116 , test loss : 0.176448\n",
      "epoch = 88 train_loss : 0.156074 , test loss : 0.175670\n",
      "epoch = 89 train_loss : 0.154987 , test loss : 0.174698\n",
      "epoch = 90 train_loss : 0.154082 , test loss : 0.174139\n",
      "epoch = 91 train_loss : 0.153467 , test loss : 0.173238\n",
      "epoch = 92 train_loss : 0.152352 , test loss : 0.172803\n",
      "epoch = 93 train_loss : 0.151422 , test loss : 0.172553\n",
      "epoch = 94 train_loss : 0.150580 , test loss : 0.171687\n",
      "epoch = 95 train_loss : 0.149842 , test loss : 0.171078\n",
      "epoch = 96 train_loss : 0.148917 , test loss : 0.170565\n",
      "epoch = 97 train_loss : 0.148068 , test loss : 0.170204\n",
      "epoch = 98 train_loss : 0.147191 , test loss : 0.169437\n",
      "epoch = 99 train_loss : 0.146361 , test loss : 0.169134\n",
      "epoch = 100 train_loss : 0.145693 , test loss : 0.168291\n",
      "epoch = 101 train_loss : 0.144867 , test loss : 0.168144\n",
      "epoch = 102 train_loss : 0.144097 , test loss : 0.167515\n",
      "epoch = 104 train_loss : 0.142888 , test loss : 0.166932\n",
      "epoch = 106 train_loss : 0.141404 , test loss : 0.166072\n",
      "epoch = 107 train_loss : 0.140770 , test loss : 0.165731\n",
      "epoch = 108 train_loss : 0.140297 , test loss : 0.165689\n",
      "epoch = 109 train_loss : 0.139521 , test loss : 0.165078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 110 train_loss : 0.139003 , test loss : 0.164566\n",
      "epoch = 111 train_loss : 0.138357 , test loss : 0.164370\n",
      "epoch = 112 train_loss : 0.137902 , test loss : 0.163800\n",
      "epoch = 113 train_loss : 0.137280 , test loss : 0.163779\n",
      "epoch = 114 train_loss : 0.136751 , test loss : 0.163284\n",
      "epoch = 116 train_loss : 0.135627 , test loss : 0.163061\n",
      "epoch = 117 train_loss : 0.135458 , test loss : 0.162951\n",
      "epoch = 118 train_loss : 0.134686 , test loss : 0.162680\n",
      "epoch = 119 train_loss : 0.134189 , test loss : 0.162343\n",
      "epoch = 120 train_loss : 0.133763 , test loss : 0.161963\n",
      "epoch = 122 train_loss : 0.132951 , test loss : 0.161896\n",
      "epoch = 123 train_loss : 0.132572 , test loss : 0.161460\n",
      "epoch = 124 train_loss : 0.131962 , test loss : 0.161269\n",
      "epoch = 125 train_loss : 0.131581 , test loss : 0.160611\n",
      "epoch = 127 train_loss : 0.130719 , test loss : 0.160542\n",
      "epoch = 128 train_loss : 0.130348 , test loss : 0.160313\n",
      "epoch = 129 train_loss : 0.130064 , test loss : 0.160062\n",
      "epoch = 130 train_loss : 0.129684 , test loss : 0.159856\n",
      "epoch = 133 train_loss : 0.128548 , test loss : 0.159710\n",
      "epoch = 135 train_loss : 0.127988 , test loss : 0.159243\n",
      "epoch = 136 train_loss : 0.127717 , test loss : 0.159153\n",
      "epoch = 137 train_loss : 0.127634 , test loss : 0.158785\n",
      "epoch = 141 train_loss : 0.126264 , test loss : 0.158691\n",
      "epoch = 143 train_loss : 0.125533 , test loss : 0.158557\n",
      "epoch = 144 train_loss : 0.125221 , test loss : 0.158356\n",
      "epoch = 146 train_loss : 0.124698 , test loss : 0.158329\n",
      "epoch = 148 train_loss : 0.124187 , test loss : 0.158231\n",
      "epoch = 150 train_loss : 0.123651 , test loss : 0.158200\n",
      "epoch = 151 train_loss : 0.123451 , test loss : 0.158000\n",
      "epoch = 152 train_loss : 0.123253 , test loss : 0.157710\n",
      "epoch = 158 train_loss : 0.121788 , test loss : 0.157249\n",
      "epoch = 159 train_loss : 0.121609 , test loss : 0.157185\n",
      "epoch = 161 train_loss : 0.121404 , test loss : 0.157120\n",
      "epoch = 162 train_loss : 0.120934 , test loss : 0.157023\n",
      "epoch = 164 train_loss : 0.120608 , test loss : 0.157014\n",
      "epoch = 165 train_loss : 0.120336 , test loss : 0.156890\n",
      "epoch = 166 train_loss : 0.120151 , test loss : 0.156826\n",
      "epoch = 167 train_loss : 0.120239 , test loss : 0.156667\n",
      "epoch = 168 train_loss : 0.119763 , test loss : 0.156470\n",
      "epoch = 170 train_loss : 0.119385 , test loss : 0.156431\n",
      "epoch = 177 train_loss : 0.118393 , test loss : 0.156330\n",
      "epoch = 180 train_loss : 0.117775 , test loss : 0.156130\n",
      "epoch = 183 train_loss : 0.117357 , test loss : 0.156015\n",
      "epoch = 191 train_loss : 0.116065 , test loss : 0.155862\n",
      "epoch = 195 train_loss : 0.115694 , test loss : 0.155540\n",
      "epoch = 200 train_loss : 0.115089 , test loss : 0.155366\n",
      "epoch = 212 train_loss : 0.113503 , test loss : 0.155345\n",
      "epoch = 218 train_loss : 0.112966 , test loss : 0.155293\n",
      "epoch = 224 train_loss : 0.112339 , test loss : 0.155281\n",
      "epoch = 226 train_loss : 0.112184 , test loss : 0.155233\n",
      "epoch = 229 train_loss : 0.111860 , test loss : 0.155142\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.111860,test loss : 0.155142\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.671345 , test loss : 0.658892\n",
      "epoch = 2 train_loss : 0.568516 , test loss : 0.560983\n",
      "epoch = 3 train_loss : 0.508502 , test loss : 0.503790\n",
      "epoch = 4 train_loss : 0.468374 , test loss : 0.463950\n",
      "epoch = 5 train_loss : 0.440337 , test loss : 0.435995\n",
      "epoch = 6 train_loss : 0.418924 , test loss : 0.414623\n",
      "epoch = 7 train_loss : 0.402837 , test loss : 0.398406\n",
      "epoch = 8 train_loss : 0.389298 , test loss : 0.384507\n",
      "epoch = 9 train_loss : 0.377737 , test loss : 0.373054\n",
      "epoch = 10 train_loss : 0.367708 , test loss : 0.363512\n",
      "epoch = 11 train_loss : 0.358524 , test loss : 0.355117\n",
      "epoch = 12 train_loss : 0.350170 , test loss : 0.347787\n",
      "epoch = 13 train_loss : 0.342351 , test loss : 0.340631\n",
      "epoch = 14 train_loss : 0.335008 , test loss : 0.333904\n",
      "epoch = 15 train_loss : 0.327985 , test loss : 0.327789\n",
      "epoch = 16 train_loss : 0.321254 , test loss : 0.321797\n",
      "epoch = 17 train_loss : 0.314976 , test loss : 0.316773\n",
      "epoch = 18 train_loss : 0.309054 , test loss : 0.311771\n",
      "epoch = 19 train_loss : 0.303178 , test loss : 0.306696\n",
      "epoch = 20 train_loss : 0.297600 , test loss : 0.302027\n",
      "epoch = 21 train_loss : 0.292405 , test loss : 0.297731\n",
      "epoch = 22 train_loss : 0.287322 , test loss : 0.292960\n",
      "epoch = 23 train_loss : 0.282508 , test loss : 0.289208\n",
      "epoch = 24 train_loss : 0.277992 , test loss : 0.285036\n",
      "epoch = 25 train_loss : 0.273643 , test loss : 0.281318\n",
      "epoch = 26 train_loss : 0.269411 , test loss : 0.277534\n",
      "epoch = 27 train_loss : 0.265390 , test loss : 0.273616\n",
      "epoch = 28 train_loss : 0.261397 , test loss : 0.270338\n",
      "epoch = 29 train_loss : 0.257502 , test loss : 0.266823\n",
      "epoch = 30 train_loss : 0.253830 , test loss : 0.264064\n",
      "epoch = 31 train_loss : 0.250234 , test loss : 0.260987\n",
      "epoch = 32 train_loss : 0.246539 , test loss : 0.257187\n",
      "epoch = 33 train_loss : 0.243215 , test loss : 0.255057\n",
      "epoch = 34 train_loss : 0.239753 , test loss : 0.251387\n",
      "epoch = 35 train_loss : 0.236552 , test loss : 0.248934\n",
      "epoch = 36 train_loss : 0.233366 , test loss : 0.245842\n",
      "epoch = 37 train_loss : 0.230362 , test loss : 0.243208\n",
      "epoch = 38 train_loss : 0.227306 , test loss : 0.240824\n",
      "epoch = 39 train_loss : 0.224488 , test loss : 0.238138\n",
      "epoch = 40 train_loss : 0.221838 , test loss : 0.235312\n",
      "epoch = 41 train_loss : 0.218756 , test loss : 0.233549\n",
      "epoch = 42 train_loss : 0.216038 , test loss : 0.230883\n",
      "epoch = 43 train_loss : 0.213447 , test loss : 0.228825\n",
      "epoch = 44 train_loss : 0.210908 , test loss : 0.227210\n",
      "epoch = 45 train_loss : 0.208242 , test loss : 0.224517\n",
      "epoch = 46 train_loss : 0.205875 , test loss : 0.222774\n",
      "epoch = 47 train_loss : 0.203531 , test loss : 0.220444\n",
      "epoch = 48 train_loss : 0.201197 , test loss : 0.218689\n",
      "epoch = 49 train_loss : 0.199102 , test loss : 0.217581\n",
      "epoch = 50 train_loss : 0.196778 , test loss : 0.215017\n",
      "epoch = 51 train_loss : 0.194696 , test loss : 0.213167\n",
      "epoch = 52 train_loss : 0.192576 , test loss : 0.211131\n",
      "epoch = 53 train_loss : 0.190990 , test loss : 0.209730\n",
      "epoch = 54 train_loss : 0.188763 , test loss : 0.208689\n",
      "epoch = 55 train_loss : 0.187112 , test loss : 0.206924\n",
      "epoch = 56 train_loss : 0.184936 , test loss : 0.205201\n",
      "epoch = 57 train_loss : 0.183223 , test loss : 0.203740\n",
      "epoch = 58 train_loss : 0.181458 , test loss : 0.202648\n",
      "epoch = 59 train_loss : 0.179856 , test loss : 0.200923\n",
      "epoch = 60 train_loss : 0.178275 , test loss : 0.199831\n",
      "epoch = 61 train_loss : 0.176674 , test loss : 0.198483\n",
      "epoch = 62 train_loss : 0.175057 , test loss : 0.197281\n",
      "epoch = 63 train_loss : 0.173554 , test loss : 0.195570\n",
      "epoch = 64 train_loss : 0.172369 , test loss : 0.194425\n",
      "epoch = 65 train_loss : 0.170768 , test loss : 0.193621\n",
      "epoch = 66 train_loss : 0.169304 , test loss : 0.192508\n",
      "epoch = 67 train_loss : 0.167982 , test loss : 0.191206\n",
      "epoch = 68 train_loss : 0.166604 , test loss : 0.189929\n",
      "epoch = 69 train_loss : 0.165375 , test loss : 0.189445\n",
      "epoch = 70 train_loss : 0.164153 , test loss : 0.188763\n",
      "epoch = 71 train_loss : 0.163053 , test loss : 0.187772\n",
      "epoch = 72 train_loss : 0.161915 , test loss : 0.185923\n",
      "epoch = 73 train_loss : 0.160760 , test loss : 0.185874\n",
      "epoch = 74 train_loss : 0.159763 , test loss : 0.184769\n",
      "epoch = 75 train_loss : 0.158764 , test loss : 0.183019\n",
      "epoch = 76 train_loss : 0.157553 , test loss : 0.182699\n",
      "epoch = 77 train_loss : 0.156518 , test loss : 0.181652\n",
      "epoch = 78 train_loss : 0.155536 , test loss : 0.180972\n",
      "epoch = 79 train_loss : 0.154622 , test loss : 0.179816\n",
      "epoch = 80 train_loss : 0.153698 , test loss : 0.179067\n",
      "epoch = 81 train_loss : 0.152919 , test loss : 0.178101\n",
      "epoch = 82 train_loss : 0.151983 , test loss : 0.177166\n",
      "epoch = 83 train_loss : 0.151157 , test loss : 0.177024\n",
      "epoch = 84 train_loss : 0.150316 , test loss : 0.176496\n",
      "epoch = 85 train_loss : 0.149528 , test loss : 0.175387\n",
      "epoch = 86 train_loss : 0.148685 , test loss : 0.175281\n",
      "epoch = 87 train_loss : 0.147951 , test loss : 0.174147\n",
      "epoch = 88 train_loss : 0.147330 , test loss : 0.174066\n",
      "epoch = 89 train_loss : 0.146721 , test loss : 0.172712\n",
      "epoch = 91 train_loss : 0.145154 , test loss : 0.171533\n",
      "epoch = 92 train_loss : 0.144450 , test loss : 0.170814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 94 train_loss : 0.143148 , test loss : 0.169778\n",
      "epoch = 95 train_loss : 0.142626 , test loss : 0.169212\n",
      "epoch = 96 train_loss : 0.141995 , test loss : 0.169157\n",
      "epoch = 97 train_loss : 0.141408 , test loss : 0.168478\n",
      "epoch = 99 train_loss : 0.140306 , test loss : 0.167699\n",
      "epoch = 100 train_loss : 0.139708 , test loss : 0.167515\n",
      "epoch = 101 train_loss : 0.139331 , test loss : 0.167430\n",
      "epoch = 102 train_loss : 0.139129 , test loss : 0.167363\n",
      "epoch = 103 train_loss : 0.138228 , test loss : 0.166094\n",
      "epoch = 104 train_loss : 0.137911 , test loss : 0.165501\n",
      "epoch = 105 train_loss : 0.137314 , test loss : 0.165234\n",
      "epoch = 106 train_loss : 0.136872 , test loss : 0.165146\n",
      "epoch = 107 train_loss : 0.136498 , test loss : 0.164997\n",
      "epoch = 108 train_loss : 0.135976 , test loss : 0.164525\n",
      "epoch = 109 train_loss : 0.135578 , test loss : 0.164159\n",
      "epoch = 111 train_loss : 0.134738 , test loss : 0.163316\n",
      "epoch = 113 train_loss : 0.133945 , test loss : 0.163092\n",
      "epoch = 114 train_loss : 0.133941 , test loss : 0.162838\n",
      "epoch = 115 train_loss : 0.133203 , test loss : 0.161880\n",
      "epoch = 118 train_loss : 0.132258 , test loss : 0.161507\n",
      "epoch = 120 train_loss : 0.131741 , test loss : 0.161424\n",
      "epoch = 121 train_loss : 0.131258 , test loss : 0.161059\n",
      "epoch = 122 train_loss : 0.130971 , test loss : 0.160430\n",
      "epoch = 124 train_loss : 0.130201 , test loss : 0.160357\n",
      "epoch = 126 train_loss : 0.129771 , test loss : 0.160126\n",
      "epoch = 127 train_loss : 0.129424 , test loss : 0.160085\n",
      "epoch = 128 train_loss : 0.129020 , test loss : 0.159954\n",
      "epoch = 129 train_loss : 0.128835 , test loss : 0.159476\n",
      "epoch = 131 train_loss : 0.128304 , test loss : 0.159060\n",
      "epoch = 133 train_loss : 0.127758 , test loss : 0.159010\n",
      "epoch = 135 train_loss : 0.127371 , test loss : 0.158614\n",
      "epoch = 136 train_loss : 0.127015 , test loss : 0.158219\n",
      "epoch = 140 train_loss : 0.126247 , test loss : 0.157776\n",
      "epoch = 143 train_loss : 0.125403 , test loss : 0.157668\n",
      "epoch = 147 train_loss : 0.124592 , test loss : 0.157474\n",
      "epoch = 149 train_loss : 0.124268 , test loss : 0.157263\n",
      "epoch = 150 train_loss : 0.124032 , test loss : 0.157122\n",
      "epoch = 151 train_loss : 0.123829 , test loss : 0.157017\n",
      "epoch = 152 train_loss : 0.123615 , test loss : 0.156916\n",
      "epoch = 155 train_loss : 0.123246 , test loss : 0.156702\n",
      "epoch = 156 train_loss : 0.123007 , test loss : 0.156343\n",
      "epoch = 162 train_loss : 0.122088 , test loss : 0.155561\n",
      "epoch = 178 train_loss : 0.119791 , test loss : 0.155355\n",
      "epoch = 184 train_loss : 0.119110 , test loss : 0.155278\n",
      "epoch = 191 train_loss : 0.118212 , test loss : 0.155146\n",
      "epoch = 206 train_loss : 0.116741 , test loss : 0.154863\n",
      "epoch = 213 train_loss : 0.116203 , test loss : 0.154795\n",
      "epoch = 221 train_loss : 0.115686 , test loss : 0.154658\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.115686,test loss : 0.154658\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.719017 , test loss : 0.653916\n",
      "epoch = 2 train_loss : 0.586774 , test loss : 0.524794\n",
      "epoch = 3 train_loss : 0.506236 , test loss : 0.452933\n",
      "epoch = 4 train_loss : 0.458477 , test loss : 0.414516\n",
      "epoch = 5 train_loss : 0.427957 , test loss : 0.391584\n",
      "epoch = 6 train_loss : 0.407080 , test loss : 0.377057\n",
      "epoch = 7 train_loss : 0.391746 , test loss : 0.365911\n",
      "epoch = 8 train_loss : 0.378936 , test loss : 0.356467\n",
      "epoch = 9 train_loss : 0.368017 , test loss : 0.348169\n",
      "epoch = 10 train_loss : 0.358169 , test loss : 0.340904\n",
      "epoch = 11 train_loss : 0.349147 , test loss : 0.333627\n",
      "epoch = 12 train_loss : 0.340938 , test loss : 0.326877\n",
      "epoch = 13 train_loss : 0.333084 , test loss : 0.320749\n",
      "epoch = 14 train_loss : 0.325972 , test loss : 0.315186\n",
      "epoch = 15 train_loss : 0.319090 , test loss : 0.309657\n",
      "epoch = 16 train_loss : 0.312263 , test loss : 0.304133\n",
      "epoch = 17 train_loss : 0.306099 , test loss : 0.299399\n",
      "epoch = 18 train_loss : 0.300240 , test loss : 0.294170\n",
      "epoch = 19 train_loss : 0.294519 , test loss : 0.289805\n",
      "epoch = 20 train_loss : 0.289090 , test loss : 0.285538\n",
      "epoch = 21 train_loss : 0.283879 , test loss : 0.281535\n",
      "epoch = 22 train_loss : 0.278844 , test loss : 0.277847\n",
      "epoch = 23 train_loss : 0.274097 , test loss : 0.273973\n",
      "epoch = 24 train_loss : 0.269532 , test loss : 0.269945\n",
      "epoch = 25 train_loss : 0.265257 , test loss : 0.266638\n",
      "epoch = 26 train_loss : 0.261193 , test loss : 0.262805\n",
      "epoch = 27 train_loss : 0.257245 , test loss : 0.259290\n",
      "epoch = 28 train_loss : 0.253462 , test loss : 0.256160\n",
      "epoch = 29 train_loss : 0.249898 , test loss : 0.253183\n",
      "epoch = 30 train_loss : 0.246462 , test loss : 0.250124\n",
      "epoch = 31 train_loss : 0.243149 , test loss : 0.247793\n",
      "epoch = 32 train_loss : 0.239943 , test loss : 0.244521\n",
      "epoch = 33 train_loss : 0.236818 , test loss : 0.242336\n",
      "epoch = 34 train_loss : 0.233844 , test loss : 0.239715\n",
      "epoch = 35 train_loss : 0.230900 , test loss : 0.237075\n",
      "epoch = 36 train_loss : 0.227986 , test loss : 0.234623\n",
      "epoch = 37 train_loss : 0.225281 , test loss : 0.232132\n",
      "epoch = 38 train_loss : 0.222545 , test loss : 0.229995\n",
      "epoch = 39 train_loss : 0.219893 , test loss : 0.227657\n",
      "epoch = 40 train_loss : 0.217297 , test loss : 0.225606\n",
      "epoch = 41 train_loss : 0.214881 , test loss : 0.223819\n",
      "epoch = 42 train_loss : 0.212483 , test loss : 0.221729\n",
      "epoch = 43 train_loss : 0.210084 , test loss : 0.219937\n",
      "epoch = 44 train_loss : 0.207762 , test loss : 0.217489\n",
      "epoch = 45 train_loss : 0.205545 , test loss : 0.215885\n",
      "epoch = 46 train_loss : 0.203484 , test loss : 0.214232\n",
      "epoch = 47 train_loss : 0.201290 , test loss : 0.212214\n",
      "epoch = 48 train_loss : 0.199191 , test loss : 0.210288\n",
      "epoch = 49 train_loss : 0.197353 , test loss : 0.208654\n",
      "epoch = 50 train_loss : 0.195274 , test loss : 0.207136\n",
      "epoch = 51 train_loss : 0.193517 , test loss : 0.206108\n",
      "epoch = 52 train_loss : 0.191609 , test loss : 0.204146\n",
      "epoch = 53 train_loss : 0.189728 , test loss : 0.202410\n",
      "epoch = 54 train_loss : 0.188218 , test loss : 0.200733\n",
      "epoch = 55 train_loss : 0.186370 , test loss : 0.199583\n",
      "epoch = 56 train_loss : 0.184676 , test loss : 0.198277\n",
      "epoch = 57 train_loss : 0.183122 , test loss : 0.197202\n",
      "epoch = 58 train_loss : 0.181499 , test loss : 0.195707\n",
      "epoch = 59 train_loss : 0.180276 , test loss : 0.193983\n",
      "epoch = 60 train_loss : 0.178598 , test loss : 0.193183\n",
      "epoch = 61 train_loss : 0.177163 , test loss : 0.191530\n",
      "epoch = 62 train_loss : 0.175789 , test loss : 0.190883\n",
      "epoch = 63 train_loss : 0.174437 , test loss : 0.189627\n",
      "epoch = 64 train_loss : 0.173159 , test loss : 0.188859\n",
      "epoch = 65 train_loss : 0.171904 , test loss : 0.187099\n",
      "epoch = 66 train_loss : 0.170717 , test loss : 0.186568\n",
      "epoch = 67 train_loss : 0.169525 , test loss : 0.185525\n",
      "epoch = 68 train_loss : 0.168439 , test loss : 0.184793\n",
      "epoch = 69 train_loss : 0.167118 , test loss : 0.183351\n",
      "epoch = 70 train_loss : 0.166004 , test loss : 0.182181\n",
      "epoch = 71 train_loss : 0.164904 , test loss : 0.181768\n",
      "epoch = 72 train_loss : 0.163858 , test loss : 0.180850\n",
      "epoch = 73 train_loss : 0.162816 , test loss : 0.180344\n",
      "epoch = 74 train_loss : 0.162030 , test loss : 0.179683\n",
      "epoch = 75 train_loss : 0.160814 , test loss : 0.178441\n",
      "epoch = 76 train_loss : 0.159921 , test loss : 0.177810\n",
      "epoch = 77 train_loss : 0.158910 , test loss : 0.177186\n",
      "epoch = 78 train_loss : 0.158567 , test loss : 0.176761\n",
      "epoch = 79 train_loss : 0.157127 , test loss : 0.176018\n",
      "epoch = 80 train_loss : 0.156309 , test loss : 0.175233\n",
      "epoch = 81 train_loss : 0.155549 , test loss : 0.174926\n",
      "epoch = 82 train_loss : 0.154676 , test loss : 0.174048\n",
      "epoch = 83 train_loss : 0.153819 , test loss : 0.173180\n",
      "epoch = 84 train_loss : 0.153006 , test loss : 0.172597\n",
      "epoch = 85 train_loss : 0.152283 , test loss : 0.172154\n",
      "epoch = 86 train_loss : 0.151705 , test loss : 0.171716\n",
      "epoch = 87 train_loss : 0.150771 , test loss : 0.171298\n",
      "epoch = 88 train_loss : 0.150199 , test loss : 0.170919\n",
      "epoch = 89 train_loss : 0.149316 , test loss : 0.170544\n",
      "epoch = 90 train_loss : 0.148606 , test loss : 0.169963\n",
      "epoch = 91 train_loss : 0.148055 , test loss : 0.169566\n",
      "epoch = 92 train_loss : 0.147307 , test loss : 0.168647\n",
      "epoch = 94 train_loss : 0.146135 , test loss : 0.168378\n",
      "epoch = 95 train_loss : 0.145715 , test loss : 0.166973\n",
      "epoch = 98 train_loss : 0.143678 , test loss : 0.166431\n",
      "epoch = 99 train_loss : 0.143135 , test loss : 0.165947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 102 train_loss : 0.141434 , test loss : 0.165588\n",
      "epoch = 103 train_loss : 0.140952 , test loss : 0.165348\n",
      "epoch = 104 train_loss : 0.140454 , test loss : 0.165090\n",
      "epoch = 105 train_loss : 0.140005 , test loss : 0.164674\n",
      "epoch = 106 train_loss : 0.139464 , test loss : 0.164411\n",
      "epoch = 107 train_loss : 0.139000 , test loss : 0.164074\n",
      "epoch = 108 train_loss : 0.138485 , test loss : 0.163481\n",
      "epoch = 111 train_loss : 0.137168 , test loss : 0.163246\n",
      "epoch = 112 train_loss : 0.136872 , test loss : 0.163185\n",
      "epoch = 113 train_loss : 0.136225 , test loss : 0.162948\n",
      "epoch = 114 train_loss : 0.135878 , test loss : 0.162920\n",
      "epoch = 115 train_loss : 0.135622 , test loss : 0.162855\n",
      "epoch = 116 train_loss : 0.135013 , test loss : 0.162301\n",
      "epoch = 117 train_loss : 0.134638 , test loss : 0.162295\n",
      "epoch = 118 train_loss : 0.134264 , test loss : 0.162101\n",
      "epoch = 119 train_loss : 0.133991 , test loss : 0.161651\n",
      "epoch = 121 train_loss : 0.133007 , test loss : 0.161467\n",
      "epoch = 123 train_loss : 0.132324 , test loss : 0.160973\n",
      "epoch = 125 train_loss : 0.131685 , test loss : 0.160968\n",
      "epoch = 126 train_loss : 0.131362 , test loss : 0.160850\n",
      "epoch = 128 train_loss : 0.130632 , test loss : 0.160720\n",
      "epoch = 130 train_loss : 0.129970 , test loss : 0.160415\n",
      "epoch = 132 train_loss : 0.129508 , test loss : 0.160089\n",
      "epoch = 134 train_loss : 0.128746 , test loss : 0.159607\n",
      "epoch = 138 train_loss : 0.127783 , test loss : 0.159551\n",
      "epoch = 143 train_loss : 0.126414 , test loss : 0.159473\n",
      "epoch = 144 train_loss : 0.126333 , test loss : 0.159339\n",
      "epoch = 148 train_loss : 0.125416 , test loss : 0.159317\n",
      "epoch = 149 train_loss : 0.125049 , test loss : 0.159133\n",
      "epoch = 153 train_loss : 0.124213 , test loss : 0.159019\n",
      "epoch = 156 train_loss : 0.123798 , test loss : 0.158791\n",
      "epoch = 160 train_loss : 0.123077 , test loss : 0.158438\n",
      "epoch = 178 train_loss : 0.120266 , test loss : 0.158433\n",
      "epoch = 180 train_loss : 0.120055 , test loss : 0.158145\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.120055,test loss : 0.158145\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.113247,total test loss mean : 0.161493 \n",
      "-----------------------------------------------------------------------------\n",
      "pred :\n",
      " [[ 1.0064764 ]\n",
      " [ 0.49801496]\n",
      " [-0.00561502]\n",
      " [ 0.27099374]\n",
      " [ 0.10155676]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.719016969203949,\n",
       "  0.5867739319801331,\n",
       "  0.5062360763549805,\n",
       "  0.4584769606590271,\n",
       "  0.42795678973197937,\n",
       "  0.40707987546920776,\n",
       "  0.39174550771713257,\n",
       "  0.378935843706131,\n",
       "  0.3680165112018585,\n",
       "  0.3581693768501282,\n",
       "  0.3491467237472534,\n",
       "  0.3409375250339508,\n",
       "  0.33308395743370056,\n",
       "  0.3259718120098114,\n",
       "  0.3190900385379791,\n",
       "  0.3122630715370178,\n",
       "  0.306098610162735,\n",
       "  0.3002399802207947,\n",
       "  0.29451921582221985,\n",
       "  0.28908973932266235,\n",
       "  0.28387880325317383,\n",
       "  0.27884432673454285,\n",
       "  0.2740970849990845,\n",
       "  0.26953208446502686,\n",
       "  0.26525694131851196,\n",
       "  0.26119303703308105,\n",
       "  0.2572445571422577,\n",
       "  0.253462016582489,\n",
       "  0.24989835917949677,\n",
       "  0.2464621663093567,\n",
       "  0.2431492805480957,\n",
       "  0.2399432212114334,\n",
       "  0.23681803047657013,\n",
       "  0.23384425044059753,\n",
       "  0.23089995980262756,\n",
       "  0.22798557579517365,\n",
       "  0.22528132796287537,\n",
       "  0.22254489362239838,\n",
       "  0.21989288926124573,\n",
       "  0.2172972410917282,\n",
       "  0.21488076448440552,\n",
       "  0.21248282492160797,\n",
       "  0.2100844383239746,\n",
       "  0.20776183903217316,\n",
       "  0.20554494857788086,\n",
       "  0.20348365604877472,\n",
       "  0.2012898474931717,\n",
       "  0.19919098913669586,\n",
       "  0.19735342264175415,\n",
       "  0.19527404010295868,\n",
       "  0.19351714849472046,\n",
       "  0.19160941243171692,\n",
       "  0.18972831964492798,\n",
       "  0.1882176399230957,\n",
       "  0.18636982142925262,\n",
       "  0.18467578291893005,\n",
       "  0.1831216663122177,\n",
       "  0.1814989596605301,\n",
       "  0.18027564883232117,\n",
       "  0.17859800159931183,\n",
       "  0.17716316878795624,\n",
       "  0.1757885366678238,\n",
       "  0.17443706095218658,\n",
       "  0.1731589138507843,\n",
       "  0.17190362513065338,\n",
       "  0.17071741819381714,\n",
       "  0.1695249080657959,\n",
       "  0.16843898594379425,\n",
       "  0.16711781919002533,\n",
       "  0.16600419580936432,\n",
       "  0.16490410268306732,\n",
       "  0.16385821998119354,\n",
       "  0.1628158688545227,\n",
       "  0.16203029453754425,\n",
       "  0.16081444919109344,\n",
       "  0.15992121398448944,\n",
       "  0.1589103490114212,\n",
       "  0.1585673838853836,\n",
       "  0.1571265310049057,\n",
       "  0.1563093066215515,\n",
       "  0.1555485725402832,\n",
       "  0.15467581152915955,\n",
       "  0.15381929278373718,\n",
       "  0.15300630033016205,\n",
       "  0.15228299796581268,\n",
       "  0.15170541405677795,\n",
       "  0.15077131986618042,\n",
       "  0.1501985341310501,\n",
       "  0.1493159830570221,\n",
       "  0.14860643446445465,\n",
       "  0.1480553299188614,\n",
       "  0.14730677008628845,\n",
       "  0.1461348533630371,\n",
       "  0.14571517705917358,\n",
       "  0.1436777561903,\n",
       "  0.14313480257987976,\n",
       "  0.14143384993076324,\n",
       "  0.14095167815685272,\n",
       "  0.1404535472393036,\n",
       "  0.14000459015369415,\n",
       "  0.13946399092674255,\n",
       "  0.13899962604045868,\n",
       "  0.13848534226417542,\n",
       "  0.13716809451580048,\n",
       "  0.13687220215797424,\n",
       "  0.13622474670410156,\n",
       "  0.1358782947063446,\n",
       "  0.13562209904193878,\n",
       "  0.1350128948688507,\n",
       "  0.13463826477527618,\n",
       "  0.1342635303735733,\n",
       "  0.1339908391237259,\n",
       "  0.13300693035125732,\n",
       "  0.13232368230819702,\n",
       "  0.13168540596961975,\n",
       "  0.13136158883571625,\n",
       "  0.1306319236755371,\n",
       "  0.12996995449066162,\n",
       "  0.12950819730758667,\n",
       "  0.12874647974967957,\n",
       "  0.12778319418430328,\n",
       "  0.12641406059265137,\n",
       "  0.12633255124092102,\n",
       "  0.12541572749614716,\n",
       "  0.12504911422729492,\n",
       "  0.12421286106109619,\n",
       "  0.1237984225153923,\n",
       "  0.12307703495025635,\n",
       "  0.12026633322238922,\n",
       "  0.12005453556776047],\n",
       " [0.6539158821105957,\n",
       "  0.524793803691864,\n",
       "  0.45293325185775757,\n",
       "  0.41451573371887207,\n",
       "  0.3915841281414032,\n",
       "  0.37705671787261963,\n",
       "  0.3659110963344574,\n",
       "  0.356466680765152,\n",
       "  0.34816890954971313,\n",
       "  0.3409040868282318,\n",
       "  0.3336274027824402,\n",
       "  0.32687684893608093,\n",
       "  0.3207489252090454,\n",
       "  0.31518635153770447,\n",
       "  0.3096572458744049,\n",
       "  0.30413293838500977,\n",
       "  0.2993992567062378,\n",
       "  0.29416993260383606,\n",
       "  0.28980493545532227,\n",
       "  0.28553763031959534,\n",
       "  0.28153473138809204,\n",
       "  0.2778465747833252,\n",
       "  0.27397289872169495,\n",
       "  0.26994502544403076,\n",
       "  0.2666381299495697,\n",
       "  0.2628054916858673,\n",
       "  0.2592901289463043,\n",
       "  0.25616002082824707,\n",
       "  0.2531825602054596,\n",
       "  0.250124454498291,\n",
       "  0.24779333174228668,\n",
       "  0.24452058970928192,\n",
       "  0.24233625829219818,\n",
       "  0.23971499502658844,\n",
       "  0.23707526922225952,\n",
       "  0.2346232384443283,\n",
       "  0.23213204741477966,\n",
       "  0.2299949824810028,\n",
       "  0.2276567667722702,\n",
       "  0.22560562193393707,\n",
       "  0.2238186001777649,\n",
       "  0.22172889113426208,\n",
       "  0.21993674337863922,\n",
       "  0.2174893021583557,\n",
       "  0.21588513255119324,\n",
       "  0.21423181891441345,\n",
       "  0.21221444010734558,\n",
       "  0.2102876454591751,\n",
       "  0.20865385234355927,\n",
       "  0.2071361094713211,\n",
       "  0.20610783994197845,\n",
       "  0.20414642989635468,\n",
       "  0.20240959525108337,\n",
       "  0.20073345303535461,\n",
       "  0.19958259165287018,\n",
       "  0.19827720522880554,\n",
       "  0.1972017139196396,\n",
       "  0.1957065314054489,\n",
       "  0.19398300349712372,\n",
       "  0.19318272173404694,\n",
       "  0.19153009355068207,\n",
       "  0.19088299572467804,\n",
       "  0.1896272599697113,\n",
       "  0.18885894119739532,\n",
       "  0.18709896504878998,\n",
       "  0.1865677386522293,\n",
       "  0.18552498519420624,\n",
       "  0.18479318916797638,\n",
       "  0.1833505481481552,\n",
       "  0.18218055367469788,\n",
       "  0.18176805973052979,\n",
       "  0.18084999918937683,\n",
       "  0.1803438365459442,\n",
       "  0.179683119058609,\n",
       "  0.1784408539533615,\n",
       "  0.17780998349189758,\n",
       "  0.177185520529747,\n",
       "  0.1767614483833313,\n",
       "  0.17601844668388367,\n",
       "  0.17523349821567535,\n",
       "  0.17492583394050598,\n",
       "  0.1740480363368988,\n",
       "  0.17318008840084076,\n",
       "  0.17259745299816132,\n",
       "  0.17215433716773987,\n",
       "  0.17171575129032135,\n",
       "  0.17129817605018616,\n",
       "  0.17091931402683258,\n",
       "  0.17054365575313568,\n",
       "  0.1699628084897995,\n",
       "  0.16956616938114166,\n",
       "  0.16864721477031708,\n",
       "  0.16837771236896515,\n",
       "  0.16697344183921814,\n",
       "  0.16643087565898895,\n",
       "  0.1659470647573471,\n",
       "  0.16558820009231567,\n",
       "  0.16534824669361115,\n",
       "  0.16508984565734863,\n",
       "  0.1646736115217209,\n",
       "  0.16441094875335693,\n",
       "  0.1640743911266327,\n",
       "  0.16348059475421906,\n",
       "  0.16324591636657715,\n",
       "  0.1631850153207779,\n",
       "  0.16294768452644348,\n",
       "  0.16291990876197815,\n",
       "  0.1628551036119461,\n",
       "  0.1623009890317917,\n",
       "  0.16229479014873505,\n",
       "  0.16210147738456726,\n",
       "  0.16165056824684143,\n",
       "  0.1614668369293213,\n",
       "  0.1609732210636139,\n",
       "  0.16096767783164978,\n",
       "  0.16085033118724823,\n",
       "  0.16072028875350952,\n",
       "  0.16041457653045654,\n",
       "  0.16008880734443665,\n",
       "  0.15960681438446045,\n",
       "  0.15955056250095367,\n",
       "  0.15947259962558746,\n",
       "  0.15933874249458313,\n",
       "  0.15931661427021027,\n",
       "  0.15913322567939758,\n",
       "  0.1590193212032318,\n",
       "  0.15879110991954803,\n",
       "  0.15843823552131653,\n",
       "  0.15843302011489868,\n",
       "  0.1581454575061798])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],8),nn.ReLU(),nn.Linear(8,1))\n",
    "net1=get_net()\n",
    "y4_hat=train_kfold_pred(net1,5000,0.0001,5,x44_train,y44_train,64,0,0,x44_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
