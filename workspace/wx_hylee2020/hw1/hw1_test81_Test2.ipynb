{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:03.486382Z",
     "start_time": "2021-12-30T01:48:38.192935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch import optim,nn\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew,kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:09.653735Z",
     "start_time": "2021-12-30T01:49:09.212709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\train.csv',encoding='big5')\n",
    "test_data=pd.read_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\test.csv',encoding='big5',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:10.326773Z",
     "start_time": "2021-12-30T01:49:10.315772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (4320, 27)\n",
      "test_data shape:  (4320, 11)\n"
     ]
    }
   ],
   "source": [
    "print('train_data shape: ',train_data.shape)\n",
    "print('test_data shape: ',test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:11.110818Z",
     "start_time": "2021-12-30T01:49:11.072816Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data1=train_data.replace('NR',0)\n",
    "train_data1=train_data1.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:11.833859Z",
     "start_time": "2021-12-30T01:49:11.754855Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data={}\n",
    "for m in range(12):\n",
    "    month_data=np.empty((18,20*24))\n",
    "    for d in range(20):\n",
    "        month_data[:,d*24:(d+1)*24]=train_data1.iloc[m*20*18+d*18:m*20*18+(d+1)*18,:]\n",
    "    year_data[m]=month_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:12.447894Z",
     "start_time": "2021-12-30T01:49:12.441894Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.empty((12*471,9*18))\n",
    "y=np.empty((12*471,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:13.079930Z",
     "start_time": "2021-12-30T01:49:13.035928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in range(12):\n",
    "    for g in range(471):\n",
    "        x[m*471+g:m*471+g+1,:]=year_data[m][:,g:g+9].reshape(1,-1)\n",
    "        y[m*471+g:m*471+g+1,:]=year_data[m][9,g+9]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- just test no normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:14.504012Z",
     "start_time": "2021-12-30T01:49:14.497012Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import optim,nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:16.522127Z",
     "start_time": "2021-12-30T01:49:16.420122Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_k_fold_data(net,num_epochs,lr,train_features,train_labels,test_features,test_labels,batch_size,montum,wd):\n",
    "#     net=nn.Linear(train_features.shape[1],1)\n",
    "#     net=nn.Sequential(nn.Linear(train_features.shape[1],1))\n",
    "    loss=nn.MSELoss()\n",
    "#     optimizer=optim.SGD(net.parameters(),lr=lr,momentum=montum,weight_decay=wd)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=lr,weight_decay=wd)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    train_l,test_l=[],[]\n",
    "    \n",
    "    min_test_loss=1000\n",
    "    early_stop_cnt=0\n",
    "    train_loss,test_loss=0,0\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            l=loss(net(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "#         if (e+1) %1000==0 and test_features is not  None:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss=loss(net(test_features),test_labels).item()\n",
    "            if test_loss<min_test_loss:\n",
    "                min_test_loss=test_loss\n",
    "#                 test_l.append(test_loss)\n",
    "                train_loss=loss(net(train_features),train_labels).item()\n",
    "                test_l.append(test_loss)\n",
    "                train_l.append(train_loss)\n",
    "                print('epoch = %d train_loss : %f , test loss : %f' % (e+1,train_loss,test_loss))\n",
    "                early_stop_cnt=0\n",
    "            else:\n",
    "                early_stop_cnt+=1\n",
    "        if early_stop_cnt > 500:\n",
    "            \n",
    "            break\n",
    "                \n",
    "#             net.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 train_l.append(loss(net(train_features),train_labels).item())\n",
    "#                 test_l.append(loss(net(test_features),test_labels).item())\n",
    "# #                 print('epoch ',(e+1),'train loss : ',train_l[-1],'test loss : ',test_l[-1])\n",
    "\n",
    "    return train_l,test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:26.245684Z",
     "start_time": "2021-12-30T01:49:26.210682Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kfold_data(k,j,x,y,random_state=13):\n",
    "    assert k>=1, 'k must >=1'\n",
    "    fold_size = x.shape[0] // k\n",
    "    x_train,y_train=None,None\n",
    "    row_list=list(range(x.shape[0]))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(row_list)\n",
    "    for i in range(k):\n",
    "        idx=slice(fold_size*i,fold_size*(i+1))\n",
    "        x_part,y_part=x[row_list[idx],:],y[row_list[idx],:]\n",
    "        if i==j:\n",
    "            x_val,y_val=x_part,y_part\n",
    "        elif x_train is None:\n",
    "            x_train,y_train=x_part,y_part\n",
    "        else:\n",
    "            x_train=torch.cat((x_train,x_part))\n",
    "            y_train=torch.cat((y_train,y_part))\n",
    "    return x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:28.296801Z",
     "start_time": "2021-12-30T01:49:28.251798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:49:29.721882Z",
     "start_time": "2021-12-30T01:49:29.482869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=torch.Tensor(x)\n",
    "y1=torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:52:56.348701Z",
     "start_time": "2021-12-30T01:49:34.899178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 129.186523 , test loss : 136.567505\n",
      "epoch = 2 train_loss : 91.456566 , test loss : 99.858284\n",
      "epoch = 3 train_loss : 76.014778 , test loss : 83.505875\n",
      "epoch = 4 train_loss : 71.316811 , test loss : 79.143204\n",
      "epoch = 5 train_loss : 59.957409 , test loss : 66.713173\n",
      "epoch = 6 train_loss : 57.076389 , test loss : 63.113998\n",
      "epoch = 7 train_loss : 52.733757 , test loss : 58.500515\n",
      "epoch = 9 train_loss : 50.595963 , test loss : 56.371109\n",
      "epoch = 10 train_loss : 47.822048 , test loss : 52.793026\n",
      "epoch = 11 train_loss : 44.997459 , test loss : 50.417725\n",
      "epoch = 12 train_loss : 44.734993 , test loss : 49.856937\n",
      "epoch = 14 train_loss : 43.259151 , test loss : 48.907909\n",
      "epoch = 15 train_loss : 42.558681 , test loss : 47.375183\n",
      "epoch = 16 train_loss : 40.457382 , test loss : 45.670235\n",
      "epoch = 17 train_loss : 39.537884 , test loss : 45.058956\n",
      "epoch = 18 train_loss : 39.331291 , test loss : 44.441578\n",
      "epoch = 21 train_loss : 38.949688 , test loss : 44.177612\n",
      "epoch = 24 train_loss : 37.403019 , test loss : 43.308556\n",
      "epoch = 25 train_loss : 36.589127 , test loss : 42.258659\n",
      "epoch = 26 train_loss : 36.152294 , test loss : 42.119518\n",
      "epoch = 28 train_loss : 35.720856 , test loss : 41.396713\n",
      "epoch = 34 train_loss : 34.606152 , test loss : 40.640949\n",
      "epoch = 36 train_loss : 34.417912 , test loss : 40.426178\n",
      "epoch = 39 train_loss : 34.015110 , test loss : 40.250248\n",
      "epoch = 40 train_loss : 34.566288 , test loss : 40.135918\n",
      "epoch = 48 train_loss : 33.629433 , test loss : 39.626698\n",
      "epoch = 51 train_loss : 33.106354 , test loss : 39.512360\n",
      "epoch = 53 train_loss : 32.987598 , test loss : 39.222191\n",
      "epoch = 63 train_loss : 32.686268 , test loss : 39.034668\n",
      "epoch = 72 train_loss : 32.441639 , test loss : 38.975315\n",
      "epoch = 80 train_loss : 32.145279 , test loss : 38.655949\n",
      "epoch = 82 train_loss : 32.137924 , test loss : 38.560909\n",
      "epoch = 105 train_loss : 31.836821 , test loss : 38.432198\n",
      "epoch = 137 train_loss : 31.676910 , test loss : 38.337372\n",
      "epoch = 149 train_loss : 31.606728 , test loss : 38.335400\n",
      "epoch = 162 train_loss : 31.814421 , test loss : 38.334957\n",
      "epoch = 255 train_loss : 31.705561 , test loss : 38.268288\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.705561,test loss : 38.268288\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 146.681595 , test loss : 156.996536\n",
      "epoch = 2 train_loss : 91.325958 , test loss : 101.116745\n",
      "epoch = 3 train_loss : 73.391472 , test loss : 83.592476\n",
      "epoch = 4 train_loss : 67.226112 , test loss : 78.088974\n",
      "epoch = 5 train_loss : 60.729389 , test loss : 71.123192\n",
      "epoch = 6 train_loss : 56.406910 , test loss : 67.245728\n",
      "epoch = 7 train_loss : 52.979435 , test loss : 63.855061\n",
      "epoch = 8 train_loss : 51.074627 , test loss : 61.728683\n",
      "epoch = 10 train_loss : 47.577972 , test loss : 59.821152\n",
      "epoch = 11 train_loss : 44.047131 , test loss : 55.884205\n",
      "epoch = 12 train_loss : 42.945492 , test loss : 54.632210\n",
      "epoch = 15 train_loss : 39.556957 , test loss : 51.513847\n",
      "epoch = 18 train_loss : 37.794136 , test loss : 49.416515\n",
      "epoch = 19 train_loss : 37.575069 , test loss : 49.239498\n",
      "epoch = 21 train_loss : 36.481777 , test loss : 48.686749\n",
      "epoch = 27 train_loss : 35.260262 , test loss : 45.578213\n",
      "epoch = 29 train_loss : 35.445789 , test loss : 45.452686\n",
      "epoch = 36 train_loss : 34.025570 , test loss : 43.899406\n",
      "epoch = 37 train_loss : 33.644180 , test loss : 43.277416\n",
      "epoch = 44 train_loss : 33.651505 , test loss : 43.113007\n",
      "epoch = 49 train_loss : 32.871784 , test loss : 42.452072\n",
      "epoch = 59 train_loss : 33.455379 , test loss : 42.282288\n",
      "epoch = 60 train_loss : 33.375702 , test loss : 42.023289\n",
      "epoch = 63 train_loss : 32.217651 , test loss : 41.485416\n",
      "epoch = 71 train_loss : 32.300915 , test loss : 41.451546\n",
      "epoch = 73 train_loss : 32.128883 , test loss : 41.070606\n",
      "epoch = 75 train_loss : 31.938326 , test loss : 40.666847\n",
      "epoch = 81 train_loss : 32.086151 , test loss : 40.549709\n",
      "epoch = 95 train_loss : 32.063396 , test loss : 40.405285\n",
      "epoch = 145 train_loss : 31.861818 , test loss : 40.009991\n",
      "epoch = 164 train_loss : 31.562010 , test loss : 39.975681\n",
      "epoch = 201 train_loss : 31.380993 , test loss : 39.845623\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.380993,test loss : 39.845623\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 210.206802 , test loss : 221.590500\n",
      "epoch = 2 train_loss : 123.795074 , test loss : 117.833389\n",
      "epoch = 3 train_loss : 97.804947 , test loss : 93.823746\n",
      "epoch = 4 train_loss : 84.478424 , test loss : 78.246315\n",
      "epoch = 5 train_loss : 75.640251 , test loss : 69.373611\n",
      "epoch = 6 train_loss : 69.718605 , test loss : 62.865788\n",
      "epoch = 7 train_loss : 65.016953 , test loss : 58.243259\n",
      "epoch = 8 train_loss : 61.574009 , test loss : 54.746006\n",
      "epoch = 9 train_loss : 59.970314 , test loss : 52.781635\n",
      "epoch = 10 train_loss : 56.541298 , test loss : 49.631828\n",
      "epoch = 11 train_loss : 54.530518 , test loss : 48.273415\n",
      "epoch = 12 train_loss : 52.818214 , test loss : 46.817059\n",
      "epoch = 13 train_loss : 51.081493 , test loss : 44.449177\n",
      "epoch = 14 train_loss : 50.043079 , test loss : 43.258545\n",
      "epoch = 15 train_loss : 47.917583 , test loss : 41.085049\n",
      "epoch = 16 train_loss : 47.274548 , test loss : 40.425274\n",
      "epoch = 18 train_loss : 44.705864 , test loss : 38.118645\n",
      "epoch = 20 train_loss : 43.398960 , test loss : 37.224556\n",
      "epoch = 22 train_loss : 43.038189 , test loss : 36.903809\n",
      "epoch = 23 train_loss : 41.474518 , test loss : 35.654812\n",
      "epoch = 24 train_loss : 40.663559 , test loss : 34.351883\n",
      "epoch = 28 train_loss : 39.642044 , test loss : 34.166702\n",
      "epoch = 30 train_loss : 38.413406 , test loss : 32.851231\n",
      "epoch = 39 train_loss : 37.456516 , test loss : 32.729458\n",
      "epoch = 40 train_loss : 36.898121 , test loss : 32.276131\n",
      "epoch = 41 train_loss : 36.234894 , test loss : 31.327343\n",
      "epoch = 52 train_loss : 35.233658 , test loss : 31.286554\n",
      "epoch = 54 train_loss : 35.284000 , test loss : 31.239656\n",
      "epoch = 60 train_loss : 34.819355 , test loss : 30.950771\n",
      "epoch = 80 train_loss : 34.334167 , test loss : 30.653128\n",
      "epoch = 125 train_loss : 33.708439 , test loss : 30.616735\n",
      "epoch = 144 train_loss : 33.589058 , test loss : 30.609884\n",
      "epoch = 201 train_loss : 33.658741 , test loss : 30.537233\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 33.658741,test loss : 30.537233\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 221.474396 , test loss : 219.006302\n",
      "epoch = 2 train_loss : 119.925484 , test loss : 119.472038\n",
      "epoch = 3 train_loss : 94.006332 , test loss : 94.158577\n",
      "epoch = 4 train_loss : 81.532997 , test loss : 82.040306\n",
      "epoch = 5 train_loss : 73.037651 , test loss : 73.834145\n",
      "epoch = 6 train_loss : 68.282486 , test loss : 69.400208\n",
      "epoch = 7 train_loss : 63.183250 , test loss : 64.304367\n",
      "epoch = 8 train_loss : 60.760937 , test loss : 62.132000\n",
      "epoch = 9 train_loss : 57.828148 , test loss : 59.241447\n",
      "epoch = 10 train_loss : 56.987965 , test loss : 58.218616\n",
      "epoch = 11 train_loss : 53.694717 , test loss : 54.957386\n",
      "epoch = 12 train_loss : 51.633884 , test loss : 52.800564\n",
      "epoch = 13 train_loss : 49.997559 , test loss : 51.231564\n",
      "epoch = 14 train_loss : 49.310486 , test loss : 50.551117\n",
      "epoch = 15 train_loss : 47.323647 , test loss : 48.378395\n",
      "epoch = 16 train_loss : 46.463749 , test loss : 47.418930\n",
      "epoch = 18 train_loss : 44.892204 , test loss : 45.932972\n",
      "epoch = 21 train_loss : 44.006298 , test loss : 45.037910\n",
      "epoch = 22 train_loss : 41.843304 , test loss : 42.690662\n",
      "epoch = 23 train_loss : 40.935246 , test loss : 41.521149\n",
      "epoch = 24 train_loss : 40.761505 , test loss : 41.176270\n",
      "epoch = 25 train_loss : 40.296040 , test loss : 40.908298\n",
      "epoch = 29 train_loss : 38.269531 , test loss : 39.052879\n",
      "epoch = 31 train_loss : 38.391014 , test loss : 38.875973\n",
      "epoch = 32 train_loss : 37.523785 , test loss : 38.488213\n",
      "epoch = 35 train_loss : 36.582050 , test loss : 37.761242\n",
      "epoch = 38 train_loss : 36.710880 , test loss : 37.458630\n",
      "epoch = 44 train_loss : 35.480244 , test loss : 36.950207\n",
      "epoch = 47 train_loss : 35.039532 , test loss : 36.326912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 51 train_loss : 34.612225 , test loss : 35.977840\n",
      "epoch = 54 train_loss : 34.914539 , test loss : 35.796871\n",
      "epoch = 56 train_loss : 34.253906 , test loss : 35.600224\n",
      "epoch = 64 train_loss : 34.041706 , test loss : 35.500839\n",
      "epoch = 66 train_loss : 34.161835 , test loss : 35.278553\n",
      "epoch = 71 train_loss : 33.670616 , test loss : 34.965538\n",
      "epoch = 73 train_loss : 33.556187 , test loss : 34.941944\n",
      "epoch = 77 train_loss : 33.399952 , test loss : 34.729050\n",
      "epoch = 85 train_loss : 33.174728 , test loss : 34.534832\n",
      "epoch = 89 train_loss : 33.504894 , test loss : 34.479115\n",
      "epoch = 107 train_loss : 33.009270 , test loss : 34.271988\n",
      "epoch = 119 train_loss : 32.964245 , test loss : 34.228230\n",
      "epoch = 127 train_loss : 32.902618 , test loss : 34.161488\n",
      "epoch = 145 train_loss : 32.835857 , test loss : 34.042061\n",
      "epoch = 396 train_loss : 32.693550 , test loss : 34.040062\n",
      "epoch = 431 train_loss : 32.638397 , test loss : 33.995911\n",
      "epoch = 756 train_loss : 32.560535 , test loss : 33.973000\n",
      "epoch = 773 train_loss : 32.548962 , test loss : 33.917702\n",
      "epoch = 780 train_loss : 32.647896 , test loss : 33.752552\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.647896,test loss : 33.752552\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 141.438126 , test loss : 122.784492\n",
      "epoch = 2 train_loss : 97.946487 , test loss : 87.469612\n",
      "epoch = 3 train_loss : 79.527397 , test loss : 71.068344\n",
      "epoch = 4 train_loss : 69.446091 , test loss : 62.054066\n",
      "epoch = 5 train_loss : 63.430145 , test loss : 56.538013\n",
      "epoch = 6 train_loss : 59.130238 , test loss : 52.512466\n",
      "epoch = 7 train_loss : 55.986916 , test loss : 49.541813\n",
      "epoch = 9 train_loss : 54.022060 , test loss : 47.555103\n",
      "epoch = 10 train_loss : 49.665115 , test loss : 43.538212\n",
      "epoch = 11 train_loss : 48.021832 , test loss : 42.091305\n",
      "epoch = 13 train_loss : 45.878700 , test loss : 40.035603\n",
      "epoch = 14 train_loss : 44.804893 , test loss : 39.569386\n",
      "epoch = 15 train_loss : 43.934414 , test loss : 38.729919\n",
      "epoch = 17 train_loss : 44.297356 , test loss : 38.390316\n",
      "epoch = 20 train_loss : 41.503963 , test loss : 35.894394\n",
      "epoch = 21 train_loss : 39.895657 , test loss : 34.902649\n",
      "epoch = 23 train_loss : 39.187630 , test loss : 34.114319\n",
      "epoch = 25 train_loss : 38.244228 , test loss : 33.393040\n",
      "epoch = 28 train_loss : 38.493282 , test loss : 33.268410\n",
      "epoch = 31 train_loss : 37.119759 , test loss : 32.413971\n",
      "epoch = 33 train_loss : 36.831287 , test loss : 32.336521\n",
      "epoch = 37 train_loss : 36.449020 , test loss : 31.739958\n",
      "epoch = 41 train_loss : 35.825844 , test loss : 31.125832\n",
      "epoch = 53 train_loss : 35.302902 , test loss : 30.818691\n",
      "epoch = 60 train_loss : 34.960541 , test loss : 30.586571\n",
      "epoch = 69 train_loss : 34.732368 , test loss : 30.316786\n",
      "epoch = 72 train_loss : 34.582146 , test loss : 30.193848\n",
      "epoch = 79 train_loss : 34.575119 , test loss : 30.023172\n",
      "epoch = 80 train_loss : 34.358856 , test loss : 30.018957\n",
      "epoch = 81 train_loss : 34.334808 , test loss : 29.986050\n",
      "epoch = 95 train_loss : 34.101051 , test loss : 29.981480\n",
      "epoch = 110 train_loss : 34.228416 , test loss : 29.857016\n",
      "epoch = 138 train_loss : 34.058155 , test loss : 29.632673\n",
      "epoch = 153 train_loss : 33.884583 , test loss : 29.600384\n",
      "epoch = 187 train_loss : 33.798870 , test loss : 29.508457\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.798870,test loss : 29.508457\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.638412,total test loss mean : 34.382431 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T02:24:50.698522Z",
     "start_time": "2021-12-28T02:17:21.373822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 290.766388 , test loss : 269.512115\n",
      "epoch = 2 train_loss : 103.084366 , test loss : 134.009445\n",
      "epoch = 3 train_loss : 79.996941 , test loss : 101.958191\n",
      "epoch = 4 train_loss : 70.435394 , test loss : 84.803787\n",
      "epoch = 5 train_loss : 64.179726 , test loss : 74.874535\n",
      "epoch = 6 train_loss : 59.422081 , test loss : 70.178734\n",
      "epoch = 7 train_loss : 56.428925 , test loss : 67.311516\n",
      "epoch = 8 train_loss : 54.308441 , test loss : 60.004467\n",
      "epoch = 9 train_loss : 51.060757 , test loss : 57.502617\n",
      "epoch = 10 train_loss : 50.022552 , test loss : 55.552086\n",
      "epoch = 11 train_loss : 47.512028 , test loss : 53.037868\n",
      "epoch = 12 train_loss : 46.209293 , test loss : 51.636555\n",
      "epoch = 13 train_loss : 44.205700 , test loss : 51.578796\n",
      "epoch = 15 train_loss : 45.089931 , test loss : 48.935425\n",
      "epoch = 16 train_loss : 41.220982 , test loss : 47.141804\n",
      "epoch = 20 train_loss : 38.471390 , test loss : 46.138603\n",
      "epoch = 22 train_loss : 39.110271 , test loss : 44.030369\n",
      "epoch = 24 train_loss : 36.903030 , test loss : 43.335476\n",
      "epoch = 26 train_loss : 36.534931 , test loss : 42.058006\n",
      "epoch = 38 train_loss : 34.008827 , test loss : 41.306564\n",
      "epoch = 43 train_loss : 34.276772 , test loss : 40.211624\n",
      "epoch = 76 train_loss : 32.621796 , test loss : 39.394806\n",
      "epoch = 80 train_loss : 32.170753 , test loss : 39.274220\n",
      "epoch = 88 train_loss : 33.075703 , test loss : 39.157803\n",
      "epoch = 274 train_loss : 32.268150 , test loss : 39.044209\n",
      "epoch = 589 train_loss : 31.994390 , test loss : 38.944489\n",
      "epoch = 599 train_loss : 31.550230 , test loss : 38.846043\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.550230,test loss : 38.846043\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 275.036987 , test loss : 402.659393\n",
      "epoch = 2 train_loss : 114.712807 , test loss : 167.458221\n",
      "epoch = 3 train_loss : 81.981705 , test loss : 121.469376\n",
      "epoch = 4 train_loss : 68.923409 , test loss : 98.154694\n",
      "epoch = 5 train_loss : 64.048538 , test loss : 92.143738\n",
      "epoch = 6 train_loss : 59.652012 , test loss : 84.900047\n",
      "epoch = 7 train_loss : 57.034042 , test loss : 78.888657\n",
      "epoch = 8 train_loss : 52.427448 , test loss : 71.992302\n",
      "epoch = 9 train_loss : 50.332047 , test loss : 68.905090\n",
      "epoch = 10 train_loss : 48.032677 , test loss : 65.338242\n",
      "epoch = 12 train_loss : 45.443630 , test loss : 60.436218\n",
      "epoch = 13 train_loss : 43.757626 , test loss : 58.598961\n",
      "epoch = 14 train_loss : 42.526455 , test loss : 56.018871\n",
      "epoch = 15 train_loss : 41.537239 , test loss : 54.611076\n",
      "epoch = 17 train_loss : 42.191341 , test loss : 54.218914\n",
      "epoch = 18 train_loss : 40.650654 , test loss : 53.151836\n",
      "epoch = 19 train_loss : 38.510506 , test loss : 49.883240\n",
      "epoch = 23 train_loss : 36.884483 , test loss : 46.895962\n",
      "epoch = 25 train_loss : 36.290504 , test loss : 46.410480\n",
      "epoch = 26 train_loss : 35.988335 , test loss : 45.628731\n",
      "epoch = 28 train_loss : 35.724854 , test loss : 45.321850\n",
      "epoch = 31 train_loss : 35.001968 , test loss : 43.985962\n",
      "epoch = 34 train_loss : 34.521172 , test loss : 43.650959\n",
      "epoch = 35 train_loss : 34.480122 , test loss : 43.155491\n",
      "epoch = 36 train_loss : 33.967091 , test loss : 42.682800\n",
      "epoch = 39 train_loss : 33.814510 , test loss : 42.138500\n",
      "epoch = 45 train_loss : 33.388424 , test loss : 41.999451\n",
      "epoch = 49 train_loss : 32.963131 , test loss : 41.638714\n",
      "epoch = 53 train_loss : 32.799736 , test loss : 41.219830\n",
      "epoch = 54 train_loss : 32.808556 , test loss : 41.161785\n",
      "epoch = 69 train_loss : 32.610756 , test loss : 40.988708\n",
      "epoch = 76 train_loss : 32.282063 , test loss : 40.781052\n",
      "epoch = 77 train_loss : 32.021572 , test loss : 40.336727\n",
      "epoch = 83 train_loss : 31.775738 , test loss : 40.177670\n",
      "epoch = 127 train_loss : 31.731323 , test loss : 40.044788\n",
      "epoch = 166 train_loss : 31.706999 , test loss : 39.806553\n",
      "epoch = 665 train_loss : 31.345417 , test loss : 39.623024\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.345417,test loss : 39.623024\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 273.269928 , test loss : 278.072693\n",
      "epoch = 2 train_loss : 112.476158 , test loss : 129.571060\n",
      "epoch = 3 train_loss : 83.898918 , test loss : 90.439644\n",
      "epoch = 4 train_loss : 73.486961 , test loss : 82.637794\n",
      "epoch = 5 train_loss : 71.933075 , test loss : 74.722702\n",
      "epoch = 6 train_loss : 62.276295 , test loss : 72.001579\n",
      "epoch = 7 train_loss : 62.711960 , test loss : 67.987213\n",
      "epoch = 8 train_loss : 55.519489 , test loss : 65.565590\n",
      "epoch = 9 train_loss : 53.052498 , test loss : 64.971313\n",
      "epoch = 10 train_loss : 50.416122 , test loss : 60.781780\n",
      "epoch = 11 train_loss : 50.181816 , test loss : 58.537495\n",
      "epoch = 12 train_loss : 46.912918 , test loss : 56.975491\n",
      "epoch = 14 train_loss : 43.921577 , test loss : 54.454292\n",
      "epoch = 16 train_loss : 44.049515 , test loss : 53.178017\n",
      "epoch = 17 train_loss : 40.841759 , test loss : 52.682053\n",
      "epoch = 19 train_loss : 39.759308 , test loss : 52.342587\n",
      "epoch = 21 train_loss : 38.166252 , test loss : 49.853607\n",
      "epoch = 22 train_loss : 37.862492 , test loss : 49.250290\n",
      "epoch = 23 train_loss : 37.255810 , test loss : 49.070866\n",
      "epoch = 24 train_loss : 36.698624 , test loss : 48.331593\n",
      "epoch = 26 train_loss : 36.314102 , test loss : 47.616547\n",
      "epoch = 27 train_loss : 36.075367 , test loss : 47.218731\n",
      "epoch = 36 train_loss : 34.342014 , test loss : 45.339657\n",
      "epoch = 39 train_loss : 33.496170 , test loss : 44.977818\n",
      "epoch = 44 train_loss : 33.225239 , test loss : 44.783150\n",
      "epoch = 52 train_loss : 33.192333 , test loss : 44.274445\n",
      "epoch = 56 train_loss : 32.713646 , test loss : 43.684170\n",
      "epoch = 69 train_loss : 33.482357 , test loss : 43.606770\n",
      "epoch = 70 train_loss : 32.176861 , test loss : 43.184105\n",
      "epoch = 74 train_loss : 31.978352 , test loss : 43.055668\n",
      "epoch = 81 train_loss : 32.637985 , test loss : 42.898956\n",
      "epoch = 82 train_loss : 32.334892 , test loss : 42.429996\n",
      "epoch = 96 train_loss : 32.153698 , test loss : 42.223404\n",
      "epoch = 106 train_loss : 31.711838 , test loss : 42.051662\n",
      "epoch = 123 train_loss : 31.330624 , test loss : 41.915104\n",
      "epoch = 149 train_loss : 31.650097 , test loss : 41.586948\n",
      "epoch = 159 train_loss : 31.084080 , test loss : 41.565536\n",
      "epoch = 208 train_loss : 31.446091 , test loss : 41.439465\n",
      "epoch = 345 train_loss : 31.864357 , test loss : 41.388424\n",
      "epoch = 358 train_loss : 31.664141 , test loss : 41.112900\n",
      "epoch = 671 train_loss : 31.034340 , test loss : 41.030445\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 31.034340,test loss : 41.030445\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 206.390793 , test loss : 173.152069\n",
      "epoch = 2 train_loss : 100.856606 , test loss : 53.294033\n",
      "epoch = 3 train_loss : 86.365433 , test loss : 47.067734\n",
      "epoch = 4 train_loss : 74.286636 , test loss : 37.724834\n",
      "epoch = 5 train_loss : 67.932068 , test loss : 34.704048\n",
      "epoch = 6 train_loss : 64.522141 , test loss : 31.689579\n",
      "epoch = 7 train_loss : 60.787716 , test loss : 30.396940\n",
      "epoch = 8 train_loss : 60.033348 , test loss : 29.896271\n",
      "epoch = 9 train_loss : 54.696312 , test loss : 28.210423\n",
      "epoch = 11 train_loss : 50.597626 , test loss : 27.872971\n",
      "epoch = 12 train_loss : 49.781097 , test loss : 25.787857\n",
      "epoch = 14 train_loss : 46.292522 , test loss : 25.135153\n",
      "epoch = 16 train_loss : 44.362637 , test loss : 24.173910\n",
      "epoch = 21 train_loss : 41.644966 , test loss : 22.780361\n",
      "epoch = 40 train_loss : 38.994682 , test loss : 22.667007\n",
      "epoch = 46 train_loss : 38.290993 , test loss : 22.259886\n",
      "epoch = 48 train_loss : 37.632141 , test loss : 22.220030\n",
      "epoch = 57 train_loss : 36.991009 , test loss : 22.026943\n",
      "epoch = 69 train_loss : 36.967388 , test loss : 21.880627\n",
      "epoch = 90 train_loss : 36.657700 , test loss : 21.873016\n",
      "epoch = 110 train_loss : 36.498367 , test loss : 21.759315\n",
      "epoch = 142 train_loss : 36.779636 , test loss : 21.738342\n",
      "epoch = 157 train_loss : 35.975906 , test loss : 21.738251\n",
      "epoch = 186 train_loss : 36.167614 , test loss : 21.664112\n",
      "epoch = 187 train_loss : 36.337997 , test loss : 21.501553\n",
      "epoch = 452 train_loss : 36.531586 , test loss : 21.373186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 579 train_loss : 36.938469 , test loss : 21.137606\n",
      "epoch = 842 train_loss : 36.743961 , test loss : 21.071686\n",
      "epoch = 875 train_loss : 37.535267 , test loss : 20.861010\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 37.535267,test loss : 20.861010\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 344.158264 , test loss : 364.149841\n",
      "epoch = 2 train_loss : 98.619385 , test loss : 119.195351\n",
      "epoch = 3 train_loss : 84.213676 , test loss : 94.371712\n",
      "epoch = 4 train_loss : 73.286697 , test loss : 87.182747\n",
      "epoch = 5 train_loss : 68.329010 , test loss : 76.775963\n",
      "epoch = 6 train_loss : 62.501350 , test loss : 72.582199\n",
      "epoch = 8 train_loss : 55.265423 , test loss : 63.680378\n",
      "epoch = 9 train_loss : 56.973656 , test loss : 58.588451\n",
      "epoch = 10 train_loss : 50.257824 , test loss : 55.361938\n",
      "epoch = 12 train_loss : 46.380188 , test loss : 52.420948\n",
      "epoch = 14 train_loss : 44.755901 , test loss : 47.015038\n",
      "epoch = 17 train_loss : 41.119034 , test loss : 44.248890\n",
      "epoch = 18 train_loss : 43.689724 , test loss : 43.210331\n",
      "epoch = 19 train_loss : 40.027187 , test loss : 42.510307\n",
      "epoch = 20 train_loss : 42.220261 , test loss : 41.062622\n",
      "epoch = 21 train_loss : 39.189140 , test loss : 39.918602\n",
      "epoch = 22 train_loss : 38.967770 , test loss : 38.976677\n",
      "epoch = 27 train_loss : 37.400150 , test loss : 38.731709\n",
      "epoch = 28 train_loss : 42.445393 , test loss : 38.414001\n",
      "epoch = 29 train_loss : 37.256992 , test loss : 36.774338\n",
      "epoch = 31 train_loss : 36.328762 , test loss : 35.890224\n",
      "epoch = 34 train_loss : 36.424881 , test loss : 35.536354\n",
      "epoch = 37 train_loss : 35.472530 , test loss : 35.225716\n",
      "epoch = 41 train_loss : 36.389984 , test loss : 34.105217\n",
      "epoch = 48 train_loss : 35.042812 , test loss : 33.864624\n",
      "epoch = 58 train_loss : 35.438004 , test loss : 33.149296\n",
      "epoch = 75 train_loss : 33.910820 , test loss : 32.783298\n",
      "epoch = 121 train_loss : 33.890854 , test loss : 32.678581\n",
      "epoch = 125 train_loss : 34.313152 , test loss : 32.557747\n",
      "epoch = 149 train_loss : 33.912701 , test loss : 32.534119\n",
      "epoch = 159 train_loss : 33.606091 , test loss : 32.473255\n",
      "epoch = 162 train_loss : 34.087986 , test loss : 32.354126\n",
      "epoch = 164 train_loss : 33.765511 , test loss : 32.060993\n",
      "epoch = 196 train_loss : 34.081886 , test loss : 32.022171\n",
      "epoch = 259 train_loss : 33.654373 , test loss : 31.827070\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.654373,test loss : 31.827070\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 33.023925,total test loss mean : 34.437518 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],512),nn.Linear(512,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### just test data col normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:53:20.211066Z",
     "start_time": "2021-12-30T01:53:20.196065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5652, 162)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:53:20.782098Z",
     "start_time": "2021-12-30T01:53:20.680092Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2=pd.DataFrame(x)\n",
    "x2=x2.apply(lambda x:((x-x.mean())/x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:53:21.183121Z",
     "start_time": "2021-12-30T01:53:21.170120Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x22=torch.Tensor(x2.values)\n",
    "y22=torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T02:36:45.573410Z",
     "start_time": "2021-12-28T02:33:36.734609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 563.576843 , test loss : 832.734558\n",
      "epoch = 11 train_loss : 244.796875 , test loss : 767.408997\n",
      "epoch = 12 train_loss : 214.190063 , test loss : 677.944275\n",
      "epoch = 13 train_loss : 185.046494 , test loss : 552.179260\n",
      "epoch = 14 train_loss : 155.866241 , test loss : 491.534088\n",
      "epoch = 15 train_loss : 132.594147 , test loss : 383.075348\n",
      "epoch = 16 train_loss : 107.768951 , test loss : 328.814972\n",
      "epoch = 17 train_loss : 87.841248 , test loss : 224.141357\n",
      "epoch = 18 train_loss : 71.900284 , test loss : 181.749496\n",
      "epoch = 19 train_loss : 59.911762 , test loss : 129.574921\n",
      "epoch = 20 train_loss : 51.394901 , test loss : 110.958374\n",
      "epoch = 21 train_loss : 45.188522 , test loss : 86.687241\n",
      "epoch = 22 train_loss : 41.066101 , test loss : 67.410683\n",
      "epoch = 23 train_loss : 38.290638 , test loss : 59.066189\n",
      "epoch = 24 train_loss : 37.328880 , test loss : 50.510220\n",
      "epoch = 25 train_loss : 36.293625 , test loss : 48.489433\n",
      "epoch = 26 train_loss : 35.523125 , test loss : 48.297016\n",
      "epoch = 27 train_loss : 34.782928 , test loss : 42.942310\n",
      "epoch = 28 train_loss : 34.318516 , test loss : 42.253948\n",
      "epoch = 31 train_loss : 33.406914 , test loss : 41.029079\n",
      "epoch = 36 train_loss : 33.337044 , test loss : 40.826561\n",
      "epoch = 42 train_loss : 32.442478 , test loss : 40.682938\n",
      "epoch = 48 train_loss : 31.916767 , test loss : 39.526470\n",
      "epoch = 53 train_loss : 31.795626 , test loss : 39.509388\n",
      "epoch = 105 train_loss : 31.804226 , test loss : 39.301285\n",
      "epoch = 206 train_loss : 31.933037 , test loss : 39.287006\n",
      "epoch = 238 train_loss : 31.214611 , test loss : 38.884525\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.214611,test loss : 38.884525\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 580.120544 , test loss : 839.246582\n",
      "epoch = 2 train_loss : 541.647034 , test loss : 702.120789\n",
      "epoch = 5 train_loss : 464.544861 , test loss : 691.266235\n",
      "epoch = 6 train_loss : 437.128571 , test loss : 660.577942\n",
      "epoch = 7 train_loss : 406.016296 , test loss : 627.048828\n",
      "epoch = 8 train_loss : 372.587006 , test loss : 609.201233\n",
      "epoch = 9 train_loss : 337.919312 , test loss : 513.657104\n",
      "epoch = 10 train_loss : 299.709137 , test loss : 500.993164\n",
      "epoch = 11 train_loss : 264.801270 , test loss : 498.492584\n",
      "epoch = 12 train_loss : 225.073853 , test loss : 382.171814\n",
      "epoch = 13 train_loss : 188.391052 , test loss : 306.713928\n",
      "epoch = 14 train_loss : 154.392105 , test loss : 264.226562\n",
      "epoch = 15 train_loss : 125.254051 , test loss : 218.612900\n",
      "epoch = 16 train_loss : 100.089012 , test loss : 154.432129\n",
      "epoch = 17 train_loss : 79.594040 , test loss : 132.653397\n",
      "epoch = 18 train_loss : 63.983635 , test loss : 95.762024\n",
      "epoch = 19 train_loss : 53.230156 , test loss : 77.959778\n",
      "epoch = 20 train_loss : 45.995663 , test loss : 69.179420\n",
      "epoch = 21 train_loss : 41.216908 , test loss : 57.629215\n",
      "epoch = 22 train_loss : 38.555996 , test loss : 50.386948\n",
      "epoch = 23 train_loss : 36.277119 , test loss : 48.435837\n",
      "epoch = 24 train_loss : 35.095123 , test loss : 46.820515\n",
      "epoch = 25 train_loss : 34.610939 , test loss : 45.763767\n",
      "epoch = 26 train_loss : 34.638271 , test loss : 45.617630\n",
      "epoch = 28 train_loss : 34.205379 , test loss : 44.292709\n",
      "epoch = 29 train_loss : 33.254894 , test loss : 43.429771\n",
      "epoch = 32 train_loss : 32.734089 , test loss : 42.797882\n",
      "epoch = 33 train_loss : 32.762527 , test loss : 42.557858\n",
      "epoch = 36 train_loss : 32.404881 , test loss : 42.104549\n",
      "epoch = 39 train_loss : 32.215469 , test loss : 41.817692\n",
      "epoch = 43 train_loss : 31.907740 , test loss : 41.532536\n",
      "epoch = 49 train_loss : 31.610710 , test loss : 40.823696\n",
      "epoch = 59 train_loss : 31.492588 , test loss : 40.636311\n",
      "epoch = 72 train_loss : 31.323383 , test loss : 40.527603\n",
      "epoch = 81 train_loss : 31.706974 , test loss : 40.485645\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.706974,test loss : 40.485645\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 604.350647 , test loss : 649.065674\n",
      "epoch = 13 train_loss : 236.083969 , test loss : 634.641907\n",
      "epoch = 14 train_loss : 206.713470 , test loss : 543.402283\n",
      "epoch = 15 train_loss : 177.505814 , test loss : 465.643585\n",
      "epoch = 16 train_loss : 150.621307 , test loss : 397.371094\n",
      "epoch = 17 train_loss : 125.577965 , test loss : 322.213470\n",
      "epoch = 18 train_loss : 104.612732 , test loss : 233.851471\n",
      "epoch = 19 train_loss : 85.818581 , test loss : 204.363617\n",
      "epoch = 20 train_loss : 71.391304 , test loss : 147.257401\n",
      "epoch = 21 train_loss : 59.838661 , test loss : 127.255760\n",
      "epoch = 22 train_loss : 51.558060 , test loss : 92.183578\n",
      "epoch = 23 train_loss : 46.170952 , test loss : 73.201836\n",
      "epoch = 24 train_loss : 42.437962 , test loss : 61.358707\n",
      "epoch = 25 train_loss : 39.821007 , test loss : 59.918633\n",
      "epoch = 26 train_loss : 37.640831 , test loss : 54.741367\n",
      "epoch = 27 train_loss : 35.736046 , test loss : 52.955593\n",
      "epoch = 28 train_loss : 35.081192 , test loss : 51.527225\n",
      "epoch = 29 train_loss : 34.643684 , test loss : 48.845676\n",
      "epoch = 30 train_loss : 34.238079 , test loss : 47.715290\n",
      "epoch = 32 train_loss : 33.605953 , test loss : 46.448246\n",
      "epoch = 33 train_loss : 33.214096 , test loss : 46.118279\n",
      "epoch = 34 train_loss : 33.130829 , test loss : 45.947430\n",
      "epoch = 35 train_loss : 32.877647 , test loss : 45.770916\n",
      "epoch = 36 train_loss : 33.118504 , test loss : 45.734013\n",
      "epoch = 37 train_loss : 33.160469 , test loss : 45.685020\n",
      "epoch = 38 train_loss : 32.982010 , test loss : 45.058605\n",
      "epoch = 41 train_loss : 32.173340 , test loss : 45.002304\n",
      "epoch = 42 train_loss : 32.730305 , test loss : 44.522022\n",
      "epoch = 45 train_loss : 32.199455 , test loss : 43.954529\n",
      "epoch = 51 train_loss : 31.486975 , test loss : 43.623581\n",
      "epoch = 56 train_loss : 31.880379 , test loss : 43.444782\n",
      "epoch = 68 train_loss : 31.486359 , test loss : 43.126488\n",
      "epoch = 73 train_loss : 31.307232 , test loss : 43.109222\n",
      "epoch = 76 train_loss : 31.281849 , test loss : 42.734905\n",
      "epoch = 85 train_loss : 31.139263 , test loss : 42.613018\n",
      "epoch = 96 train_loss : 30.664150 , test loss : 42.558392\n",
      "epoch = 99 train_loss : 30.754995 , test loss : 42.427299\n",
      "epoch = 100 train_loss : 30.807468 , test loss : 42.288273\n",
      "epoch = 102 train_loss : 30.905748 , test loss : 42.233940\n",
      "epoch = 107 train_loss : 30.754047 , test loss : 42.079941\n",
      "epoch = 129 train_loss : 30.692411 , test loss : 41.899483\n",
      "epoch = 175 train_loss : 30.568306 , test loss : 41.834751\n",
      "epoch = 186 train_loss : 30.717096 , test loss : 41.680943\n",
      "epoch = 223 train_loss : 30.950483 , test loss : 41.678265\n",
      "epoch = 320 train_loss : 30.961567 , test loss : 41.643208\n",
      "epoch = 398 train_loss : 30.500710 , test loss : 41.631847\n",
      "epoch = 551 train_loss : 30.556591 , test loss : 41.630310\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 30.556591,test loss : 41.630310\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 645.571472 , test loss : 487.138428\n",
      "epoch = 10 train_loss : 352.990173 , test loss : 483.980957\n",
      "epoch = 11 train_loss : 318.743713 , test loss : 452.703125\n",
      "epoch = 12 train_loss : 283.928986 , test loss : 413.594604\n",
      "epoch = 13 train_loss : 249.978226 , test loss : 366.470795\n",
      "epoch = 14 train_loss : 214.552460 , test loss : 305.641113\n",
      "epoch = 15 train_loss : 182.070709 , test loss : 235.738678\n",
      "epoch = 16 train_loss : 151.367752 , test loss : 192.028931\n",
      "epoch = 17 train_loss : 124.773125 , test loss : 151.339905\n",
      "epoch = 18 train_loss : 101.967903 , test loss : 115.842705\n",
      "epoch = 19 train_loss : 85.286240 , test loss : 95.753174\n",
      "epoch = 20 train_loss : 70.829010 , test loss : 72.867714\n",
      "epoch = 21 train_loss : 61.016457 , test loss : 49.242172\n",
      "epoch = 22 train_loss : 52.633823 , test loss : 39.778316\n",
      "epoch = 23 train_loss : 48.857956 , test loss : 37.344040\n",
      "epoch = 24 train_loss : 44.584583 , test loss : 27.380148\n",
      "epoch = 25 train_loss : 42.682339 , test loss : 25.806246\n",
      "epoch = 27 train_loss : 40.189766 , test loss : 24.122923\n",
      "epoch = 28 train_loss : 39.725845 , test loss : 23.936655\n",
      "epoch = 29 train_loss : 39.286049 , test loss : 23.635416\n",
      "epoch = 31 train_loss : 38.659355 , test loss : 23.399364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 35 train_loss : 37.688641 , test loss : 23.398241\n",
      "epoch = 39 train_loss : 37.174675 , test loss : 23.071039\n",
      "epoch = 42 train_loss : 37.052330 , test loss : 22.730919\n",
      "epoch = 47 train_loss : 36.647984 , test loss : 22.539539\n",
      "epoch = 51 train_loss : 36.479469 , test loss : 22.492062\n",
      "epoch = 72 train_loss : 35.717010 , test loss : 22.463718\n",
      "epoch = 94 train_loss : 35.570087 , test loss : 22.332874\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 35.570087,test loss : 22.332874\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 627.315674 , test loss : 616.007874\n",
      "epoch = 2 train_loss : 572.924744 , test loss : 612.647827\n",
      "epoch = 3 train_loss : 543.352234 , test loss : 608.106201\n",
      "epoch = 4 train_loss : 514.450195 , test loss : 601.866272\n",
      "epoch = 9 train_loss : 361.626282 , test loss : 592.471252\n",
      "epoch = 10 train_loss : 326.927460 , test loss : 554.085449\n",
      "epoch = 11 train_loss : 291.853973 , test loss : 506.943024\n",
      "epoch = 12 train_loss : 257.447235 , test loss : 451.700073\n",
      "epoch = 13 train_loss : 222.597382 , test loss : 409.848999\n",
      "epoch = 14 train_loss : 189.318863 , test loss : 349.360596\n",
      "epoch = 15 train_loss : 158.543854 , test loss : 284.825043\n",
      "epoch = 16 train_loss : 131.158325 , test loss : 227.189346\n",
      "epoch = 17 train_loss : 110.201859 , test loss : 197.308884\n",
      "epoch = 18 train_loss : 89.362579 , test loss : 138.553589\n",
      "epoch = 19 train_loss : 72.763916 , test loss : 102.659241\n",
      "epoch = 20 train_loss : 61.380680 , test loss : 81.684814\n",
      "epoch = 21 train_loss : 52.649002 , test loss : 63.381031\n",
      "epoch = 22 train_loss : 47.357235 , test loss : 55.323509\n",
      "epoch = 23 train_loss : 43.360584 , test loss : 47.990246\n",
      "epoch = 24 train_loss : 40.403881 , test loss : 42.505135\n",
      "epoch = 25 train_loss : 38.815662 , test loss : 39.645885\n",
      "epoch = 26 train_loss : 37.962791 , test loss : 38.404636\n",
      "epoch = 27 train_loss : 37.690659 , test loss : 38.081493\n",
      "epoch = 28 train_loss : 36.760098 , test loss : 37.026222\n",
      "epoch = 29 train_loss : 37.097988 , test loss : 36.438713\n",
      "epoch = 31 train_loss : 36.162861 , test loss : 36.258965\n",
      "epoch = 32 train_loss : 35.421696 , test loss : 35.688953\n",
      "epoch = 33 train_loss : 35.807220 , test loss : 35.301201\n",
      "epoch = 34 train_loss : 35.765636 , test loss : 35.000462\n",
      "epoch = 37 train_loss : 34.945553 , test loss : 34.925785\n",
      "epoch = 41 train_loss : 35.398029 , test loss : 34.170414\n",
      "epoch = 44 train_loss : 34.485954 , test loss : 34.077431\n",
      "epoch = 46 train_loss : 34.026199 , test loss : 33.838223\n",
      "epoch = 47 train_loss : 34.123745 , test loss : 33.734062\n",
      "epoch = 48 train_loss : 34.211300 , test loss : 33.452511\n",
      "epoch = 51 train_loss : 34.451736 , test loss : 33.142181\n",
      "epoch = 55 train_loss : 33.567101 , test loss : 32.884506\n",
      "epoch = 60 train_loss : 33.442955 , test loss : 32.600689\n",
      "epoch = 62 train_loss : 33.577324 , test loss : 32.534790\n",
      "epoch = 70 train_loss : 33.489388 , test loss : 32.422459\n",
      "epoch = 72 train_loss : 33.364532 , test loss : 32.116581\n",
      "epoch = 85 train_loss : 33.202888 , test loss : 32.054352\n",
      "epoch = 96 train_loss : 33.352314 , test loss : 31.983181\n",
      "epoch = 135 train_loss : 33.751221 , test loss : 31.730675\n",
      "epoch = 150 train_loss : 33.193142 , test loss : 31.640821\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.193142,test loss : 31.640821\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.448281,total test loss mean : 34.994835 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x22.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x22,y22,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:16:45.502570Z",
     "start_time": "2021-12-29T06:09:26.908484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 572.718445 , test loss : 584.010437\n",
      "epoch = 2 train_loss : 522.648865 , test loss : 538.788757\n",
      "epoch = 3 train_loss : 479.260925 , test loss : 500.751770\n",
      "epoch = 4 train_loss : 431.364075 , test loss : 453.181488\n",
      "epoch = 5 train_loss : 373.274139 , test loss : 394.611633\n",
      "epoch = 6 train_loss : 308.810272 , test loss : 328.901825\n",
      "epoch = 7 train_loss : 240.460709 , test loss : 254.985916\n",
      "epoch = 8 train_loss : 176.963196 , test loss : 191.133621\n",
      "epoch = 9 train_loss : 119.721054 , test loss : 129.870667\n",
      "epoch = 10 train_loss : 78.511131 , test loss : 86.935173\n",
      "epoch = 11 train_loss : 54.415157 , test loss : 61.995895\n",
      "epoch = 12 train_loss : 43.039936 , test loss : 49.880802\n",
      "epoch = 13 train_loss : 38.245274 , test loss : 44.676754\n",
      "epoch = 14 train_loss : 37.054710 , test loss : 43.680313\n",
      "epoch = 17 train_loss : 35.117310 , test loss : 42.466881\n",
      "epoch = 18 train_loss : 34.847382 , test loss : 41.714108\n",
      "epoch = 20 train_loss : 33.589920 , test loss : 40.671570\n",
      "epoch = 28 train_loss : 32.676655 , test loss : 40.012390\n",
      "epoch = 31 train_loss : 32.621048 , test loss : 39.378891\n",
      "epoch = 36 train_loss : 31.783453 , test loss : 39.074406\n",
      "epoch = 109 train_loss : 31.415457 , test loss : 38.783646\n",
      "epoch = 479 train_loss : 31.225880 , test loss : 38.780869\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.225880,test loss : 38.780869\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 576.192932 , test loss : 563.626160\n",
      "epoch = 2 train_loss : 521.887085 , test loss : 524.657471\n",
      "epoch = 3 train_loss : 478.075562 , test loss : 488.315491\n",
      "epoch = 4 train_loss : 428.294312 , test loss : 442.616730\n",
      "epoch = 5 train_loss : 369.718811 , test loss : 392.868347\n",
      "epoch = 6 train_loss : 303.410736 , test loss : 330.995941\n",
      "epoch = 7 train_loss : 236.286606 , test loss : 264.985901\n",
      "epoch = 8 train_loss : 170.423172 , test loss : 197.772751\n",
      "epoch = 9 train_loss : 116.174706 , test loss : 138.346542\n",
      "epoch = 10 train_loss : 76.880730 , test loss : 92.992577\n",
      "epoch = 11 train_loss : 53.057377 , test loss : 68.107033\n",
      "epoch = 12 train_loss : 42.146824 , test loss : 55.255127\n",
      "epoch = 13 train_loss : 37.243565 , test loss : 49.361702\n",
      "epoch = 14 train_loss : 35.948742 , test loss : 46.331310\n",
      "epoch = 15 train_loss : 36.106743 , test loss : 46.067909\n",
      "epoch = 17 train_loss : 34.382725 , test loss : 45.052475\n",
      "epoch = 18 train_loss : 33.568691 , test loss : 43.879875\n",
      "epoch = 21 train_loss : 32.674042 , test loss : 43.227173\n",
      "epoch = 22 train_loss : 33.228512 , test loss : 42.898140\n",
      "epoch = 23 train_loss : 32.446789 , test loss : 42.427250\n",
      "epoch = 27 train_loss : 32.470009 , test loss : 41.769665\n",
      "epoch = 35 train_loss : 31.897499 , test loss : 41.343899\n",
      "epoch = 38 train_loss : 31.803549 , test loss : 41.060753\n",
      "epoch = 42 train_loss : 31.920727 , test loss : 40.888340\n",
      "epoch = 61 train_loss : 32.012688 , test loss : 40.344646\n",
      "epoch = 78 train_loss : 31.431530 , test loss : 40.200893\n",
      "epoch = 123 train_loss : 31.158346 , test loss : 40.098377\n",
      "epoch = 255 train_loss : 31.671913 , test loss : 40.064800\n",
      "epoch = 582 train_loss : 31.131283 , test loss : 40.045872\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.131283,test loss : 40.045872\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 572.503723 , test loss : 596.078247\n",
      "epoch = 2 train_loss : 525.387146 , test loss : 534.820801\n",
      "epoch = 3 train_loss : 480.406921 , test loss : 486.917969\n",
      "epoch = 4 train_loss : 433.322693 , test loss : 440.343903\n",
      "epoch = 5 train_loss : 374.115417 , test loss : 387.430847\n",
      "epoch = 6 train_loss : 308.969818 , test loss : 318.363098\n",
      "epoch = 7 train_loss : 242.016098 , test loss : 250.199219\n",
      "epoch = 8 train_loss : 177.320786 , test loss : 181.775391\n",
      "epoch = 9 train_loss : 121.523788 , test loss : 126.150688\n",
      "epoch = 10 train_loss : 82.204498 , test loss : 80.916298\n",
      "epoch = 11 train_loss : 57.841553 , test loss : 55.093914\n",
      "epoch = 12 train_loss : 46.161514 , test loss : 43.198826\n",
      "epoch = 13 train_loss : 41.754944 , test loss : 38.408066\n",
      "epoch = 14 train_loss : 39.486130 , test loss : 35.630180\n",
      "epoch = 15 train_loss : 37.876114 , test loss : 33.912140\n",
      "epoch = 16 train_loss : 37.579937 , test loss : 33.253757\n",
      "epoch = 17 train_loss : 36.360573 , test loss : 32.630905\n",
      "epoch = 19 train_loss : 36.133007 , test loss : 32.298512\n",
      "epoch = 21 train_loss : 35.203983 , test loss : 31.776337\n",
      "epoch = 37 train_loss : 34.581608 , test loss : 31.601492\n",
      "epoch = 42 train_loss : 34.162922 , test loss : 31.561659\n",
      "epoch = 54 train_loss : 33.535755 , test loss : 31.517864\n",
      "epoch = 58 train_loss : 33.568527 , test loss : 31.353479\n",
      "epoch = 62 train_loss : 34.068607 , test loss : 31.260468\n",
      "epoch = 340 train_loss : 33.150471 , test loss : 31.165726\n",
      "epoch = 828 train_loss : 33.192722 , test loss : 31.098724\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 33.192722,test loss : 31.098724\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 575.453491 , test loss : 563.956421\n",
      "epoch = 2 train_loss : 522.856567 , test loss : 521.945312\n",
      "epoch = 3 train_loss : 477.709076 , test loss : 481.084259\n",
      "epoch = 4 train_loss : 428.253540 , test loss : 438.801849\n",
      "epoch = 5 train_loss : 369.938354 , test loss : 383.793701\n",
      "epoch = 6 train_loss : 304.766693 , test loss : 322.254456\n",
      "epoch = 7 train_loss : 236.525757 , test loss : 252.176590\n",
      "epoch = 8 train_loss : 172.105499 , test loss : 185.402283\n",
      "epoch = 9 train_loss : 120.252632 , test loss : 127.455200\n",
      "epoch = 10 train_loss : 78.124992 , test loss : 83.768860\n",
      "epoch = 11 train_loss : 54.709991 , test loss : 59.047115\n",
      "epoch = 12 train_loss : 44.273602 , test loss : 47.773861\n",
      "epoch = 13 train_loss : 39.536171 , test loss : 41.251545\n",
      "epoch = 14 train_loss : 37.514881 , test loss : 39.042847\n",
      "epoch = 16 train_loss : 36.147644 , test loss : 37.270473\n",
      "epoch = 21 train_loss : 35.421192 , test loss : 36.526997\n",
      "epoch = 23 train_loss : 35.548023 , test loss : 36.364220\n",
      "epoch = 26 train_loss : 35.048195 , test loss : 35.843914\n",
      "epoch = 33 train_loss : 33.378139 , test loss : 35.635429\n",
      "epoch = 36 train_loss : 34.077667 , test loss : 35.608013\n",
      "epoch = 38 train_loss : 33.201874 , test loss : 34.888203\n",
      "epoch = 44 train_loss : 32.809452 , test loss : 34.653965\n",
      "epoch = 63 train_loss : 33.143982 , test loss : 34.644764\n",
      "epoch = 64 train_loss : 32.547787 , test loss : 34.612106\n",
      "epoch = 107 train_loss : 32.845821 , test loss : 34.471992\n",
      "epoch = 196 train_loss : 32.632557 , test loss : 34.432323\n",
      "epoch = 256 train_loss : 32.486942 , test loss : 34.367252\n",
      "epoch = 350 train_loss : 32.542271 , test loss : 34.305431\n",
      "epoch = 587 train_loss : 32.402088 , test loss : 34.249123\n",
      "epoch = 953 train_loss : 32.402527 , test loss : 34.229546\n",
      "epoch = 992 train_loss : 32.216408 , test loss : 34.205376\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.216408,test loss : 34.205376\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 574.274414 , test loss : 575.877197\n",
      "epoch = 2 train_loss : 522.518738 , test loss : 526.939514\n",
      "epoch = 3 train_loss : 480.846161 , test loss : 484.407928\n",
      "epoch = 4 train_loss : 433.333496 , test loss : 433.691315\n",
      "epoch = 5 train_loss : 377.552429 , test loss : 383.603577\n",
      "epoch = 6 train_loss : 311.139465 , test loss : 312.559326\n",
      "epoch = 7 train_loss : 241.666550 , test loss : 244.129349\n",
      "epoch = 8 train_loss : 175.254684 , test loss : 177.509552\n",
      "epoch = 9 train_loss : 120.241859 , test loss : 122.463722\n",
      "epoch = 10 train_loss : 80.795357 , test loss : 82.694046\n",
      "epoch = 11 train_loss : 56.167511 , test loss : 55.491913\n",
      "epoch = 12 train_loss : 45.847805 , test loss : 42.551025\n",
      "epoch = 13 train_loss : 40.515240 , test loss : 37.586117\n",
      "epoch = 16 train_loss : 37.285477 , test loss : 34.742336\n",
      "epoch = 17 train_loss : 36.346359 , test loss : 32.948879\n",
      "epoch = 21 train_loss : 36.000652 , test loss : 32.625721\n",
      "epoch = 23 train_loss : 35.470131 , test loss : 32.544693\n",
      "epoch = 26 train_loss : 34.723763 , test loss : 31.504349\n",
      "epoch = 27 train_loss : 34.668064 , test loss : 31.271341\n",
      "epoch = 28 train_loss : 34.735180 , test loss : 31.166920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 31 train_loss : 35.138771 , test loss : 31.126564\n",
      "epoch = 36 train_loss : 34.116096 , test loss : 31.032524\n",
      "epoch = 40 train_loss : 34.017723 , test loss : 30.509760\n",
      "epoch = 42 train_loss : 33.864189 , test loss : 30.366016\n",
      "epoch = 44 train_loss : 33.771214 , test loss : 30.251110\n",
      "epoch = 57 train_loss : 33.601959 , test loss : 30.230684\n",
      "epoch = 90 train_loss : 33.839481 , test loss : 30.217751\n",
      "epoch = 121 train_loss : 33.607899 , test loss : 29.801674\n",
      "epoch = 177 train_loss : 33.617168 , test loss : 29.759855\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.617168,test loss : 29.759855\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.276692,total test loss mean : 34.778139 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x22.shape[1],512),nn.Linear(512,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x22,y22,256,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- just test linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:53:34.773899Z",
     "start_time": "2021-12-30T01:53:26.612432Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso,ElasticNet,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:53:35.664950Z",
     "start_time": "2021-12-30T01:53:35.650949Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "\n",
    "def rmlse_cv(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x)\n",
    "    rmse=np.sqrt(-cross_val_score(model,x,y,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:54:27.052889Z",
     "start_time": "2021-12-30T01:54:22.634636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 5.9364 (0.6516)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.0005,random_state=1))\n",
    "score=rmlse_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:54:31.476142Z",
     "start_time": "2021-12-30T01:54:31.466141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8588435719005165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(34.326048 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:54:40.248643Z",
     "start_time": "2021-12-30T01:54:36.604435Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " enet score: 5.9364 (0.6516)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "enet=make_pipeline(RobustScaler(),ElasticNet(alpha=0.0005,l1_ratio=0.9))\n",
    "scoreo=rmlse_cv(enet)\n",
    "print(\"\\n enet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:54:43.029803Z",
     "start_time": "2021-12-30T01:54:41.697726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ridge score: 5.9404 (0.6500)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge=make_pipeline(RobustScaler(),Ridge(alpha=0.5))\n",
    "score=rmlse_cv(ridge)\n",
    "print(\"\\n ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:56:05.091496Z",
     "start_time": "2021-12-30T01:54:49.267159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 6.9629 (1.0416)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000,\n",
    "                                   learning_rate=0.05,\n",
    "                                   max_depth=4,\n",
    "                                   max_features='sqrt',\n",
    "                                   min_samples_leaf=15,\n",
    "                                   min_samples_split=10,\n",
    "                                   loss='huber',\n",
    "                                   random_state=5)\n",
    "score = rmlse_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:57:58.349974Z",
     "start_time": "2021-12-30T01:57:15.910547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:57:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:57:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:57:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:57:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:57:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Xgboost score: 6.5696 (0.8384)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "score = rmlse_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:04.543328Z",
     "start_time": "2021-12-30T01:58:03.058244Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 6.6617 (0.9785)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "score = rmlse_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:17.510070Z",
     "start_time": "2021-12-30T01:58:17.484069Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_list=[]\n",
    "for i in range(12):\n",
    "    month_list.append(pd.DataFrame(year_data[i]))\n",
    "all_train_data=pd.concat(month_list,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:18.079103Z",
     "start_time": "2021-12-30T01:58:18.067102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 480)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_list[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:18.600132Z",
     "start_time": "2021-12-30T01:58:18.594132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check reshape data is right ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:20.401235Z",
     "start_time": "2021-12-30T01:58:20.349233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>109.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>108.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>114.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       9    10    11   12   13     14     15   16   17\n",
       "475  37.0  0.0  76.0  2.6  1.9  109.0   97.0  1.0  1.4\n",
       "476  28.0  0.0  80.0  2.2  1.9  108.0  107.0  1.7  1.3\n",
       "477  17.0  0.0  82.0  2.3  1.9  114.0  118.0  1.5  1.6\n",
       "478  24.0  0.0  84.0  2.3  2.0  108.0  100.0  2.0  1.8\n",
       "479  29.0  0.0  84.0  2.3  2.0  109.0  105.0  2.0  2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.iloc[-5:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:21.272285Z",
     "start_time": "2021-12-30T01:58:21.206282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.527413</td>\n",
       "      <td>1.702396</td>\n",
       "      <td>0.388363</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.135729</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.247726</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.414236</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.763125</td>\n",
       "      <td>1.839653</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.290152</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>0.323573</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.282155</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.577133</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.662537</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.816940</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.300000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.527413     1.702396     0.388363     0.140427     2.135729   \n",
       "std       6.290152     0.125265     0.323573     0.104645     2.282155   \n",
       "min     -12.300000    -0.200000    -0.120000     0.000000    -1.100000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.247726    31.905469    42.709201    21.414236   \n",
       "std       6.187555     7.577133    18.703486    26.222292    16.662537   \n",
       "min       0.000000    -2.400000     0.000000     0.000000    -1.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    29.250000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.763125     1.839653   156.329271   \n",
       "std       2.045443    13.361351     1.816940     0.181839    95.745881   \n",
       "min       0.000000    29.000000    -1.600000    -0.200000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T03:08:39.600886Z",
     "start_time": "2021-12-28T03:08:39.594886Z"
    },
    "collapsed": true
   },
   "source": [
    "### correct outlier value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:23.556416Z",
     "start_time": "2021-12-30T01:58:23.552416Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data1=year_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:24.508470Z",
     "start_time": "2021-12-30T01:58:24.459468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      "---------- pm2.5 start : \n",
      " -3.1 \n",
      "\n",
      "-8.0\n",
      "-7.2\n",
      "-6.8\n",
      "-6.5\n",
      "-7.1\n",
      "-7.4\n",
      "-8.1\n",
      "-8.3\n",
      "-8.4\n",
      "-9.3\n",
      "-10.6\n",
      "-11.2\n",
      "-12.1\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-12.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 19.0 18.0\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n"
     ]
    }
   ],
   "source": [
    "# temperature always >=0 in Taiwan and change fast when temperature <=0 ,so correct it\n",
    "for idx in [0]:\t\n",
    "\tfor m in range(12):\n",
    "\t\tprint(' month : ',m)\n",
    "\t\ti=0\n",
    "\t\twhile i<480:\n",
    "\t\t\tif year_data1[m][idx,i] <=0:\n",
    "\t\t\t\tprint('---------- pm2.5 start : \\n',year_data1[m][idx,i],'\\n')\n",
    "\t\t\t\tfor k in range(30):\n",
    "\t\t\t\t\tif k+i+1>479:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif year_data1[m][idx,k+i+1] >0:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(year_data1[m][idx,k+i+1])\n",
    "\t\t\t\ti=i+k\n",
    "\t\t\t\tprint('pm2.5 end ------------')\n",
    "\t\t\t\tprint('correct value between  :',year_data1[m][idx,i-1-k],year_data1[m][idx,i+1])\n",
    "\t\t\t\t## add correct to mean value\n",
    "\t\t\t\tyear_data1[m][idx,i-k:i+1]=(year_data1[m][idx,i-1-k]+year_data1[m][idx,i+1])/2\n",
    "\t\t\ti=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:25.228512Z",
     "start_time": "2021-12-30T01:58:25.210511Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_list=[]\n",
    "for i in range(12):\n",
    "    month_list.append(pd.DataFrame(year_data1[i]))\n",
    "all_train_data1=pd.concat(month_list,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:25.938552Z",
     "start_time": "2021-12-30T01:58:25.871548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.610382</td>\n",
       "      <td>1.702396</td>\n",
       "      <td>0.388363</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.135729</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.247726</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.414236</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.763125</td>\n",
       "      <td>1.839653</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.062216</td>\n",
       "      <td>0.125265</td>\n",
       "      <td>0.323573</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.282155</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.577133</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.662537</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.816940</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.700000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.610382     1.702396     0.388363     0.140427     2.135729   \n",
       "std       6.062216     0.125265     0.323573     0.104645     2.282155   \n",
       "min       6.700000    -0.200000    -0.120000     0.000000    -1.100000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.247726    31.905469    42.709201    21.414236   \n",
       "std       6.187555     7.577133    18.703486    26.222292    16.662537   \n",
       "min       0.000000    -2.400000     0.000000     0.000000    -1.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    29.250000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.763125     1.839653   156.329271   \n",
       "std       2.045443    13.361351     1.816940     0.181839    95.745881   \n",
       "min       0.000000    29.000000    -1.600000    -0.200000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:26.681595Z",
     "start_time": "2021-12-30T01:58:26.576589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.8 1.8\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.12 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.34 0.26\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.5 0.3\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.1 1.0\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -1.1 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 6.6 1.2\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      "---------- pm2.5 start : \n",
      " -0.9 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 17.0 17.0\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 7.4 10.0\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -2.4 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 7.0 6.6\n",
      " month :  11\n",
      " month :  0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 46.0 51.0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 6.0 16.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 13.0 16.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 55.0 48.0\n",
      " month :  4\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 5.0 1.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.0 4.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 5.0 0.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 10.0 9.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 9.0 2.0\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 4.0\n",
      " month :  5\n",
      " month :  6\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 20.0 27.0\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 18.0 18.0\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -1.0 \n",
      "\n",
      "-1.0\n",
      "pm2.5 end ------------\n",
      "correct value between  : 13.0 7.0\n",
      " month :  0\n",
      "---------- pm2.5 start : \n",
      " -0.9 \n",
      "\n",
      "-0.9\n",
      "-0.9\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.6 1.3\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "-0.1\n",
      "-0.2\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.1 1.2\n",
      " month :  1\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 1.1 0.3\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      "---------- pm2.5 start : \n",
      " -1.5 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.2 2.3\n",
      "---------- pm2.5 start : \n",
      " -0.3 \n",
      "\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 3.8 2.2\n",
      " month :  6\n",
      " month :  7\n",
      "---------- pm2.5 start : \n",
      " -1.6 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 4.3 2.7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 0.9\n",
      "---------- pm2.5 start : \n",
      " -0.1 \n",
      "\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.2 0.3\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.4\n",
      "-0.5\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 1.2\n",
      "---------- pm2.5 start : \n",
      " -0.3 \n",
      "\n",
      "-0.3\n",
      "pm2.5 end ------------\n",
      "correct value between  : 0.0 1.1\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.8 2.0\n",
      " month :  0\n",
      " month :  1\n",
      " month :  2\n",
      " month :  3\n",
      " month :  4\n",
      " month :  5\n",
      " month :  6\n",
      " month :  7\n",
      " month :  8\n",
      " month :  9\n",
      " month :  10\n",
      " month :  11\n",
      "---------- pm2.5 start : \n",
      " -0.2 \n",
      "\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "-0.2\n",
      "pm2.5 end ------------\n",
      "correct value between  : 2.0 1.9\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2,4,6,9,12,13]:\t\n",
    "\tfor m in range(12):\n",
    "\t\tprint(' month : ',m)\n",
    "\t\ti=0\n",
    "\t\twhile i<480:\n",
    "\t\t\tif year_data1[m][idx,i] <0:\n",
    "\t\t\t\tprint('---------- pm2.5 start : \\n',year_data1[m][idx,i],'\\n')\n",
    "\t\t\t\tfor k in range(30):\n",
    "\t\t\t\t\tif k+i+1>479:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif year_data1[m][idx,k+i+1] >=0:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(year_data1[m][idx,k+i+1])\n",
    "\t\t\t\ti=i+k\n",
    "\t\t\t\tprint('pm2.5 end ------------')\n",
    "\t\t\t\tprint('correct value between  :',year_data1[m][idx,i-1-k],year_data1[m][idx,i+1])\n",
    "\t\t\t\t## add correct to mean value\n",
    "\t\t\t\tyear_data1[m][idx,i-k:i+1]=(year_data1[m][idx,i-1-k]+year_data1[m][idx,i+1])/2\n",
    "\t\t\ti=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:51.274001Z",
     "start_time": "2021-12-30T01:58:51.258000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_list=[]\n",
    "for i in range(12):\n",
    "    month_list.append(pd.DataFrame(year_data1[i]))\n",
    "all_train_data1=pd.concat(month_list,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T01:58:51.922038Z",
     "start_time": "2021-12-30T01:58:51.862035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.610382</td>\n",
       "      <td>1.705521</td>\n",
       "      <td>0.388436</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.136970</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.254115</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.534201</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.769089</td>\n",
       "      <td>1.843012</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.062216</td>\n",
       "      <td>0.100203</td>\n",
       "      <td>0.323505</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.281611</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.571422</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.576035</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.809743</td>\n",
       "      <td>0.163008</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.610382     1.705521     0.388436     0.140427     2.136970   \n",
       "std       6.062216     0.100203     0.323505     0.104645     2.281611   \n",
       "min       6.700000     0.000000     0.080000     0.000000     0.000000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.254115    31.905469    42.709201    21.534201   \n",
       "std       6.187555     7.571422    18.703486    26.222292    16.576035   \n",
       "min       0.000000     1.300000     0.000000     0.000000     0.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    30.000000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.769089     1.843012   156.329271   \n",
       "std       2.045443    13.361351     1.809743     0.163008    95.745881   \n",
       "min       0.000000    29.000000     0.000000     0.000000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:01:27.455934Z",
     "start_time": "2021-12-30T02:01:27.448934Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x3=np.empty((12*471,18*9))\n",
    "y3=np.empty((12*471,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:01:28.134973Z",
     "start_time": "2021-12-30T02:01:28.082970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in range(12):\n",
    "    for g in range(471):\n",
    "        x3[m*471+g:m*471+g+1,:]=year_data1[m][:,g:g+9].reshape(1,-1)\n",
    "        y3[m*471+g:m*471+g+1,:]=year_data1[m][9,g+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:01.078858Z",
     "start_time": "2021-12-30T02:02:01.065857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7, 1.7, 1.7, 1.7, 1.8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data[11][-5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:01.723894Z",
     "start_time": "2021-12-30T02:02:01.719894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7, 1.7, 1.7, 1.7, 1.8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data1[11][-5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:02.306928Z",
     "start_time": "2021-12-30T02:02:02.299927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3, 1.7, 0.7, 0.4, 1.1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-5,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:02.875960Z",
     "start_time": "2021-12-30T02:02:02.866960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3, 1.7, 0.7, 0.4, 1.1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3[-5,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:03.365988Z",
     "start_time": "2021-12-30T02:02:03.357988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [28.],\n",
       "       [17.],\n",
       "       [24.],\n",
       "       [29.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:03.903019Z",
     "start_time": "2021-12-30T02:02:03.894019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [28.],\n",
       "       [17.],\n",
       "       [24.],\n",
       "       [29.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:04.805071Z",
     "start_time": "2021-12-30T02:02:04.794070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:05.511111Z",
     "start_time": "2021-12-30T02:02:05.500110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3[y3<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:05.954136Z",
     "start_time": "2021-12-30T02:02:05.947136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3[x3<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:06.504168Z",
     "start_time": "2021-12-30T02:02:06.417163Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x33=pd.DataFrame(x3)\n",
    "x33=x33.apply(lambda x: (x-x.mean())/x.std())\n",
    "x33=x33.values\n",
    "y33=y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:07.530227Z",
     "start_time": "2021-12-30T02:02:07.507225Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x333=torch.Tensor(x33)\n",
    "y333=torch.Tensor(y33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T02:16:28.216948Z",
     "start_time": "2021-12-29T02:12:18.918689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 150.251907 , test loss : 155.604050\n",
      "epoch = 2 train_loss : 99.558205 , test loss : 104.195030\n",
      "epoch = 3 train_loss : 80.369507 , test loss : 87.102425\n",
      "epoch = 4 train_loss : 69.669907 , test loss : 75.825897\n",
      "epoch = 5 train_loss : 64.667076 , test loss : 70.746811\n",
      "epoch = 6 train_loss : 61.921131 , test loss : 67.884300\n",
      "epoch = 7 train_loss : 56.259201 , test loss : 62.566200\n",
      "epoch = 8 train_loss : 52.487587 , test loss : 58.312618\n",
      "epoch = 9 train_loss : 50.237362 , test loss : 55.953819\n",
      "epoch = 10 train_loss : 48.078827 , test loss : 53.591438\n",
      "epoch = 12 train_loss : 45.296902 , test loss : 50.552940\n",
      "epoch = 13 train_loss : 43.835632 , test loss : 48.931911\n",
      "epoch = 14 train_loss : 43.257683 , test loss : 48.668621\n",
      "epoch = 15 train_loss : 43.066242 , test loss : 48.321022\n",
      "epoch = 16 train_loss : 41.003517 , test loss : 46.407482\n",
      "epoch = 18 train_loss : 40.249680 , test loss : 45.904747\n",
      "epoch = 19 train_loss : 38.598541 , test loss : 44.173035\n",
      "epoch = 20 train_loss : 38.547020 , test loss : 44.082150\n",
      "epoch = 22 train_loss : 37.248482 , test loss : 42.881256\n",
      "epoch = 23 train_loss : 37.011169 , test loss : 42.585403\n",
      "epoch = 26 train_loss : 36.006237 , test loss : 42.196953\n",
      "epoch = 27 train_loss : 36.063396 , test loss : 41.977585\n",
      "epoch = 32 train_loss : 35.185047 , test loss : 41.576931\n",
      "epoch = 33 train_loss : 35.144768 , test loss : 40.977394\n",
      "epoch = 34 train_loss : 34.678127 , test loss : 40.857880\n",
      "epoch = 37 train_loss : 34.473026 , test loss : 40.780830\n",
      "epoch = 38 train_loss : 34.395901 , test loss : 40.455273\n",
      "epoch = 47 train_loss : 33.358772 , test loss : 39.841576\n",
      "epoch = 50 train_loss : 33.210590 , test loss : 39.612091\n",
      "epoch = 61 train_loss : 32.744186 , test loss : 39.266121\n",
      "epoch = 65 train_loss : 32.891804 , test loss : 39.043297\n",
      "epoch = 69 train_loss : 32.580742 , test loss : 39.013527\n",
      "epoch = 76 train_loss : 32.249630 , test loss : 38.681110\n",
      "epoch = 102 train_loss : 32.055527 , test loss : 38.664467\n",
      "epoch = 108 train_loss : 31.887192 , test loss : 38.646629\n",
      "epoch = 110 train_loss : 31.938704 , test loss : 38.565674\n",
      "epoch = 113 train_loss : 31.797230 , test loss : 38.562164\n",
      "epoch = 130 train_loss : 31.782171 , test loss : 38.475536\n",
      "epoch = 167 train_loss : 31.622107 , test loss : 38.448021\n",
      "epoch = 232 train_loss : 31.607468 , test loss : 38.441761\n",
      "epoch = 307 train_loss : 31.533176 , test loss : 38.386894\n",
      "epoch = 360 train_loss : 31.507948 , test loss : 38.383743\n",
      "epoch = 388 train_loss : 31.486395 , test loss : 38.380219\n",
      "epoch = 468 train_loss : 31.524921 , test loss : 38.329308\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.524921,test loss : 38.329308\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 143.725555 , test loss : 154.987457\n",
      "epoch = 2 train_loss : 100.910851 , test loss : 113.883461\n",
      "epoch = 3 train_loss : 83.219131 , test loss : 95.803833\n",
      "epoch = 4 train_loss : 72.540367 , test loss : 84.528183\n",
      "epoch = 5 train_loss : 66.115387 , test loss : 77.704483\n",
      "epoch = 6 train_loss : 65.482933 , test loss : 75.550949\n",
      "epoch = 7 train_loss : 57.813988 , test loss : 68.540169\n",
      "epoch = 8 train_loss : 54.613674 , test loss : 65.679649\n",
      "epoch = 9 train_loss : 52.527237 , test loss : 64.081070\n",
      "epoch = 11 train_loss : 48.902870 , test loss : 60.918900\n",
      "epoch = 12 train_loss : 46.654434 , test loss : 57.656437\n",
      "epoch = 13 train_loss : 44.123055 , test loss : 56.219910\n",
      "epoch = 14 train_loss : 43.174698 , test loss : 54.817467\n",
      "epoch = 15 train_loss : 41.921715 , test loss : 53.645023\n",
      "epoch = 16 train_loss : 40.889576 , test loss : 52.606224\n",
      "epoch = 18 train_loss : 40.200459 , test loss : 51.252213\n",
      "epoch = 25 train_loss : 36.500397 , test loss : 48.231174\n",
      "epoch = 27 train_loss : 36.285896 , test loss : 47.165508\n",
      "epoch = 31 train_loss : 35.126976 , test loss : 45.532291\n",
      "epoch = 38 train_loss : 34.985157 , test loss : 44.890324\n",
      "epoch = 39 train_loss : 33.863876 , test loss : 44.277374\n",
      "epoch = 44 train_loss : 33.594116 , test loss : 43.653275\n",
      "epoch = 49 train_loss : 33.022732 , test loss : 42.533009\n",
      "epoch = 66 train_loss : 32.898987 , test loss : 41.859562\n",
      "epoch = 67 train_loss : 32.332130 , test loss : 41.832455\n",
      "epoch = 70 train_loss : 32.160141 , test loss : 41.358372\n",
      "epoch = 74 train_loss : 32.483154 , test loss : 41.176147\n",
      "epoch = 84 train_loss : 32.174908 , test loss : 40.907177\n",
      "epoch = 93 train_loss : 31.883329 , test loss : 40.875656\n",
      "epoch = 95 train_loss : 31.801115 , test loss : 40.688587\n",
      "epoch = 105 train_loss : 31.625254 , test loss : 40.409760\n",
      "epoch = 114 train_loss : 31.569515 , test loss : 40.341904\n",
      "epoch = 116 train_loss : 31.833282 , test loss : 40.203236\n",
      "epoch = 128 train_loss : 31.569878 , test loss : 40.164585\n",
      "epoch = 150 train_loss : 31.563631 , test loss : 40.151329\n",
      "epoch = 170 train_loss : 31.539246 , test loss : 39.784611\n",
      "epoch = 410 train_loss : 31.426306 , test loss : 39.765163\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.426306,test loss : 39.765163\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 145.884232 , test loss : 140.887878\n",
      "epoch = 2 train_loss : 120.065048 , test loss : 116.224304\n",
      "epoch = 3 train_loss : 98.570274 , test loss : 94.186981\n",
      "epoch = 4 train_loss : 81.681030 , test loss : 73.767868\n",
      "epoch = 5 train_loss : 75.400017 , test loss : 69.698990\n",
      "epoch = 6 train_loss : 64.741722 , test loss : 57.722424\n",
      "epoch = 7 train_loss : 60.742702 , test loss : 53.652279\n",
      "epoch = 8 train_loss : 58.748707 , test loss : 52.589188\n",
      "epoch = 9 train_loss : 55.252384 , test loss : 48.977894\n",
      "epoch = 11 train_loss : 53.850754 , test loss : 48.374622\n",
      "epoch = 12 train_loss : 50.319855 , test loss : 43.622704\n",
      "epoch = 13 train_loss : 50.156013 , test loss : 43.097050\n",
      "epoch = 14 train_loss : 47.216991 , test loss : 40.599445\n",
      "epoch = 15 train_loss : 45.989624 , test loss : 39.233509\n",
      "epoch = 16 train_loss : 45.114216 , test loss : 38.344410\n",
      "epoch = 18 train_loss : 43.299843 , test loss : 36.700054\n",
      "epoch = 22 train_loss : 41.115692 , test loss : 34.517052\n",
      "epoch = 27 train_loss : 39.084946 , test loss : 33.301525\n",
      "epoch = 29 train_loss : 39.071964 , test loss : 33.191559\n",
      "epoch = 35 train_loss : 37.630730 , test loss : 32.264652\n",
      "epoch = 37 train_loss : 37.642590 , test loss : 31.549349\n",
      "epoch = 41 train_loss : 36.586323 , test loss : 31.301083\n",
      "epoch = 44 train_loss : 36.068253 , test loss : 31.177195\n",
      "epoch = 49 train_loss : 35.864624 , test loss : 30.882711\n",
      "epoch = 50 train_loss : 35.517689 , test loss : 30.831886\n",
      "epoch = 54 train_loss : 35.153355 , test loss : 30.668146\n",
      "epoch = 102 train_loss : 33.920467 , test loss : 30.383089\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 33.920467,test loss : 30.383089\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 142.874252 , test loss : 142.546906\n",
      "epoch = 2 train_loss : 119.191261 , test loss : 116.087776\n",
      "epoch = 3 train_loss : 88.238503 , test loss : 86.509819\n",
      "epoch = 4 train_loss : 78.222191 , test loss : 77.165604\n",
      "epoch = 5 train_loss : 71.658936 , test loss : 71.025558\n",
      "epoch = 6 train_loss : 66.289833 , test loss : 66.185440\n",
      "epoch = 7 train_loss : 61.963337 , test loss : 62.200985\n",
      "epoch = 8 train_loss : 58.489521 , test loss : 59.226700\n",
      "epoch = 9 train_loss : 56.484394 , test loss : 57.165253\n",
      "epoch = 11 train_loss : 51.688873 , test loss : 52.250797\n",
      "epoch = 12 train_loss : 49.865849 , test loss : 50.368149\n",
      "epoch = 13 train_loss : 47.525772 , test loss : 47.625549\n",
      "epoch = 14 train_loss : 46.856441 , test loss : 47.474556\n",
      "epoch = 16 train_loss : 43.777718 , test loss : 43.869785\n",
      "epoch = 19 train_loss : 41.434441 , test loss : 41.466133\n",
      "epoch = 22 train_loss : 39.722618 , test loss : 40.094814\n",
      "epoch = 23 train_loss : 39.498554 , test loss : 39.797440\n",
      "epoch = 26 train_loss : 38.299229 , test loss : 39.027855\n",
      "epoch = 28 train_loss : 38.559696 , test loss : 38.656879\n",
      "epoch = 30 train_loss : 36.811920 , test loss : 37.361240\n",
      "epoch = 32 train_loss : 36.628784 , test loss : 36.882042\n",
      "epoch = 34 train_loss : 35.838390 , test loss : 36.666584\n",
      "epoch = 42 train_loss : 35.663643 , test loss : 36.283394\n",
      "epoch = 44 train_loss : 34.760086 , test loss : 35.802444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 47 train_loss : 34.565628 , test loss : 35.519215\n",
      "epoch = 52 train_loss : 34.032391 , test loss : 35.292900\n",
      "epoch = 55 train_loss : 34.050674 , test loss : 35.128277\n",
      "epoch = 58 train_loss : 33.804146 , test loss : 34.602654\n",
      "epoch = 87 train_loss : 33.378014 , test loss : 34.423214\n",
      "epoch = 92 train_loss : 33.236534 , test loss : 34.405964\n",
      "epoch = 114 train_loss : 32.970219 , test loss : 34.267426\n",
      "epoch = 125 train_loss : 32.875366 , test loss : 34.185539\n",
      "epoch = 126 train_loss : 32.862984 , test loss : 34.093227\n",
      "epoch = 155 train_loss : 33.150898 , test loss : 33.923546\n",
      "epoch = 206 train_loss : 32.652462 , test loss : 33.831314\n",
      "epoch = 599 train_loss : 32.596390 , test loss : 33.752548\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.596390,test loss : 33.752548\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 217.226624 , test loss : 210.688721\n",
      "epoch = 2 train_loss : 124.173622 , test loss : 113.696732\n",
      "epoch = 3 train_loss : 96.885925 , test loss : 88.073257\n",
      "epoch = 4 train_loss : 83.384079 , test loss : 75.425491\n",
      "epoch = 5 train_loss : 74.445267 , test loss : 67.556084\n",
      "epoch = 6 train_loss : 69.508949 , test loss : 62.718414\n",
      "epoch = 7 train_loss : 65.273666 , test loss : 58.496239\n",
      "epoch = 8 train_loss : 58.464451 , test loss : 51.935070\n",
      "epoch = 9 train_loss : 57.514267 , test loss : 51.249962\n",
      "epoch = 10 train_loss : 54.963215 , test loss : 48.700630\n",
      "epoch = 11 train_loss : 53.136543 , test loss : 47.158134\n",
      "epoch = 12 train_loss : 49.328178 , test loss : 43.412411\n",
      "epoch = 15 train_loss : 45.439144 , test loss : 39.797569\n",
      "epoch = 16 train_loss : 44.844486 , test loss : 39.342064\n",
      "epoch = 19 train_loss : 42.372627 , test loss : 36.976665\n",
      "epoch = 20 train_loss : 41.550728 , test loss : 36.130901\n",
      "epoch = 25 train_loss : 40.350388 , test loss : 35.325302\n",
      "epoch = 26 train_loss : 38.908703 , test loss : 33.888447\n",
      "epoch = 27 train_loss : 38.565826 , test loss : 33.491726\n",
      "epoch = 29 train_loss : 38.134262 , test loss : 33.042660\n",
      "epoch = 32 train_loss : 37.749619 , test loss : 33.005898\n",
      "epoch = 33 train_loss : 37.158371 , test loss : 32.269398\n",
      "epoch = 34 train_loss : 37.011303 , test loss : 32.167774\n",
      "epoch = 44 train_loss : 36.297901 , test loss : 31.830486\n",
      "epoch = 51 train_loss : 35.566666 , test loss : 31.281530\n",
      "epoch = 53 train_loss : 35.568539 , test loss : 30.834728\n",
      "epoch = 55 train_loss : 35.325760 , test loss : 30.576435\n",
      "epoch = 59 train_loss : 35.022369 , test loss : 30.527760\n",
      "epoch = 70 train_loss : 34.647186 , test loss : 30.500654\n",
      "epoch = 73 train_loss : 34.607864 , test loss : 30.309664\n",
      "epoch = 79 train_loss : 34.431690 , test loss : 30.185942\n",
      "epoch = 81 train_loss : 34.482990 , test loss : 30.057896\n",
      "epoch = 97 train_loss : 34.496082 , test loss : 30.051306\n",
      "epoch = 103 train_loss : 34.525021 , test loss : 29.985331\n",
      "epoch = 108 train_loss : 34.300770 , test loss : 29.784212\n",
      "epoch = 127 train_loss : 34.087532 , test loss : 29.729136\n",
      "epoch = 137 train_loss : 33.921806 , test loss : 29.676088\n",
      "epoch = 167 train_loss : 33.912956 , test loss : 29.598385\n",
      "epoch = 206 train_loss : 33.988064 , test loss : 29.575928\n",
      "epoch = 292 train_loss : 33.757290 , test loss : 29.474783\n",
      "epoch = 503 train_loss : 33.724987 , test loss : 29.448877\n",
      "epoch = 537 train_loss : 33.708096 , test loss : 29.430435\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.708096,test loss : 29.430435\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.635236,total test loss mean : 34.332109 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T05:51:27.381571Z",
     "start_time": "2021-12-28T05:38:58.692749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 242.862030 , test loss : 430.585968\n",
      "epoch = 2 train_loss : 119.124214 , test loss : 118.581306\n",
      "epoch = 3 train_loss : 92.216858 , test loss : 113.473755\n",
      "epoch = 4 train_loss : 79.558067 , test loss : 93.636253\n",
      "epoch = 5 train_loss : 68.957764 , test loss : 77.322014\n",
      "epoch = 6 train_loss : 62.653736 , test loss : 67.041039\n",
      "epoch = 7 train_loss : 55.060841 , test loss : 60.360199\n",
      "epoch = 8 train_loss : 51.390102 , test loss : 59.180382\n",
      "epoch = 9 train_loss : 50.936089 , test loss : 54.854618\n",
      "epoch = 10 train_loss : 43.929916 , test loss : 50.223682\n",
      "epoch = 12 train_loss : 41.247108 , test loss : 49.901432\n",
      "epoch = 13 train_loss : 39.674068 , test loss : 46.727482\n",
      "epoch = 16 train_loss : 40.105263 , test loss : 46.483082\n",
      "epoch = 17 train_loss : 38.295731 , test loss : 44.586624\n",
      "epoch = 19 train_loss : 40.744301 , test loss : 44.009396\n",
      "epoch = 26 train_loss : 34.560661 , test loss : 41.944489\n",
      "epoch = 28 train_loss : 34.315250 , test loss : 41.782665\n",
      "epoch = 35 train_loss : 34.449360 , test loss : 41.747913\n",
      "epoch = 38 train_loss : 33.810379 , test loss : 41.590111\n",
      "epoch = 42 train_loss : 34.711914 , test loss : 40.877445\n",
      "epoch = 44 train_loss : 33.038746 , test loss : 40.100815\n",
      "epoch = 60 train_loss : 32.789215 , test loss : 40.058155\n",
      "epoch = 68 train_loss : 32.600666 , test loss : 38.928970\n",
      "epoch = 233 train_loss : 32.028053 , test loss : 38.828194\n",
      "epoch = 417 train_loss : 31.511808 , test loss : 38.819115\n",
      "epoch = 488 train_loss : 31.813438 , test loss : 38.777073\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.813438,test loss : 38.777073\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 253.703796 , test loss : 440.871918\n",
      "epoch = 2 train_loss : 104.174599 , test loss : 149.008163\n",
      "epoch = 3 train_loss : 94.792305 , test loss : 135.465988\n",
      "epoch = 4 train_loss : 78.804909 , test loss : 111.314926\n",
      "epoch = 5 train_loss : 69.498032 , test loss : 98.251556\n",
      "epoch = 6 train_loss : 61.887409 , test loss : 85.660118\n",
      "epoch = 7 train_loss : 57.378086 , test loss : 79.908150\n",
      "epoch = 8 train_loss : 51.841846 , test loss : 70.944679\n",
      "epoch = 9 train_loss : 47.992577 , test loss : 64.512093\n",
      "epoch = 10 train_loss : 45.789753 , test loss : 60.871986\n",
      "epoch = 11 train_loss : 42.871513 , test loss : 56.334328\n",
      "epoch = 12 train_loss : 41.698345 , test loss : 54.440136\n",
      "epoch = 13 train_loss : 40.573380 , test loss : 52.262966\n",
      "epoch = 15 train_loss : 39.052319 , test loss : 51.004421\n",
      "epoch = 17 train_loss : 37.073654 , test loss : 47.347801\n",
      "epoch = 18 train_loss : 37.212677 , test loss : 47.180450\n",
      "epoch = 23 train_loss : 35.805759 , test loss : 44.462952\n",
      "epoch = 36 train_loss : 34.388588 , test loss : 43.084526\n",
      "epoch = 40 train_loss : 33.564358 , test loss : 42.065128\n",
      "epoch = 53 train_loss : 32.905937 , test loss : 41.927387\n",
      "epoch = 54 train_loss : 32.895794 , test loss : 41.400433\n",
      "epoch = 55 train_loss : 33.018860 , test loss : 41.259201\n",
      "epoch = 72 train_loss : 32.545242 , test loss : 40.690968\n",
      "epoch = 98 train_loss : 32.738194 , test loss : 40.556381\n",
      "epoch = 116 train_loss : 32.054626 , test loss : 40.210392\n",
      "epoch = 211 train_loss : 31.799917 , test loss : 39.939659\n",
      "epoch = 220 train_loss : 31.837509 , test loss : 39.402359\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.837509,test loss : 39.402359\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 270.867645 , test loss : 163.364166\n",
      "epoch = 2 train_loss : 117.495750 , test loss : 110.353653\n",
      "epoch = 3 train_loss : 94.724281 , test loss : 94.813744\n",
      "epoch = 4 train_loss : 82.552658 , test loss : 83.261574\n",
      "epoch = 5 train_loss : 68.976898 , test loss : 77.428528\n",
      "epoch = 6 train_loss : 62.561283 , test loss : 69.858719\n",
      "epoch = 7 train_loss : 55.846210 , test loss : 64.834953\n",
      "epoch = 9 train_loss : 49.139481 , test loss : 61.530731\n",
      "epoch = 10 train_loss : 46.571369 , test loss : 59.675236\n",
      "epoch = 11 train_loss : 44.382282 , test loss : 55.448380\n",
      "epoch = 14 train_loss : 41.920422 , test loss : 52.926861\n",
      "epoch = 15 train_loss : 38.992741 , test loss : 49.967983\n",
      "epoch = 16 train_loss : 39.305904 , test loss : 49.337700\n",
      "epoch = 19 train_loss : 40.317932 , test loss : 49.005825\n",
      "epoch = 20 train_loss : 36.268410 , test loss : 47.788101\n",
      "epoch = 21 train_loss : 37.650093 , test loss : 47.368855\n",
      "epoch = 23 train_loss : 35.732601 , test loss : 46.190586\n",
      "epoch = 24 train_loss : 35.424816 , test loss : 46.125187\n",
      "epoch = 26 train_loss : 34.736931 , test loss : 46.062012\n",
      "epoch = 27 train_loss : 33.997177 , test loss : 45.894722\n",
      "epoch = 31 train_loss : 33.875698 , test loss : 45.329277\n",
      "epoch = 35 train_loss : 33.110207 , test loss : 44.081505\n",
      "epoch = 49 train_loss : 32.805611 , test loss : 43.952251\n",
      "epoch = 54 train_loss : 31.969185 , test loss : 43.326141\n",
      "epoch = 76 train_loss : 33.096554 , test loss : 42.641216\n",
      "epoch = 77 train_loss : 32.498779 , test loss : 42.602821\n",
      "epoch = 79 train_loss : 32.031094 , test loss : 42.247803\n",
      "epoch = 94 train_loss : 32.646935 , test loss : 41.956024\n",
      "epoch = 133 train_loss : 31.590672 , test loss : 41.768368\n",
      "epoch = 200 train_loss : 31.313713 , test loss : 41.676247\n",
      "epoch = 228 train_loss : 31.474735 , test loss : 41.439980\n",
      "epoch = 253 train_loss : 31.458986 , test loss : 41.217033\n",
      "epoch = 364 train_loss : 31.221523 , test loss : 41.202030\n",
      "epoch = 461 train_loss : 31.155672 , test loss : 41.180252\n",
      "epoch = 523 train_loss : 31.092924 , test loss : 41.135956\n",
      "epoch = 643 train_loss : 31.079573 , test loss : 41.066849\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 31.079573,test loss : 41.066849\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 379.128387 , test loss : 151.578537\n",
      "epoch = 2 train_loss : 126.353790 , test loss : 52.539356\n",
      "epoch = 4 train_loss : 96.758987 , test loss : 43.711193\n",
      "epoch = 5 train_loss : 85.197861 , test loss : 39.515598\n",
      "epoch = 6 train_loss : 78.825142 , test loss : 36.877522\n",
      "epoch = 7 train_loss : 68.417595 , test loss : 33.936707\n",
      "epoch = 9 train_loss : 57.829910 , test loss : 30.182486\n",
      "epoch = 13 train_loss : 50.946491 , test loss : 26.472439\n",
      "epoch = 17 train_loss : 43.144169 , test loss : 23.874323\n",
      "epoch = 19 train_loss : 42.897598 , test loss : 23.736223\n",
      "epoch = 22 train_loss : 41.821518 , test loss : 22.071968\n",
      "epoch = 40 train_loss : 38.422337 , test loss : 21.727371\n",
      "epoch = 43 train_loss : 39.473049 , test loss : 21.671101\n",
      "epoch = 65 train_loss : 37.723583 , test loss : 21.551376\n",
      "epoch = 70 train_loss : 37.728294 , test loss : 21.505310\n",
      "epoch = 76 train_loss : 36.851471 , test loss : 21.490700\n",
      "epoch = 106 train_loss : 37.714268 , test loss : 21.099810\n",
      "epoch = 124 train_loss : 37.353622 , test loss : 20.952677\n",
      "epoch = 251 train_loss : 37.325062 , test loss : 20.905018\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 37.325062,test loss : 20.905018\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 243.779495 , test loss : 225.714340\n",
      "epoch = 2 train_loss : 125.996101 , test loss : 167.298065\n",
      "epoch = 3 train_loss : 94.713829 , test loss : 104.134155\n",
      "epoch = 4 train_loss : 77.539474 , test loss : 91.158653\n",
      "epoch = 5 train_loss : 68.915871 , test loss : 75.734833\n",
      "epoch = 6 train_loss : 59.858738 , test loss : 73.648758\n",
      "epoch = 7 train_loss : 54.621819 , test loss : 62.527672\n",
      "epoch = 9 train_loss : 48.565594 , test loss : 54.083157\n",
      "epoch = 11 train_loss : 45.894913 , test loss : 50.538513\n",
      "epoch = 13 train_loss : 43.483994 , test loss : 45.703239\n",
      "epoch = 14 train_loss : 44.058201 , test loss : 44.136383\n",
      "epoch = 15 train_loss : 42.265835 , test loss : 42.654675\n",
      "epoch = 18 train_loss : 39.509907 , test loss : 42.124271\n",
      "epoch = 20 train_loss : 38.539719 , test loss : 39.985474\n",
      "epoch = 21 train_loss : 37.813538 , test loss : 38.976456\n",
      "epoch = 22 train_loss : 37.827145 , test loss : 38.188316\n",
      "epoch = 26 train_loss : 37.022041 , test loss : 36.775948\n",
      "epoch = 35 train_loss : 35.974651 , test loss : 35.392849\n",
      "epoch = 42 train_loss : 35.610878 , test loss : 35.058311\n",
      "epoch = 43 train_loss : 36.030460 , test loss : 34.184673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 49 train_loss : 34.928020 , test loss : 33.869534\n",
      "epoch = 51 train_loss : 36.700760 , test loss : 33.787556\n",
      "epoch = 63 train_loss : 35.367897 , test loss : 33.556740\n",
      "epoch = 64 train_loss : 34.876911 , test loss : 32.767750\n",
      "epoch = 76 train_loss : 34.153156 , test loss : 32.471138\n",
      "epoch = 137 train_loss : 33.618958 , test loss : 32.308193\n",
      "epoch = 166 train_loss : 34.511906 , test loss : 32.157074\n",
      "epoch = 198 train_loss : 33.693707 , test loss : 31.952950\n",
      "epoch = 460 train_loss : 33.335690 , test loss : 31.911142\n",
      "epoch = 670 train_loss : 33.825115 , test loss : 31.892073\n",
      "epoch = 784 train_loss : 33.554974 , test loss : 31.700590\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.554974,test loss : 31.700590\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 33.122111,total test loss mean : 34.370378 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],512),nn.Linear(512,256),nn.Linear(256,64),nn.Linear(64,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T08:49:30.635619Z",
     "start_time": "2021-12-28T08:41:07.260827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 288.760529 , test loss : 299.105316\n",
      "epoch = 2 train_loss : 234.510315 , test loss : 249.888062\n",
      "epoch = 3 train_loss : 229.500900 , test loss : 245.100098\n",
      "epoch = 4 train_loss : 221.382858 , test loss : 236.312546\n",
      "epoch = 5 train_loss : 214.687164 , test loss : 229.509644\n",
      "epoch = 6 train_loss : 208.009369 , test loss : 222.841476\n",
      "epoch = 7 train_loss : 201.419632 , test loss : 216.145477\n",
      "epoch = 8 train_loss : 195.092239 , test loss : 209.845413\n",
      "epoch = 9 train_loss : 188.901154 , test loss : 203.525360\n",
      "epoch = 10 train_loss : 183.050842 , test loss : 197.447571\n",
      "epoch = 11 train_loss : 177.628250 , test loss : 191.980637\n",
      "epoch = 12 train_loss : 172.545654 , test loss : 186.748230\n",
      "epoch = 13 train_loss : 167.733047 , test loss : 181.838089\n",
      "epoch = 14 train_loss : 163.276962 , test loss : 177.231750\n",
      "epoch = 15 train_loss : 159.083923 , test loss : 172.846954\n",
      "epoch = 16 train_loss : 155.173172 , test loss : 168.875824\n",
      "epoch = 17 train_loss : 151.477036 , test loss : 165.003204\n",
      "epoch = 18 train_loss : 147.988449 , test loss : 161.379242\n",
      "epoch = 19 train_loss : 144.766418 , test loss : 157.974915\n",
      "epoch = 20 train_loss : 141.702652 , test loss : 154.786331\n",
      "epoch = 21 train_loss : 138.850693 , test loss : 151.810074\n",
      "epoch = 22 train_loss : 136.153442 , test loss : 148.956390\n",
      "epoch = 23 train_loss : 133.528610 , test loss : 146.234451\n",
      "epoch = 24 train_loss : 131.135101 , test loss : 143.687973\n",
      "epoch = 25 train_loss : 128.772476 , test loss : 141.266464\n",
      "epoch = 26 train_loss : 126.515480 , test loss : 138.836212\n",
      "epoch = 27 train_loss : 124.349731 , test loss : 136.594040\n",
      "epoch = 28 train_loss : 122.293922 , test loss : 134.343323\n",
      "epoch = 29 train_loss : 120.304153 , test loss : 132.371521\n",
      "epoch = 30 train_loss : 118.363808 , test loss : 130.188141\n",
      "epoch = 31 train_loss : 116.467323 , test loss : 128.262619\n",
      "epoch = 32 train_loss : 114.686279 , test loss : 126.483391\n",
      "epoch = 33 train_loss : 112.885040 , test loss : 124.455025\n",
      "epoch = 34 train_loss : 111.236076 , test loss : 122.857300\n",
      "epoch = 35 train_loss : 109.572433 , test loss : 120.952904\n",
      "epoch = 36 train_loss : 107.920898 , test loss : 119.355888\n",
      "epoch = 37 train_loss : 106.424294 , test loss : 117.621040\n",
      "epoch = 38 train_loss : 104.923332 , test loss : 116.232704\n",
      "epoch = 39 train_loss : 103.423866 , test loss : 114.628540\n",
      "epoch = 40 train_loss : 102.008629 , test loss : 113.074272\n",
      "epoch = 41 train_loss : 100.636841 , test loss : 111.639954\n",
      "epoch = 42 train_loss : 99.297279 , test loss : 110.284302\n",
      "epoch = 43 train_loss : 97.988602 , test loss : 108.812714\n",
      "epoch = 44 train_loss : 96.728951 , test loss : 107.535088\n",
      "epoch = 45 train_loss : 95.500641 , test loss : 106.223793\n",
      "epoch = 46 train_loss : 94.307854 , test loss : 104.948433\n",
      "epoch = 47 train_loss : 93.210068 , test loss : 103.856277\n",
      "epoch = 48 train_loss : 92.108650 , test loss : 102.705917\n",
      "epoch = 49 train_loss : 91.024406 , test loss : 101.445145\n",
      "epoch = 50 train_loss : 89.987640 , test loss : 100.340401\n",
      "epoch = 51 train_loss : 88.950722 , test loss : 99.264282\n",
      "epoch = 52 train_loss : 88.182724 , test loss : 98.617790\n",
      "epoch = 53 train_loss : 87.138771 , test loss : 97.226166\n",
      "epoch = 54 train_loss : 86.397858 , test loss : 96.728958\n",
      "epoch = 55 train_loss : 85.282005 , test loss : 95.349655\n",
      "epoch = 56 train_loss : 84.455536 , test loss : 94.420959\n",
      "epoch = 57 train_loss : 83.767792 , test loss : 93.880882\n",
      "epoch = 58 train_loss : 82.858002 , test loss : 92.677269\n",
      "epoch = 59 train_loss : 82.076759 , test loss : 91.957504\n",
      "epoch = 60 train_loss : 81.311081 , test loss : 91.064102\n",
      "epoch = 61 train_loss : 80.754791 , test loss : 90.306976\n",
      "epoch = 62 train_loss : 79.956329 , test loss : 89.518929\n",
      "epoch = 63 train_loss : 79.386887 , test loss : 89.093857\n",
      "epoch = 64 train_loss : 78.648232 , test loss : 88.081123\n",
      "epoch = 65 train_loss : 77.991249 , test loss : 87.510361\n",
      "epoch = 66 train_loss : 77.351219 , test loss : 86.767235\n",
      "epoch = 67 train_loss : 76.831711 , test loss : 86.088974\n",
      "epoch = 68 train_loss : 76.203064 , test loss : 85.464645\n",
      "epoch = 69 train_loss : 75.698303 , test loss : 84.997925\n",
      "epoch = 70 train_loss : 75.260162 , test loss : 84.285110\n",
      "epoch = 71 train_loss : 74.639923 , test loss : 83.673752\n",
      "epoch = 72 train_loss : 74.428444 , test loss : 83.666756\n",
      "epoch = 73 train_loss : 73.613968 , test loss : 82.640038\n",
      "epoch = 74 train_loss : 73.165230 , test loss : 82.038895\n",
      "epoch = 75 train_loss : 72.699684 , test loss : 81.646072\n",
      "epoch = 76 train_loss : 72.234894 , test loss : 81.122063\n",
      "epoch = 77 train_loss : 71.776962 , test loss : 80.505302\n",
      "epoch = 78 train_loss : 71.352257 , test loss : 80.091446\n",
      "epoch = 79 train_loss : 71.041595 , test loss : 79.804893\n",
      "epoch = 80 train_loss : 70.529564 , test loss : 79.111160\n",
      "epoch = 81 train_loss : 70.144524 , test loss : 78.649292\n",
      "epoch = 82 train_loss : 70.112083 , test loss : 78.397865\n",
      "epoch = 83 train_loss : 69.430016 , test loss : 77.921043\n",
      "epoch = 84 train_loss : 69.016006 , test loss : 77.347778\n",
      "epoch = 85 train_loss : 68.648308 , test loss : 76.937698\n",
      "epoch = 86 train_loss : 68.294350 , test loss : 76.589760\n",
      "epoch = 87 train_loss : 68.218178 , test loss : 76.589188\n",
      "epoch = 88 train_loss : 67.625450 , test loss : 75.840775\n",
      "epoch = 89 train_loss : 67.483406 , test loss : 75.463608\n",
      "epoch = 90 train_loss : 67.054008 , test loss : 75.229622\n",
      "epoch = 91 train_loss : 66.670029 , test loss : 74.621559\n",
      "epoch = 92 train_loss : 66.341141 , test loss : 74.251900\n",
      "epoch = 93 train_loss : 66.000626 , test loss : 73.890121\n",
      "epoch = 94 train_loss : 65.869453 , test loss : 73.843895\n",
      "epoch = 95 train_loss : 65.403923 , test loss : 73.194656\n",
      "epoch = 96 train_loss : 65.100822 , test loss : 72.880051\n",
      "epoch = 97 train_loss : 64.983093 , test loss : 72.598877\n",
      "epoch = 98 train_loss : 64.553284 , test loss : 72.271156\n",
      "epoch = 99 train_loss : 64.273972 , test loss : 71.967529\n",
      "epoch = 100 train_loss : 64.106407 , test loss : 71.592201\n",
      "epoch = 101 train_loss : 63.872005 , test loss : 71.309395\n",
      "epoch = 102 train_loss : 63.536289 , test loss : 71.126495\n",
      "epoch = 103 train_loss : 63.276413 , test loss : 70.824310\n",
      "epoch = 104 train_loss : 62.896847 , test loss : 70.306473\n",
      "epoch = 105 train_loss : 62.709263 , test loss : 70.019897\n",
      "epoch = 106 train_loss : 62.518417 , test loss : 69.975327\n",
      "epoch = 107 train_loss : 62.130379 , test loss : 69.428925\n",
      "epoch = 108 train_loss : 61.879772 , test loss : 69.160278\n",
      "epoch = 109 train_loss : 61.640450 , test loss : 68.842010\n",
      "epoch = 110 train_loss : 61.599636 , test loss : 68.671997\n",
      "epoch = 111 train_loss : 61.594654 , test loss : 68.581909\n",
      "epoch = 112 train_loss : 60.901993 , test loss : 68.004410\n",
      "epoch = 113 train_loss : 60.727131 , test loss : 67.891418\n",
      "epoch = 114 train_loss : 60.445679 , test loss : 67.531525\n",
      "epoch = 115 train_loss : 60.201042 , test loss : 67.190147\n",
      "epoch = 116 train_loss : 60.000683 , test loss : 66.939629\n",
      "epoch = 117 train_loss : 59.750950 , test loss : 66.725319\n",
      "epoch = 118 train_loss : 59.522835 , test loss : 66.470299\n",
      "epoch = 119 train_loss : 59.276936 , test loss : 66.125946\n",
      "epoch = 120 train_loss : 59.067291 , test loss : 65.886070\n",
      "epoch = 121 train_loss : 59.110157 , test loss : 65.803581\n",
      "epoch = 122 train_loss : 58.887188 , test loss : 65.789360\n",
      "epoch = 123 train_loss : 58.459980 , test loss : 65.132004\n",
      "epoch = 124 train_loss : 58.234371 , test loss : 64.893433\n",
      "epoch = 125 train_loss : 57.952618 , test loss : 64.669197\n",
      "epoch = 127 train_loss : 57.761402 , test loss : 64.285843\n",
      "epoch = 129 train_loss : 57.233688 , test loss : 63.742580\n",
      "epoch = 130 train_loss : 56.905216 , test loss : 63.428410\n",
      "epoch = 131 train_loss : 56.704453 , test loss : 63.194378\n",
      "epoch = 132 train_loss : 56.508152 , test loss : 63.050411\n",
      "epoch = 133 train_loss : 56.338768 , test loss : 62.755875\n",
      "epoch = 135 train_loss : 56.100174 , test loss : 62.426037\n",
      "epoch = 136 train_loss : 55.661030 , test loss : 62.076000\n",
      "epoch = 138 train_loss : 55.481068 , test loss : 61.934654\n",
      "epoch = 139 train_loss : 55.096684 , test loss : 61.392857\n",
      "epoch = 140 train_loss : 54.883949 , test loss : 61.193428\n",
      "epoch = 141 train_loss : 54.687359 , test loss : 61.006596\n",
      "epoch = 142 train_loss : 54.487957 , test loss : 60.771271\n",
      "epoch = 143 train_loss : 54.355160 , test loss : 60.551670\n",
      "epoch = 145 train_loss : 53.913155 , test loss : 60.093819\n",
      "epoch = 147 train_loss : 53.564137 , test loss : 59.777321\n",
      "epoch = 148 train_loss : 53.354549 , test loss : 59.526760\n",
      "epoch = 149 train_loss : 53.368587 , test loss : 59.386086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 150 train_loss : 53.291855 , test loss : 59.281574\n",
      "epoch = 151 train_loss : 53.142475 , test loss : 59.100426\n",
      "epoch = 152 train_loss : 52.649277 , test loss : 58.768467\n",
      "epoch = 154 train_loss : 52.350552 , test loss : 58.456951\n",
      "epoch = 155 train_loss : 52.252956 , test loss : 58.362350\n",
      "epoch = 156 train_loss : 52.162903 , test loss : 58.284046\n",
      "epoch = 157 train_loss : 51.896244 , test loss : 57.977318\n",
      "epoch = 158 train_loss : 51.652313 , test loss : 57.675774\n",
      "epoch = 159 train_loss : 51.408676 , test loss : 57.392944\n",
      "epoch = 160 train_loss : 51.537674 , test loss : 57.357029\n",
      "epoch = 161 train_loss : 51.573090 , test loss : 57.348331\n",
      "epoch = 162 train_loss : 51.365749 , test loss : 57.123726\n",
      "epoch = 163 train_loss : 50.794296 , test loss : 56.622768\n",
      "epoch = 164 train_loss : 50.613033 , test loss : 56.541996\n",
      "epoch = 165 train_loss : 50.449718 , test loss : 56.373264\n",
      "epoch = 167 train_loss : 50.368111 , test loss : 56.317455\n",
      "epoch = 168 train_loss : 50.050758 , test loss : 55.969307\n",
      "epoch = 169 train_loss : 49.781536 , test loss : 55.597729\n",
      "epoch = 171 train_loss : 49.498165 , test loss : 55.316315\n",
      "epoch = 172 train_loss : 49.316025 , test loss : 55.108837\n",
      "epoch = 173 train_loss : 49.241848 , test loss : 55.072220\n",
      "epoch = 174 train_loss : 49.059830 , test loss : 54.864544\n",
      "epoch = 175 train_loss : 48.939548 , test loss : 54.613750\n",
      "epoch = 176 train_loss : 48.722439 , test loss : 54.467346\n",
      "epoch = 178 train_loss : 48.464180 , test loss : 54.194176\n",
      "epoch = 179 train_loss : 48.288677 , test loss : 53.994808\n",
      "epoch = 180 train_loss : 48.128998 , test loss : 53.806400\n",
      "epoch = 181 train_loss : 48.004166 , test loss : 53.648750\n",
      "epoch = 183 train_loss : 47.842567 , test loss : 53.567627\n",
      "epoch = 184 train_loss : 47.696594 , test loss : 53.256283\n",
      "epoch = 186 train_loss : 47.549889 , test loss : 53.057301\n",
      "epoch = 187 train_loss : 47.299530 , test loss : 52.828266\n",
      "epoch = 188 train_loss : 47.104649 , test loss : 52.772568\n",
      "epoch = 189 train_loss : 46.901634 , test loss : 52.469524\n",
      "epoch = 190 train_loss : 46.869118 , test loss : 52.391342\n",
      "epoch = 191 train_loss : 46.675575 , test loss : 52.200191\n",
      "epoch = 193 train_loss : 46.451027 , test loss : 52.079449\n",
      "epoch = 194 train_loss : 46.338879 , test loss : 51.960934\n",
      "epoch = 195 train_loss : 46.146877 , test loss : 51.710468\n",
      "epoch = 196 train_loss : 46.005421 , test loss : 51.542969\n",
      "epoch = 197 train_loss : 45.889534 , test loss : 51.442890\n",
      "epoch = 199 train_loss : 45.638615 , test loss : 51.138325\n",
      "epoch = 200 train_loss : 45.517025 , test loss : 51.017502\n",
      "epoch = 201 train_loss : 45.442699 , test loss : 50.882694\n",
      "epoch = 202 train_loss : 45.278622 , test loss : 50.786034\n",
      "epoch = 203 train_loss : 45.172337 , test loss : 50.655640\n",
      "epoch = 204 train_loss : 45.051552 , test loss : 50.511333\n",
      "epoch = 205 train_loss : 44.933590 , test loss : 50.429802\n",
      "epoch = 206 train_loss : 44.868614 , test loss : 50.388802\n",
      "epoch = 207 train_loss : 44.762993 , test loss : 50.276749\n",
      "epoch = 208 train_loss : 44.593452 , test loss : 50.055614\n",
      "epoch = 210 train_loss : 44.398830 , test loss : 49.883980\n",
      "epoch = 212 train_loss : 44.301834 , test loss : 49.648174\n",
      "epoch = 213 train_loss : 44.056870 , test loss : 49.516712\n",
      "epoch = 215 train_loss : 43.855644 , test loss : 49.334282\n",
      "epoch = 216 train_loss : 43.939545 , test loss : 49.275276\n",
      "epoch = 217 train_loss : 43.688377 , test loss : 49.047710\n",
      "epoch = 219 train_loss : 43.428959 , test loss : 48.857807\n",
      "epoch = 220 train_loss : 43.474953 , test loss : 48.794704\n",
      "epoch = 221 train_loss : 43.377491 , test loss : 48.679871\n",
      "epoch = 222 train_loss : 43.187984 , test loss : 48.529572\n",
      "epoch = 225 train_loss : 42.841991 , test loss : 48.254131\n",
      "epoch = 227 train_loss : 42.654018 , test loss : 48.062416\n",
      "epoch = 230 train_loss : 42.690948 , test loss : 47.931896\n",
      "epoch = 231 train_loss : 42.363670 , test loss : 47.820694\n",
      "epoch = 232 train_loss : 42.230732 , test loss : 47.580921\n",
      "epoch = 233 train_loss : 42.182606 , test loss : 47.480766\n",
      "epoch = 235 train_loss : 42.034081 , test loss : 47.377762\n",
      "epoch = 237 train_loss : 41.797623 , test loss : 47.141453\n",
      "epoch = 238 train_loss : 41.800377 , test loss : 47.072880\n",
      "epoch = 239 train_loss : 41.620323 , test loss : 46.981583\n",
      "epoch = 240 train_loss : 41.542976 , test loss : 46.964165\n",
      "epoch = 241 train_loss : 41.467583 , test loss : 46.879509\n",
      "epoch = 242 train_loss : 41.392387 , test loss : 46.808601\n",
      "epoch = 243 train_loss : 41.280045 , test loss : 46.677120\n",
      "epoch = 244 train_loss : 41.201355 , test loss : 46.564693\n",
      "epoch = 246 train_loss : 41.051914 , test loss : 46.452675\n",
      "epoch = 248 train_loss : 40.930954 , test loss : 46.252533\n",
      "epoch = 252 train_loss : 40.593533 , test loss : 46.013653\n",
      "epoch = 254 train_loss : 40.447708 , test loss : 45.807270\n",
      "epoch = 257 train_loss : 40.521507 , test loss : 45.778969\n",
      "epoch = 258 train_loss : 40.267822 , test loss : 45.746990\n",
      "epoch = 259 train_loss : 40.120705 , test loss : 45.571686\n",
      "epoch = 261 train_loss : 40.004745 , test loss : 45.443916\n",
      "epoch = 262 train_loss : 39.945721 , test loss : 45.383652\n",
      "epoch = 264 train_loss : 39.906380 , test loss : 45.205498\n",
      "epoch = 265 train_loss : 39.779671 , test loss : 45.108589\n",
      "epoch = 266 train_loss : 39.632198 , test loss : 45.008575\n",
      "epoch = 272 train_loss : 39.276890 , test loss : 44.653454\n",
      "epoch = 275 train_loss : 39.102303 , test loss : 44.481773\n",
      "epoch = 276 train_loss : 39.018917 , test loss : 44.441376\n",
      "epoch = 279 train_loss : 39.039909 , test loss : 44.357166\n",
      "epoch = 281 train_loss : 38.976524 , test loss : 44.263985\n",
      "epoch = 284 train_loss : 38.596043 , test loss : 43.984245\n",
      "epoch = 285 train_loss : 38.526188 , test loss : 43.942978\n",
      "epoch = 286 train_loss : 38.523766 , test loss : 43.881695\n",
      "epoch = 288 train_loss : 38.425156 , test loss : 43.804741\n",
      "epoch = 291 train_loss : 38.209854 , test loss : 43.644337\n",
      "epoch = 294 train_loss : 38.065620 , test loss : 43.551888\n",
      "epoch = 295 train_loss : 38.135056 , test loss : 43.508297\n",
      "epoch = 296 train_loss : 37.958786 , test loss : 43.420517\n",
      "epoch = 298 train_loss : 37.881268 , test loss : 43.415432\n",
      "epoch = 299 train_loss : 37.852680 , test loss : 43.392807\n",
      "epoch = 301 train_loss : 37.751282 , test loss : 43.198093\n",
      "epoch = 303 train_loss : 37.639622 , test loss : 43.124435\n",
      "epoch = 305 train_loss : 37.559814 , test loss : 43.079418\n",
      "epoch = 307 train_loss : 37.454121 , test loss : 42.972549\n",
      "epoch = 312 train_loss : 37.289425 , test loss : 42.914661\n",
      "epoch = 314 train_loss : 37.207302 , test loss : 42.820385\n",
      "epoch = 316 train_loss : 37.120506 , test loss : 42.608761\n",
      "epoch = 318 train_loss : 37.008801 , test loss : 42.575180\n",
      "epoch = 321 train_loss : 36.913334 , test loss : 42.552692\n",
      "epoch = 322 train_loss : 36.848591 , test loss : 42.418659\n",
      "epoch = 325 train_loss : 36.736034 , test loss : 42.350250\n",
      "epoch = 326 train_loss : 36.733932 , test loss : 42.283195\n",
      "epoch = 329 train_loss : 36.593952 , test loss : 42.244526\n",
      "epoch = 332 train_loss : 36.482628 , test loss : 42.099785\n",
      "epoch = 333 train_loss : 36.499409 , test loss : 42.059757\n",
      "epoch = 334 train_loss : 36.420589 , test loss : 42.041828\n",
      "epoch = 336 train_loss : 36.352757 , test loss : 42.024551\n",
      "epoch = 338 train_loss : 36.285275 , test loss : 41.936432\n",
      "epoch = 339 train_loss : 36.254028 , test loss : 41.903351\n",
      "epoch = 340 train_loss : 36.312714 , test loss : 41.883625\n",
      "epoch = 341 train_loss : 36.262600 , test loss : 41.822624\n",
      "epoch = 343 train_loss : 36.123753 , test loss : 41.800354\n",
      "epoch = 344 train_loss : 36.143623 , test loss : 41.758568\n",
      "epoch = 346 train_loss : 36.034309 , test loss : 41.735634\n",
      "epoch = 347 train_loss : 35.998768 , test loss : 41.666954\n",
      "epoch = 348 train_loss : 35.970356 , test loss : 41.635635\n",
      "epoch = 352 train_loss : 35.872074 , test loss : 41.533302\n",
      "epoch = 353 train_loss : 35.817833 , test loss : 41.531082\n",
      "epoch = 354 train_loss : 35.793358 , test loss : 41.479099\n",
      "epoch = 356 train_loss : 35.763832 , test loss : 41.432091\n",
      "epoch = 357 train_loss : 35.769318 , test loss : 41.421791\n",
      "epoch = 360 train_loss : 35.660473 , test loss : 41.344402\n",
      "epoch = 363 train_loss : 35.548634 , test loss : 41.305389\n",
      "epoch = 367 train_loss : 35.511528 , test loss : 41.212566\n",
      "epoch = 368 train_loss : 35.417206 , test loss : 41.191505\n",
      "epoch = 369 train_loss : 35.416573 , test loss : 41.134983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 372 train_loss : 35.313892 , test loss : 41.124584\n",
      "epoch = 374 train_loss : 35.264469 , test loss : 41.046535\n",
      "epoch = 378 train_loss : 35.344063 , test loss : 41.030548\n",
      "epoch = 380 train_loss : 35.121494 , test loss : 40.943882\n",
      "epoch = 381 train_loss : 35.099327 , test loss : 40.893944\n",
      "epoch = 384 train_loss : 35.084538 , test loss : 40.880508\n",
      "epoch = 385 train_loss : 35.015724 , test loss : 40.830517\n",
      "epoch = 390 train_loss : 34.911461 , test loss : 40.754025\n",
      "epoch = 393 train_loss : 34.921089 , test loss : 40.717049\n",
      "epoch = 394 train_loss : 34.929749 , test loss : 40.702599\n",
      "epoch = 398 train_loss : 34.828613 , test loss : 40.648743\n",
      "epoch = 399 train_loss : 34.788113 , test loss : 40.614304\n",
      "epoch = 402 train_loss : 34.666615 , test loss : 40.573494\n",
      "epoch = 403 train_loss : 34.759628 , test loss : 40.570953\n",
      "epoch = 407 train_loss : 34.578041 , test loss : 40.525467\n",
      "epoch = 410 train_loss : 34.514271 , test loss : 40.450233\n",
      "epoch = 412 train_loss : 34.477901 , test loss : 40.423401\n",
      "epoch = 415 train_loss : 34.450367 , test loss : 40.337147\n",
      "epoch = 418 train_loss : 34.426830 , test loss : 40.333698\n",
      "epoch = 421 train_loss : 34.331177 , test loss : 40.318069\n",
      "epoch = 423 train_loss : 34.301029 , test loss : 40.311951\n",
      "epoch = 424 train_loss : 34.324112 , test loss : 40.243488\n",
      "epoch = 425 train_loss : 34.259239 , test loss : 40.234516\n",
      "epoch = 427 train_loss : 34.269321 , test loss : 40.203938\n",
      "epoch = 430 train_loss : 34.233646 , test loss : 40.170521\n",
      "epoch = 436 train_loss : 34.125462 , test loss : 40.106968\n",
      "epoch = 443 train_loss : 34.024227 , test loss : 40.023251\n",
      "epoch = 445 train_loss : 33.964142 , test loss : 40.011875\n",
      "epoch = 446 train_loss : 34.061115 , test loss : 39.983013\n",
      "epoch = 447 train_loss : 33.964886 , test loss : 39.973232\n",
      "epoch = 452 train_loss : 33.869343 , test loss : 39.968086\n",
      "epoch = 453 train_loss : 33.865440 , test loss : 39.930378\n",
      "epoch = 457 train_loss : 33.913731 , test loss : 39.919617\n",
      "epoch = 458 train_loss : 33.784359 , test loss : 39.889046\n",
      "epoch = 461 train_loss : 33.857807 , test loss : 39.859985\n",
      "epoch = 464 train_loss : 33.719139 , test loss : 39.821014\n",
      "epoch = 473 train_loss : 33.692833 , test loss : 39.767990\n",
      "epoch = 474 train_loss : 33.700039 , test loss : 39.758156\n",
      "epoch = 477 train_loss : 33.590202 , test loss : 39.737026\n",
      "epoch = 479 train_loss : 33.541508 , test loss : 39.733093\n",
      "epoch = 485 train_loss : 33.549717 , test loss : 39.661488\n",
      "epoch = 487 train_loss : 33.515694 , test loss : 39.638515\n",
      "epoch = 495 train_loss : 33.492729 , test loss : 39.605721\n",
      "epoch = 498 train_loss : 33.368992 , test loss : 39.521080\n",
      "epoch = 506 train_loss : 33.285004 , test loss : 39.502956\n",
      "epoch = 507 train_loss : 33.275040 , test loss : 39.490925\n",
      "epoch = 511 train_loss : 33.272182 , test loss : 39.478237\n",
      "epoch = 515 train_loss : 33.184509 , test loss : 39.476898\n",
      "epoch = 517 train_loss : 33.262558 , test loss : 39.463757\n",
      "epoch = 518 train_loss : 33.228291 , test loss : 39.424809\n",
      "epoch = 524 train_loss : 33.110172 , test loss : 39.393810\n",
      "epoch = 525 train_loss : 33.151558 , test loss : 39.379612\n",
      "epoch = 528 train_loss : 33.133389 , test loss : 39.338577\n",
      "epoch = 540 train_loss : 32.983814 , test loss : 39.321507\n",
      "epoch = 545 train_loss : 33.006660 , test loss : 39.280357\n",
      "epoch = 552 train_loss : 32.949043 , test loss : 39.239708\n",
      "epoch = 556 train_loss : 32.885071 , test loss : 39.225716\n",
      "epoch = 559 train_loss : 32.896130 , test loss : 39.196774\n",
      "epoch = 566 train_loss : 32.796104 , test loss : 39.185745\n",
      "epoch = 567 train_loss : 32.807926 , test loss : 39.168156\n",
      "epoch = 574 train_loss : 32.764359 , test loss : 39.156559\n",
      "epoch = 577 train_loss : 32.726719 , test loss : 39.142715\n",
      "epoch = 581 train_loss : 32.727985 , test loss : 39.131844\n",
      "epoch = 590 train_loss : 32.716442 , test loss : 39.114944\n",
      "epoch = 591 train_loss : 32.679272 , test loss : 39.083580\n",
      "epoch = 593 train_loss : 32.640148 , test loss : 39.075050\n",
      "epoch = 597 train_loss : 32.739738 , test loss : 39.065277\n",
      "epoch = 605 train_loss : 32.569912 , test loss : 39.022964\n",
      "epoch = 611 train_loss : 32.640148 , test loss : 39.007713\n",
      "epoch = 615 train_loss : 32.582127 , test loss : 38.998978\n",
      "epoch = 617 train_loss : 32.530693 , test loss : 38.955280\n",
      "epoch = 634 train_loss : 32.450359 , test loss : 38.933655\n",
      "epoch = 637 train_loss : 32.410255 , test loss : 38.924191\n",
      "epoch = 648 train_loss : 32.443001 , test loss : 38.910015\n",
      "epoch = 649 train_loss : 32.365730 , test loss : 38.889988\n",
      "epoch = 653 train_loss : 32.350479 , test loss : 38.864590\n",
      "epoch = 660 train_loss : 32.335869 , test loss : 38.849773\n",
      "epoch = 671 train_loss : 32.373554 , test loss : 38.848663\n",
      "epoch = 674 train_loss : 32.289555 , test loss : 38.802456\n",
      "epoch = 691 train_loss : 32.196354 , test loss : 38.770210\n",
      "epoch = 705 train_loss : 32.153126 , test loss : 38.756336\n",
      "epoch = 714 train_loss : 32.154034 , test loss : 38.738022\n",
      "epoch = 719 train_loss : 32.097519 , test loss : 38.724701\n",
      "epoch = 726 train_loss : 32.143978 , test loss : 38.713486\n",
      "epoch = 735 train_loss : 32.095081 , test loss : 38.708359\n",
      "epoch = 741 train_loss : 32.150021 , test loss : 38.707439\n",
      "epoch = 743 train_loss : 32.092636 , test loss : 38.701794\n",
      "epoch = 747 train_loss : 32.040493 , test loss : 38.678875\n",
      "epoch = 750 train_loss : 32.012089 , test loss : 38.656448\n",
      "epoch = 755 train_loss : 32.008675 , test loss : 38.646320\n",
      "epoch = 773 train_loss : 31.981619 , test loss : 38.589417\n",
      "epoch = 818 train_loss : 31.855583 , test loss : 38.568264\n",
      "epoch = 838 train_loss : 31.870829 , test loss : 38.560863\n",
      "epoch = 845 train_loss : 31.850653 , test loss : 38.531616\n",
      "epoch = 882 train_loss : 31.816465 , test loss : 38.524441\n",
      "epoch = 886 train_loss : 31.752953 , test loss : 38.519581\n",
      "epoch = 897 train_loss : 31.738382 , test loss : 38.510960\n",
      "epoch = 907 train_loss : 31.735823 , test loss : 38.496552\n",
      "epoch = 929 train_loss : 31.722500 , test loss : 38.461803\n",
      "epoch = 999 train_loss : 31.615479 , test loss : 38.434673\n",
      "epoch = 1075 train_loss : 31.575268 , test loss : 38.434391\n",
      "epoch = 1106 train_loss : 31.600471 , test loss : 38.407646\n",
      "epoch = 1197 train_loss : 31.527287 , test loss : 38.403160\n",
      "epoch = 1295 train_loss : 31.433979 , test loss : 38.399971\n",
      "epoch = 1329 train_loss : 31.422678 , test loss : 38.393585\n",
      "epoch = 1467 train_loss : 31.406178 , test loss : 38.388405\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 31.406178,test loss : 38.388405\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 516.044189 , test loss : 498.930359\n",
      "epoch = 2 train_loss : 349.910217 , test loss : 353.481293\n",
      "epoch = 3 train_loss : 336.089203 , test loss : 346.770538\n",
      "epoch = 4 train_loss : 322.383484 , test loss : 331.964417\n",
      "epoch = 5 train_loss : 309.450592 , test loss : 318.207764\n",
      "epoch = 6 train_loss : 297.041046 , test loss : 305.976959\n",
      "epoch = 7 train_loss : 284.771851 , test loss : 294.211456\n",
      "epoch = 8 train_loss : 272.732452 , test loss : 283.155853\n",
      "epoch = 9 train_loss : 261.470245 , test loss : 272.232025\n",
      "epoch = 10 train_loss : 250.852325 , test loss : 261.283417\n",
      "epoch = 11 train_loss : 240.643295 , test loss : 252.299271\n",
      "epoch = 12 train_loss : 231.226089 , test loss : 243.121826\n",
      "epoch = 13 train_loss : 222.241806 , test loss : 235.045883\n",
      "epoch = 14 train_loss : 213.982758 , test loss : 226.628250\n",
      "epoch = 15 train_loss : 206.157440 , test loss : 219.398102\n",
      "epoch = 16 train_loss : 199.047485 , test loss : 213.018753\n",
      "epoch = 17 train_loss : 192.419724 , test loss : 206.367172\n",
      "epoch = 18 train_loss : 186.260910 , test loss : 201.054199\n",
      "epoch = 19 train_loss : 180.554886 , test loss : 195.272354\n",
      "epoch = 20 train_loss : 175.189789 , test loss : 190.518143\n",
      "epoch = 21 train_loss : 170.388474 , test loss : 186.158951\n",
      "epoch = 22 train_loss : 165.784210 , test loss : 181.863159\n",
      "epoch = 23 train_loss : 161.561508 , test loss : 177.760223\n",
      "epoch = 24 train_loss : 157.750092 , test loss : 174.343613\n",
      "epoch = 25 train_loss : 154.168808 , test loss : 171.222336\n",
      "epoch = 26 train_loss : 150.767044 , test loss : 167.849670\n",
      "epoch = 27 train_loss : 147.617462 , test loss : 164.937454\n",
      "epoch = 28 train_loss : 144.663025 , test loss : 162.145096\n",
      "epoch = 29 train_loss : 142.007278 , test loss : 159.511978\n",
      "epoch = 30 train_loss : 139.499130 , test loss : 157.042236\n",
      "epoch = 31 train_loss : 137.074448 , test loss : 155.163483\n",
      "epoch = 32 train_loss : 134.788498 , test loss : 152.767502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 33 train_loss : 132.719315 , test loss : 150.769745\n",
      "epoch = 34 train_loss : 130.729111 , test loss : 148.753815\n",
      "epoch = 35 train_loss : 128.893021 , test loss : 146.882385\n",
      "epoch = 36 train_loss : 127.122955 , test loss : 145.417603\n",
      "epoch = 37 train_loss : 125.385361 , test loss : 143.578232\n",
      "epoch = 38 train_loss : 123.784668 , test loss : 141.973450\n",
      "epoch = 39 train_loss : 122.241714 , test loss : 140.430420\n",
      "epoch = 40 train_loss : 120.738068 , test loss : 138.911957\n",
      "epoch = 41 train_loss : 119.343369 , test loss : 137.266495\n",
      "epoch = 42 train_loss : 117.946274 , test loss : 135.876160\n",
      "epoch = 43 train_loss : 116.632790 , test loss : 134.478088\n",
      "epoch = 44 train_loss : 115.374565 , test loss : 133.228760\n",
      "epoch = 45 train_loss : 114.149895 , test loss : 132.010483\n",
      "epoch = 46 train_loss : 112.949539 , test loss : 130.518661\n",
      "epoch = 47 train_loss : 111.775475 , test loss : 129.395218\n",
      "epoch = 48 train_loss : 110.656464 , test loss : 128.275238\n",
      "epoch = 49 train_loss : 109.603485 , test loss : 126.754547\n",
      "epoch = 50 train_loss : 108.486725 , test loss : 125.741524\n",
      "epoch = 51 train_loss : 107.437416 , test loss : 124.568947\n",
      "epoch = 52 train_loss : 106.410210 , test loss : 123.485550\n",
      "epoch = 53 train_loss : 105.431160 , test loss : 122.425453\n",
      "epoch = 54 train_loss : 104.485199 , test loss : 121.062988\n",
      "epoch = 55 train_loss : 103.504974 , test loss : 120.138069\n",
      "epoch = 56 train_loss : 102.604523 , test loss : 119.150604\n",
      "epoch = 57 train_loss : 101.696449 , test loss : 118.145149\n",
      "epoch = 58 train_loss : 100.817802 , test loss : 116.926765\n",
      "epoch = 59 train_loss : 99.928864 , test loss : 116.128288\n",
      "epoch = 60 train_loss : 99.064690 , test loss : 114.951752\n",
      "epoch = 61 train_loss : 98.225784 , test loss : 114.108055\n",
      "epoch = 62 train_loss : 97.403999 , test loss : 113.050934\n",
      "epoch = 63 train_loss : 96.587212 , test loss : 112.094009\n",
      "epoch = 64 train_loss : 95.804016 , test loss : 111.240616\n",
      "epoch = 65 train_loss : 95.099655 , test loss : 110.611328\n",
      "epoch = 66 train_loss : 94.280785 , test loss : 109.471504\n",
      "epoch = 67 train_loss : 93.556046 , test loss : 108.455498\n",
      "epoch = 68 train_loss : 92.890030 , test loss : 107.485588\n",
      "epoch = 69 train_loss : 92.230278 , test loss : 107.315590\n",
      "epoch = 70 train_loss : 91.372330 , test loss : 106.019531\n",
      "epoch = 71 train_loss : 91.031181 , test loss : 105.028358\n",
      "epoch = 73 train_loss : 89.506569 , test loss : 103.448349\n",
      "epoch = 74 train_loss : 88.829918 , test loss : 103.294212\n",
      "epoch = 75 train_loss : 88.136421 , test loss : 101.912140\n",
      "epoch = 76 train_loss : 87.432785 , test loss : 101.512291\n",
      "epoch = 77 train_loss : 86.824806 , test loss : 100.507942\n",
      "epoch = 78 train_loss : 86.310524 , test loss : 100.302063\n",
      "epoch = 79 train_loss : 85.716568 , test loss : 99.042229\n",
      "epoch = 80 train_loss : 85.071022 , test loss : 98.760605\n",
      "epoch = 81 train_loss : 84.458244 , test loss : 97.833534\n",
      "epoch = 82 train_loss : 83.910309 , test loss : 97.361153\n",
      "epoch = 83 train_loss : 83.316345 , test loss : 96.518387\n",
      "epoch = 84 train_loss : 82.772820 , test loss : 95.963600\n",
      "epoch = 85 train_loss : 82.256073 , test loss : 95.372231\n",
      "epoch = 86 train_loss : 81.719269 , test loss : 94.713570\n",
      "epoch = 87 train_loss : 81.214653 , test loss : 94.141800\n",
      "epoch = 88 train_loss : 80.806992 , test loss : 93.376495\n",
      "epoch = 89 train_loss : 80.323303 , test loss : 93.281715\n",
      "epoch = 90 train_loss : 79.722939 , test loss : 92.302788\n",
      "epoch = 91 train_loss : 79.225548 , test loss : 91.748169\n",
      "epoch = 92 train_loss : 78.823639 , test loss : 91.149254\n",
      "epoch = 93 train_loss : 78.432106 , test loss : 91.082436\n",
      "epoch = 94 train_loss : 77.845749 , test loss : 90.085686\n",
      "epoch = 95 train_loss : 77.448738 , test loss : 89.871674\n",
      "epoch = 96 train_loss : 77.082077 , test loss : 89.061806\n",
      "epoch = 97 train_loss : 76.639420 , test loss : 89.032417\n",
      "epoch = 98 train_loss : 76.129570 , test loss : 88.086655\n",
      "epoch = 99 train_loss : 75.707230 , test loss : 87.901917\n",
      "epoch = 100 train_loss : 75.367676 , test loss : 87.152313\n",
      "epoch = 101 train_loss : 74.852798 , test loss : 86.877785\n",
      "epoch = 102 train_loss : 74.434532 , test loss : 86.262138\n",
      "epoch = 103 train_loss : 74.053337 , test loss : 85.946503\n",
      "epoch = 104 train_loss : 73.682442 , test loss : 85.376602\n",
      "epoch = 105 train_loss : 73.282341 , test loss : 84.961815\n",
      "epoch = 106 train_loss : 72.922966 , test loss : 84.772591\n",
      "epoch = 107 train_loss : 72.677757 , test loss : 84.139526\n",
      "epoch = 108 train_loss : 72.189156 , test loss : 83.916176\n",
      "epoch = 109 train_loss : 71.900673 , test loss : 83.331779\n",
      "epoch = 110 train_loss : 71.470573 , test loss : 83.116486\n",
      "epoch = 111 train_loss : 71.187599 , test loss : 82.543121\n",
      "epoch = 112 train_loss : 70.846260 , test loss : 82.496117\n",
      "epoch = 113 train_loss : 70.429832 , test loss : 81.772377\n",
      "epoch = 114 train_loss : 70.367378 , test loss : 81.496803\n",
      "epoch = 116 train_loss : 69.437904 , test loss : 80.904655\n",
      "epoch = 117 train_loss : 69.281273 , test loss : 80.423454\n",
      "epoch = 118 train_loss : 68.860275 , test loss : 80.338028\n",
      "epoch = 119 train_loss : 68.484055 , test loss : 79.752495\n",
      "epoch = 120 train_loss : 68.724541 , test loss : 79.670746\n",
      "epoch = 122 train_loss : 67.567719 , test loss : 78.895744\n",
      "epoch = 123 train_loss : 67.336472 , test loss : 78.457420\n",
      "epoch = 125 train_loss : 66.704201 , test loss : 77.882942\n",
      "epoch = 126 train_loss : 66.561775 , test loss : 77.583389\n",
      "epoch = 127 train_loss : 66.116585 , test loss : 77.361938\n",
      "epoch = 128 train_loss : 66.008507 , test loss : 76.995178\n",
      "epoch = 129 train_loss : 65.678505 , test loss : 76.662277\n",
      "epoch = 130 train_loss : 65.280876 , test loss : 76.376427\n",
      "epoch = 132 train_loss : 64.799316 , test loss : 75.837410\n",
      "epoch = 134 train_loss : 64.220039 , test loss : 75.274467\n",
      "epoch = 136 train_loss : 63.687664 , test loss : 74.766464\n",
      "epoch = 138 train_loss : 63.187443 , test loss : 74.375465\n",
      "epoch = 139 train_loss : 62.918270 , test loss : 74.075394\n",
      "epoch = 140 train_loss : 62.770744 , test loss : 73.740723\n",
      "epoch = 141 train_loss : 62.480637 , test loss : 73.454803\n",
      "epoch = 142 train_loss : 62.169991 , test loss : 73.305328\n",
      "epoch = 143 train_loss : 61.937618 , test loss : 73.004936\n",
      "epoch = 144 train_loss : 61.777912 , test loss : 72.796143\n",
      "epoch = 145 train_loss : 61.438942 , test loss : 72.554428\n",
      "epoch = 146 train_loss : 61.216625 , test loss : 72.267204\n",
      "epoch = 147 train_loss : 61.130424 , test loss : 72.080299\n",
      "epoch = 149 train_loss : 60.516930 , test loss : 71.604164\n",
      "epoch = 150 train_loss : 60.300091 , test loss : 71.526466\n",
      "epoch = 151 train_loss : 60.045280 , test loss : 71.195099\n",
      "epoch = 153 train_loss : 59.657570 , test loss : 70.698715\n",
      "epoch = 155 train_loss : 59.172276 , test loss : 70.281548\n",
      "epoch = 157 train_loss : 58.696705 , test loss : 69.940079\n",
      "epoch = 159 train_loss : 58.262325 , test loss : 69.453316\n",
      "epoch = 160 train_loss : 58.041096 , test loss : 69.243469\n",
      "epoch = 161 train_loss : 57.919518 , test loss : 68.992096\n",
      "epoch = 162 train_loss : 57.707466 , test loss : 68.819824\n",
      "epoch = 164 train_loss : 57.197441 , test loss : 68.487061\n",
      "epoch = 165 train_loss : 57.092453 , test loss : 68.225349\n",
      "epoch = 167 train_loss : 56.607597 , test loss : 67.998703\n",
      "epoch = 168 train_loss : 56.376133 , test loss : 67.725502\n",
      "epoch = 170 train_loss : 56.068413 , test loss : 67.606598\n",
      "epoch = 171 train_loss : 55.895420 , test loss : 67.063271\n",
      "epoch = 172 train_loss : 55.570431 , test loss : 66.851707\n",
      "epoch = 173 train_loss : 55.349758 , test loss : 66.774734\n",
      "epoch = 174 train_loss : 55.158409 , test loss : 66.636871\n",
      "epoch = 175 train_loss : 55.012917 , test loss : 66.538429\n",
      "epoch = 176 train_loss : 54.765587 , test loss : 66.138527\n",
      "epoch = 177 train_loss : 54.572189 , test loss : 66.075287\n",
      "epoch = 178 train_loss : 54.361431 , test loss : 65.827995\n",
      "epoch = 179 train_loss : 54.202530 , test loss : 65.752037\n",
      "epoch = 181 train_loss : 53.806744 , test loss : 65.363945\n",
      "epoch = 182 train_loss : 53.700024 , test loss : 65.050453\n",
      "epoch = 183 train_loss : 53.421482 , test loss : 64.895889\n",
      "epoch = 184 train_loss : 53.218437 , test loss : 64.776451\n",
      "epoch = 185 train_loss : 53.033680 , test loss : 64.567230\n",
      "epoch = 186 train_loss : 52.896992 , test loss : 64.331055\n",
      "epoch = 187 train_loss : 52.688244 , test loss : 64.184326\n",
      "epoch = 188 train_loss : 52.476162 , test loss : 64.071022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 190 train_loss : 52.563210 , test loss : 63.858692\n",
      "epoch = 191 train_loss : 52.012016 , test loss : 63.544781\n",
      "epoch = 192 train_loss : 51.908978 , test loss : 63.377678\n",
      "epoch = 193 train_loss : 51.687553 , test loss : 63.199482\n",
      "epoch = 194 train_loss : 51.647705 , test loss : 63.124939\n",
      "epoch = 195 train_loss : 51.241505 , test loss : 62.935001\n",
      "epoch = 196 train_loss : 51.204723 , test loss : 62.718201\n",
      "epoch = 200 train_loss : 50.391014 , test loss : 62.119194\n",
      "epoch = 202 train_loss : 50.053406 , test loss : 61.835754\n",
      "epoch = 203 train_loss : 49.898346 , test loss : 61.615543\n",
      "epoch = 204 train_loss : 49.752811 , test loss : 61.579170\n",
      "epoch = 205 train_loss : 49.604626 , test loss : 61.341122\n",
      "epoch = 206 train_loss : 49.455776 , test loss : 61.180130\n",
      "epoch = 207 train_loss : 49.252289 , test loss : 61.040607\n",
      "epoch = 209 train_loss : 48.973236 , test loss : 60.742294\n",
      "epoch = 212 train_loss : 48.471134 , test loss : 60.406094\n",
      "epoch = 213 train_loss : 48.356258 , test loss : 60.175144\n",
      "epoch = 214 train_loss : 48.181389 , test loss : 60.159519\n",
      "epoch = 215 train_loss : 48.034019 , test loss : 60.054855\n",
      "epoch = 216 train_loss : 47.875034 , test loss : 59.887230\n",
      "epoch = 217 train_loss : 47.742096 , test loss : 59.790848\n",
      "epoch = 218 train_loss : 47.617901 , test loss : 59.522194\n",
      "epoch = 219 train_loss : 47.426228 , test loss : 59.441658\n",
      "epoch = 220 train_loss : 47.281380 , test loss : 59.225468\n",
      "epoch = 221 train_loss : 47.262852 , test loss : 59.104752\n",
      "epoch = 222 train_loss : 47.074287 , test loss : 58.971161\n",
      "epoch = 223 train_loss : 47.138111 , test loss : 58.914101\n",
      "epoch = 224 train_loss : 46.706383 , test loss : 58.734589\n",
      "epoch = 225 train_loss : 46.657669 , test loss : 58.584564\n",
      "epoch = 227 train_loss : 46.618687 , test loss : 58.453358\n",
      "epoch = 228 train_loss : 46.157959 , test loss : 58.238010\n",
      "epoch = 230 train_loss : 45.889633 , test loss : 57.968163\n",
      "epoch = 231 train_loss : 45.759113 , test loss : 57.881123\n",
      "epoch = 233 train_loss : 45.527256 , test loss : 57.718590\n",
      "epoch = 234 train_loss : 45.370335 , test loss : 57.438442\n",
      "epoch = 237 train_loss : 45.010380 , test loss : 57.103008\n",
      "epoch = 238 train_loss : 44.933163 , test loss : 56.972866\n",
      "epoch = 241 train_loss : 44.498199 , test loss : 56.752914\n",
      "epoch = 242 train_loss : 44.516994 , test loss : 56.526695\n",
      "epoch = 243 train_loss : 44.260399 , test loss : 56.425270\n",
      "epoch = 245 train_loss : 44.032547 , test loss : 56.155296\n",
      "epoch = 248 train_loss : 43.664787 , test loss : 55.878654\n",
      "epoch = 249 train_loss : 43.553741 , test loss : 55.873486\n",
      "epoch = 251 train_loss : 43.440811 , test loss : 55.539333\n",
      "epoch = 252 train_loss : 43.249111 , test loss : 55.418243\n",
      "epoch = 255 train_loss : 42.898579 , test loss : 55.092442\n",
      "epoch = 256 train_loss : 42.783264 , test loss : 55.047546\n",
      "epoch = 257 train_loss : 42.753048 , test loss : 54.906281\n",
      "epoch = 258 train_loss : 42.599331 , test loss : 54.797173\n",
      "epoch = 261 train_loss : 42.734123 , test loss : 54.707642\n",
      "epoch = 262 train_loss : 42.172623 , test loss : 54.475143\n",
      "epoch = 264 train_loss : 41.983524 , test loss : 54.197445\n",
      "epoch = 266 train_loss : 41.783554 , test loss : 54.083023\n",
      "epoch = 267 train_loss : 41.867069 , test loss : 53.957504\n",
      "epoch = 269 train_loss : 41.665504 , test loss : 53.739788\n",
      "epoch = 270 train_loss : 41.452091 , test loss : 53.647297\n",
      "epoch = 273 train_loss : 41.140121 , test loss : 53.358040\n",
      "epoch = 274 train_loss : 41.116447 , test loss : 53.279270\n",
      "epoch = 276 train_loss : 40.875099 , test loss : 53.163620\n",
      "epoch = 277 train_loss : 40.825901 , test loss : 53.016232\n",
      "epoch = 279 train_loss : 40.633617 , test loss : 52.825848\n",
      "epoch = 280 train_loss : 40.540989 , test loss : 52.765316\n",
      "epoch = 282 train_loss : 40.369316 , test loss : 52.635136\n",
      "epoch = 283 train_loss : 40.288635 , test loss : 52.524914\n",
      "epoch = 285 train_loss : 40.256340 , test loss : 52.407890\n",
      "epoch = 286 train_loss : 40.080139 , test loss : 52.265972\n",
      "epoch = 287 train_loss : 40.086231 , test loss : 52.156590\n",
      "epoch = 290 train_loss : 39.751934 , test loss : 52.049946\n",
      "epoch = 291 train_loss : 39.690025 , test loss : 51.841045\n",
      "epoch = 294 train_loss : 39.521229 , test loss : 51.604374\n",
      "epoch = 295 train_loss : 39.436386 , test loss : 51.529079\n",
      "epoch = 298 train_loss : 39.176182 , test loss : 51.440834\n",
      "epoch = 299 train_loss : 39.271576 , test loss : 51.264336\n",
      "epoch = 301 train_loss : 39.175240 , test loss : 51.087807\n",
      "epoch = 302 train_loss : 38.918015 , test loss : 51.019814\n",
      "epoch = 303 train_loss : 38.838993 , test loss : 51.003651\n",
      "epoch = 304 train_loss : 38.890690 , test loss : 50.872124\n",
      "epoch = 305 train_loss : 38.799904 , test loss : 50.799126\n",
      "epoch = 306 train_loss : 38.687786 , test loss : 50.719303\n",
      "epoch = 307 train_loss : 38.645306 , test loss : 50.678375\n",
      "epoch = 310 train_loss : 38.619320 , test loss : 50.554768\n",
      "epoch = 311 train_loss : 38.342567 , test loss : 50.446682\n",
      "epoch = 312 train_loss : 38.367897 , test loss : 50.327106\n",
      "epoch = 313 train_loss : 38.265663 , test loss : 50.283394\n",
      "epoch = 316 train_loss : 38.421494 , test loss : 50.143703\n",
      "epoch = 317 train_loss : 38.367752 , test loss : 50.135944\n",
      "epoch = 318 train_loss : 38.080692 , test loss : 49.919132\n",
      "epoch = 321 train_loss : 37.939007 , test loss : 49.744099\n",
      "epoch = 324 train_loss : 37.633575 , test loss : 49.628418\n",
      "epoch = 326 train_loss : 37.777660 , test loss : 49.478882\n",
      "epoch = 329 train_loss : 37.399868 , test loss : 49.278954\n",
      "epoch = 332 train_loss : 37.259731 , test loss : 49.233906\n",
      "epoch = 334 train_loss : 37.151707 , test loss : 49.013496\n",
      "epoch = 335 train_loss : 37.113316 , test loss : 49.000263\n",
      "epoch = 337 train_loss : 37.114368 , test loss : 48.803951\n",
      "epoch = 339 train_loss : 36.939571 , test loss : 48.688526\n",
      "epoch = 340 train_loss : 36.976837 , test loss : 48.615036\n",
      "epoch = 343 train_loss : 36.775455 , test loss : 48.510662\n",
      "epoch = 344 train_loss : 36.729004 , test loss : 48.427265\n",
      "epoch = 345 train_loss : 36.823196 , test loss : 48.412300\n",
      "epoch = 348 train_loss : 36.721226 , test loss : 48.206108\n",
      "epoch = 350 train_loss : 36.515877 , test loss : 48.141354\n",
      "epoch = 351 train_loss : 36.445896 , test loss : 48.081703\n",
      "epoch = 353 train_loss : 36.367016 , test loss : 47.994019\n",
      "epoch = 354 train_loss : 36.402992 , test loss : 47.940758\n",
      "epoch = 355 train_loss : 36.408566 , test loss : 47.840721\n",
      "epoch = 357 train_loss : 36.221340 , test loss : 47.819878\n",
      "epoch = 358 train_loss : 36.193504 , test loss : 47.693726\n",
      "epoch = 361 train_loss : 36.080105 , test loss : 47.611591\n",
      "epoch = 363 train_loss : 36.004433 , test loss : 47.495705\n",
      "epoch = 364 train_loss : 36.015087 , test loss : 47.437054\n",
      "epoch = 365 train_loss : 35.935081 , test loss : 47.396832\n",
      "epoch = 368 train_loss : 36.121929 , test loss : 47.314316\n",
      "epoch = 369 train_loss : 36.177425 , test loss : 47.283657\n",
      "epoch = 371 train_loss : 35.999718 , test loss : 47.126778\n",
      "epoch = 372 train_loss : 35.848965 , test loss : 47.031418\n",
      "epoch = 374 train_loss : 35.833019 , test loss : 46.979614\n",
      "epoch = 376 train_loss : 35.588581 , test loss : 46.934391\n",
      "epoch = 377 train_loss : 35.629951 , test loss : 46.837570\n",
      "epoch = 380 train_loss : 35.708664 , test loss : 46.790363\n",
      "epoch = 382 train_loss : 35.488483 , test loss : 46.598148\n",
      "epoch = 383 train_loss : 35.399651 , test loss : 46.583862\n",
      "epoch = 389 train_loss : 35.238392 , test loss : 46.457336\n",
      "epoch = 391 train_loss : 35.191704 , test loss : 46.343769\n",
      "epoch = 393 train_loss : 35.188534 , test loss : 46.170002\n",
      "epoch = 396 train_loss : 35.285725 , test loss : 46.080101\n",
      "epoch = 400 train_loss : 34.961906 , test loss : 46.072094\n",
      "epoch = 401 train_loss : 35.193352 , test loss : 45.979733\n",
      "epoch = 403 train_loss : 34.896084 , test loss : 45.903721\n",
      "epoch = 405 train_loss : 34.846111 , test loss : 45.781189\n",
      "epoch = 408 train_loss : 34.806725 , test loss : 45.648003\n",
      "epoch = 412 train_loss : 34.821144 , test loss : 45.555481\n",
      "epoch = 414 train_loss : 34.668720 , test loss : 45.467983\n",
      "epoch = 415 train_loss : 34.641029 , test loss : 45.445675\n",
      "epoch = 418 train_loss : 34.614334 , test loss : 45.322777\n",
      "epoch = 419 train_loss : 34.645161 , test loss : 45.322773\n",
      "epoch = 420 train_loss : 34.543663 , test loss : 45.281662\n",
      "epoch = 421 train_loss : 34.550159 , test loss : 45.264095\n",
      "epoch = 423 train_loss : 34.485096 , test loss : 45.234386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 425 train_loss : 34.477524 , test loss : 45.098793\n",
      "epoch = 427 train_loss : 34.470139 , test loss : 45.079391\n",
      "epoch = 431 train_loss : 34.368095 , test loss : 45.062523\n",
      "epoch = 432 train_loss : 34.326771 , test loss : 44.978745\n",
      "epoch = 433 train_loss : 34.304470 , test loss : 44.943569\n",
      "epoch = 434 train_loss : 34.397263 , test loss : 44.880672\n",
      "epoch = 438 train_loss : 34.235573 , test loss : 44.738621\n",
      "epoch = 442 train_loss : 34.178860 , test loss : 44.680847\n",
      "epoch = 444 train_loss : 34.124130 , test loss : 44.651627\n",
      "epoch = 446 train_loss : 34.103294 , test loss : 44.549393\n",
      "epoch = 448 train_loss : 34.098133 , test loss : 44.524082\n",
      "epoch = 452 train_loss : 34.006470 , test loss : 44.423637\n",
      "epoch = 453 train_loss : 34.008717 , test loss : 44.401405\n",
      "epoch = 456 train_loss : 33.958122 , test loss : 44.274021\n",
      "epoch = 462 train_loss : 33.873318 , test loss : 44.226921\n",
      "epoch = 463 train_loss : 33.850018 , test loss : 44.120773\n",
      "epoch = 467 train_loss : 33.834549 , test loss : 44.071552\n",
      "epoch = 471 train_loss : 33.788895 , test loss : 43.985035\n",
      "epoch = 475 train_loss : 33.896164 , test loss : 43.902054\n",
      "epoch = 479 train_loss : 33.792397 , test loss : 43.815639\n",
      "epoch = 480 train_loss : 33.709190 , test loss : 43.747604\n",
      "epoch = 482 train_loss : 33.832653 , test loss : 43.742855\n",
      "epoch = 487 train_loss : 33.545082 , test loss : 43.665176\n",
      "epoch = 488 train_loss : 33.531094 , test loss : 43.610630\n",
      "epoch = 489 train_loss : 33.614086 , test loss : 43.598431\n",
      "epoch = 490 train_loss : 33.542927 , test loss : 43.567932\n",
      "epoch = 495 train_loss : 33.519409 , test loss : 43.461773\n",
      "epoch = 496 train_loss : 33.440212 , test loss : 43.460972\n",
      "epoch = 498 train_loss : 33.423340 , test loss : 43.382710\n",
      "epoch = 502 train_loss : 33.420876 , test loss : 43.284168\n",
      "epoch = 505 train_loss : 33.371124 , test loss : 43.216713\n",
      "epoch = 508 train_loss : 33.311253 , test loss : 43.202164\n",
      "epoch = 512 train_loss : 33.278439 , test loss : 43.144215\n",
      "epoch = 514 train_loss : 33.246777 , test loss : 43.110142\n",
      "epoch = 515 train_loss : 33.375084 , test loss : 43.106998\n",
      "epoch = 518 train_loss : 33.220440 , test loss : 43.031761\n",
      "epoch = 525 train_loss : 33.239605 , test loss : 42.913174\n",
      "epoch = 526 train_loss : 33.203449 , test loss : 42.902218\n",
      "epoch = 529 train_loss : 33.118317 , test loss : 42.822201\n",
      "epoch = 534 train_loss : 33.094952 , test loss : 42.783340\n",
      "epoch = 537 train_loss : 33.035942 , test loss : 42.747234\n",
      "epoch = 542 train_loss : 33.086388 , test loss : 42.663639\n",
      "epoch = 544 train_loss : 33.008320 , test loss : 42.616013\n",
      "epoch = 546 train_loss : 33.019566 , test loss : 42.548004\n",
      "epoch = 552 train_loss : 32.911179 , test loss : 42.507866\n",
      "epoch = 553 train_loss : 32.895657 , test loss : 42.494110\n",
      "epoch = 558 train_loss : 32.854507 , test loss : 42.437393\n",
      "epoch = 559 train_loss : 32.851151 , test loss : 42.378105\n",
      "epoch = 560 train_loss : 32.843121 , test loss : 42.363327\n",
      "epoch = 562 train_loss : 32.902397 , test loss : 42.344852\n",
      "epoch = 564 train_loss : 32.814110 , test loss : 42.298393\n",
      "epoch = 568 train_loss : 32.784790 , test loss : 42.278877\n",
      "epoch = 569 train_loss : 32.856289 , test loss : 42.270550\n",
      "epoch = 579 train_loss : 32.735493 , test loss : 42.084736\n",
      "epoch = 587 train_loss : 32.647903 , test loss : 42.083752\n",
      "epoch = 589 train_loss : 32.643360 , test loss : 42.029503\n",
      "epoch = 592 train_loss : 32.626957 , test loss : 42.029121\n",
      "epoch = 595 train_loss : 32.590565 , test loss : 41.942970\n",
      "epoch = 599 train_loss : 32.570545 , test loss : 41.929409\n",
      "epoch = 605 train_loss : 32.664391 , test loss : 41.833046\n",
      "epoch = 615 train_loss : 32.475346 , test loss : 41.734146\n",
      "epoch = 625 train_loss : 32.421497 , test loss : 41.689186\n",
      "epoch = 628 train_loss : 32.420860 , test loss : 41.625130\n",
      "epoch = 632 train_loss : 32.543533 , test loss : 41.617588\n",
      "epoch = 636 train_loss : 32.360619 , test loss : 41.572472\n",
      "epoch = 638 train_loss : 32.348942 , test loss : 41.537674\n",
      "epoch = 640 train_loss : 32.339931 , test loss : 41.496490\n",
      "epoch = 646 train_loss : 32.354572 , test loss : 41.460361\n",
      "epoch = 654 train_loss : 32.290024 , test loss : 41.416561\n",
      "epoch = 655 train_loss : 32.271011 , test loss : 41.412174\n",
      "epoch = 659 train_loss : 32.254574 , test loss : 41.403736\n",
      "epoch = 660 train_loss : 32.258575 , test loss : 41.343521\n",
      "epoch = 664 train_loss : 32.251438 , test loss : 41.330723\n",
      "epoch = 674 train_loss : 32.186146 , test loss : 41.289391\n",
      "epoch = 678 train_loss : 32.300800 , test loss : 41.288467\n",
      "epoch = 679 train_loss : 32.202190 , test loss : 41.213150\n",
      "epoch = 680 train_loss : 32.173737 , test loss : 41.187817\n",
      "epoch = 692 train_loss : 32.142086 , test loss : 41.134628\n",
      "epoch = 693 train_loss : 32.188183 , test loss : 41.127964\n",
      "epoch = 699 train_loss : 32.089058 , test loss : 41.124828\n",
      "epoch = 700 train_loss : 32.083942 , test loss : 41.100651\n",
      "epoch = 704 train_loss : 32.101246 , test loss : 41.100452\n",
      "epoch = 707 train_loss : 32.187172 , test loss : 41.079273\n",
      "epoch = 712 train_loss : 32.048317 , test loss : 41.074860\n",
      "epoch = 713 train_loss : 32.040558 , test loss : 41.007259\n",
      "epoch = 716 train_loss : 32.040581 , test loss : 41.006069\n",
      "epoch = 721 train_loss : 32.012951 , test loss : 40.979881\n",
      "epoch = 723 train_loss : 32.006588 , test loss : 40.962135\n",
      "epoch = 727 train_loss : 32.033142 , test loss : 40.934280\n",
      "epoch = 730 train_loss : 32.028782 , test loss : 40.906536\n",
      "epoch = 741 train_loss : 31.955418 , test loss : 40.868050\n",
      "epoch = 748 train_loss : 31.973284 , test loss : 40.822197\n",
      "epoch = 754 train_loss : 32.083340 , test loss : 40.820927\n",
      "epoch = 759 train_loss : 31.931984 , test loss : 40.726715\n",
      "epoch = 766 train_loss : 31.886391 , test loss : 40.716892\n",
      "epoch = 768 train_loss : 31.919075 , test loss : 40.708706\n",
      "epoch = 778 train_loss : 31.854445 , test loss : 40.629559\n",
      "epoch = 792 train_loss : 31.856741 , test loss : 40.598957\n",
      "epoch = 806 train_loss : 31.778448 , test loss : 40.546803\n",
      "epoch = 821 train_loss : 31.794291 , test loss : 40.531837\n",
      "epoch = 828 train_loss : 31.727699 , test loss : 40.498810\n",
      "epoch = 831 train_loss : 31.733063 , test loss : 40.461098\n",
      "epoch = 835 train_loss : 31.725950 , test loss : 40.419495\n",
      "epoch = 850 train_loss : 31.689516 , test loss : 40.419266\n",
      "epoch = 853 train_loss : 31.680382 , test loss : 40.384796\n",
      "epoch = 872 train_loss : 31.638231 , test loss : 40.348347\n",
      "epoch = 889 train_loss : 31.705292 , test loss : 40.303734\n",
      "epoch = 898 train_loss : 31.596561 , test loss : 40.291943\n",
      "epoch = 901 train_loss : 31.598595 , test loss : 40.288670\n",
      "epoch = 910 train_loss : 31.594753 , test loss : 40.274483\n",
      "epoch = 916 train_loss : 31.613859 , test loss : 40.273285\n",
      "epoch = 921 train_loss : 31.566505 , test loss : 40.268784\n",
      "epoch = 925 train_loss : 31.623198 , test loss : 40.185696\n",
      "epoch = 934 train_loss : 31.576382 , test loss : 40.177353\n",
      "epoch = 958 train_loss : 31.554440 , test loss : 40.150181\n",
      "epoch = 976 train_loss : 31.494064 , test loss : 40.146622\n",
      "epoch = 978 train_loss : 31.527218 , test loss : 40.105328\n",
      "epoch = 993 train_loss : 31.502493 , test loss : 40.047016\n",
      "epoch = 1034 train_loss : 31.450184 , test loss : 40.027401\n",
      "epoch = 1051 train_loss : 31.462425 , test loss : 40.004627\n",
      "epoch = 1071 train_loss : 31.424206 , test loss : 39.954636\n",
      "epoch = 1104 train_loss : 31.440245 , test loss : 39.948483\n",
      "epoch = 1115 train_loss : 31.379192 , test loss : 39.915192\n",
      "epoch = 1126 train_loss : 31.414583 , test loss : 39.914806\n",
      "epoch = 1179 train_loss : 31.486942 , test loss : 39.904587\n",
      "epoch = 1181 train_loss : 31.371555 , test loss : 39.900860\n",
      "epoch = 1187 train_loss : 31.324863 , test loss : 39.899055\n",
      "epoch = 1189 train_loss : 31.345282 , test loss : 39.864666\n",
      "epoch = 1205 train_loss : 31.324215 , test loss : 39.845005\n",
      "epoch = 1242 train_loss : 31.356976 , test loss : 39.844563\n",
      "epoch = 1263 train_loss : 31.281851 , test loss : 39.825943\n",
      "epoch = 1283 train_loss : 31.280285 , test loss : 39.805447\n",
      "epoch = 1365 train_loss : 31.281284 , test loss : 39.750656\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 31.281284,test loss : 39.750656\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 332.193848 , test loss : 338.501648\n",
      "epoch = 2 train_loss : 305.683929 , test loss : 310.486359\n",
      "epoch = 3 train_loss : 281.393616 , test loss : 284.643250\n",
      "epoch = 4 train_loss : 259.733429 , test loss : 262.202850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5 train_loss : 240.952545 , test loss : 243.256042\n",
      "epoch = 6 train_loss : 223.997131 , test loss : 225.277786\n",
      "epoch = 7 train_loss : 209.691376 , test loss : 210.648575\n",
      "epoch = 8 train_loss : 197.018417 , test loss : 197.378098\n",
      "epoch = 9 train_loss : 186.425308 , test loss : 186.132126\n",
      "epoch = 10 train_loss : 177.018311 , test loss : 176.552277\n",
      "epoch = 11 train_loss : 168.936020 , test loss : 168.113495\n",
      "epoch = 12 train_loss : 161.902451 , test loss : 160.741379\n",
      "epoch = 13 train_loss : 155.839401 , test loss : 154.347977\n",
      "epoch = 14 train_loss : 150.472946 , test loss : 148.696518\n",
      "epoch = 15 train_loss : 145.586807 , test loss : 143.663025\n",
      "epoch = 16 train_loss : 141.261688 , test loss : 139.150726\n",
      "epoch = 17 train_loss : 137.420761 , test loss : 135.138901\n",
      "epoch = 18 train_loss : 133.950714 , test loss : 131.534836\n",
      "epoch = 19 train_loss : 130.719727 , test loss : 128.169006\n",
      "epoch = 20 train_loss : 127.680626 , test loss : 124.960640\n",
      "epoch = 21 train_loss : 124.935585 , test loss : 122.032463\n",
      "epoch = 22 train_loss : 122.332245 , test loss : 119.456238\n",
      "epoch = 23 train_loss : 119.929184 , test loss : 116.806435\n",
      "epoch = 24 train_loss : 117.630020 , test loss : 114.526581\n",
      "epoch = 25 train_loss : 115.493065 , test loss : 112.370232\n",
      "epoch = 26 train_loss : 113.530594 , test loss : 110.321175\n",
      "epoch = 27 train_loss : 111.732483 , test loss : 108.142242\n",
      "epoch = 28 train_loss : 109.835602 , test loss : 106.347603\n",
      "epoch = 29 train_loss : 108.464149 , test loss : 105.201195\n",
      "epoch = 30 train_loss : 106.821335 , test loss : 102.924667\n",
      "epoch = 31 train_loss : 104.882896 , test loss : 101.181892\n",
      "epoch = 32 train_loss : 103.668678 , test loss : 99.678726\n",
      "epoch = 33 train_loss : 102.120346 , test loss : 98.444977\n",
      "epoch = 34 train_loss : 100.828453 , test loss : 97.067764\n",
      "epoch = 35 train_loss : 99.783958 , test loss : 96.079178\n",
      "epoch = 36 train_loss : 98.800743 , test loss : 94.323387\n",
      "epoch = 37 train_loss : 97.093567 , test loss : 92.984070\n",
      "epoch = 38 train_loss : 96.001007 , test loss : 91.763199\n",
      "epoch = 39 train_loss : 94.950653 , test loss : 90.647255\n",
      "epoch = 40 train_loss : 93.941460 , test loss : 89.573776\n",
      "epoch = 41 train_loss : 92.962227 , test loss : 88.262123\n",
      "epoch = 42 train_loss : 92.204659 , test loss : 87.779640\n",
      "epoch = 43 train_loss : 91.215523 , test loss : 86.202812\n",
      "epoch = 44 train_loss : 90.241196 , test loss : 85.346260\n",
      "epoch = 45 train_loss : 89.464333 , test loss : 84.428978\n",
      "epoch = 46 train_loss : 88.634956 , test loss : 83.508972\n",
      "epoch = 47 train_loss : 88.097519 , test loss : 82.690369\n",
      "epoch = 48 train_loss : 87.207123 , test loss : 82.219055\n",
      "epoch = 49 train_loss : 86.406380 , test loss : 81.151703\n",
      "epoch = 50 train_loss : 85.876717 , test loss : 80.306755\n",
      "epoch = 51 train_loss : 85.180702 , test loss : 79.953400\n",
      "epoch = 52 train_loss : 84.813477 , test loss : 79.659630\n",
      "epoch = 53 train_loss : 83.780090 , test loss : 78.132431\n",
      "epoch = 54 train_loss : 83.340034 , test loss : 77.884476\n",
      "epoch = 55 train_loss : 82.611687 , test loss : 76.863304\n",
      "epoch = 56 train_loss : 82.298813 , test loss : 76.271675\n",
      "epoch = 57 train_loss : 81.580490 , test loss : 75.613617\n",
      "epoch = 58 train_loss : 80.974792 , test loss : 75.005470\n",
      "epoch = 59 train_loss : 80.601891 , test loss : 74.834000\n",
      "epoch = 60 train_loss : 80.049355 , test loss : 73.874626\n",
      "epoch = 61 train_loss : 79.535126 , test loss : 73.333000\n",
      "epoch = 62 train_loss : 79.065559 , test loss : 72.773048\n",
      "epoch = 63 train_loss : 78.560127 , test loss : 72.523430\n",
      "epoch = 64 train_loss : 78.311165 , test loss : 72.374168\n",
      "epoch = 65 train_loss : 77.641907 , test loss : 71.369286\n",
      "epoch = 66 train_loss : 77.288673 , test loss : 70.923843\n",
      "epoch = 67 train_loss : 77.279053 , test loss : 70.580872\n",
      "epoch = 68 train_loss : 76.421906 , test loss : 69.994781\n",
      "epoch = 69 train_loss : 76.055817 , test loss : 69.828224\n",
      "epoch = 70 train_loss : 75.660355 , test loss : 69.159142\n",
      "epoch = 71 train_loss : 75.235390 , test loss : 68.901833\n",
      "epoch = 72 train_loss : 74.885307 , test loss : 68.517754\n",
      "epoch = 73 train_loss : 74.500542 , test loss : 68.058411\n",
      "epoch = 74 train_loss : 74.334816 , test loss : 67.597939\n",
      "epoch = 75 train_loss : 73.790733 , test loss : 67.213554\n",
      "epoch = 77 train_loss : 73.362114 , test loss : 67.125351\n",
      "epoch = 78 train_loss : 73.152466 , test loss : 66.235153\n",
      "epoch = 79 train_loss : 72.458504 , test loss : 65.793434\n",
      "epoch = 80 train_loss : 72.376694 , test loss : 65.486687\n",
      "epoch = 81 train_loss : 71.818588 , test loss : 65.303947\n",
      "epoch = 82 train_loss : 71.615036 , test loss : 65.260330\n",
      "epoch = 84 train_loss : 70.873215 , test loss : 64.244415\n",
      "epoch = 85 train_loss : 70.681236 , test loss : 63.872993\n",
      "epoch = 86 train_loss : 70.287102 , test loss : 63.612732\n",
      "epoch = 87 train_loss : 70.073715 , test loss : 63.356472\n",
      "epoch = 89 train_loss : 69.576523 , test loss : 62.728092\n",
      "epoch = 90 train_loss : 69.432251 , test loss : 62.480984\n",
      "epoch = 91 train_loss : 68.862038 , test loss : 62.187847\n",
      "epoch = 92 train_loss : 68.620285 , test loss : 61.847786\n",
      "epoch = 94 train_loss : 68.070160 , test loss : 61.355488\n",
      "epoch = 95 train_loss : 67.927032 , test loss : 61.124031\n",
      "epoch = 96 train_loss : 67.550148 , test loss : 60.945198\n",
      "epoch = 97 train_loss : 67.277367 , test loss : 60.682026\n",
      "epoch = 98 train_loss : 67.025406 , test loss : 60.292072\n",
      "epoch = 99 train_loss : 66.797180 , test loss : 60.043892\n",
      "epoch = 101 train_loss : 66.393997 , test loss : 59.938271\n",
      "epoch = 102 train_loss : 66.104126 , test loss : 59.620155\n",
      "epoch = 105 train_loss : 65.740524 , test loss : 59.502804\n",
      "epoch = 106 train_loss : 65.102531 , test loss : 58.468113\n",
      "epoch = 107 train_loss : 64.884285 , test loss : 58.214729\n",
      "epoch = 109 train_loss : 64.424797 , test loss : 57.726620\n",
      "epoch = 110 train_loss : 64.516884 , test loss : 57.679649\n",
      "epoch = 111 train_loss : 63.986870 , test loss : 57.400181\n",
      "epoch = 112 train_loss : 64.118744 , test loss : 57.201153\n",
      "epoch = 113 train_loss : 63.989464 , test loss : 57.064800\n",
      "epoch = 114 train_loss : 63.362682 , test loss : 56.849949\n",
      "epoch = 115 train_loss : 63.132637 , test loss : 56.599911\n",
      "epoch = 116 train_loss : 62.930794 , test loss : 56.243332\n",
      "epoch = 117 train_loss : 63.134796 , test loss : 56.221832\n",
      "epoch = 118 train_loss : 62.638908 , test loss : 56.209694\n",
      "epoch = 119 train_loss : 62.327423 , test loss : 55.830238\n",
      "epoch = 120 train_loss : 62.093185 , test loss : 55.493912\n",
      "epoch = 121 train_loss : 61.915581 , test loss : 55.219139\n",
      "epoch = 123 train_loss : 61.480061 , test loss : 54.858406\n",
      "epoch = 124 train_loss : 61.300358 , test loss : 54.659603\n",
      "epoch = 126 train_loss : 60.965652 , test loss : 54.530743\n",
      "epoch = 127 train_loss : 60.705196 , test loss : 54.079613\n",
      "epoch = 128 train_loss : 60.503696 , test loss : 53.922592\n",
      "epoch = 130 train_loss : 60.428009 , test loss : 53.613216\n",
      "epoch = 132 train_loss : 59.765835 , test loss : 53.190907\n",
      "epoch = 133 train_loss : 59.701088 , test loss : 52.960415\n",
      "epoch = 134 train_loss : 59.390018 , test loss : 52.800373\n",
      "epoch = 137 train_loss : 58.869823 , test loss : 52.375828\n",
      "epoch = 138 train_loss : 59.244019 , test loss : 52.373096\n",
      "epoch = 139 train_loss : 58.510876 , test loss : 51.966404\n",
      "epoch = 141 train_loss : 58.189182 , test loss : 51.755707\n",
      "epoch = 142 train_loss : 58.489929 , test loss : 51.689869\n",
      "epoch = 143 train_loss : 57.899101 , test loss : 51.174755\n",
      "epoch = 145 train_loss : 57.476639 , test loss : 50.962620\n",
      "epoch = 146 train_loss : 57.312023 , test loss : 50.846092\n",
      "epoch = 147 train_loss : 57.247627 , test loss : 50.608978\n",
      "epoch = 148 train_loss : 57.030197 , test loss : 50.441582\n",
      "epoch = 149 train_loss : 56.909111 , test loss : 50.262794\n",
      "epoch = 150 train_loss : 56.719139 , test loss : 50.102367\n",
      "epoch = 153 train_loss : 56.248623 , test loss : 49.872879\n",
      "epoch = 154 train_loss : 56.028423 , test loss : 49.542706\n",
      "epoch = 155 train_loss : 55.995796 , test loss : 49.350998\n",
      "epoch = 156 train_loss : 55.741158 , test loss : 49.126194\n",
      "epoch = 157 train_loss : 55.566322 , test loss : 49.090370\n",
      "epoch = 158 train_loss : 55.442135 , test loss : 48.837620\n",
      "epoch = 160 train_loss : 55.414398 , test loss : 48.650810\n",
      "epoch = 161 train_loss : 55.356735 , test loss : 48.576702\n",
      "epoch = 162 train_loss : 54.800945 , test loss : 48.246769\n",
      "epoch = 163 train_loss : 54.654480 , test loss : 48.089352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 165 train_loss : 54.453983 , test loss : 47.858162\n",
      "epoch = 166 train_loss : 54.223244 , test loss : 47.684052\n",
      "epoch = 167 train_loss : 54.100456 , test loss : 47.668617\n",
      "epoch = 168 train_loss : 54.038837 , test loss : 47.641777\n",
      "epoch = 170 train_loss : 53.760220 , test loss : 47.396904\n",
      "epoch = 171 train_loss : 53.512100 , test loss : 47.045654\n",
      "epoch = 172 train_loss : 53.387371 , test loss : 46.768997\n",
      "epoch = 173 train_loss : 53.237846 , test loss : 46.737171\n",
      "epoch = 175 train_loss : 53.043716 , test loss : 46.632816\n",
      "epoch = 178 train_loss : 52.575161 , test loss : 46.075638\n",
      "epoch = 179 train_loss : 52.507435 , test loss : 45.951611\n",
      "epoch = 180 train_loss : 52.310680 , test loss : 45.799812\n",
      "epoch = 181 train_loss : 52.193951 , test loss : 45.730988\n",
      "epoch = 183 train_loss : 51.971073 , test loss : 45.530800\n",
      "epoch = 184 train_loss : 51.820778 , test loss : 45.388973\n",
      "epoch = 186 train_loss : 51.571327 , test loss : 45.064728\n",
      "epoch = 187 train_loss : 51.475334 , test loss : 44.879753\n",
      "epoch = 188 train_loss : 51.315125 , test loss : 44.817368\n",
      "epoch = 190 train_loss : 51.185814 , test loss : 44.794289\n",
      "epoch = 191 train_loss : 51.019566 , test loss : 44.654037\n",
      "epoch = 192 train_loss : 50.834732 , test loss : 44.331921\n",
      "epoch = 193 train_loss : 51.006306 , test loss : 44.250343\n",
      "epoch = 194 train_loss : 50.594570 , test loss : 44.154839\n",
      "epoch = 195 train_loss : 50.506821 , test loss : 44.019997\n",
      "epoch = 196 train_loss : 50.358536 , test loss : 43.880367\n",
      "epoch = 197 train_loss : 50.426991 , test loss : 43.834614\n",
      "epoch = 199 train_loss : 50.021793 , test loss : 43.524525\n",
      "epoch = 200 train_loss : 50.030903 , test loss : 43.452427\n",
      "epoch = 201 train_loss : 49.871983 , test loss : 43.262409\n",
      "epoch = 202 train_loss : 49.679325 , test loss : 43.178532\n",
      "epoch = 203 train_loss : 49.571228 , test loss : 43.080830\n",
      "epoch = 205 train_loss : 49.359440 , test loss : 42.830029\n",
      "epoch = 207 train_loss : 49.140537 , test loss : 42.671516\n",
      "epoch = 208 train_loss : 49.035812 , test loss : 42.584801\n",
      "epoch = 209 train_loss : 48.920544 , test loss : 42.485394\n",
      "epoch = 210 train_loss : 48.837326 , test loss : 42.333984\n",
      "epoch = 212 train_loss : 48.604656 , test loss : 42.136539\n",
      "epoch = 213 train_loss : 48.592968 , test loss : 42.005661\n",
      "epoch = 214 train_loss : 48.482342 , test loss : 41.911617\n",
      "epoch = 215 train_loss : 48.467129 , test loss : 41.836994\n",
      "epoch = 216 train_loss : 48.221203 , test loss : 41.785019\n",
      "epoch = 220 train_loss : 47.826397 , test loss : 41.335575\n",
      "epoch = 222 train_loss : 47.953697 , test loss : 41.332985\n",
      "epoch = 223 train_loss : 47.570423 , test loss : 41.015800\n",
      "epoch = 224 train_loss : 47.411449 , test loss : 40.856865\n",
      "epoch = 228 train_loss : 47.151577 , test loss : 40.808445\n",
      "epoch = 229 train_loss : 47.132675 , test loss : 40.596588\n",
      "epoch = 231 train_loss : 46.891018 , test loss : 40.327339\n",
      "epoch = 232 train_loss : 46.806072 , test loss : 40.256977\n",
      "epoch = 233 train_loss : 46.656139 , test loss : 40.128819\n",
      "epoch = 234 train_loss : 46.493050 , test loss : 40.021957\n",
      "epoch = 235 train_loss : 46.406548 , test loss : 39.973251\n",
      "epoch = 236 train_loss : 46.321407 , test loss : 39.896202\n",
      "epoch = 238 train_loss : 46.178612 , test loss : 39.663918\n",
      "epoch = 239 train_loss : 46.065144 , test loss : 39.657394\n",
      "epoch = 241 train_loss : 46.154095 , test loss : 39.574684\n",
      "epoch = 243 train_loss : 45.846958 , test loss : 39.523140\n",
      "epoch = 244 train_loss : 45.680355 , test loss : 39.171524\n",
      "epoch = 247 train_loss : 45.443573 , test loss : 39.050236\n",
      "epoch = 248 train_loss : 45.457508 , test loss : 38.955391\n",
      "epoch = 249 train_loss : 45.252060 , test loss : 38.818962\n",
      "epoch = 250 train_loss : 45.174885 , test loss : 38.782169\n",
      "epoch = 251 train_loss : 45.091301 , test loss : 38.661030\n",
      "epoch = 252 train_loss : 45.022499 , test loss : 38.588524\n",
      "epoch = 253 train_loss : 44.937763 , test loss : 38.511890\n",
      "epoch = 255 train_loss : 44.808285 , test loss : 38.371590\n",
      "epoch = 259 train_loss : 44.504623 , test loss : 38.187176\n",
      "epoch = 260 train_loss : 44.525242 , test loss : 38.103153\n",
      "epoch = 262 train_loss : 44.289028 , test loss : 37.986652\n",
      "epoch = 266 train_loss : 44.150867 , test loss : 37.705032\n",
      "epoch = 268 train_loss : 44.047459 , test loss : 37.661346\n",
      "epoch = 269 train_loss : 43.801785 , test loss : 37.448292\n",
      "epoch = 270 train_loss : 43.753559 , test loss : 37.372467\n",
      "epoch = 273 train_loss : 43.515537 , test loss : 37.211773\n",
      "epoch = 274 train_loss : 43.460743 , test loss : 37.138180\n",
      "epoch = 275 train_loss : 43.447758 , test loss : 37.131298\n",
      "epoch = 276 train_loss : 43.322788 , test loss : 36.975906\n",
      "epoch = 277 train_loss : 43.246693 , test loss : 36.945847\n",
      "epoch = 278 train_loss : 43.230251 , test loss : 36.888538\n",
      "epoch = 279 train_loss : 43.167789 , test loss : 36.850090\n",
      "epoch = 280 train_loss : 43.065144 , test loss : 36.741383\n",
      "epoch = 281 train_loss : 43.011650 , test loss : 36.676903\n",
      "epoch = 282 train_loss : 42.987331 , test loss : 36.661011\n",
      "epoch = 283 train_loss : 42.876453 , test loss : 36.594311\n",
      "epoch = 286 train_loss : 42.689960 , test loss : 36.408485\n",
      "epoch = 289 train_loss : 42.513481 , test loss : 36.239315\n",
      "epoch = 292 train_loss : 42.530190 , test loss : 36.233120\n",
      "epoch = 293 train_loss : 42.344433 , test loss : 36.056427\n",
      "epoch = 296 train_loss : 42.116539 , test loss : 35.869686\n",
      "epoch = 299 train_loss : 41.961018 , test loss : 35.760086\n",
      "epoch = 301 train_loss : 41.880959 , test loss : 35.681606\n",
      "epoch = 303 train_loss : 41.732635 , test loss : 35.576641\n",
      "epoch = 307 train_loss : 41.547112 , test loss : 35.441406\n",
      "epoch = 308 train_loss : 41.480103 , test loss : 35.350914\n",
      "epoch = 311 train_loss : 41.319241 , test loss : 35.205654\n",
      "epoch = 313 train_loss : 41.273796 , test loss : 35.128067\n",
      "epoch = 314 train_loss : 41.195744 , test loss : 35.062305\n",
      "epoch = 316 train_loss : 41.075630 , test loss : 34.947563\n",
      "epoch = 319 train_loss : 41.014828 , test loss : 34.924728\n",
      "epoch = 322 train_loss : 40.801144 , test loss : 34.770039\n",
      "epoch = 323 train_loss : 40.791569 , test loss : 34.743782\n",
      "epoch = 324 train_loss : 40.741108 , test loss : 34.727142\n",
      "epoch = 325 train_loss : 40.736736 , test loss : 34.641727\n",
      "epoch = 326 train_loss : 40.668468 , test loss : 34.601574\n",
      "epoch = 331 train_loss : 40.384289 , test loss : 34.413616\n",
      "epoch = 332 train_loss : 40.357056 , test loss : 34.347687\n",
      "epoch = 334 train_loss : 40.256809 , test loss : 34.274185\n",
      "epoch = 335 train_loss : 40.214283 , test loss : 34.252785\n",
      "epoch = 336 train_loss : 40.186062 , test loss : 34.236900\n",
      "epoch = 339 train_loss : 40.187565 , test loss : 34.180344\n",
      "epoch = 342 train_loss : 39.959522 , test loss : 34.064789\n",
      "epoch = 343 train_loss : 39.919971 , test loss : 34.013100\n",
      "epoch = 348 train_loss : 39.695049 , test loss : 33.836418\n",
      "epoch = 350 train_loss : 39.705944 , test loss : 33.832157\n",
      "epoch = 351 train_loss : 39.588383 , test loss : 33.725159\n",
      "epoch = 353 train_loss : 39.523014 , test loss : 33.624775\n",
      "epoch = 358 train_loss : 39.395611 , test loss : 33.570126\n",
      "epoch = 360 train_loss : 39.276134 , test loss : 33.511524\n",
      "epoch = 361 train_loss : 39.225956 , test loss : 33.490623\n",
      "epoch = 363 train_loss : 39.252872 , test loss : 33.428474\n",
      "epoch = 365 train_loss : 39.089417 , test loss : 33.352341\n",
      "epoch = 367 train_loss : 39.106083 , test loss : 33.340492\n",
      "epoch = 368 train_loss : 39.033333 , test loss : 33.280991\n",
      "epoch = 370 train_loss : 38.926128 , test loss : 33.252678\n",
      "epoch = 374 train_loss : 38.838558 , test loss : 33.195728\n",
      "epoch = 375 train_loss : 38.767441 , test loss : 33.093914\n",
      "epoch = 376 train_loss : 38.749500 , test loss : 33.069805\n",
      "epoch = 379 train_loss : 38.666130 , test loss : 32.989273\n",
      "epoch = 380 train_loss : 38.615498 , test loss : 32.943264\n",
      "epoch = 385 train_loss : 38.537395 , test loss : 32.940819\n",
      "epoch = 387 train_loss : 38.422054 , test loss : 32.845005\n",
      "epoch = 391 train_loss : 38.312908 , test loss : 32.794785\n",
      "epoch = 394 train_loss : 38.218166 , test loss : 32.735146\n",
      "epoch = 397 train_loss : 38.148540 , test loss : 32.644466\n",
      "epoch = 399 train_loss : 38.098862 , test loss : 32.569492\n",
      "epoch = 403 train_loss : 38.021439 , test loss : 32.531998\n",
      "epoch = 407 train_loss : 37.882633 , test loss : 32.457863\n",
      "epoch = 408 train_loss : 37.875710 , test loss : 32.435944\n",
      "epoch = 410 train_loss : 37.808296 , test loss : 32.402428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 413 train_loss : 37.768707 , test loss : 32.371902\n",
      "epoch = 416 train_loss : 37.675529 , test loss : 32.332447\n",
      "epoch = 418 train_loss : 37.667397 , test loss : 32.253925\n",
      "epoch = 422 train_loss : 37.518578 , test loss : 32.243980\n",
      "epoch = 423 train_loss : 37.492943 , test loss : 32.190365\n",
      "epoch = 425 train_loss : 37.477615 , test loss : 32.167675\n",
      "epoch = 427 train_loss : 37.445274 , test loss : 32.155334\n",
      "epoch = 428 train_loss : 37.383724 , test loss : 32.094330\n",
      "epoch = 431 train_loss : 37.348137 , test loss : 32.073524\n",
      "epoch = 436 train_loss : 37.236633 , test loss : 32.049778\n",
      "epoch = 437 train_loss : 37.211369 , test loss : 32.015785\n",
      "epoch = 440 train_loss : 37.135494 , test loss : 31.945898\n",
      "epoch = 447 train_loss : 37.006859 , test loss : 31.883465\n",
      "epoch = 450 train_loss : 36.945911 , test loss : 31.874651\n",
      "epoch = 451 train_loss : 36.963726 , test loss : 31.846531\n",
      "epoch = 452 train_loss : 36.985653 , test loss : 31.844479\n",
      "epoch = 455 train_loss : 36.888817 , test loss : 31.820919\n",
      "epoch = 457 train_loss : 36.867413 , test loss : 31.797506\n",
      "epoch = 460 train_loss : 36.769142 , test loss : 31.742369\n",
      "epoch = 463 train_loss : 36.721649 , test loss : 31.676962\n",
      "epoch = 466 train_loss : 36.663181 , test loss : 31.641808\n",
      "epoch = 470 train_loss : 36.598309 , test loss : 31.627239\n",
      "epoch = 474 train_loss : 36.531044 , test loss : 31.583767\n",
      "epoch = 476 train_loss : 36.503780 , test loss : 31.572073\n",
      "epoch = 480 train_loss : 36.439926 , test loss : 31.509474\n",
      "epoch = 489 train_loss : 36.303234 , test loss : 31.446304\n",
      "epoch = 496 train_loss : 36.203457 , test loss : 31.411480\n",
      "epoch = 498 train_loss : 36.178345 , test loss : 31.365669\n",
      "epoch = 506 train_loss : 36.070271 , test loss : 31.360584\n",
      "epoch = 507 train_loss : 36.058838 , test loss : 31.289793\n",
      "epoch = 514 train_loss : 35.962971 , test loss : 31.281139\n",
      "epoch = 517 train_loss : 35.941284 , test loss : 31.241720\n",
      "epoch = 521 train_loss : 35.884361 , test loss : 31.204615\n",
      "epoch = 531 train_loss : 35.790562 , test loss : 31.171944\n",
      "epoch = 536 train_loss : 35.711456 , test loss : 31.131670\n",
      "epoch = 546 train_loss : 35.592407 , test loss : 31.110632\n",
      "epoch = 548 train_loss : 35.575241 , test loss : 31.097570\n",
      "epoch = 556 train_loss : 35.495335 , test loss : 31.096191\n",
      "epoch = 560 train_loss : 35.473190 , test loss : 31.081814\n",
      "epoch = 563 train_loss : 35.460957 , test loss : 31.069502\n",
      "epoch = 566 train_loss : 35.397877 , test loss : 30.992365\n",
      "epoch = 587 train_loss : 35.229912 , test loss : 30.938564\n",
      "epoch = 593 train_loss : 35.164787 , test loss : 30.906624\n",
      "epoch = 606 train_loss : 35.085636 , test loss : 30.899111\n",
      "epoch = 619 train_loss : 34.962700 , test loss : 30.847380\n",
      "epoch = 633 train_loss : 34.865490 , test loss : 30.835350\n",
      "epoch = 641 train_loss : 34.814758 , test loss : 30.782936\n",
      "epoch = 655 train_loss : 34.737495 , test loss : 30.772469\n",
      "epoch = 663 train_loss : 34.696747 , test loss : 30.768328\n",
      "epoch = 669 train_loss : 34.638577 , test loss : 30.724392\n",
      "epoch = 670 train_loss : 34.635529 , test loss : 30.707563\n",
      "epoch = 708 train_loss : 34.440975 , test loss : 30.651665\n",
      "epoch = 773 train_loss : 34.145145 , test loss : 30.632637\n",
      "epoch = 861 train_loss : 33.847057 , test loss : 30.614561\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 33.847057,test loss : 30.614561\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 2 train_loss : 613.084351 , test loss : 629.898254\n",
      "epoch = 3 train_loss : 359.208557 , test loss : 367.877594\n",
      "epoch = 4 train_loss : 269.047729 , test loss : 273.192078\n",
      "epoch = 5 train_loss : 245.098618 , test loss : 247.018265\n",
      "epoch = 6 train_loss : 239.182281 , test loss : 240.211258\n",
      "epoch = 7 train_loss : 235.844681 , test loss : 236.616699\n",
      "epoch = 8 train_loss : 232.420502 , test loss : 233.126343\n",
      "epoch = 9 train_loss : 228.936707 , test loss : 229.638657\n",
      "epoch = 10 train_loss : 225.462494 , test loss : 226.214279\n",
      "epoch = 11 train_loss : 221.819977 , test loss : 222.500259\n",
      "epoch = 12 train_loss : 218.242050 , test loss : 218.883469\n",
      "epoch = 13 train_loss : 214.674530 , test loss : 215.341095\n",
      "epoch = 14 train_loss : 211.142212 , test loss : 211.818405\n",
      "epoch = 15 train_loss : 207.560364 , test loss : 208.178268\n",
      "epoch = 16 train_loss : 204.035461 , test loss : 204.688400\n",
      "epoch = 17 train_loss : 200.669403 , test loss : 201.346344\n",
      "epoch = 18 train_loss : 197.210556 , test loss : 197.856644\n",
      "epoch = 19 train_loss : 193.867477 , test loss : 194.537979\n",
      "epoch = 20 train_loss : 190.585052 , test loss : 191.273788\n",
      "epoch = 21 train_loss : 187.433395 , test loss : 188.116745\n",
      "epoch = 22 train_loss : 184.316269 , test loss : 185.061600\n",
      "epoch = 23 train_loss : 181.313492 , test loss : 182.044556\n",
      "epoch = 24 train_loss : 178.341660 , test loss : 179.116699\n",
      "epoch = 25 train_loss : 175.489426 , test loss : 176.272751\n",
      "epoch = 26 train_loss : 172.672195 , test loss : 173.491486\n",
      "epoch = 27 train_loss : 169.965256 , test loss : 170.824036\n",
      "epoch = 28 train_loss : 167.325943 , test loss : 168.202393\n",
      "epoch = 29 train_loss : 164.797272 , test loss : 165.694382\n",
      "epoch = 30 train_loss : 162.338959 , test loss : 163.270462\n",
      "epoch = 31 train_loss : 159.965698 , test loss : 160.927322\n",
      "epoch = 32 train_loss : 157.640549 , test loss : 158.621002\n",
      "epoch = 33 train_loss : 155.410675 , test loss : 156.428604\n",
      "epoch = 34 train_loss : 153.220749 , test loss : 154.268219\n",
      "epoch = 35 train_loss : 151.112503 , test loss : 152.180771\n",
      "epoch = 36 train_loss : 149.125473 , test loss : 150.228348\n",
      "epoch = 37 train_loss : 147.165009 , test loss : 148.287491\n",
      "epoch = 38 train_loss : 145.253403 , test loss : 146.400421\n",
      "epoch = 39 train_loss : 143.417725 , test loss : 144.599518\n",
      "epoch = 40 train_loss : 141.645645 , test loss : 142.842331\n",
      "epoch = 41 train_loss : 139.919769 , test loss : 141.143585\n",
      "epoch = 42 train_loss : 138.255386 , test loss : 139.497940\n",
      "epoch = 43 train_loss : 136.632294 , test loss : 137.888702\n",
      "epoch = 44 train_loss : 135.076920 , test loss : 136.363419\n",
      "epoch = 45 train_loss : 133.582626 , test loss : 134.863785\n",
      "epoch = 46 train_loss : 132.125046 , test loss : 133.437332\n",
      "epoch = 47 train_loss : 130.707703 , test loss : 132.011383\n",
      "epoch = 48 train_loss : 129.342789 , test loss : 130.666260\n",
      "epoch = 49 train_loss : 127.976341 , test loss : 129.323547\n",
      "epoch = 50 train_loss : 126.645699 , test loss : 127.996475\n",
      "epoch = 51 train_loss : 125.391037 , test loss : 126.754654\n",
      "epoch = 52 train_loss : 124.174522 , test loss : 125.521378\n",
      "epoch = 53 train_loss : 122.963974 , test loss : 124.327141\n",
      "epoch = 54 train_loss : 121.806778 , test loss : 123.147163\n",
      "epoch = 55 train_loss : 120.630600 , test loss : 121.990013\n",
      "epoch = 56 train_loss : 119.511284 , test loss : 120.857780\n",
      "epoch = 57 train_loss : 118.410530 , test loss : 119.763756\n",
      "epoch = 58 train_loss : 117.326363 , test loss : 118.698181\n",
      "epoch = 59 train_loss : 116.260201 , test loss : 117.609894\n",
      "epoch = 60 train_loss : 115.223854 , test loss : 116.568130\n",
      "epoch = 61 train_loss : 114.204590 , test loss : 115.550896\n",
      "epoch = 62 train_loss : 113.241028 , test loss : 114.553291\n",
      "epoch = 63 train_loss : 112.241264 , test loss : 113.573227\n",
      "epoch = 64 train_loss : 111.291687 , test loss : 112.601608\n",
      "epoch = 65 train_loss : 110.362320 , test loss : 111.675232\n",
      "epoch = 66 train_loss : 109.452164 , test loss : 110.732956\n",
      "epoch = 67 train_loss : 108.547882 , test loss : 109.847427\n",
      "epoch = 68 train_loss : 107.673470 , test loss : 108.927643\n",
      "epoch = 69 train_loss : 106.813950 , test loss : 108.068710\n",
      "epoch = 70 train_loss : 105.936516 , test loss : 107.192749\n",
      "epoch = 71 train_loss : 105.096855 , test loss : 106.336624\n",
      "epoch = 72 train_loss : 104.281006 , test loss : 105.497116\n",
      "epoch = 73 train_loss : 103.454063 , test loss : 104.665321\n",
      "epoch = 74 train_loss : 102.649239 , test loss : 103.831100\n",
      "epoch = 75 train_loss : 101.875137 , test loss : 103.058121\n",
      "epoch = 76 train_loss : 101.091461 , test loss : 102.267159\n",
      "epoch = 77 train_loss : 100.350075 , test loss : 101.475449\n",
      "epoch = 78 train_loss : 99.586273 , test loss : 100.717461\n",
      "epoch = 79 train_loss : 98.840088 , test loss : 99.980698\n",
      "epoch = 80 train_loss : 98.104630 , test loss : 99.237732\n",
      "epoch = 81 train_loss : 97.401390 , test loss : 98.473083\n",
      "epoch = 82 train_loss : 96.686874 , test loss : 97.802979\n",
      "epoch = 83 train_loss : 95.974373 , test loss : 97.042030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 84 train_loss : 95.285278 , test loss : 96.372261\n",
      "epoch = 85 train_loss : 94.591576 , test loss : 95.652771\n",
      "epoch = 86 train_loss : 93.928490 , test loss : 94.966133\n",
      "epoch = 87 train_loss : 93.273605 , test loss : 94.324844\n",
      "epoch = 88 train_loss : 92.616913 , test loss : 93.637329\n",
      "epoch = 89 train_loss : 91.966057 , test loss : 93.008377\n",
      "epoch = 90 train_loss : 91.330894 , test loss : 92.345490\n",
      "epoch = 91 train_loss : 90.720558 , test loss : 91.742783\n",
      "epoch = 92 train_loss : 90.087669 , test loss : 91.069878\n",
      "epoch = 93 train_loss : 89.485466 , test loss : 90.491997\n",
      "epoch = 94 train_loss : 88.885635 , test loss : 89.870773\n",
      "epoch = 95 train_loss : 88.300285 , test loss : 89.303337\n",
      "epoch = 96 train_loss : 87.716545 , test loss : 88.699867\n",
      "epoch = 97 train_loss : 87.150116 , test loss : 88.110107\n",
      "epoch = 98 train_loss : 86.616882 , test loss : 87.615181\n",
      "epoch = 99 train_loss : 86.037567 , test loss : 87.023384\n",
      "epoch = 100 train_loss : 85.495041 , test loss : 86.452118\n",
      "epoch = 101 train_loss : 84.953522 , test loss : 85.947350\n",
      "epoch = 102 train_loss : 84.430939 , test loss : 85.387817\n",
      "epoch = 103 train_loss : 83.903679 , test loss : 84.898369\n",
      "epoch = 104 train_loss : 83.394104 , test loss : 84.348198\n",
      "epoch = 105 train_loss : 82.863991 , test loss : 83.830048\n",
      "epoch = 106 train_loss : 82.368965 , test loss : 83.338417\n",
      "epoch = 107 train_loss : 81.878716 , test loss : 82.841728\n",
      "epoch = 108 train_loss : 81.395699 , test loss : 82.362961\n",
      "epoch = 109 train_loss : 80.915443 , test loss : 81.906937\n",
      "epoch = 110 train_loss : 80.445274 , test loss : 81.439934\n",
      "epoch = 111 train_loss : 79.963783 , test loss : 80.967865\n",
      "epoch = 112 train_loss : 79.523430 , test loss : 80.520279\n",
      "epoch = 113 train_loss : 79.070030 , test loss : 80.075111\n",
      "epoch = 114 train_loss : 78.612045 , test loss : 79.611732\n",
      "epoch = 115 train_loss : 78.177567 , test loss : 79.202766\n",
      "epoch = 116 train_loss : 77.780594 , test loss : 78.782013\n",
      "epoch = 117 train_loss : 77.337433 , test loss : 78.381340\n",
      "epoch = 118 train_loss : 76.912666 , test loss : 77.942558\n",
      "epoch = 119 train_loss : 76.497475 , test loss : 77.534576\n",
      "epoch = 120 train_loss : 76.093040 , test loss : 77.160004\n",
      "epoch = 121 train_loss : 75.694633 , test loss : 76.773140\n",
      "epoch = 122 train_loss : 75.298195 , test loss : 76.369431\n",
      "epoch = 123 train_loss : 74.913879 , test loss : 76.003098\n",
      "epoch = 124 train_loss : 74.540756 , test loss : 75.635101\n",
      "epoch = 125 train_loss : 74.156631 , test loss : 75.265015\n",
      "epoch = 126 train_loss : 73.780495 , test loss : 74.896225\n",
      "epoch = 127 train_loss : 73.436378 , test loss : 74.555771\n",
      "epoch = 128 train_loss : 73.068726 , test loss : 74.222427\n",
      "epoch = 129 train_loss : 72.691689 , test loss : 73.840599\n",
      "epoch = 130 train_loss : 72.356216 , test loss : 73.523552\n",
      "epoch = 131 train_loss : 72.009048 , test loss : 73.196495\n",
      "epoch = 132 train_loss : 71.665054 , test loss : 72.848930\n",
      "epoch = 133 train_loss : 71.332161 , test loss : 72.527031\n",
      "epoch = 134 train_loss : 71.017479 , test loss : 72.247231\n",
      "epoch = 135 train_loss : 70.683510 , test loss : 71.913536\n",
      "epoch = 136 train_loss : 70.360817 , test loss : 71.586021\n",
      "epoch = 137 train_loss : 70.074234 , test loss : 71.316574\n",
      "epoch = 138 train_loss : 69.755592 , test loss : 71.028481\n",
      "epoch = 139 train_loss : 69.439072 , test loss : 70.704407\n",
      "epoch = 141 train_loss : 69.040482 , test loss : 70.333046\n",
      "epoch = 142 train_loss : 68.558823 , test loss : 69.883209\n",
      "epoch = 143 train_loss : 68.278481 , test loss : 69.630318\n",
      "epoch = 144 train_loss : 68.110962 , test loss : 69.480576\n",
      "epoch = 145 train_loss : 67.703476 , test loss : 69.088478\n",
      "epoch = 146 train_loss : 67.411629 , test loss : 68.811691\n",
      "epoch = 147 train_loss : 67.184250 , test loss : 68.597687\n",
      "epoch = 148 train_loss : 67.025513 , test loss : 68.448418\n",
      "epoch = 149 train_loss : 66.604721 , test loss : 68.043152\n",
      "epoch = 150 train_loss : 66.357094 , test loss : 67.797882\n",
      "epoch = 151 train_loss : 66.130608 , test loss : 67.608322\n",
      "epoch = 152 train_loss : 65.913071 , test loss : 67.382469\n",
      "epoch = 153 train_loss : 65.570976 , test loss : 67.067154\n",
      "epoch = 154 train_loss : 65.351845 , test loss : 66.864304\n",
      "epoch = 155 train_loss : 65.091377 , test loss : 66.622963\n",
      "epoch = 156 train_loss : 64.846504 , test loss : 66.384209\n",
      "epoch = 157 train_loss : 64.630318 , test loss : 66.204163\n",
      "epoch = 158 train_loss : 64.360443 , test loss : 65.937401\n",
      "epoch = 159 train_loss : 64.171898 , test loss : 65.744919\n",
      "epoch = 160 train_loss : 63.919899 , test loss : 65.514359\n",
      "epoch = 161 train_loss : 63.811958 , test loss : 65.444000\n",
      "epoch = 162 train_loss : 63.473923 , test loss : 65.087631\n",
      "epoch = 163 train_loss : 63.228477 , test loss : 64.874496\n",
      "epoch = 164 train_loss : 63.145477 , test loss : 64.818336\n",
      "epoch = 165 train_loss : 63.088802 , test loss : 64.720314\n",
      "epoch = 166 train_loss : 62.594147 , test loss : 64.276047\n",
      "epoch = 167 train_loss : 62.604965 , test loss : 64.250999\n",
      "epoch = 168 train_loss : 62.166683 , test loss : 63.880398\n",
      "epoch = 169 train_loss : 61.875778 , test loss : 63.586922\n",
      "epoch = 171 train_loss : 61.598320 , test loss : 63.353371\n",
      "epoch = 172 train_loss : 61.374153 , test loss : 63.137234\n",
      "epoch = 173 train_loss : 61.044487 , test loss : 62.772964\n",
      "epoch = 174 train_loss : 60.833168 , test loss : 62.576004\n",
      "epoch = 175 train_loss : 60.727856 , test loss : 62.455452\n",
      "epoch = 176 train_loss : 60.507622 , test loss : 62.293362\n",
      "epoch = 177 train_loss : 60.239697 , test loss : 61.987133\n",
      "epoch = 178 train_loss : 60.156868 , test loss : 61.959064\n",
      "epoch = 179 train_loss : 59.957302 , test loss : 61.785034\n",
      "epoch = 180 train_loss : 59.816872 , test loss : 61.566483\n",
      "epoch = 181 train_loss : 59.517162 , test loss : 61.329079\n",
      "epoch = 182 train_loss : 59.374126 , test loss : 61.232082\n",
      "epoch = 183 train_loss : 59.161030 , test loss : 60.940361\n",
      "epoch = 185 train_loss : 58.713276 , test loss : 60.533012\n",
      "epoch = 186 train_loss : 58.610020 , test loss : 60.480839\n",
      "epoch = 187 train_loss : 58.377045 , test loss : 60.226284\n",
      "epoch = 188 train_loss : 58.159851 , test loss : 60.013145\n",
      "epoch = 189 train_loss : 57.977375 , test loss : 59.808243\n",
      "epoch = 190 train_loss : 57.991165 , test loss : 59.766304\n",
      "epoch = 191 train_loss : 57.897984 , test loss : 59.678257\n",
      "epoch = 192 train_loss : 57.624760 , test loss : 59.541252\n",
      "epoch = 193 train_loss : 57.282585 , test loss : 59.156956\n",
      "epoch = 195 train_loss : 56.922398 , test loss : 58.759964\n",
      "epoch = 196 train_loss : 56.819653 , test loss : 58.724384\n",
      "epoch = 197 train_loss : 56.872112 , test loss : 58.635876\n",
      "epoch = 198 train_loss : 56.403549 , test loss : 58.251884\n",
      "epoch = 200 train_loss : 56.222408 , test loss : 58.026485\n",
      "epoch = 201 train_loss : 56.033619 , test loss : 57.820229\n",
      "epoch = 202 train_loss : 55.742004 , test loss : 57.647785\n",
      "epoch = 203 train_loss : 55.601223 , test loss : 57.499268\n",
      "epoch = 204 train_loss : 55.403030 , test loss : 57.231262\n",
      "epoch = 205 train_loss : 55.411926 , test loss : 57.184361\n",
      "epoch = 206 train_loss : 55.080723 , test loss : 56.962048\n",
      "epoch = 207 train_loss : 54.957733 , test loss : 56.867844\n",
      "epoch = 208 train_loss : 54.845425 , test loss : 56.752331\n",
      "epoch = 209 train_loss : 54.577129 , test loss : 56.433884\n",
      "epoch = 210 train_loss : 54.442337 , test loss : 56.307812\n",
      "epoch = 211 train_loss : 54.263458 , test loss : 56.124538\n",
      "epoch = 212 train_loss : 54.096115 , test loss : 55.920689\n",
      "epoch = 213 train_loss : 53.935722 , test loss : 55.796909\n",
      "epoch = 214 train_loss : 53.822880 , test loss : 55.704720\n",
      "epoch = 216 train_loss : 53.498341 , test loss : 55.370136\n",
      "epoch = 218 train_loss : 53.229572 , test loss : 54.998020\n",
      "epoch = 219 train_loss : 53.007011 , test loss : 54.835617\n",
      "epoch = 220 train_loss : 53.041164 , test loss : 54.756348\n",
      "epoch = 221 train_loss : 52.790230 , test loss : 54.536995\n",
      "epoch = 222 train_loss : 52.598415 , test loss : 54.355335\n",
      "epoch = 224 train_loss : 52.271248 , test loss : 54.034706\n",
      "epoch = 225 train_loss : 52.164761 , test loss : 54.000916\n",
      "epoch = 227 train_loss : 51.832588 , test loss : 53.598545\n",
      "epoch = 228 train_loss : 51.773018 , test loss : 53.470669\n",
      "epoch = 230 train_loss : 51.461960 , test loss : 53.173008\n",
      "epoch = 231 train_loss : 51.364464 , test loss : 53.049904\n",
      "epoch = 232 train_loss : 51.204498 , test loss : 52.882565\n",
      "epoch = 233 train_loss : 50.986530 , test loss : 52.722401\n",
      "epoch = 235 train_loss : 50.795738 , test loss : 52.597214\n",
      "epoch = 236 train_loss : 50.693157 , test loss : 52.285225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 237 train_loss : 50.436321 , test loss : 52.140759\n",
      "epoch = 238 train_loss : 50.341408 , test loss : 52.113979\n",
      "epoch = 239 train_loss : 50.170025 , test loss : 51.863731\n",
      "epoch = 240 train_loss : 50.037457 , test loss : 51.741302\n",
      "epoch = 241 train_loss : 49.986244 , test loss : 51.610367\n",
      "epoch = 242 train_loss : 49.803936 , test loss : 51.515427\n",
      "epoch = 244 train_loss : 49.684376 , test loss : 51.452461\n",
      "epoch = 245 train_loss : 49.483829 , test loss : 51.201023\n",
      "epoch = 246 train_loss : 49.313789 , test loss : 51.032127\n",
      "epoch = 248 train_loss : 49.036823 , test loss : 50.595047\n",
      "epoch = 250 train_loss : 48.748806 , test loss : 50.367844\n",
      "epoch = 251 train_loss : 48.726093 , test loss : 50.250957\n",
      "epoch = 252 train_loss : 48.507885 , test loss : 50.055794\n",
      "epoch = 253 train_loss : 48.406265 , test loss : 49.954277\n",
      "epoch = 255 train_loss : 48.149364 , test loss : 49.696484\n",
      "epoch = 256 train_loss : 48.039185 , test loss : 49.644318\n",
      "epoch = 257 train_loss : 47.909809 , test loss : 49.490448\n",
      "epoch = 258 train_loss : 47.909279 , test loss : 49.348404\n",
      "epoch = 260 train_loss : 47.578838 , test loss : 49.145359\n",
      "epoch = 262 train_loss : 47.322510 , test loss : 48.783909\n",
      "epoch = 264 train_loss : 47.179798 , test loss : 48.780613\n",
      "epoch = 265 train_loss : 46.982098 , test loss : 48.483116\n",
      "epoch = 266 train_loss : 46.882343 , test loss : 48.328194\n",
      "epoch = 268 train_loss : 46.699081 , test loss : 48.069260\n",
      "epoch = 269 train_loss : 46.619617 , test loss : 47.996059\n",
      "epoch = 270 train_loss : 46.431404 , test loss : 47.891556\n",
      "epoch = 271 train_loss : 46.390102 , test loss : 47.757057\n",
      "epoch = 272 train_loss : 46.275585 , test loss : 47.638874\n",
      "epoch = 275 train_loss : 45.907047 , test loss : 47.344807\n",
      "epoch = 277 train_loss : 45.766617 , test loss : 47.095295\n",
      "epoch = 279 train_loss : 45.616802 , test loss : 46.888111\n",
      "epoch = 281 train_loss : 45.299973 , test loss : 46.664352\n",
      "epoch = 283 train_loss : 45.296249 , test loss : 46.533268\n",
      "epoch = 284 train_loss : 45.071976 , test loss : 46.359375\n",
      "epoch = 286 train_loss : 44.813137 , test loss : 46.131481\n",
      "epoch = 287 train_loss : 44.808002 , test loss : 46.012638\n",
      "epoch = 288 train_loss : 44.613918 , test loss : 45.970974\n",
      "epoch = 290 train_loss : 44.423275 , test loss : 45.778042\n",
      "epoch = 291 train_loss : 44.333199 , test loss : 45.657269\n",
      "epoch = 293 train_loss : 44.353817 , test loss : 45.539845\n",
      "epoch = 295 train_loss : 44.052822 , test loss : 45.265507\n",
      "epoch = 296 train_loss : 43.882301 , test loss : 45.128235\n",
      "epoch = 297 train_loss : 43.821884 , test loss : 45.052948\n",
      "epoch = 298 train_loss : 43.701210 , test loss : 44.999161\n",
      "epoch = 299 train_loss : 43.640522 , test loss : 44.835159\n",
      "epoch = 302 train_loss : 43.358208 , test loss : 44.633980\n",
      "epoch = 303 train_loss : 43.308502 , test loss : 44.628685\n",
      "epoch = 305 train_loss : 43.116402 , test loss : 44.351673\n",
      "epoch = 307 train_loss : 42.955070 , test loss : 44.209663\n",
      "epoch = 308 train_loss : 42.883572 , test loss : 44.076653\n",
      "epoch = 309 train_loss : 42.891285 , test loss : 44.030170\n",
      "epoch = 310 train_loss : 42.724899 , test loss : 43.889111\n",
      "epoch = 312 train_loss : 42.568058 , test loss : 43.747849\n",
      "epoch = 314 train_loss : 42.400410 , test loss : 43.611206\n",
      "epoch = 316 train_loss : 42.374020 , test loss : 43.447666\n",
      "epoch = 318 train_loss : 42.095955 , test loss : 43.265076\n",
      "epoch = 320 train_loss : 41.991699 , test loss : 43.143169\n",
      "epoch = 323 train_loss : 41.774750 , test loss : 43.026669\n",
      "epoch = 324 train_loss : 41.725044 , test loss : 42.813171\n",
      "epoch = 326 train_loss : 41.528103 , test loss : 42.702747\n",
      "epoch = 330 train_loss : 41.273174 , test loss : 42.480846\n",
      "epoch = 331 train_loss : 41.186615 , test loss : 42.355747\n",
      "epoch = 333 train_loss : 41.058247 , test loss : 42.227020\n",
      "epoch = 334 train_loss : 40.999157 , test loss : 42.157139\n",
      "epoch = 335 train_loss : 41.018219 , test loss : 42.057434\n",
      "epoch = 336 train_loss : 40.875977 , test loss : 42.050930\n",
      "epoch = 337 train_loss : 41.048820 , test loss : 42.024010\n",
      "epoch = 338 train_loss : 40.844204 , test loss : 41.870480\n",
      "epoch = 340 train_loss : 40.617943 , test loss : 41.795528\n",
      "epoch = 341 train_loss : 40.734066 , test loss : 41.772438\n",
      "epoch = 343 train_loss : 40.522793 , test loss : 41.551437\n",
      "epoch = 345 train_loss : 40.325806 , test loss : 41.493221\n",
      "epoch = 347 train_loss : 40.220409 , test loss : 41.430759\n",
      "epoch = 348 train_loss : 40.153873 , test loss : 41.323174\n",
      "epoch = 349 train_loss : 40.177727 , test loss : 41.217743\n",
      "epoch = 350 train_loss : 40.204033 , test loss : 41.189991\n",
      "epoch = 351 train_loss : 40.212013 , test loss : 41.135921\n",
      "epoch = 353 train_loss : 39.878792 , test loss : 40.956615\n",
      "epoch = 355 train_loss : 39.765282 , test loss : 40.923191\n",
      "epoch = 357 train_loss : 39.712910 , test loss : 40.760033\n",
      "epoch = 359 train_loss : 39.550457 , test loss : 40.699596\n",
      "epoch = 362 train_loss : 39.399044 , test loss : 40.527370\n",
      "epoch = 363 train_loss : 39.390392 , test loss : 40.443565\n",
      "epoch = 364 train_loss : 39.366978 , test loss : 40.392826\n",
      "epoch = 367 train_loss : 39.153084 , test loss : 40.272541\n",
      "epoch = 369 train_loss : 39.079998 , test loss : 40.166809\n",
      "epoch = 372 train_loss : 38.947628 , test loss : 40.010319\n",
      "epoch = 374 train_loss : 38.825802 , test loss : 39.964554\n",
      "epoch = 375 train_loss : 38.778194 , test loss : 39.892082\n",
      "epoch = 376 train_loss : 38.845058 , test loss : 39.838573\n",
      "epoch = 377 train_loss : 38.688839 , test loss : 39.828972\n",
      "epoch = 378 train_loss : 38.645966 , test loss : 39.805603\n",
      "epoch = 379 train_loss : 38.603592 , test loss : 39.723576\n",
      "epoch = 380 train_loss : 38.557426 , test loss : 39.705639\n",
      "epoch = 381 train_loss : 38.588879 , test loss : 39.622593\n",
      "epoch = 384 train_loss : 38.397209 , test loss : 39.481445\n",
      "epoch = 388 train_loss : 38.242851 , test loss : 39.421402\n",
      "epoch = 390 train_loss : 38.349842 , test loss : 39.355431\n",
      "epoch = 391 train_loss : 38.326309 , test loss : 39.311886\n",
      "epoch = 396 train_loss : 38.089050 , test loss : 39.087555\n",
      "epoch = 397 train_loss : 37.898106 , test loss : 38.964523\n",
      "epoch = 401 train_loss : 37.754040 , test loss : 38.953098\n",
      "epoch = 402 train_loss : 37.714703 , test loss : 38.805626\n",
      "epoch = 405 train_loss : 37.605804 , test loss : 38.802582\n",
      "epoch = 407 train_loss : 37.567516 , test loss : 38.775509\n",
      "epoch = 408 train_loss : 37.513878 , test loss : 38.642040\n",
      "epoch = 409 train_loss : 37.585903 , test loss : 38.601791\n",
      "epoch = 414 train_loss : 37.322083 , test loss : 38.466515\n",
      "epoch = 417 train_loss : 37.322926 , test loss : 38.405529\n",
      "epoch = 418 train_loss : 37.340790 , test loss : 38.379326\n",
      "epoch = 420 train_loss : 37.130680 , test loss : 38.289192\n",
      "epoch = 421 train_loss : 37.128914 , test loss : 38.251068\n",
      "epoch = 423 train_loss : 37.044888 , test loss : 38.239143\n",
      "epoch = 425 train_loss : 37.217659 , test loss : 38.225384\n",
      "epoch = 426 train_loss : 37.000969 , test loss : 38.113461\n",
      "epoch = 431 train_loss : 36.821766 , test loss : 38.075748\n",
      "epoch = 432 train_loss : 36.971424 , test loss : 38.043571\n",
      "epoch = 433 train_loss : 36.775066 , test loss : 37.933651\n",
      "epoch = 435 train_loss : 36.737930 , test loss : 37.899864\n",
      "epoch = 436 train_loss : 36.691002 , test loss : 37.878567\n",
      "epoch = 437 train_loss : 36.709236 , test loss : 37.867474\n",
      "epoch = 438 train_loss : 36.644051 , test loss : 37.843872\n",
      "epoch = 443 train_loss : 36.535557 , test loss : 37.827469\n",
      "epoch = 445 train_loss : 36.533585 , test loss : 37.685272\n",
      "epoch = 447 train_loss : 36.418766 , test loss : 37.656063\n",
      "epoch = 448 train_loss : 36.391365 , test loss : 37.627731\n",
      "epoch = 449 train_loss : 36.367554 , test loss : 37.617615\n",
      "epoch = 452 train_loss : 36.329643 , test loss : 37.521248\n",
      "epoch = 454 train_loss : 36.266369 , test loss : 37.465111\n",
      "epoch = 457 train_loss : 36.230698 , test loss : 37.417309\n",
      "epoch = 460 train_loss : 36.205372 , test loss : 37.386009\n",
      "epoch = 461 train_loss : 36.123760 , test loss : 37.299397\n",
      "epoch = 462 train_loss : 36.083794 , test loss : 37.295670\n",
      "epoch = 465 train_loss : 36.023052 , test loss : 37.269363\n",
      "epoch = 469 train_loss : 36.026108 , test loss : 37.237949\n",
      "epoch = 472 train_loss : 35.913200 , test loss : 37.218075\n",
      "epoch = 474 train_loss : 35.903702 , test loss : 37.081444\n",
      "epoch = 475 train_loss : 35.878204 , test loss : 37.048309\n",
      "epoch = 479 train_loss : 35.738354 , test loss : 37.034973\n",
      "epoch = 480 train_loss : 35.748051 , test loss : 36.999386\n",
      "epoch = 483 train_loss : 35.695724 , test loss : 36.933708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 487 train_loss : 35.597206 , test loss : 36.901684\n",
      "epoch = 490 train_loss : 35.576408 , test loss : 36.825768\n",
      "epoch = 497 train_loss : 35.461536 , test loss : 36.748646\n",
      "epoch = 502 train_loss : 35.384346 , test loss : 36.659729\n",
      "epoch = 505 train_loss : 35.301750 , test loss : 36.654308\n",
      "epoch = 510 train_loss : 35.232712 , test loss : 36.568283\n",
      "epoch = 516 train_loss : 35.179352 , test loss : 36.493225\n",
      "epoch = 518 train_loss : 35.110737 , test loss : 36.465855\n",
      "epoch = 520 train_loss : 35.109180 , test loss : 36.414772\n",
      "epoch = 527 train_loss : 34.985950 , test loss : 36.382778\n",
      "epoch = 530 train_loss : 35.096497 , test loss : 36.330425\n",
      "epoch = 535 train_loss : 34.882980 , test loss : 36.274750\n",
      "epoch = 539 train_loss : 34.835377 , test loss : 36.255936\n",
      "epoch = 540 train_loss : 34.821186 , test loss : 36.238926\n",
      "epoch = 541 train_loss : 34.932709 , test loss : 36.196182\n",
      "epoch = 543 train_loss : 34.821442 , test loss : 36.136360\n",
      "epoch = 548 train_loss : 34.744690 , test loss : 36.130894\n",
      "epoch = 549 train_loss : 34.714386 , test loss : 36.115345\n",
      "epoch = 553 train_loss : 34.670574 , test loss : 36.113449\n",
      "epoch = 556 train_loss : 34.656116 , test loss : 36.047394\n",
      "epoch = 558 train_loss : 34.615685 , test loss : 36.033112\n",
      "epoch = 561 train_loss : 34.641014 , test loss : 35.990982\n",
      "epoch = 565 train_loss : 34.543240 , test loss : 35.968014\n",
      "epoch = 571 train_loss : 34.520668 , test loss : 35.957333\n",
      "epoch = 574 train_loss : 34.454464 , test loss : 35.916058\n",
      "epoch = 576 train_loss : 34.430954 , test loss : 35.899624\n",
      "epoch = 577 train_loss : 34.422710 , test loss : 35.881191\n",
      "epoch = 582 train_loss : 34.457493 , test loss : 35.854668\n",
      "epoch = 585 train_loss : 34.342709 , test loss : 35.827770\n",
      "epoch = 587 train_loss : 34.394482 , test loss : 35.776573\n",
      "epoch = 593 train_loss : 34.291126 , test loss : 35.717159\n",
      "epoch = 601 train_loss : 34.283306 , test loss : 35.704166\n",
      "epoch = 603 train_loss : 34.201118 , test loss : 35.672333\n",
      "epoch = 611 train_loss : 34.249657 , test loss : 35.654884\n",
      "epoch = 615 train_loss : 34.099274 , test loss : 35.615433\n",
      "epoch = 617 train_loss : 34.104004 , test loss : 35.606842\n",
      "epoch = 619 train_loss : 34.068634 , test loss : 35.588787\n",
      "epoch = 621 train_loss : 34.065502 , test loss : 35.574299\n",
      "epoch = 624 train_loss : 34.063725 , test loss : 35.570385\n",
      "epoch = 625 train_loss : 34.065361 , test loss : 35.559696\n",
      "epoch = 627 train_loss : 34.012920 , test loss : 35.544003\n",
      "epoch = 630 train_loss : 34.012501 , test loss : 35.473259\n",
      "epoch = 636 train_loss : 33.956799 , test loss : 35.448524\n",
      "epoch = 640 train_loss : 33.932232 , test loss : 35.446060\n",
      "epoch = 641 train_loss : 33.921379 , test loss : 35.432838\n",
      "epoch = 644 train_loss : 33.907955 , test loss : 35.423214\n",
      "epoch = 652 train_loss : 33.941967 , test loss : 35.401001\n",
      "epoch = 656 train_loss : 33.844803 , test loss : 35.371517\n",
      "epoch = 659 train_loss : 33.893051 , test loss : 35.370079\n",
      "epoch = 660 train_loss : 33.879295 , test loss : 35.331566\n",
      "epoch = 663 train_loss : 33.804321 , test loss : 35.327755\n",
      "epoch = 664 train_loss : 33.818714 , test loss : 35.312717\n",
      "epoch = 668 train_loss : 33.822483 , test loss : 35.289726\n",
      "epoch = 671 train_loss : 33.745033 , test loss : 35.283268\n",
      "epoch = 673 train_loss : 33.781628 , test loss : 35.261826\n",
      "epoch = 678 train_loss : 33.762939 , test loss : 35.258972\n",
      "epoch = 679 train_loss : 33.775822 , test loss : 35.243351\n",
      "epoch = 688 train_loss : 33.648190 , test loss : 35.242039\n",
      "epoch = 692 train_loss : 33.740509 , test loss : 35.222160\n",
      "epoch = 694 train_loss : 33.621357 , test loss : 35.172989\n",
      "epoch = 705 train_loss : 33.563320 , test loss : 35.152176\n",
      "epoch = 706 train_loss : 33.558304 , test loss : 35.132027\n",
      "epoch = 710 train_loss : 33.539471 , test loss : 35.120728\n",
      "epoch = 711 train_loss : 33.596382 , test loss : 35.075775\n",
      "epoch = 717 train_loss : 33.526352 , test loss : 35.030071\n",
      "epoch = 732 train_loss : 33.471813 , test loss : 35.004292\n",
      "epoch = 741 train_loss : 33.440830 , test loss : 34.981312\n",
      "epoch = 747 train_loss : 33.434608 , test loss : 34.953392\n",
      "epoch = 754 train_loss : 33.375259 , test loss : 34.904869\n",
      "epoch = 767 train_loss : 33.319729 , test loss : 34.884991\n",
      "epoch = 772 train_loss : 33.378704 , test loss : 34.880013\n",
      "epoch = 774 train_loss : 33.303726 , test loss : 34.873108\n",
      "epoch = 784 train_loss : 33.254707 , test loss : 34.870850\n",
      "epoch = 788 train_loss : 33.304253 , test loss : 34.847809\n",
      "epoch = 792 train_loss : 33.258915 , test loss : 34.821053\n",
      "epoch = 806 train_loss : 33.232224 , test loss : 34.785816\n",
      "epoch = 807 train_loss : 33.223549 , test loss : 34.782139\n",
      "epoch = 810 train_loss : 33.196468 , test loss : 34.765396\n",
      "epoch = 815 train_loss : 33.174984 , test loss : 34.758438\n",
      "epoch = 827 train_loss : 33.127308 , test loss : 34.755669\n",
      "epoch = 829 train_loss : 33.161728 , test loss : 34.742710\n",
      "epoch = 837 train_loss : 33.223667 , test loss : 34.705601\n",
      "epoch = 846 train_loss : 33.144241 , test loss : 34.698429\n",
      "epoch = 848 train_loss : 33.192101 , test loss : 34.679199\n",
      "epoch = 857 train_loss : 33.080147 , test loss : 34.650646\n",
      "epoch = 862 train_loss : 33.046341 , test loss : 34.647610\n",
      "epoch = 865 train_loss : 33.058487 , test loss : 34.626980\n",
      "epoch = 866 train_loss : 33.083122 , test loss : 34.624718\n",
      "epoch = 872 train_loss : 33.057201 , test loss : 34.607605\n",
      "epoch = 876 train_loss : 33.031799 , test loss : 34.605572\n",
      "epoch = 884 train_loss : 33.058506 , test loss : 34.591099\n",
      "epoch = 888 train_loss : 33.000889 , test loss : 34.586075\n",
      "epoch = 895 train_loss : 32.984001 , test loss : 34.553101\n",
      "epoch = 928 train_loss : 32.943993 , test loss : 34.539803\n",
      "epoch = 934 train_loss : 32.969910 , test loss : 34.515812\n",
      "epoch = 936 train_loss : 32.904739 , test loss : 34.513836\n",
      "epoch = 941 train_loss : 33.015869 , test loss : 34.512623\n",
      "epoch = 948 train_loss : 32.897236 , test loss : 34.512169\n",
      "epoch = 953 train_loss : 32.872826 , test loss : 34.503826\n",
      "epoch = 963 train_loss : 32.864731 , test loss : 34.441006\n",
      "epoch = 1000 train_loss : 32.879692 , test loss : 34.439110\n",
      "epoch = 1014 train_loss : 32.779785 , test loss : 34.416550\n",
      "epoch = 1018 train_loss : 32.783707 , test loss : 34.411022\n",
      "epoch = 1021 train_loss : 32.775555 , test loss : 34.405632\n",
      "epoch = 1022 train_loss : 32.805119 , test loss : 34.397655\n",
      "epoch = 1023 train_loss : 32.820728 , test loss : 34.370804\n",
      "epoch = 1032 train_loss : 32.846226 , test loss : 34.368439\n",
      "epoch = 1062 train_loss : 32.737423 , test loss : 34.359127\n",
      "epoch = 1071 train_loss : 32.823498 , test loss : 34.332386\n",
      "epoch = 1080 train_loss : 32.709679 , test loss : 34.331718\n",
      "epoch = 1093 train_loss : 32.698994 , test loss : 34.303524\n",
      "epoch = 1095 train_loss : 32.724407 , test loss : 34.300282\n",
      "epoch = 1108 train_loss : 32.726955 , test loss : 34.294861\n",
      "epoch = 1126 train_loss : 32.669964 , test loss : 34.286495\n",
      "epoch = 1127 train_loss : 32.679199 , test loss : 34.275532\n",
      "epoch = 1135 train_loss : 32.687111 , test loss : 34.274681\n",
      "epoch = 1147 train_loss : 32.654747 , test loss : 34.271297\n",
      "epoch = 1174 train_loss : 32.695805 , test loss : 34.267532\n",
      "epoch = 1206 train_loss : 32.625214 , test loss : 34.247169\n",
      "epoch = 1233 train_loss : 32.672272 , test loss : 34.245380\n",
      "epoch = 1241 train_loss : 32.610458 , test loss : 34.226753\n",
      "epoch = 1245 train_loss : 32.611801 , test loss : 34.199722\n",
      "epoch = 1257 train_loss : 32.639496 , test loss : 34.192417\n",
      "epoch = 1306 train_loss : 32.598499 , test loss : 34.184280\n",
      "epoch = 1340 train_loss : 32.563969 , test loss : 34.182335\n",
      "epoch = 1359 train_loss : 32.567284 , test loss : 34.176250\n",
      "epoch = 1430 train_loss : 32.549416 , test loss : 34.170246\n",
      "epoch = 1446 train_loss : 32.542023 , test loss : 34.148136\n",
      "epoch = 1550 train_loss : 32.527615 , test loss : 34.143673\n",
      "epoch = 1556 train_loss : 32.511589 , test loss : 34.130951\n",
      "epoch = 1604 train_loss : 32.510899 , test loss : 34.116550\n",
      "epoch = 1654 train_loss : 32.474808 , test loss : 34.107426\n",
      "epoch = 1955 train_loss : 32.454372 , test loss : 34.105221\n",
      "epoch = 1960 train_loss : 32.502110 , test loss : 34.073753\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 32.502110,test loss : 34.073753\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 572.781189 , test loss : 575.513367\n",
      "epoch = 2 train_loss : 454.580688 , test loss : 467.618103\n",
      "epoch = 3 train_loss : 437.184692 , test loss : 451.156921\n",
      "epoch = 4 train_loss : 415.837372 , test loss : 426.793152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5 train_loss : 396.441620 , test loss : 404.982910\n",
      "epoch = 6 train_loss : 376.913208 , test loss : 383.944366\n",
      "epoch = 7 train_loss : 358.417664 , test loss : 363.824524\n",
      "epoch = 8 train_loss : 340.220520 , test loss : 344.203705\n",
      "epoch = 9 train_loss : 323.078064 , test loss : 325.789948\n",
      "epoch = 10 train_loss : 306.856445 , test loss : 308.005585\n",
      "epoch = 11 train_loss : 291.486450 , test loss : 291.461334\n",
      "epoch = 12 train_loss : 276.987213 , test loss : 275.986847\n",
      "epoch = 13 train_loss : 263.574585 , test loss : 261.539612\n",
      "epoch = 14 train_loss : 251.216446 , test loss : 248.182434\n",
      "epoch = 15 train_loss : 239.573395 , test loss : 235.837234\n",
      "epoch = 16 train_loss : 228.946091 , test loss : 224.446442\n",
      "epoch = 17 train_loss : 218.886887 , test loss : 213.751282\n",
      "epoch = 18 train_loss : 209.740936 , test loss : 204.051254\n",
      "epoch = 19 train_loss : 201.189774 , test loss : 194.963959\n",
      "epoch = 20 train_loss : 193.402969 , test loss : 186.712082\n",
      "epoch = 21 train_loss : 186.186508 , test loss : 179.099182\n",
      "epoch = 22 train_loss : 179.602783 , test loss : 172.169693\n",
      "epoch = 23 train_loss : 173.509903 , test loss : 165.808334\n",
      "epoch = 24 train_loss : 167.896774 , test loss : 159.937057\n",
      "epoch = 25 train_loss : 162.717865 , test loss : 154.523041\n",
      "epoch = 26 train_loss : 157.945999 , test loss : 149.563538\n",
      "epoch = 27 train_loss : 153.751160 , test loss : 145.315872\n",
      "epoch = 28 train_loss : 149.560318 , test loss : 140.950089\n",
      "epoch = 29 train_loss : 145.841187 , test loss : 137.132919\n",
      "epoch = 30 train_loss : 142.316528 , test loss : 133.482971\n",
      "epoch = 31 train_loss : 139.062256 , test loss : 130.248581\n",
      "epoch = 32 train_loss : 136.018616 , test loss : 127.146431\n",
      "epoch = 33 train_loss : 133.206573 , test loss : 124.302467\n",
      "epoch = 34 train_loss : 130.565262 , test loss : 121.666260\n",
      "epoch = 35 train_loss : 128.018295 , test loss : 119.138443\n",
      "epoch = 36 train_loss : 125.665337 , test loss : 116.761803\n",
      "epoch = 37 train_loss : 123.458771 , test loss : 114.606842\n",
      "epoch = 38 train_loss : 121.338234 , test loss : 112.479721\n",
      "epoch = 39 train_loss : 119.362808 , test loss : 110.589058\n",
      "epoch = 40 train_loss : 117.458740 , test loss : 108.720322\n",
      "epoch = 41 train_loss : 115.645813 , test loss : 106.919388\n",
      "epoch = 42 train_loss : 113.910973 , test loss : 105.272171\n",
      "epoch = 43 train_loss : 112.236977 , test loss : 103.643532\n",
      "epoch = 44 train_loss : 110.637138 , test loss : 102.139252\n",
      "epoch = 45 train_loss : 109.080269 , test loss : 100.600395\n",
      "epoch = 46 train_loss : 107.621735 , test loss : 99.160469\n",
      "epoch = 47 train_loss : 106.200455 , test loss : 97.866852\n",
      "epoch = 48 train_loss : 104.820869 , test loss : 96.551697\n",
      "epoch = 49 train_loss : 103.493835 , test loss : 95.219437\n",
      "epoch = 50 train_loss : 102.213165 , test loss : 93.968826\n",
      "epoch = 51 train_loss : 100.977608 , test loss : 92.850639\n",
      "epoch = 52 train_loss : 99.791222 , test loss : 91.763779\n",
      "epoch = 53 train_loss : 98.661171 , test loss : 90.598846\n",
      "epoch = 54 train_loss : 97.537682 , test loss : 89.552544\n",
      "epoch = 55 train_loss : 96.479813 , test loss : 88.663368\n",
      "epoch = 56 train_loss : 95.612846 , test loss : 87.574532\n",
      "epoch = 57 train_loss : 94.450073 , test loss : 86.778732\n",
      "epoch = 58 train_loss : 93.438797 , test loss : 85.697044\n",
      "epoch = 59 train_loss : 92.502052 , test loss : 84.788857\n",
      "epoch = 60 train_loss : 91.551682 , test loss : 84.028946\n",
      "epoch = 61 train_loss : 90.662476 , test loss : 83.117661\n",
      "epoch = 62 train_loss : 89.822472 , test loss : 82.370300\n",
      "epoch = 63 train_loss : 88.957565 , test loss : 81.565720\n",
      "epoch = 64 train_loss : 88.350082 , test loss : 80.825294\n",
      "epoch = 65 train_loss : 87.663528 , test loss : 80.600426\n",
      "epoch = 66 train_loss : 86.629257 , test loss : 79.396156\n",
      "epoch = 67 train_loss : 85.902496 , test loss : 78.668701\n",
      "epoch = 68 train_loss : 85.241219 , test loss : 78.229668\n",
      "epoch = 69 train_loss : 84.510994 , test loss : 77.388542\n",
      "epoch = 70 train_loss : 83.828491 , test loss : 76.898743\n",
      "epoch = 71 train_loss : 83.162056 , test loss : 76.239021\n",
      "epoch = 72 train_loss : 82.528130 , test loss : 75.642479\n",
      "epoch = 73 train_loss : 81.946106 , test loss : 75.043358\n",
      "epoch = 74 train_loss : 81.376045 , test loss : 74.686447\n",
      "epoch = 75 train_loss : 80.814598 , test loss : 73.988853\n",
      "epoch = 76 train_loss : 80.317253 , test loss : 73.508682\n",
      "epoch = 77 train_loss : 79.650513 , test loss : 73.039978\n",
      "epoch = 78 train_loss : 79.121315 , test loss : 72.507118\n",
      "epoch = 79 train_loss : 78.622643 , test loss : 72.136574\n",
      "epoch = 80 train_loss : 78.098457 , test loss : 71.590492\n",
      "epoch = 81 train_loss : 77.632759 , test loss : 71.141090\n",
      "epoch = 83 train_loss : 76.755630 , test loss : 70.316788\n",
      "epoch = 84 train_loss : 76.220528 , test loss : 69.920029\n",
      "epoch = 85 train_loss : 75.792580 , test loss : 69.543800\n",
      "epoch = 86 train_loss : 75.510994 , test loss : 69.169212\n",
      "epoch = 87 train_loss : 75.115005 , test loss : 69.028976\n",
      "epoch = 88 train_loss : 74.936539 , test loss : 68.627533\n",
      "epoch = 89 train_loss : 74.219376 , test loss : 68.174072\n",
      "epoch = 90 train_loss : 73.750648 , test loss : 67.675903\n",
      "epoch = 91 train_loss : 73.407303 , test loss : 67.326973\n",
      "epoch = 92 train_loss : 73.126862 , test loss : 67.192528\n",
      "epoch = 93 train_loss : 72.817703 , test loss : 66.749870\n",
      "epoch = 94 train_loss : 72.347977 , test loss : 66.434280\n",
      "epoch = 95 train_loss : 72.088188 , test loss : 66.227730\n",
      "epoch = 96 train_loss : 71.637428 , test loss : 65.708344\n",
      "epoch = 97 train_loss : 71.384941 , test loss : 65.448021\n",
      "epoch = 98 train_loss : 71.077454 , test loss : 65.303673\n",
      "epoch = 99 train_loss : 70.664444 , test loss : 64.888771\n",
      "epoch = 100 train_loss : 70.356972 , test loss : 64.543770\n",
      "epoch = 101 train_loss : 70.193329 , test loss : 64.364311\n",
      "epoch = 102 train_loss : 69.780342 , test loss : 64.092972\n",
      "epoch = 104 train_loss : 69.143425 , test loss : 63.423199\n",
      "epoch = 105 train_loss : 68.851967 , test loss : 63.201580\n",
      "epoch = 106 train_loss : 68.749878 , test loss : 63.161293\n",
      "epoch = 107 train_loss : 68.257942 , test loss : 62.641697\n",
      "epoch = 108 train_loss : 68.027328 , test loss : 62.392792\n",
      "epoch = 109 train_loss : 67.886620 , test loss : 62.351906\n",
      "epoch = 110 train_loss : 67.449265 , test loss : 61.855568\n",
      "epoch = 111 train_loss : 67.250778 , test loss : 61.659298\n",
      "epoch = 112 train_loss : 66.910583 , test loss : 61.383076\n",
      "epoch = 113 train_loss : 66.651810 , test loss : 61.142662\n",
      "epoch = 114 train_loss : 66.412552 , test loss : 60.904575\n",
      "epoch = 115 train_loss : 66.180634 , test loss : 60.662750\n",
      "epoch = 116 train_loss : 65.946770 , test loss : 60.514954\n",
      "epoch = 117 train_loss : 65.681770 , test loss : 60.251709\n",
      "epoch = 118 train_loss : 65.401253 , test loss : 59.970695\n",
      "epoch = 119 train_loss : 65.156242 , test loss : 59.737957\n",
      "epoch = 121 train_loss : 64.764465 , test loss : 59.330593\n",
      "epoch = 122 train_loss : 64.511703 , test loss : 59.093311\n",
      "epoch = 123 train_loss : 64.231392 , test loss : 58.854507\n",
      "epoch = 125 train_loss : 63.787746 , test loss : 58.421841\n",
      "epoch = 126 train_loss : 63.591873 , test loss : 58.285259\n",
      "epoch = 127 train_loss : 63.302635 , test loss : 57.972019\n",
      "epoch = 128 train_loss : 63.080494 , test loss : 57.774799\n",
      "epoch = 129 train_loss : 62.880318 , test loss : 57.596306\n",
      "epoch = 130 train_loss : 62.680943 , test loss : 57.399673\n",
      "epoch = 131 train_loss : 62.445908 , test loss : 57.166950\n",
      "epoch = 132 train_loss : 62.279663 , test loss : 57.000832\n",
      "epoch = 133 train_loss : 62.074528 , test loss : 56.800255\n",
      "epoch = 135 train_loss : 61.619667 , test loss : 56.426537\n",
      "epoch = 136 train_loss : 61.387058 , test loss : 56.197865\n",
      "epoch = 137 train_loss : 61.143826 , test loss : 55.943993\n",
      "epoch = 139 train_loss : 60.883045 , test loss : 55.723778\n",
      "epoch = 140 train_loss : 60.523853 , test loss : 55.333267\n",
      "epoch = 141 train_loss : 60.508682 , test loss : 55.306171\n",
      "epoch = 142 train_loss : 60.117962 , test loss : 54.983505\n",
      "epoch = 143 train_loss : 59.940781 , test loss : 54.819454\n",
      "epoch = 144 train_loss : 59.839218 , test loss : 54.724216\n",
      "epoch = 145 train_loss : 59.558502 , test loss : 54.445518\n",
      "epoch = 146 train_loss : 59.361343 , test loss : 54.264130\n",
      "epoch = 147 train_loss : 59.139896 , test loss : 54.022961\n",
      "epoch = 148 train_loss : 58.945705 , test loss : 53.842262\n",
      "epoch = 150 train_loss : 58.633541 , test loss : 53.505142\n",
      "epoch = 152 train_loss : 58.211330 , test loss : 53.137821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 154 train_loss : 57.896088 , test loss : 52.823601\n",
      "epoch = 155 train_loss : 57.765366 , test loss : 52.701195\n",
      "epoch = 156 train_loss : 57.627930 , test loss : 52.567177\n",
      "epoch = 157 train_loss : 57.258923 , test loss : 52.236595\n",
      "epoch = 158 train_loss : 57.063034 , test loss : 52.029739\n",
      "epoch = 160 train_loss : 56.713505 , test loss : 51.714340\n",
      "epoch = 161 train_loss : 56.550419 , test loss : 51.585358\n",
      "epoch = 162 train_loss : 56.344017 , test loss : 51.347023\n",
      "epoch = 163 train_loss : 56.203003 , test loss : 51.241497\n",
      "epoch = 164 train_loss : 55.990208 , test loss : 51.014557\n",
      "epoch = 165 train_loss : 55.882462 , test loss : 50.916065\n",
      "epoch = 166 train_loss : 55.645386 , test loss : 50.672001\n",
      "epoch = 167 train_loss : 55.465515 , test loss : 50.508686\n",
      "epoch = 169 train_loss : 55.153076 , test loss : 50.194958\n",
      "epoch = 170 train_loss : 54.980690 , test loss : 50.051109\n",
      "epoch = 171 train_loss : 54.810341 , test loss : 49.901672\n",
      "epoch = 172 train_loss : 54.632904 , test loss : 49.686962\n",
      "epoch = 175 train_loss : 54.143402 , test loss : 49.234211\n",
      "epoch = 176 train_loss : 53.950203 , test loss : 49.061249\n",
      "epoch = 177 train_loss : 53.795815 , test loss : 48.911964\n",
      "epoch = 178 train_loss : 53.655434 , test loss : 48.781338\n",
      "epoch = 179 train_loss : 53.608959 , test loss : 48.717506\n",
      "epoch = 180 train_loss : 53.310104 , test loss : 48.463741\n",
      "epoch = 181 train_loss : 53.232704 , test loss : 48.341202\n",
      "epoch = 182 train_loss : 52.993687 , test loss : 48.134705\n",
      "epoch = 183 train_loss : 52.848690 , test loss : 48.010952\n",
      "epoch = 185 train_loss : 52.535995 , test loss : 47.731396\n",
      "epoch = 186 train_loss : 52.433575 , test loss : 47.600327\n",
      "epoch = 187 train_loss : 52.233955 , test loss : 47.406391\n",
      "epoch = 188 train_loss : 52.100719 , test loss : 47.317848\n",
      "epoch = 189 train_loss : 51.982437 , test loss : 47.212074\n",
      "epoch = 190 train_loss : 51.796654 , test loss : 47.055214\n",
      "epoch = 191 train_loss : 51.723900 , test loss : 46.947498\n",
      "epoch = 192 train_loss : 51.656399 , test loss : 46.917183\n",
      "epoch = 193 train_loss : 51.361691 , test loss : 46.615612\n",
      "epoch = 194 train_loss : 51.193127 , test loss : 46.436237\n",
      "epoch = 196 train_loss : 51.052116 , test loss : 46.241989\n",
      "epoch = 197 train_loss : 50.770470 , test loss : 46.024647\n",
      "epoch = 199 train_loss : 50.495235 , test loss : 45.754467\n",
      "epoch = 201 train_loss : 50.347435 , test loss : 45.570477\n",
      "epoch = 202 train_loss : 50.081947 , test loss : 45.372295\n",
      "epoch = 203 train_loss : 50.058624 , test loss : 45.371487\n",
      "epoch = 206 train_loss : 49.919903 , test loss : 45.293499\n",
      "epoch = 207 train_loss : 49.422688 , test loss : 44.699707\n",
      "epoch = 210 train_loss : 49.040733 , test loss : 44.343742\n",
      "epoch = 211 train_loss : 48.953510 , test loss : 44.242321\n",
      "epoch = 212 train_loss : 48.899506 , test loss : 44.170189\n",
      "epoch = 213 train_loss : 48.765488 , test loss : 44.055077\n",
      "epoch = 214 train_loss : 48.593628 , test loss : 43.949406\n",
      "epoch = 215 train_loss : 48.499775 , test loss : 43.854137\n",
      "epoch = 217 train_loss : 48.346687 , test loss : 43.728012\n",
      "epoch = 218 train_loss : 48.360664 , test loss : 43.602066\n",
      "epoch = 219 train_loss : 48.257759 , test loss : 43.521061\n",
      "epoch = 220 train_loss : 47.916897 , test loss : 43.257839\n",
      "epoch = 221 train_loss : 47.722267 , test loss : 43.118732\n",
      "epoch = 222 train_loss : 47.614727 , test loss : 42.980679\n",
      "epoch = 224 train_loss : 47.379143 , test loss : 42.717224\n",
      "epoch = 227 train_loss : 47.065720 , test loss : 42.436954\n",
      "epoch = 228 train_loss : 46.939827 , test loss : 42.328476\n",
      "epoch = 231 train_loss : 46.621147 , test loss : 42.041737\n",
      "epoch = 232 train_loss : 46.621258 , test loss : 41.981846\n",
      "epoch = 233 train_loss : 46.593201 , test loss : 41.941628\n",
      "epoch = 234 train_loss : 46.310909 , test loss : 41.708397\n",
      "epoch = 235 train_loss : 46.299259 , test loss : 41.665752\n",
      "epoch = 236 train_loss : 46.120293 , test loss : 41.531994\n",
      "epoch = 237 train_loss : 46.016407 , test loss : 41.440056\n",
      "epoch = 239 train_loss : 45.889957 , test loss : 41.247063\n",
      "epoch = 241 train_loss : 45.642136 , test loss : 41.012001\n",
      "epoch = 243 train_loss : 45.631893 , test loss : 40.993835\n",
      "epoch = 244 train_loss : 45.547714 , test loss : 40.885227\n",
      "epoch = 245 train_loss : 45.324741 , test loss : 40.687443\n",
      "epoch = 246 train_loss : 45.169033 , test loss : 40.648766\n",
      "epoch = 247 train_loss : 45.118721 , test loss : 40.619343\n",
      "epoch = 249 train_loss : 44.969898 , test loss : 40.467159\n",
      "epoch = 250 train_loss : 44.914845 , test loss : 40.304462\n",
      "epoch = 252 train_loss : 44.627613 , test loss : 40.120441\n",
      "epoch = 253 train_loss : 44.585003 , test loss : 39.994686\n",
      "epoch = 254 train_loss : 44.446327 , test loss : 39.918850\n",
      "epoch = 255 train_loss : 44.368866 , test loss : 39.838657\n",
      "epoch = 256 train_loss : 44.320450 , test loss : 39.738789\n",
      "epoch = 257 train_loss : 44.242359 , test loss : 39.667496\n",
      "epoch = 258 train_loss : 44.113644 , test loss : 39.553051\n",
      "epoch = 261 train_loss : 43.865955 , test loss : 39.358711\n",
      "epoch = 263 train_loss : 43.705280 , test loss : 39.185406\n",
      "epoch = 266 train_loss : 43.785210 , test loss : 39.183395\n",
      "epoch = 267 train_loss : 43.449738 , test loss : 38.989208\n",
      "epoch = 268 train_loss : 43.344856 , test loss : 38.826618\n",
      "epoch = 269 train_loss : 43.323437 , test loss : 38.774719\n",
      "epoch = 273 train_loss : 43.016571 , test loss : 38.566994\n",
      "epoch = 274 train_loss : 43.011112 , test loss : 38.453072\n",
      "epoch = 275 train_loss : 42.867176 , test loss : 38.430580\n",
      "epoch = 277 train_loss : 42.710213 , test loss : 38.191586\n",
      "epoch = 280 train_loss : 42.529293 , test loss : 37.978989\n",
      "epoch = 283 train_loss : 42.332214 , test loss : 37.796463\n",
      "epoch = 284 train_loss : 42.322163 , test loss : 37.724461\n",
      "epoch = 286 train_loss : 42.124447 , test loss : 37.619740\n",
      "epoch = 289 train_loss : 41.977573 , test loss : 37.585842\n",
      "epoch = 290 train_loss : 41.897453 , test loss : 37.510067\n",
      "epoch = 291 train_loss : 41.984711 , test loss : 37.412697\n",
      "epoch = 292 train_loss : 41.749409 , test loss : 37.276096\n",
      "epoch = 293 train_loss : 41.680710 , test loss : 37.206078\n",
      "epoch = 295 train_loss : 41.594685 , test loss : 37.085434\n",
      "epoch = 298 train_loss : 41.394825 , test loss : 36.965038\n",
      "epoch = 299 train_loss : 41.425194 , test loss : 36.889080\n",
      "epoch = 301 train_loss : 41.238941 , test loss : 36.858822\n",
      "epoch = 302 train_loss : 41.204033 , test loss : 36.800541\n",
      "epoch = 303 train_loss : 41.151554 , test loss : 36.763885\n",
      "epoch = 306 train_loss : 40.953278 , test loss : 36.505043\n",
      "epoch = 309 train_loss : 40.801716 , test loss : 36.396374\n",
      "epoch = 310 train_loss : 40.919727 , test loss : 36.375919\n",
      "epoch = 311 train_loss : 40.707615 , test loss : 36.288536\n",
      "epoch = 313 train_loss : 40.608944 , test loss : 36.230152\n",
      "epoch = 315 train_loss : 40.661526 , test loss : 36.133297\n",
      "epoch = 316 train_loss : 40.469387 , test loss : 36.074581\n",
      "epoch = 318 train_loss : 40.475506 , test loss : 35.972557\n",
      "epoch = 321 train_loss : 40.267906 , test loss : 35.928040\n",
      "epoch = 322 train_loss : 40.351051 , test loss : 35.830475\n",
      "epoch = 323 train_loss : 40.152119 , test loss : 35.758610\n",
      "epoch = 326 train_loss : 40.084160 , test loss : 35.658325\n",
      "epoch = 327 train_loss : 40.013611 , test loss : 35.581497\n",
      "epoch = 329 train_loss : 39.883659 , test loss : 35.508091\n",
      "epoch = 330 train_loss : 39.846504 , test loss : 35.447170\n",
      "epoch = 333 train_loss : 39.723515 , test loss : 35.344654\n",
      "epoch = 336 train_loss : 39.602688 , test loss : 35.244553\n",
      "epoch = 338 train_loss : 39.756519 , test loss : 35.229050\n",
      "epoch = 339 train_loss : 39.483112 , test loss : 35.116703\n",
      "epoch = 340 train_loss : 39.507885 , test loss : 35.102001\n",
      "epoch = 341 train_loss : 39.413471 , test loss : 35.024967\n",
      "epoch = 343 train_loss : 39.356731 , test loss : 34.958393\n",
      "epoch = 345 train_loss : 39.258495 , test loss : 34.931190\n",
      "epoch = 347 train_loss : 39.184551 , test loss : 34.831158\n",
      "epoch = 348 train_loss : 39.159195 , test loss : 34.803802\n",
      "epoch = 350 train_loss : 39.085602 , test loss : 34.775448\n",
      "epoch = 351 train_loss : 39.060444 , test loss : 34.739761\n",
      "epoch = 352 train_loss : 39.019966 , test loss : 34.670517\n",
      "epoch = 353 train_loss : 38.980030 , test loss : 34.627457\n",
      "epoch = 355 train_loss : 38.927181 , test loss : 34.576309\n",
      "epoch = 356 train_loss : 39.048851 , test loss : 34.554989\n",
      "epoch = 357 train_loss : 38.872734 , test loss : 34.493538\n",
      "epoch = 358 train_loss : 38.808270 , test loss : 34.475147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 360 train_loss : 38.758865 , test loss : 34.370003\n",
      "epoch = 362 train_loss : 38.718620 , test loss : 34.329189\n",
      "epoch = 367 train_loss : 38.554642 , test loss : 34.290344\n",
      "epoch = 368 train_loss : 38.502808 , test loss : 34.209679\n",
      "epoch = 369 train_loss : 38.466888 , test loss : 34.142532\n",
      "epoch = 370 train_loss : 38.544647 , test loss : 34.124893\n",
      "epoch = 374 train_loss : 38.326870 , test loss : 34.001205\n",
      "epoch = 377 train_loss : 38.343723 , test loss : 33.930786\n",
      "epoch = 378 train_loss : 38.280632 , test loss : 33.901962\n",
      "epoch = 381 train_loss : 38.141670 , test loss : 33.873417\n",
      "epoch = 382 train_loss : 38.161694 , test loss : 33.793835\n",
      "epoch = 383 train_loss : 38.176174 , test loss : 33.756092\n",
      "epoch = 387 train_loss : 38.038662 , test loss : 33.658596\n",
      "epoch = 389 train_loss : 37.925968 , test loss : 33.607292\n",
      "epoch = 392 train_loss : 37.840664 , test loss : 33.583981\n",
      "epoch = 393 train_loss : 37.848736 , test loss : 33.490124\n",
      "epoch = 395 train_loss : 37.777935 , test loss : 33.467365\n",
      "epoch = 399 train_loss : 37.677273 , test loss : 33.395119\n",
      "epoch = 400 train_loss : 37.680733 , test loss : 33.351864\n",
      "epoch = 404 train_loss : 37.561741 , test loss : 33.301407\n",
      "epoch = 408 train_loss : 37.489803 , test loss : 33.184677\n",
      "epoch = 410 train_loss : 37.446003 , test loss : 33.168022\n",
      "epoch = 411 train_loss : 37.413975 , test loss : 33.140953\n",
      "epoch = 414 train_loss : 37.359974 , test loss : 33.082096\n",
      "epoch = 415 train_loss : 37.385551 , test loss : 33.037426\n",
      "epoch = 418 train_loss : 37.272259 , test loss : 33.007206\n",
      "epoch = 419 train_loss : 37.250629 , test loss : 33.001106\n",
      "epoch = 420 train_loss : 37.241852 , test loss : 32.941105\n",
      "epoch = 422 train_loss : 37.196030 , test loss : 32.923641\n",
      "epoch = 425 train_loss : 37.140530 , test loss : 32.907433\n",
      "epoch = 427 train_loss : 37.129528 , test loss : 32.838493\n",
      "epoch = 430 train_loss : 37.147469 , test loss : 32.772434\n",
      "epoch = 435 train_loss : 36.961956 , test loss : 32.725704\n",
      "epoch = 436 train_loss : 36.947731 , test loss : 32.694916\n",
      "epoch = 439 train_loss : 36.988960 , test loss : 32.665878\n",
      "epoch = 440 train_loss : 36.878998 , test loss : 32.634716\n",
      "epoch = 444 train_loss : 36.868160 , test loss : 32.555218\n",
      "epoch = 445 train_loss : 36.807072 , test loss : 32.542034\n",
      "epoch = 446 train_loss : 36.807774 , test loss : 32.518322\n",
      "epoch = 448 train_loss : 36.747860 , test loss : 32.509014\n",
      "epoch = 450 train_loss : 36.717312 , test loss : 32.445210\n",
      "epoch = 451 train_loss : 36.725632 , test loss : 32.438053\n",
      "epoch = 455 train_loss : 36.670681 , test loss : 32.402821\n",
      "epoch = 456 train_loss : 36.729816 , test loss : 32.389191\n",
      "epoch = 458 train_loss : 36.591499 , test loss : 32.368046\n",
      "epoch = 461 train_loss : 36.559525 , test loss : 32.332924\n",
      "epoch = 465 train_loss : 36.558414 , test loss : 32.256813\n",
      "epoch = 468 train_loss : 36.450581 , test loss : 32.255630\n",
      "epoch = 470 train_loss : 36.427052 , test loss : 32.170818\n",
      "epoch = 477 train_loss : 36.337368 , test loss : 32.111595\n",
      "epoch = 481 train_loss : 36.349510 , test loss : 32.079037\n",
      "epoch = 485 train_loss : 36.299133 , test loss : 32.014614\n",
      "epoch = 491 train_loss : 36.173485 , test loss : 31.967810\n",
      "epoch = 492 train_loss : 36.197720 , test loss : 31.945858\n",
      "epoch = 494 train_loss : 36.131485 , test loss : 31.926527\n",
      "epoch = 497 train_loss : 36.101341 , test loss : 31.910347\n",
      "epoch = 500 train_loss : 36.072250 , test loss : 31.881678\n",
      "epoch = 504 train_loss : 36.017536 , test loss : 31.852760\n",
      "epoch = 506 train_loss : 36.001896 , test loss : 31.836092\n",
      "epoch = 512 train_loss : 35.937660 , test loss : 31.754126\n",
      "epoch = 515 train_loss : 35.938301 , test loss : 31.705532\n",
      "epoch = 522 train_loss : 35.912613 , test loss : 31.674568\n",
      "epoch = 523 train_loss : 35.842419 , test loss : 31.623512\n",
      "epoch = 527 train_loss : 35.861565 , test loss : 31.620955\n",
      "epoch = 529 train_loss : 35.769722 , test loss : 31.611040\n",
      "epoch = 533 train_loss : 35.780632 , test loss : 31.546814\n",
      "epoch = 538 train_loss : 35.706520 , test loss : 31.516537\n",
      "epoch = 547 train_loss : 35.608246 , test loss : 31.460697\n",
      "epoch = 550 train_loss : 35.605404 , test loss : 31.435875\n",
      "epoch = 552 train_loss : 35.648800 , test loss : 31.417582\n",
      "epoch = 553 train_loss : 35.631603 , test loss : 31.410254\n",
      "epoch = 558 train_loss : 35.545460 , test loss : 31.369423\n",
      "epoch = 561 train_loss : 35.514988 , test loss : 31.348854\n",
      "epoch = 568 train_loss : 35.478706 , test loss : 31.277245\n",
      "epoch = 576 train_loss : 35.389755 , test loss : 31.241674\n",
      "epoch = 584 train_loss : 35.369091 , test loss : 31.208372\n",
      "epoch = 585 train_loss : 35.357265 , test loss : 31.193874\n",
      "epoch = 588 train_loss : 35.298607 , test loss : 31.131916\n",
      "epoch = 594 train_loss : 35.282730 , test loss : 31.127979\n",
      "epoch = 595 train_loss : 35.246925 , test loss : 31.109852\n",
      "epoch = 600 train_loss : 35.274788 , test loss : 31.106476\n",
      "epoch = 603 train_loss : 35.194595 , test loss : 31.064751\n",
      "epoch = 604 train_loss : 35.188095 , test loss : 31.062975\n",
      "epoch = 606 train_loss : 35.185223 , test loss : 31.020164\n",
      "epoch = 615 train_loss : 35.177502 , test loss : 31.000607\n",
      "epoch = 620 train_loss : 35.106110 , test loss : 30.968983\n",
      "epoch = 627 train_loss : 35.105934 , test loss : 30.949186\n",
      "epoch = 629 train_loss : 35.046707 , test loss : 30.926647\n",
      "epoch = 636 train_loss : 34.995163 , test loss : 30.895365\n",
      "epoch = 652 train_loss : 34.912663 , test loss : 30.887245\n",
      "epoch = 656 train_loss : 35.090481 , test loss : 30.865898\n",
      "epoch = 657 train_loss : 34.889568 , test loss : 30.798544\n",
      "epoch = 673 train_loss : 34.909389 , test loss : 30.745855\n",
      "epoch = 685 train_loss : 34.766308 , test loss : 30.634241\n",
      "epoch = 700 train_loss : 34.692501 , test loss : 30.613352\n",
      "epoch = 707 train_loss : 34.668030 , test loss : 30.611403\n",
      "epoch = 710 train_loss : 34.662537 , test loss : 30.611141\n",
      "epoch = 711 train_loss : 34.642872 , test loss : 30.598288\n",
      "epoch = 716 train_loss : 34.623226 , test loss : 30.580807\n",
      "epoch = 722 train_loss : 34.678944 , test loss : 30.553774\n",
      "epoch = 728 train_loss : 34.583782 , test loss : 30.538799\n",
      "epoch = 730 train_loss : 34.591190 , test loss : 30.532368\n",
      "epoch = 735 train_loss : 34.560181 , test loss : 30.513668\n",
      "epoch = 737 train_loss : 34.555325 , test loss : 30.494596\n",
      "epoch = 746 train_loss : 34.575859 , test loss : 30.461473\n",
      "epoch = 750 train_loss : 34.502728 , test loss : 30.460072\n",
      "epoch = 753 train_loss : 34.560173 , test loss : 30.457451\n",
      "epoch = 758 train_loss : 34.471985 , test loss : 30.423565\n",
      "epoch = 765 train_loss : 34.456879 , test loss : 30.404812\n",
      "epoch = 768 train_loss : 34.440609 , test loss : 30.387892\n",
      "epoch = 775 train_loss : 34.417831 , test loss : 30.384552\n",
      "epoch = 777 train_loss : 34.412708 , test loss : 30.381254\n",
      "epoch = 784 train_loss : 34.457047 , test loss : 30.341663\n",
      "epoch = 796 train_loss : 34.404564 , test loss : 30.338503\n",
      "epoch = 805 train_loss : 34.327076 , test loss : 30.300314\n",
      "epoch = 814 train_loss : 34.302727 , test loss : 30.289616\n",
      "epoch = 824 train_loss : 34.356014 , test loss : 30.272005\n",
      "epoch = 828 train_loss : 34.267612 , test loss : 30.239826\n",
      "epoch = 832 train_loss : 34.271069 , test loss : 30.213053\n",
      "epoch = 836 train_loss : 34.252541 , test loss : 30.187996\n",
      "epoch = 867 train_loss : 34.185490 , test loss : 30.152925\n",
      "epoch = 874 train_loss : 34.193802 , test loss : 30.144583\n",
      "epoch = 879 train_loss : 34.149059 , test loss : 30.142323\n",
      "epoch = 881 train_loss : 34.224232 , test loss : 30.132481\n",
      "epoch = 899 train_loss : 34.150387 , test loss : 30.103790\n",
      "epoch = 905 train_loss : 34.098915 , test loss : 30.099463\n",
      "epoch = 911 train_loss : 34.161274 , test loss : 30.093824\n",
      "epoch = 915 train_loss : 34.134750 , test loss : 30.048414\n",
      "epoch = 931 train_loss : 34.104206 , test loss : 30.026573\n",
      "epoch = 939 train_loss : 34.081356 , test loss : 30.022493\n",
      "epoch = 943 train_loss : 34.106152 , test loss : 30.020193\n",
      "epoch = 946 train_loss : 34.077198 , test loss : 30.002764\n",
      "epoch = 961 train_loss : 34.023052 , test loss : 29.953682\n",
      "epoch = 974 train_loss : 34.014820 , test loss : 29.951094\n",
      "epoch = 979 train_loss : 33.982315 , test loss : 29.949488\n",
      "epoch = 987 train_loss : 34.015862 , test loss : 29.937176\n",
      "epoch = 1011 train_loss : 33.960991 , test loss : 29.923380\n",
      "epoch = 1034 train_loss : 33.918274 , test loss : 29.907251\n",
      "epoch = 1037 train_loss : 33.911083 , test loss : 29.884193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1053 train_loss : 33.906631 , test loss : 29.837877\n",
      "epoch = 1105 train_loss : 33.858658 , test loss : 29.825220\n",
      "epoch = 1109 train_loss : 33.825672 , test loss : 29.814447\n",
      "epoch = 1114 train_loss : 33.879551 , test loss : 29.804144\n",
      "epoch = 1129 train_loss : 33.852291 , test loss : 29.797880\n",
      "epoch = 1138 train_loss : 33.803692 , test loss : 29.797783\n",
      "epoch = 1148 train_loss : 33.808681 , test loss : 29.787867\n",
      "epoch = 1160 train_loss : 33.797993 , test loss : 29.775429\n",
      "epoch = 1166 train_loss : 33.788143 , test loss : 29.753630\n",
      "epoch = 1207 train_loss : 33.749950 , test loss : 29.733604\n",
      "epoch = 1224 train_loss : 33.772785 , test loss : 29.706675\n",
      "epoch = 1256 train_loss : 33.734791 , test loss : 29.686760\n",
      "epoch = 1315 train_loss : 33.775188 , test loss : 29.678291\n",
      "epoch = 1354 train_loss : 33.750854 , test loss : 29.672173\n",
      "epoch = 1376 train_loss : 33.668762 , test loss : 29.658360\n",
      "epoch = 1390 train_loss : 33.677979 , test loss : 29.647678\n",
      "epoch = 1418 train_loss : 33.658054 , test loss : 29.618979\n",
      "epoch = 1522 train_loss : 33.623943 , test loss : 29.601501\n",
      "epoch = 1548 train_loss : 33.627659 , test loss : 29.596369\n",
      "epoch = 1613 train_loss : 33.603893 , test loss : 29.589954\n",
      "epoch = 1647 train_loss : 33.602272 , test loss : 29.582092\n",
      "epoch = 1714 train_loss : 33.596828 , test loss : 29.575005\n",
      "epoch = 1746 train_loss : 33.576355 , test loss : 29.568577\n",
      "epoch = 1934 train_loss : 33.581554 , test loss : 29.556837\n",
      "epoch = 1986 train_loss : 33.614727 , test loss : 29.554363\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 33.614727,test loss : 29.554363\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 32.530271,total test loss mean : 34.476348 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x1.shape[1],8),nn.Linear(8,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,5000,0.0001,5,x1,y1,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:23.300129Z",
     "start_time": "2021-12-30T02:02:23.284128Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "\n",
    "def rmlse_cv2(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x33)\n",
    "    rmse=np.sqrt(-cross_val_score(model,x33,y33,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:27.646377Z",
     "start_time": "2021-12-30T02:02:24.955223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 5.6020 (0.5464)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.005,random_state=1))\n",
    "score=rmlse_cv2(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use boxcox transformer to gaussian dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:57.649093Z",
     "start_time": "2021-12-30T02:02:57.641093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox,boxcox_normmax\n",
    "from scipy.special import boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:58.624149Z",
     "start_time": "2021-12-30T02:02:58.616148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:02:59.224183Z",
     "start_time": "2021-12-30T02:02:59.217183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:01.433310Z",
     "start_time": "2021-12-30T02:03:01.388307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --skew :  -0.2834134242907861 --kurt :  -0.7968009844193018\n",
      "1 --skew :  -5.095255676523535 --kurt :  85.70760213466164\n",
      "2 --skew :  9.165303973318487 --kurt :  132.25692190213024\n",
      "3 --skew :  2.172048918138678 --kurt :  8.458548044518952\n",
      "4 --skew :  5.378836580918865 --kurt :  41.25921290333162\n",
      "5 --skew :  1.6391191931961593 --kurt :  3.8457481859587697\n",
      "6 --skew :  2.071649558193799 --kurt :  6.419180514549189\n",
      "7 --skew :  1.3121217461933794 --kurt :  5.2975502420733696\n",
      "8 --skew :  1.103678593463204 --kurt :  1.7728459308764268\n",
      "9 --skew :  1.2763236528649795 --kurt :  2.115391100082106\n",
      "10 --skew :  21.7839204262489 --kurt :  623.8917732792679\n",
      "11 --skew :  -0.6050425772235472 --kurt :  -0.1979575284081454\n",
      "12 --skew :  2.1806637991938813 --kurt :  8.332926208370576\n",
      "13 --skew :  -0.7973228533500623 --kurt :  21.5544747714386\n",
      "14 --skew :  0.5569055078560654 --kurt :  -0.9777533530993172\n",
      "15 --skew :  0.5166061431100419 --kurt :  -1.0455161114586577\n",
      "16 --skew :  0.9251663396039612 --kurt :  1.023738040336486\n",
      "17 --skew :  1.0990996760341267 --kurt :  1.2102189438217152\n"
     ]
    }
   ],
   "source": [
    "for i in range(all_train_data1.shape[1]):\n",
    "    print(all_train_data1.index[i],'--skew : ',all_train_data1[i].skew(),'--kurt : ',all_train_data1[i].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:03.067403Z",
     "start_time": "2021-12-30T02:03:02.579375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --skew :  -0.2834134242907861 --kurt :  -0.7968009844193018\n",
      "lambda :  1.461645538288768\n",
      "0 --skew :  -0.07414275326700835 --kurt :  -0.9258821506244836\n",
      "--------------------------------------------------------------------\n",
      "1 --skew :  -5.095255676523535 --kurt :  85.70760213466164\n",
      "lambda :  5.990940784090655\n",
      "1 --skew :  0.2052435896115669 --kurt :  0.583625236412292\n",
      "--------------------------------------------------------------------\n",
      "2 --skew :  9.165303973318487 --kurt :  132.25692190213024\n",
      "lambda :  -3.259330902857795\n",
      "2 --skew :  -0.003907562716963148 --kurt :  -0.06972890461562153\n",
      "--------------------------------------------------------------------\n",
      "3 --skew :  2.172048918138678 --kurt :  8.458548044518952\n",
      "lambda :  -6.182620739009405\n",
      "3 --skew :  0.05859262861967747 --kurt :  -0.5568735662256521\n",
      "--------------------------------------------------------------------\n",
      "4 --skew :  5.378836580918865 --kurt :  41.25921290333162\n",
      "lambda :  -0.7826645126628972\n",
      "4 --skew :  -0.03484059806052529 --kurt :  0.5414188516389893\n",
      "--------------------------------------------------------------------\n",
      "5 --skew :  1.6391191931961593 --kurt :  3.8457481859587697\n",
      "lambda :  0.003516830957090046\n",
      "5 --skew :  0.013408365980071172 --kurt :  0.19498206467320722\n",
      "--------------------------------------------------------------------\n",
      "6 --skew :  2.071649558193799 --kurt :  6.419180514549189\n",
      "lambda :  -0.1942146862014387\n",
      "6 --skew :  -0.002404565434079636 --kurt :  0.0440333018723158\n",
      "--------------------------------------------------------------------\n",
      "7 --skew :  1.3121217461933794 --kurt :  5.2975502420733696\n",
      "lambda :  0.41482616104608666\n",
      "7 --skew :  0.006751929748339162 --kurt :  0.28627689522357613\n",
      "--------------------------------------------------------------------\n",
      "8 --skew :  1.103678593463204 --kurt :  1.7728459308764268\n",
      "lambda :  0.4477248234931694\n",
      "8 --skew :  0.02201672862987185 --kurt :  0.1603650294853538\n",
      "--------------------------------------------------------------------\n",
      "9 --skew :  1.2763236528649795 --kurt :  2.115391100082106\n",
      "lambda :  0.4145678510523434\n",
      "9 --skew :  0.03317866068741833 --kurt :  -0.18174471082602928\n",
      "--------------------------------------------------------------------\n",
      "10 --skew :  21.7839204262489 --kurt :  623.8917732792679\n",
      "lambda :  -6.186399577904084\n",
      "10 --skew :  3.759158275003242 --kurt :  12.400036693306454\n",
      "--------------------------------------------------------------------\n",
      "11 --skew :  -0.6050425772235472 --kurt :  -0.1979575284081454\n",
      "lambda :  2.4338353657960474\n",
      "11 --skew :  -0.07298225942919347 --kurt :  -0.8136949843530794\n",
      "--------------------------------------------------------------------\n",
      "12 --skew :  2.1806637991938813 --kurt :  8.332926208370576\n",
      "lambda :  -0.24358108144432533\n",
      "12 --skew :  0.021947686457242925 --kurt :  0.5477017915641502\n",
      "--------------------------------------------------------------------\n",
      "13 --skew :  -0.7973228533500623 --kurt :  21.5544747714386\n",
      "lambda :  2.0482410553537025\n",
      "13 --skew :  0.8584013280369255 --kurt :  8.48135294318179\n",
      "--------------------------------------------------------------------\n",
      "14 --skew :  0.5569055078560654 --kurt :  -0.9777533530993172\n",
      "lambda :  0.3417183305204095\n",
      "14 --skew :  -0.11116266544173034 --kurt :  -0.5747813166565554\n",
      "--------------------------------------------------------------------\n",
      "15 --skew :  0.5166061431100419 --kurt :  -1.0455161114586577\n",
      "lambda :  0.31039132586722773\n",
      "15 --skew :  -0.12154909027070926 --kurt :  -0.6493410942779887\n",
      "--------------------------------------------------------------------\n",
      "16 --skew :  0.9251663396039612 --kurt :  1.023738040336486\n",
      "lambda :  -0.14707046206981406\n",
      "16 --skew :  0.016664314785999827 --kurt :  -0.4468770575550054\n",
      "--------------------------------------------------------------------\n",
      "17 --skew :  1.0990996760341267 --kurt :  1.2102189438217152\n",
      "lambda :  -0.2521218322454977\n",
      "17 --skew :  0.012020490427854405 --kurt :  -0.5440498606314681\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_train_data2=pd.DataFrame()\n",
    "for i in range(all_train_data1.shape[1]):\n",
    "    lm=boxcox_normmax(all_train_data1[i]+1)\n",
    "    all_train_data2[i]=boxcox1p(all_train_data1[i],lm)\n",
    "    print(all_train_data1.index[i],'--skew : ',all_train_data1[i].skew(),'--kurt : ',all_train_data1[i].kurt())\n",
    "    print('lambda : ',lm)\n",
    "    print(all_train_data2.index[i],'--skew : ',all_train_data2[i].skew(),'--kurt : ',all_train_data2[i].kurt())\n",
    "    print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:03.954454Z",
     "start_time": "2021-12-30T02:03:03.946453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 18)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:04.966512Z",
     "start_time": "2021-12-30T02:03:04.940510Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data2={}\n",
    "for m in range(12):\n",
    "    month_data2=np.empty((18,480))\n",
    "    month_data2[:,:]=all_train_data2.T.iloc[:,m*480:(m+1)*480]\n",
    "    year_data2[m]=month_data2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:11.307874Z",
     "start_time": "2021-12-30T02:03:11.283873Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data3={}\n",
    "for m in range(12):\n",
    "    month_data3=np.empty((18,480))\n",
    "    month_data3[:,:]=all_train_data1.T.iloc[:,m*480:(m+1)*480]\n",
    "    year_data3[m]=month_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:11.933910Z",
     "start_time": "2021-12-30T02:03:11.922910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6, 2.2, 2.3, 2.3, 2.3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data[11][-6,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:12.479941Z",
     "start_time": "2021-12-30T02:03:12.466941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6, 2.2, 2.3, 2.3, 2.3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data3[11][-6,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:13.005972Z",
     "start_time": "2021-12-30T02:03:12.997971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1003593 , 1.01289662, 1.03598957, 1.03598957, 1.03598957])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_data2[11][-6,-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare all_train_data1 and all_train_data2\n",
    "- all_train_data1 : just correct outlier value\n",
    "- all_train_data2 : just boxcox after all_train_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:16.012143Z",
     "start_time": "2021-12-30T02:03:15.926139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.610382</td>\n",
       "      <td>1.705521</td>\n",
       "      <td>0.388436</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>2.136970</td>\n",
       "      <td>10.125990</td>\n",
       "      <td>12.254115</td>\n",
       "      <td>31.905469</td>\n",
       "      <td>42.709201</td>\n",
       "      <td>21.534201</td>\n",
       "      <td>0.200625</td>\n",
       "      <td>73.229167</td>\n",
       "      <td>2.769089</td>\n",
       "      <td>1.843012</td>\n",
       "      <td>156.329271</td>\n",
       "      <td>158.482795</td>\n",
       "      <td>2.297240</td>\n",
       "      <td>1.712760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.062216</td>\n",
       "      <td>0.100203</td>\n",
       "      <td>0.323505</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>2.281611</td>\n",
       "      <td>6.187555</td>\n",
       "      <td>7.571422</td>\n",
       "      <td>18.703486</td>\n",
       "      <td>26.222292</td>\n",
       "      <td>16.576035</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>13.361351</td>\n",
       "      <td>1.809743</td>\n",
       "      <td>0.163008</td>\n",
       "      <td>95.745881</td>\n",
       "      <td>94.697432</td>\n",
       "      <td>1.065408</td>\n",
       "      <td>1.062683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     22.610382     1.705521     0.388436     0.140427     2.136970   \n",
       "std       6.062216     0.100203     0.323505     0.104645     2.281611   \n",
       "min       6.700000     0.000000     0.080000     0.000000     0.000000   \n",
       "25%      18.000000     1.600000     0.250000     0.070000     1.100000   \n",
       "50%      23.000000     1.700000     0.340000     0.110000     1.600000   \n",
       "75%      27.000000     1.800000     0.450000     0.180000     2.300000   \n",
       "max      36.000000     2.000000     7.570000     1.300000    31.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     10.125990    12.254115    31.905469    42.709201    21.534201   \n",
       "std       6.187555     7.571422    18.703486    26.222292    16.576035   \n",
       "min       0.000000     1.300000     0.000000     0.000000     0.000000   \n",
       "25%       5.900000     7.300000    18.000000    24.000000     9.000000   \n",
       "50%       8.600000    10.000000    29.000000    38.000000    18.000000   \n",
       "75%      13.000000    15.000000    42.000000    57.000000    30.000000   \n",
       "max      46.000000    71.000000   231.000000   181.000000   112.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.200625    73.229167     2.769089     1.843012   156.329271   \n",
       "std       2.045443    13.361351     1.809743     0.163008    95.745881   \n",
       "min       0.000000    29.000000     0.000000     0.000000     0.100000   \n",
       "25%       0.000000    64.000000     1.600000     1.700000    72.000000   \n",
       "50%       0.000000    75.000000     2.300000     1.800000   119.000000   \n",
       "75%       0.000000    84.000000     3.400000     1.900000   213.000000   \n",
       "max      74.000000    99.000000    22.000000     3.000000   360.000000   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean    158.482795     2.297240     1.712760  \n",
       "std      94.697432     1.065408     1.062683  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%      76.000000     1.500000     0.900000  \n",
       "50%     121.500000     2.100000     1.500000  \n",
       "75%     219.000000     2.900000     2.300000  \n",
       "max     360.000000     7.700000     7.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:17.124207Z",
     "start_time": "2021-12-30T02:03:17.062204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.426493</td>\n",
       "      <td>65.832202</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>0.079806</td>\n",
       "      <td>0.672361</td>\n",
       "      <td>2.283694</td>\n",
       "      <td>1.937404</td>\n",
       "      <td>7.449352</td>\n",
       "      <td>9.327724</td>\n",
       "      <td>5.756380</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>15482.226219</td>\n",
       "      <td>1.051691</td>\n",
       "      <td>3.676586</td>\n",
       "      <td>12.803597</td>\n",
       "      <td>11.687312</td>\n",
       "      <td>1.046624</td>\n",
       "      <td>0.813470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.536335</td>\n",
       "      <td>12.405338</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.176061</td>\n",
       "      <td>0.523410</td>\n",
       "      <td>0.306804</td>\n",
       "      <td>2.431622</td>\n",
       "      <td>3.291614</td>\n",
       "      <td>2.725299</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>6063.422584</td>\n",
       "      <td>0.303361</td>\n",
       "      <td>0.481140</td>\n",
       "      <td>3.602422</td>\n",
       "      <td>3.020925</td>\n",
       "      <td>0.263948</td>\n",
       "      <td>0.292340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.833239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1616.845054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.926550</td>\n",
       "      <td>50.952479</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>0.055291</td>\n",
       "      <td>0.562804</td>\n",
       "      <td>1.938097</td>\n",
       "      <td>1.735287</td>\n",
       "      <td>5.766358</td>\n",
       "      <td>7.204513</td>\n",
       "      <td>3.853588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10617.557930</td>\n",
       "      <td>0.852464</td>\n",
       "      <td>3.245618</td>\n",
       "      <td>9.751980</td>\n",
       "      <td>9.184518</td>\n",
       "      <td>0.857234</td>\n",
       "      <td>0.592611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.525274</td>\n",
       "      <td>63.921527</td>\n",
       "      <td>0.188618</td>\n",
       "      <td>0.076901</td>\n",
       "      <td>0.672848</td>\n",
       "      <td>2.270782</td>\n",
       "      <td>1.916995</td>\n",
       "      <td>7.472206</td>\n",
       "      <td>9.283713</td>\n",
       "      <td>5.763730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15534.166404</td>\n",
       "      <td>1.035990</td>\n",
       "      <td>3.534372</td>\n",
       "      <td>12.099014</td>\n",
       "      <td>11.107693</td>\n",
       "      <td>1.042283</td>\n",
       "      <td>0.818152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>88.521007</td>\n",
       "      <td>79.522794</td>\n",
       "      <td>0.215417</td>\n",
       "      <td>0.103613</td>\n",
       "      <td>0.775804</td>\n",
       "      <td>2.651342</td>\n",
       "      <td>2.143833</td>\n",
       "      <td>9.063998</td>\n",
       "      <td>11.523345</td>\n",
       "      <td>7.603404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20398.022735</td>\n",
       "      <td>1.243713</td>\n",
       "      <td>3.834142</td>\n",
       "      <td>15.383128</td>\n",
       "      <td>13.963600</td>\n",
       "      <td>1.233421</td>\n",
       "      <td>1.030980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.380091</td>\n",
       "      <td>120.311749</td>\n",
       "      <td>0.306532</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>1.192886</td>\n",
       "      <td>3.876332</td>\n",
       "      <td>2.905076</td>\n",
       "      <td>20.678088</td>\n",
       "      <td>20.721569</td>\n",
       "      <td>14.709463</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>30295.187454</td>\n",
       "      <td>2.192628</td>\n",
       "      <td>7.863631</td>\n",
       "      <td>18.965279</td>\n",
       "      <td>16.819218</td>\n",
       "      <td>1.852950</td>\n",
       "      <td>1.618322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     70.426493    65.832202     0.186377     0.079806     0.672361   \n",
       "std      25.536335    12.405338     0.041562     0.032614     0.176061   \n",
       "min      12.833239     0.000000     0.068067     0.000000     0.000000   \n",
       "25%      49.926550    50.952479     0.158556     0.055291     0.562804   \n",
       "50%      70.525274    63.921527     0.188618     0.076901     0.672848   \n",
       "75%      88.521007    79.522794     0.215417     0.103613     0.775804   \n",
       "max     133.380091   120.311749     0.306532     0.160805     1.192886   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      2.283694     1.937404     7.449352     9.327724     5.756380   \n",
       "std       0.523410     0.306804     2.431622     3.291614     2.725299   \n",
       "min       0.000000     0.769032     0.000000     0.000000     0.000000   \n",
       "25%       1.938097     1.735287     5.766358     7.204513     3.853588   \n",
       "50%       2.270782     1.916995     7.472206     9.283713     5.763730   \n",
       "75%       2.651342     2.143833     9.063998    11.523345     7.603404   \n",
       "max       3.876332     2.905076    20.678088    20.721569    14.709463   \n",
       "\n",
       "                10            11           12           13           14  \\\n",
       "count  5760.000000   5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.008977  15482.226219     1.051691     3.676586    12.803597   \n",
       "std       0.035324   6063.422584     0.303361     0.481140     3.602422   \n",
       "min       0.000000   1616.845054     0.000000     0.000000     0.096879   \n",
       "25%       0.000000  10617.557930     0.852464     3.245618     9.751980   \n",
       "50%       0.000000  15534.166404     1.035990     3.534372    12.099014   \n",
       "75%       0.000000  20398.022735     1.243713     3.834142    15.383128   \n",
       "max       0.161645  30295.187454     2.192628     7.863631    18.965279   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean     11.687312     1.046624     0.813470  \n",
       "std       3.020925     0.263948     0.292340  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       9.184518     0.857234     0.592611  \n",
       "50%      11.107693     1.042283     0.818152  \n",
       "75%      13.963600     1.233421     1.030980  \n",
       "max      16.819218     1.852950     1.618322  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:30:30.106735Z",
     "start_time": "2021-12-29T06:30:30.100734Z"
    }
   },
   "source": [
    "## diff with hw_test81\n",
    "- all_train_data3 : normalized\n",
    "- all_train_data2 : no normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:38.875451Z",
     "start_time": "2021-12-30T02:03:38.841449Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_data3=all_train_data2.copy()\n",
    "all_train_data3=all_train_data3.apply(lambda x : (x-x.mean())/x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:39.677497Z",
     "start_time": "2021-12-30T02:03:39.614493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.019875e-13</td>\n",
       "      <td>-5.144712e-14</td>\n",
       "      <td>6.653925e-14</td>\n",
       "      <td>2.549689e-14</td>\n",
       "      <td>2.334629e-15</td>\n",
       "      <td>-6.727368e-14</td>\n",
       "      <td>-4.221841e-14</td>\n",
       "      <td>2.062856e-15</td>\n",
       "      <td>5.215490e-14</td>\n",
       "      <td>1.772519e-14</td>\n",
       "      <td>-1.659610e-15</td>\n",
       "      <td>6.245795e-14</td>\n",
       "      <td>-9.682569e-15</td>\n",
       "      <td>-1.537578e-14</td>\n",
       "      <td>1.616595e-14</td>\n",
       "      <td>-8.086471e-15</td>\n",
       "      <td>3.354384e-14</td>\n",
       "      <td>3.181464e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.255345e+00</td>\n",
       "      <td>-5.306764e+00</td>\n",
       "      <td>-2.846587e+00</td>\n",
       "      <td>-2.447008e+00</td>\n",
       "      <td>-3.818917e+00</td>\n",
       "      <td>-4.363104e+00</td>\n",
       "      <td>-3.808196e+00</td>\n",
       "      <td>-3.063532e+00</td>\n",
       "      <td>-2.833784e+00</td>\n",
       "      <td>-2.112201e+00</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-2.286725e+00</td>\n",
       "      <td>-3.466795e+00</td>\n",
       "      <td>-7.641412e+00</td>\n",
       "      <td>-3.527271e+00</td>\n",
       "      <td>-3.868786e+00</td>\n",
       "      <td>-3.965265e+00</td>\n",
       "      <td>-2.782619e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.027755e-01</td>\n",
       "      <td>-1.199461e+00</td>\n",
       "      <td>-6.693840e-01</td>\n",
       "      <td>-7.516859e-01</td>\n",
       "      <td>-6.222681e-01</td>\n",
       "      <td>-6.602794e-01</td>\n",
       "      <td>-6.587790e-01</td>\n",
       "      <td>-6.921282e-01</td>\n",
       "      <td>-6.450364e-01</td>\n",
       "      <td>-6.981957e-01</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-8.022974e-01</td>\n",
       "      <td>-6.567335e-01</td>\n",
       "      <td>-8.957229e-01</td>\n",
       "      <td>-8.471015e-01</td>\n",
       "      <td>-8.284860e-01</td>\n",
       "      <td>-7.175293e-01</td>\n",
       "      <td>-7.554874e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.868283e-03</td>\n",
       "      <td>-1.540203e-01</td>\n",
       "      <td>5.390355e-02</td>\n",
       "      <td>-8.905258e-02</td>\n",
       "      <td>2.767230e-03</td>\n",
       "      <td>-2.466757e-02</td>\n",
       "      <td>-6.652185e-02</td>\n",
       "      <td>9.398760e-03</td>\n",
       "      <td>-1.337080e-02</td>\n",
       "      <td>2.696880e-03</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.566150e-03</td>\n",
       "      <td>-5.175865e-02</td>\n",
       "      <td>-2.955772e-01</td>\n",
       "      <td>-1.955858e-01</td>\n",
       "      <td>-1.918681e-01</td>\n",
       "      <td>-1.644871e-02</td>\n",
       "      <td>1.601343e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.085792e-01</td>\n",
       "      <td>1.103605e+00</td>\n",
       "      <td>6.987095e-01</td>\n",
       "      <td>7.299705e-01</td>\n",
       "      <td>5.875442e-01</td>\n",
       "      <td>7.024097e-01</td>\n",
       "      <td>6.728357e-01</td>\n",
       "      <td>6.640201e-01</td>\n",
       "      <td>6.670347e-01</td>\n",
       "      <td>6.777326e-01</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.107297e-01</td>\n",
       "      <td>6.329803e-01</td>\n",
       "      <td>3.274645e-01</td>\n",
       "      <td>7.160547e-01</td>\n",
       "      <td>7.535070e-01</td>\n",
       "      <td>7.077023e-01</td>\n",
       "      <td>7.440291e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.465256e+00</td>\n",
       "      <td>4.391621e+00</td>\n",
       "      <td>2.890982e+00</td>\n",
       "      <td>2.483615e+00</td>\n",
       "      <td>2.956513e+00</td>\n",
       "      <td>3.042810e+00</td>\n",
       "      <td>3.154037e+00</td>\n",
       "      <td>5.440292e+00</td>\n",
       "      <td>3.461476e+00</td>\n",
       "      <td>3.285175e+00</td>\n",
       "      <td>4.321989e+00</td>\n",
       "      <td>2.443003e+00</td>\n",
       "      <td>3.760984e+00</td>\n",
       "      <td>8.702351e+00</td>\n",
       "      <td>1.710428e+00</td>\n",
       "      <td>1.698787e+00</td>\n",
       "      <td>3.054866e+00</td>\n",
       "      <td>2.753135e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean   1.019875e-13 -5.144712e-14  6.653925e-14  2.549689e-14  2.334629e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.255345e+00 -5.306764e+00 -2.846587e+00 -2.447008e+00 -3.818917e+00   \n",
       "25%   -8.027755e-01 -1.199461e+00 -6.693840e-01 -7.516859e-01 -6.222681e-01   \n",
       "50%    3.868283e-03 -1.540203e-01  5.390355e-02 -8.905258e-02  2.767230e-03   \n",
       "75%    7.085792e-01  1.103605e+00  6.987095e-01  7.299705e-01  5.875442e-01   \n",
       "max    2.465256e+00  4.391621e+00  2.890982e+00  2.483615e+00  2.956513e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean  -6.727368e-14 -4.221841e-14  2.062856e-15  5.215490e-14  1.772519e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -4.363104e+00 -3.808196e+00 -3.063532e+00 -2.833784e+00 -2.112201e+00   \n",
       "25%   -6.602794e-01 -6.587790e-01 -6.921282e-01 -6.450364e-01 -6.981957e-01   \n",
       "50%   -2.466757e-02 -6.652185e-02  9.398760e-03 -1.337080e-02  2.696880e-03   \n",
       "75%    7.024097e-01  6.728357e-01  6.640201e-01  6.670347e-01  6.777326e-01   \n",
       "max    3.042810e+00  3.154037e+00  5.440292e+00  3.461476e+00  3.285175e+00   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean  -1.659610e-15  6.245795e-14 -9.682569e-15 -1.537578e-14  1.616595e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.541260e-01 -2.286725e+00 -3.466795e+00 -7.641412e+00 -3.527271e+00   \n",
       "25%   -2.541260e-01 -8.022974e-01 -6.567335e-01 -8.957229e-01 -8.471015e-01   \n",
       "50%   -2.541260e-01  8.566150e-03 -5.175865e-02 -2.955772e-01 -1.955858e-01   \n",
       "75%   -2.541260e-01  8.107297e-01  6.329803e-01  3.274645e-01  7.160547e-01   \n",
       "max    4.321989e+00  2.443003e+00  3.760984e+00  8.702351e+00  1.710428e+00   \n",
       "\n",
       "                 15            16            17  \n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  \n",
       "mean  -8.086471e-15  3.354384e-14  3.181464e-15  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -3.868786e+00 -3.965265e+00 -2.782619e+00  \n",
       "25%   -8.284860e-01 -7.175293e-01 -7.554874e-01  \n",
       "50%   -1.918681e-01 -1.644871e-02  1.601343e-02  \n",
       "75%    7.535070e-01  7.077023e-01  7.440291e-01  \n",
       "max    1.698787e+00  3.054866e+00  2.753135e+00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:40.279531Z",
     "start_time": "2021-12-30T02:03:40.221528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "      <td>5760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.426493</td>\n",
       "      <td>65.832202</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>0.079806</td>\n",
       "      <td>0.672361</td>\n",
       "      <td>2.283694</td>\n",
       "      <td>1.937404</td>\n",
       "      <td>7.449352</td>\n",
       "      <td>9.327724</td>\n",
       "      <td>5.756380</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>15482.226219</td>\n",
       "      <td>1.051691</td>\n",
       "      <td>3.676586</td>\n",
       "      <td>12.803597</td>\n",
       "      <td>11.687312</td>\n",
       "      <td>1.046624</td>\n",
       "      <td>0.813470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.536335</td>\n",
       "      <td>12.405338</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>0.032614</td>\n",
       "      <td>0.176061</td>\n",
       "      <td>0.523410</td>\n",
       "      <td>0.306804</td>\n",
       "      <td>2.431622</td>\n",
       "      <td>3.291614</td>\n",
       "      <td>2.725299</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>6063.422584</td>\n",
       "      <td>0.303361</td>\n",
       "      <td>0.481140</td>\n",
       "      <td>3.602422</td>\n",
       "      <td>3.020925</td>\n",
       "      <td>0.263948</td>\n",
       "      <td>0.292340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.833239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1616.845054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.926550</td>\n",
       "      <td>50.952479</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>0.055291</td>\n",
       "      <td>0.562804</td>\n",
       "      <td>1.938097</td>\n",
       "      <td>1.735287</td>\n",
       "      <td>5.766358</td>\n",
       "      <td>7.204513</td>\n",
       "      <td>3.853588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10617.557930</td>\n",
       "      <td>0.852464</td>\n",
       "      <td>3.245618</td>\n",
       "      <td>9.751980</td>\n",
       "      <td>9.184518</td>\n",
       "      <td>0.857234</td>\n",
       "      <td>0.592611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.525274</td>\n",
       "      <td>63.921527</td>\n",
       "      <td>0.188618</td>\n",
       "      <td>0.076901</td>\n",
       "      <td>0.672848</td>\n",
       "      <td>2.270782</td>\n",
       "      <td>1.916995</td>\n",
       "      <td>7.472206</td>\n",
       "      <td>9.283713</td>\n",
       "      <td>5.763730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15534.166404</td>\n",
       "      <td>1.035990</td>\n",
       "      <td>3.534372</td>\n",
       "      <td>12.099014</td>\n",
       "      <td>11.107693</td>\n",
       "      <td>1.042283</td>\n",
       "      <td>0.818152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>88.521007</td>\n",
       "      <td>79.522794</td>\n",
       "      <td>0.215417</td>\n",
       "      <td>0.103613</td>\n",
       "      <td>0.775804</td>\n",
       "      <td>2.651342</td>\n",
       "      <td>2.143833</td>\n",
       "      <td>9.063998</td>\n",
       "      <td>11.523345</td>\n",
       "      <td>7.603404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20398.022735</td>\n",
       "      <td>1.243713</td>\n",
       "      <td>3.834142</td>\n",
       "      <td>15.383128</td>\n",
       "      <td>13.963600</td>\n",
       "      <td>1.233421</td>\n",
       "      <td>1.030980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.380091</td>\n",
       "      <td>120.311749</td>\n",
       "      <td>0.306532</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>1.192886</td>\n",
       "      <td>3.876332</td>\n",
       "      <td>2.905076</td>\n",
       "      <td>20.678088</td>\n",
       "      <td>20.721569</td>\n",
       "      <td>14.709463</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>30295.187454</td>\n",
       "      <td>2.192628</td>\n",
       "      <td>7.863631</td>\n",
       "      <td>18.965279</td>\n",
       "      <td>16.819218</td>\n",
       "      <td>1.852950</td>\n",
       "      <td>1.618322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean     70.426493    65.832202     0.186377     0.079806     0.672361   \n",
       "std      25.536335    12.405338     0.041562     0.032614     0.176061   \n",
       "min      12.833239     0.000000     0.068067     0.000000     0.000000   \n",
       "25%      49.926550    50.952479     0.158556     0.055291     0.562804   \n",
       "50%      70.525274    63.921527     0.188618     0.076901     0.672848   \n",
       "75%      88.521007    79.522794     0.215417     0.103613     0.775804   \n",
       "max     133.380091   120.311749     0.306532     0.160805     1.192886   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  5760.000000  5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      2.283694     1.937404     7.449352     9.327724     5.756380   \n",
       "std       0.523410     0.306804     2.431622     3.291614     2.725299   \n",
       "min       0.000000     0.769032     0.000000     0.000000     0.000000   \n",
       "25%       1.938097     1.735287     5.766358     7.204513     3.853588   \n",
       "50%       2.270782     1.916995     7.472206     9.283713     5.763730   \n",
       "75%       2.651342     2.143833     9.063998    11.523345     7.603404   \n",
       "max       3.876332     2.905076    20.678088    20.721569    14.709463   \n",
       "\n",
       "                10            11           12           13           14  \\\n",
       "count  5760.000000   5760.000000  5760.000000  5760.000000  5760.000000   \n",
       "mean      0.008977  15482.226219     1.051691     3.676586    12.803597   \n",
       "std       0.035324   6063.422584     0.303361     0.481140     3.602422   \n",
       "min       0.000000   1616.845054     0.000000     0.000000     0.096879   \n",
       "25%       0.000000  10617.557930     0.852464     3.245618     9.751980   \n",
       "50%       0.000000  15534.166404     1.035990     3.534372    12.099014   \n",
       "75%       0.000000  20398.022735     1.243713     3.834142    15.383128   \n",
       "max       0.161645  30295.187454     2.192628     7.863631    18.965279   \n",
       "\n",
       "                15           16           17  \n",
       "count  5760.000000  5760.000000  5760.000000  \n",
       "mean     11.687312     1.046624     0.813470  \n",
       "std       3.020925     0.263948     0.292340  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       9.184518     0.857234     0.592611  \n",
       "50%      11.107693     1.042283     0.818152  \n",
       "75%      13.963600     1.233421     1.030980  \n",
       "max      16.819218     1.852950     1.618322  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:03:41.336592Z",
     "start_time": "2021-12-30T02:03:41.314591Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_data3={}\n",
    "for m in range(12):\n",
    "    month_data3=np.empty((18,480))\n",
    "    month_data3[:,:]=all_train_data3.T.iloc[:,m*480:(m+1)*480]\n",
    "    year_data3[m]=month_data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## diff with hw_test81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:27.032365Z",
     "start_time": "2021-12-30T02:09:26.994362Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x4=np.empty((12*471,18*9))\n",
    "y4=np.empty((12*471,1))\n",
    "\n",
    "for m in range(12):\n",
    "    for g in range(471):\n",
    "        x4[m*471+g:m*471+g+1,:]=year_data3[m][:,g:g+9].reshape(1,-1)\n",
    "        y4[m*471+g:m*471+g+1,:]=year_data3[m][9,g+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:27.459389Z",
     "start_time": "2021-12-30T02:09:27.452389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79645675, -0.79645675, -0.60553382, -1.27240954, -1.8175533 ,\n",
       "       -1.8175533 , -0.90134018,  0.3641883 ,  1.00139281, -0.25412602,\n",
       "       -0.25412602])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-6,81:92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:27.899414Z",
     "start_time": "2021-12-30T02:09:27.893414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79645675, -0.60553382, -1.27240954, -1.8175533 , -1.8175533 ,\n",
       "       -0.90134018,  0.3641883 ,  1.00139281,  1.48322449, -0.25412602,\n",
       "       -0.25412602])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-5,81:92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:28.315438Z",
     "start_time": "2021-12-30T02:09:28.310438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.60553382, -1.27240954, -1.8175533 , -1.8175533 , -0.90134018,\n",
       "        0.3641883 ,  1.00139281,  1.48322449,  1.00139281, -0.25412602,\n",
       "       -0.25412602])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-4,81:92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:28.795465Z",
     "start_time": "2021-12-30T02:09:28.788465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5652, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:29.271493Z",
     "start_time": "2021-12-30T02:09:29.266492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48322449],\n",
       "       [ 1.00139281],\n",
       "       [ 0.57751679],\n",
       "       [-0.06379855],\n",
       "       [ 0.3641883 ],\n",
       "       [ 0.6281137 ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:29.675516Z",
     "start_time": "2021-12-30T02:09:29.668515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00139281],\n",
       "       [ 0.57751679],\n",
       "       [-0.06379855],\n",
       "       [ 0.3641883 ],\n",
       "       [ 0.6281137 ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:30.111541Z",
     "start_time": "2021-12-30T02:09:30.105540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57751679],\n",
       "       [-0.06379855],\n",
       "       [ 0.3641883 ],\n",
       "       [ 0.6281137 ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:09:31.174602Z",
     "start_time": "2021-12-30T02:09:31.155600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x44=torch.Tensor(x4)\n",
    "y44=torch.Tensor(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:45:37.521636Z",
     "start_time": "2021-12-29T06:41:05.431073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.354327 , test loss : 0.390271\n",
      "epoch = 2 train_loss : 0.288429 , test loss : 0.314791\n",
      "epoch = 3 train_loss : 0.249911 , test loss : 0.273869\n",
      "epoch = 4 train_loss : 0.221793 , test loss : 0.242339\n",
      "epoch = 5 train_loss : 0.205295 , test loss : 0.224097\n",
      "epoch = 6 train_loss : 0.189097 , test loss : 0.208025\n",
      "epoch = 7 train_loss : 0.177969 , test loss : 0.197278\n",
      "epoch = 8 train_loss : 0.172280 , test loss : 0.187166\n",
      "epoch = 9 train_loss : 0.172585 , test loss : 0.186293\n",
      "epoch = 10 train_loss : 0.161396 , test loss : 0.176225\n",
      "epoch = 11 train_loss : 0.154276 , test loss : 0.169861\n",
      "epoch = 12 train_loss : 0.149747 , test loss : 0.163218\n",
      "epoch = 14 train_loss : 0.150314 , test loss : 0.162989\n",
      "epoch = 15 train_loss : 0.146769 , test loss : 0.159080\n",
      "epoch = 17 train_loss : 0.148672 , test loss : 0.158506\n",
      "epoch = 18 train_loss : 0.147083 , test loss : 0.158389\n",
      "epoch = 21 train_loss : 0.143416 , test loss : 0.156425\n",
      "epoch = 23 train_loss : 0.140625 , test loss : 0.153385\n",
      "epoch = 26 train_loss : 0.142385 , test loss : 0.152924\n",
      "epoch = 27 train_loss : 0.140171 , test loss : 0.152233\n",
      "epoch = 37 train_loss : 0.139296 , test loss : 0.149947\n",
      "epoch = 65 train_loss : 0.139394 , test loss : 0.149392\n",
      "epoch = 144 train_loss : 0.137634 , test loss : 0.149050\n",
      "epoch = 190 train_loss : 0.137251 , test loss : 0.148913\n",
      "epoch = 244 train_loss : 0.137857 , test loss : 0.148745\n",
      "epoch = 276 train_loss : 0.137310 , test loss : 0.148455\n",
      "epoch = 296 train_loss : 0.137401 , test loss : 0.148455\n",
      "epoch = 316 train_loss : 0.138135 , test loss : 0.148238\n",
      "epoch = 406 train_loss : 0.137116 , test loss : 0.148226\n",
      "epoch = 428 train_loss : 0.137045 , test loss : 0.148101\n",
      "epoch = 536 train_loss : 0.136732 , test loss : 0.147931\n",
      "epoch = 583 train_loss : 0.136974 , test loss : 0.147920\n",
      "epoch = 777 train_loss : 0.136458 , test loss : 0.147805\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.136458,test loss : 0.147805\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.303822 , test loss : 0.352182\n",
      "epoch = 2 train_loss : 0.245643 , test loss : 0.295780\n",
      "epoch = 3 train_loss : 0.215040 , test loss : 0.262692\n",
      "epoch = 4 train_loss : 0.193457 , test loss : 0.239811\n",
      "epoch = 5 train_loss : 0.183642 , test loss : 0.226967\n",
      "epoch = 6 train_loss : 0.170661 , test loss : 0.212733\n",
      "epoch = 7 train_loss : 0.163505 , test loss : 0.208628\n",
      "epoch = 9 train_loss : 0.157667 , test loss : 0.193961\n",
      "epoch = 10 train_loss : 0.150000 , test loss : 0.186577\n",
      "epoch = 11 train_loss : 0.149163 , test loss : 0.183003\n",
      "epoch = 13 train_loss : 0.149587 , test loss : 0.176616\n",
      "epoch = 14 train_loss : 0.146704 , test loss : 0.171338\n",
      "epoch = 16 train_loss : 0.143086 , test loss : 0.168649\n",
      "epoch = 18 train_loss : 0.139587 , test loss : 0.166027\n",
      "epoch = 23 train_loss : 0.139665 , test loss : 0.165652\n",
      "epoch = 25 train_loss : 0.139069 , test loss : 0.165183\n",
      "epoch = 26 train_loss : 0.138424 , test loss : 0.163598\n",
      "epoch = 34 train_loss : 0.135941 , test loss : 0.162253\n",
      "epoch = 62 train_loss : 0.135436 , test loss : 0.160000\n",
      "epoch = 80 train_loss : 0.135395 , test loss : 0.159920\n",
      "epoch = 92 train_loss : 0.135460 , test loss : 0.159244\n",
      "epoch = 155 train_loss : 0.135596 , test loss : 0.158882\n",
      "epoch = 209 train_loss : 0.136704 , test loss : 0.158751\n",
      "epoch = 411 train_loss : 0.135892 , test loss : 0.158136\n",
      "epoch = 625 train_loss : 0.134875 , test loss : 0.157931\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.134875,test loss : 0.157931\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.373180 , test loss : 0.358288\n",
      "epoch = 2 train_loss : 0.283914 , test loss : 0.263330\n",
      "epoch = 3 train_loss : 0.245916 , test loss : 0.233275\n",
      "epoch = 4 train_loss : 0.220711 , test loss : 0.211736\n",
      "epoch = 5 train_loss : 0.201685 , test loss : 0.194988\n",
      "epoch = 6 train_loss : 0.188653 , test loss : 0.185857\n",
      "epoch = 7 train_loss : 0.179160 , test loss : 0.176967\n",
      "epoch = 8 train_loss : 0.170025 , test loss : 0.164161\n",
      "epoch = 9 train_loss : 0.167983 , test loss : 0.163332\n",
      "epoch = 10 train_loss : 0.156930 , test loss : 0.157233\n",
      "epoch = 13 train_loss : 0.152271 , test loss : 0.156193\n",
      "epoch = 14 train_loss : 0.146137 , test loss : 0.149526\n",
      "epoch = 22 train_loss : 0.141162 , test loss : 0.149500\n",
      "epoch = 23 train_loss : 0.143783 , test loss : 0.149253\n",
      "epoch = 31 train_loss : 0.138370 , test loss : 0.147898\n",
      "epoch = 76 train_loss : 0.138070 , test loss : 0.147408\n",
      "epoch = 145 train_loss : 0.138283 , test loss : 0.147377\n",
      "epoch = 218 train_loss : 0.137106 , test loss : 0.147224\n",
      "epoch = 238 train_loss : 0.136907 , test loss : 0.147190\n",
      "epoch = 309 train_loss : 0.137081 , test loss : 0.147047\n",
      "epoch = 777 train_loss : 0.136852 , test loss : 0.146397\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.136852,test loss : 0.146397\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.367066 , test loss : 0.360646\n",
      "epoch = 2 train_loss : 0.295921 , test loss : 0.284832\n",
      "epoch = 3 train_loss : 0.256490 , test loss : 0.254456\n",
      "epoch = 4 train_loss : 0.231662 , test loss : 0.235312\n",
      "epoch = 5 train_loss : 0.209487 , test loss : 0.215003\n",
      "epoch = 6 train_loss : 0.198616 , test loss : 0.201660\n",
      "epoch = 7 train_loss : 0.184902 , test loss : 0.190467\n",
      "epoch = 8 train_loss : 0.177288 , test loss : 0.184156\n",
      "epoch = 9 train_loss : 0.166460 , test loss : 0.170850\n",
      "epoch = 10 train_loss : 0.161283 , test loss : 0.163961\n",
      "epoch = 13 train_loss : 0.154112 , test loss : 0.158303\n",
      "epoch = 16 train_loss : 0.148706 , test loss : 0.150778\n",
      "epoch = 17 train_loss : 0.146630 , test loss : 0.149667\n",
      "epoch = 19 train_loss : 0.146209 , test loss : 0.149651\n",
      "epoch = 23 train_loss : 0.144041 , test loss : 0.147456\n",
      "epoch = 24 train_loss : 0.142599 , test loss : 0.144951\n",
      "epoch = 25 train_loss : 0.142905 , test loss : 0.144666\n",
      "epoch = 42 train_loss : 0.140587 , test loss : 0.143044\n",
      "epoch = 49 train_loss : 0.142321 , test loss : 0.142803\n",
      "epoch = 52 train_loss : 0.141407 , test loss : 0.141666\n",
      "epoch = 59 train_loss : 0.144508 , test loss : 0.141216\n",
      "epoch = 65 train_loss : 0.141300 , test loss : 0.140858\n",
      "epoch = 118 train_loss : 0.142028 , test loss : 0.140510\n",
      "epoch = 147 train_loss : 0.142270 , test loss : 0.140036\n",
      "epoch = 166 train_loss : 0.140986 , test loss : 0.139634\n",
      "epoch = 176 train_loss : 0.139837 , test loss : 0.139183\n",
      "epoch = 638 train_loss : 0.140498 , test loss : 0.139167\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.140498,test loss : 0.139167\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.377125 , test loss : 0.375681\n",
      "epoch = 2 train_loss : 0.282712 , test loss : 0.274188\n",
      "epoch = 3 train_loss : 0.246562 , test loss : 0.234704\n",
      "epoch = 4 train_loss : 0.223337 , test loss : 0.212301\n",
      "epoch = 5 train_loss : 0.208780 , test loss : 0.198374\n",
      "epoch = 6 train_loss : 0.196143 , test loss : 0.188208\n",
      "epoch = 7 train_loss : 0.184476 , test loss : 0.176355\n",
      "epoch = 8 train_loss : 0.176949 , test loss : 0.172225\n",
      "epoch = 9 train_loss : 0.169479 , test loss : 0.163142\n",
      "epoch = 11 train_loss : 0.165684 , test loss : 0.159175\n",
      "epoch = 13 train_loss : 0.160642 , test loss : 0.150889\n",
      "epoch = 14 train_loss : 0.154471 , test loss : 0.149959\n",
      "epoch = 15 train_loss : 0.150623 , test loss : 0.146543\n",
      "epoch = 22 train_loss : 0.145749 , test loss : 0.145940\n",
      "epoch = 23 train_loss : 0.147666 , test loss : 0.142767\n",
      "epoch = 25 train_loss : 0.143787 , test loss : 0.142596\n",
      "epoch = 36 train_loss : 0.143277 , test loss : 0.141830\n",
      "epoch = 47 train_loss : 0.142888 , test loss : 0.141473\n",
      "epoch = 50 train_loss : 0.141301 , test loss : 0.140817\n",
      "epoch = 54 train_loss : 0.141013 , test loss : 0.139658\n",
      "epoch = 193 train_loss : 0.139650 , test loss : 0.139554\n",
      "epoch = 608 train_loss : 0.139120 , test loss : 0.139286\n",
      "epoch = 701 train_loss : 0.139243 , test loss : 0.138993\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.139243,test loss : 0.138993\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.137585,total test loss mean : 0.146058 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:50:17.911673Z",
     "start_time": "2021-12-29T06:45:37.523636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.317243 , test loss : 0.342729\n",
      "epoch = 2 train_loss : 0.239142 , test loss : 0.263027\n",
      "epoch = 3 train_loss : 0.211435 , test loss : 0.228256\n",
      "epoch = 4 train_loss : 0.190771 , test loss : 0.207209\n",
      "epoch = 5 train_loss : 0.178426 , test loss : 0.195883\n",
      "epoch = 6 train_loss : 0.168668 , test loss : 0.184204\n",
      "epoch = 7 train_loss : 0.166250 , test loss : 0.182232\n",
      "epoch = 8 train_loss : 0.158647 , test loss : 0.169413\n",
      "epoch = 9 train_loss : 0.152368 , test loss : 0.165382\n",
      "epoch = 10 train_loss : 0.149241 , test loss : 0.161780\n",
      "epoch = 12 train_loss : 0.148300 , test loss : 0.160614\n",
      "epoch = 14 train_loss : 0.148268 , test loss : 0.158498\n",
      "epoch = 17 train_loss : 0.142127 , test loss : 0.153723\n",
      "epoch = 20 train_loss : 0.141504 , test loss : 0.152053\n",
      "epoch = 33 train_loss : 0.140899 , test loss : 0.151999\n",
      "epoch = 40 train_loss : 0.140036 , test loss : 0.151443\n",
      "epoch = 43 train_loss : 0.138927 , test loss : 0.151213\n",
      "epoch = 44 train_loss : 0.139499 , test loss : 0.149247\n",
      "epoch = 47 train_loss : 0.138540 , test loss : 0.149081\n",
      "epoch = 109 train_loss : 0.138327 , test loss : 0.149069\n",
      "epoch = 139 train_loss : 0.137249 , test loss : 0.148580\n",
      "epoch = 407 train_loss : 0.137990 , test loss : 0.148484\n",
      "epoch = 441 train_loss : 0.136845 , test loss : 0.148088\n",
      "epoch = 637 train_loss : 0.137425 , test loss : 0.148007\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.137425,test loss : 0.148007\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.359887 , test loss : 0.406737\n",
      "epoch = 2 train_loss : 0.256824 , test loss : 0.306348\n",
      "epoch = 3 train_loss : 0.223251 , test loss : 0.271885\n",
      "epoch = 4 train_loss : 0.201891 , test loss : 0.246054\n",
      "epoch = 5 train_loss : 0.182967 , test loss : 0.225821\n",
      "epoch = 6 train_loss : 0.172575 , test loss : 0.215011\n",
      "epoch = 7 train_loss : 0.163215 , test loss : 0.202158\n",
      "epoch = 8 train_loss : 0.156848 , test loss : 0.193637\n",
      "epoch = 10 train_loss : 0.153015 , test loss : 0.185565\n",
      "epoch = 12 train_loss : 0.146702 , test loss : 0.172987\n",
      "epoch = 16 train_loss : 0.143905 , test loss : 0.170257\n",
      "epoch = 23 train_loss : 0.140217 , test loss : 0.166276\n",
      "epoch = 25 train_loss : 0.143287 , test loss : 0.165928\n",
      "epoch = 31 train_loss : 0.138987 , test loss : 0.161064\n",
      "epoch = 40 train_loss : 0.138494 , test loss : 0.161026\n",
      "epoch = 63 train_loss : 0.136504 , test loss : 0.160560\n",
      "epoch = 79 train_loss : 0.137094 , test loss : 0.160058\n",
      "epoch = 129 train_loss : 0.136362 , test loss : 0.159996\n",
      "epoch = 177 train_loss : 0.134980 , test loss : 0.159737\n",
      "epoch = 182 train_loss : 0.136246 , test loss : 0.159481\n",
      "epoch = 191 train_loss : 0.135196 , test loss : 0.159221\n",
      "epoch = 217 train_loss : 0.135988 , test loss : 0.158955\n",
      "epoch = 237 train_loss : 0.136556 , test loss : 0.158519\n",
      "epoch = 356 train_loss : 0.135488 , test loss : 0.158250\n",
      "epoch = 655 train_loss : 0.134897 , test loss : 0.158186\n",
      "epoch = 761 train_loss : 0.134949 , test loss : 0.158151\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.134949,test loss : 0.158151\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.309417 , test loss : 0.293949\n",
      "epoch = 2 train_loss : 0.243574 , test loss : 0.233079\n",
      "epoch = 3 train_loss : 0.207284 , test loss : 0.198629\n",
      "epoch = 4 train_loss : 0.189847 , test loss : 0.182188\n",
      "epoch = 5 train_loss : 0.175931 , test loss : 0.172947\n",
      "epoch = 6 train_loss : 0.169998 , test loss : 0.171580\n",
      "epoch = 8 train_loss : 0.162082 , test loss : 0.163870\n",
      "epoch = 9 train_loss : 0.163474 , test loss : 0.163263\n",
      "epoch = 10 train_loss : 0.153338 , test loss : 0.158602\n",
      "epoch = 11 train_loss : 0.147515 , test loss : 0.154171\n",
      "epoch = 13 train_loss : 0.146084 , test loss : 0.153017\n",
      "epoch = 14 train_loss : 0.147598 , test loss : 0.151591\n",
      "epoch = 17 train_loss : 0.144179 , test loss : 0.150976\n",
      "epoch = 21 train_loss : 0.141994 , test loss : 0.149970\n",
      "epoch = 28 train_loss : 0.138927 , test loss : 0.148076\n",
      "epoch = 49 train_loss : 0.139403 , test loss : 0.148027\n",
      "epoch = 52 train_loss : 0.139882 , test loss : 0.146829\n",
      "epoch = 489 train_loss : 0.137859 , test loss : 0.146601\n",
      "epoch = 548 train_loss : 0.137597 , test loss : 0.146383\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.137597,test loss : 0.146383\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.341057 , test loss : 0.350442\n",
      "epoch = 2 train_loss : 0.255460 , test loss : 0.255604\n",
      "epoch = 3 train_loss : 0.230286 , test loss : 0.232206\n",
      "epoch = 4 train_loss : 0.198353 , test loss : 0.201933\n",
      "epoch = 5 train_loss : 0.184365 , test loss : 0.185982\n",
      "epoch = 6 train_loss : 0.172968 , test loss : 0.179857\n",
      "epoch = 7 train_loss : 0.166535 , test loss : 0.169945\n",
      "epoch = 8 train_loss : 0.160229 , test loss : 0.166081\n",
      "epoch = 10 train_loss : 0.159448 , test loss : 0.163550\n",
      "epoch = 11 train_loss : 0.153037 , test loss : 0.158236\n",
      "epoch = 12 train_loss : 0.151325 , test loss : 0.155202\n",
      "epoch = 13 train_loss : 0.148914 , test loss : 0.153994\n",
      "epoch = 14 train_loss : 0.151114 , test loss : 0.151661\n",
      "epoch = 17 train_loss : 0.153992 , test loss : 0.150268\n",
      "epoch = 22 train_loss : 0.146817 , test loss : 0.145411\n",
      "epoch = 24 train_loss : 0.146523 , test loss : 0.144204\n",
      "epoch = 43 train_loss : 0.141722 , test loss : 0.140058\n",
      "epoch = 194 train_loss : 0.140584 , test loss : 0.139178\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.140584,test loss : 0.139178\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.358979 , test loss : 0.330423\n",
      "epoch = 2 train_loss : 0.261402 , test loss : 0.248700\n",
      "epoch = 3 train_loss : 0.223899 , test loss : 0.215058\n",
      "epoch = 4 train_loss : 0.200041 , test loss : 0.192122\n",
      "epoch = 5 train_loss : 0.186909 , test loss : 0.177647\n",
      "epoch = 6 train_loss : 0.183086 , test loss : 0.171987\n",
      "epoch = 7 train_loss : 0.171108 , test loss : 0.167478\n",
      "epoch = 8 train_loss : 0.165663 , test loss : 0.154061\n",
      "epoch = 10 train_loss : 0.155167 , test loss : 0.147996\n",
      "epoch = 15 train_loss : 0.148695 , test loss : 0.145149\n",
      "epoch = 20 train_loss : 0.144149 , test loss : 0.144073\n",
      "epoch = 27 train_loss : 0.144847 , test loss : 0.140470\n",
      "epoch = 117 train_loss : 0.140303 , test loss : 0.140367\n",
      "epoch = 173 train_loss : 0.141577 , test loss : 0.139728\n",
      "epoch = 537 train_loss : 0.139167 , test loss : 0.139477\n",
      "epoch = 738 train_loss : 0.140800 , test loss : 0.139060\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.140800,test loss : 0.139060\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.138271,total test loss mean : 0.146156 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],256),nn.Linear(256,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:53:03.204127Z",
     "start_time": "2021-12-29T06:50:17.913673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.500259 , test loss : 0.519400\n",
      "epoch = 2 train_loss : 0.412532 , test loss : 0.430099\n",
      "epoch = 3 train_loss : 0.379156 , test loss : 0.402438\n",
      "epoch = 4 train_loss : 0.355301 , test loss : 0.378293\n",
      "epoch = 5 train_loss : 0.337266 , test loss : 0.361386\n",
      "epoch = 6 train_loss : 0.322658 , test loss : 0.346927\n",
      "epoch = 7 train_loss : 0.310615 , test loss : 0.337034\n",
      "epoch = 8 train_loss : 0.298743 , test loss : 0.325149\n",
      "epoch = 9 train_loss : 0.288892 , test loss : 0.315243\n",
      "epoch = 10 train_loss : 0.278711 , test loss : 0.305200\n",
      "epoch = 11 train_loss : 0.271411 , test loss : 0.299324\n",
      "epoch = 12 train_loss : 0.262257 , test loss : 0.288823\n",
      "epoch = 13 train_loss : 0.255143 , test loss : 0.282591\n",
      "epoch = 14 train_loss : 0.248568 , test loss : 0.275522\n",
      "epoch = 15 train_loss : 0.241594 , test loss : 0.268819\n",
      "epoch = 16 train_loss : 0.235531 , test loss : 0.261964\n",
      "epoch = 17 train_loss : 0.233309 , test loss : 0.258607\n",
      "epoch = 18 train_loss : 0.224293 , test loss : 0.250026\n",
      "epoch = 19 train_loss : 0.219589 , test loss : 0.244511\n",
      "epoch = 20 train_loss : 0.213474 , test loss : 0.238537\n",
      "epoch = 21 train_loss : 0.208783 , test loss : 0.232822\n",
      "epoch = 22 train_loss : 0.205134 , test loss : 0.228978\n",
      "epoch = 23 train_loss : 0.202351 , test loss : 0.225741\n",
      "epoch = 24 train_loss : 0.196010 , test loss : 0.218887\n",
      "epoch = 25 train_loss : 0.192159 , test loss : 0.213735\n",
      "epoch = 26 train_loss : 0.188707 , test loss : 0.210239\n",
      "epoch = 27 train_loss : 0.185030 , test loss : 0.206077\n",
      "epoch = 28 train_loss : 0.182267 , test loss : 0.202874\n",
      "epoch = 29 train_loss : 0.179908 , test loss : 0.200014\n",
      "epoch = 31 train_loss : 0.174414 , test loss : 0.193753\n",
      "epoch = 32 train_loss : 0.171734 , test loss : 0.191812\n",
      "epoch = 33 train_loss : 0.170141 , test loss : 0.187145\n",
      "epoch = 34 train_loss : 0.167159 , test loss : 0.185963\n",
      "epoch = 35 train_loss : 0.164566 , test loss : 0.182825\n",
      "epoch = 36 train_loss : 0.164114 , test loss : 0.180982\n",
      "epoch = 37 train_loss : 0.162903 , test loss : 0.179516\n",
      "epoch = 38 train_loss : 0.160987 , test loss : 0.178610\n",
      "epoch = 39 train_loss : 0.158682 , test loss : 0.174636\n",
      "epoch = 40 train_loss : 0.157610 , test loss : 0.171997\n",
      "epoch = 41 train_loss : 0.156510 , test loss : 0.171868\n",
      "epoch = 42 train_loss : 0.154610 , test loss : 0.169646\n",
      "epoch = 43 train_loss : 0.153372 , test loss : 0.169524\n",
      "epoch = 44 train_loss : 0.151447 , test loss : 0.166472\n",
      "epoch = 46 train_loss : 0.150060 , test loss : 0.164425\n",
      "epoch = 47 train_loss : 0.149266 , test loss : 0.163775\n",
      "epoch = 49 train_loss : 0.148960 , test loss : 0.161752\n",
      "epoch = 50 train_loss : 0.147250 , test loss : 0.160125\n",
      "epoch = 52 train_loss : 0.145781 , test loss : 0.159765\n",
      "epoch = 53 train_loss : 0.144988 , test loss : 0.157859\n",
      "epoch = 56 train_loss : 0.143612 , test loss : 0.157564\n",
      "epoch = 58 train_loss : 0.142207 , test loss : 0.155750\n",
      "epoch = 59 train_loss : 0.141990 , test loss : 0.155525\n",
      "epoch = 61 train_loss : 0.141309 , test loss : 0.154212\n",
      "epoch = 67 train_loss : 0.141091 , test loss : 0.154063\n",
      "epoch = 69 train_loss : 0.139482 , test loss : 0.152145\n",
      "epoch = 73 train_loss : 0.139222 , test loss : 0.151719\n",
      "epoch = 74 train_loss : 0.139423 , test loss : 0.151417\n",
      "epoch = 76 train_loss : 0.138651 , test loss : 0.151281\n",
      "epoch = 82 train_loss : 0.139740 , test loss : 0.151134\n",
      "epoch = 88 train_loss : 0.137968 , test loss : 0.150757\n",
      "epoch = 89 train_loss : 0.137991 , test loss : 0.150509\n",
      "epoch = 91 train_loss : 0.137685 , test loss : 0.149685\n",
      "epoch = 95 train_loss : 0.137948 , test loss : 0.149674\n",
      "epoch = 97 train_loss : 0.138221 , test loss : 0.149373\n",
      "epoch = 125 train_loss : 0.137662 , test loss : 0.148954\n",
      "epoch = 142 train_loss : 0.136976 , test loss : 0.148811\n",
      "epoch = 184 train_loss : 0.137494 , test loss : 0.148413\n",
      "epoch = 187 train_loss : 0.137007 , test loss : 0.148262\n",
      "epoch = 318 train_loss : 0.136860 , test loss : 0.148226\n",
      "epoch = 335 train_loss : 0.136753 , test loss : 0.148177\n",
      "epoch = 500 train_loss : 0.136923 , test loss : 0.147983\n",
      "epoch = 793 train_loss : 0.136648 , test loss : 0.147747\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.136648,test loss : 0.147747\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.450265 , test loss : 0.496119\n",
      "epoch = 2 train_loss : 0.377709 , test loss : 0.425539\n",
      "epoch = 3 train_loss : 0.340863 , test loss : 0.390461\n",
      "epoch = 4 train_loss : 0.315733 , test loss : 0.365299\n",
      "epoch = 5 train_loss : 0.297429 , test loss : 0.350648\n",
      "epoch = 6 train_loss : 0.282655 , test loss : 0.334996\n",
      "epoch = 7 train_loss : 0.269264 , test loss : 0.321161\n",
      "epoch = 8 train_loss : 0.258508 , test loss : 0.309467\n",
      "epoch = 9 train_loss : 0.249271 , test loss : 0.299911\n",
      "epoch = 10 train_loss : 0.241818 , test loss : 0.291537\n",
      "epoch = 11 train_loss : 0.233480 , test loss : 0.284602\n",
      "epoch = 12 train_loss : 0.225349 , test loss : 0.275698\n",
      "epoch = 13 train_loss : 0.219188 , test loss : 0.267037\n",
      "epoch = 14 train_loss : 0.213010 , test loss : 0.263626\n",
      "epoch = 15 train_loss : 0.206178 , test loss : 0.253189\n",
      "epoch = 16 train_loss : 0.201930 , test loss : 0.248217\n",
      "epoch = 17 train_loss : 0.196266 , test loss : 0.241577\n",
      "epoch = 18 train_loss : 0.191630 , test loss : 0.238178\n",
      "epoch = 19 train_loss : 0.188168 , test loss : 0.231560\n",
      "epoch = 20 train_loss : 0.183547 , test loss : 0.229148\n",
      "epoch = 21 train_loss : 0.179824 , test loss : 0.223617\n",
      "epoch = 22 train_loss : 0.176751 , test loss : 0.222794\n",
      "epoch = 23 train_loss : 0.173662 , test loss : 0.217861\n",
      "epoch = 24 train_loss : 0.170218 , test loss : 0.213042\n",
      "epoch = 25 train_loss : 0.168248 , test loss : 0.208920\n",
      "epoch = 26 train_loss : 0.165598 , test loss : 0.204435\n",
      "epoch = 28 train_loss : 0.160555 , test loss : 0.200818\n",
      "epoch = 29 train_loss : 0.158762 , test loss : 0.199413\n",
      "epoch = 30 train_loss : 0.159870 , test loss : 0.199396\n",
      "epoch = 31 train_loss : 0.155722 , test loss : 0.195619\n",
      "epoch = 32 train_loss : 0.154207 , test loss : 0.190722\n",
      "epoch = 34 train_loss : 0.152117 , test loss : 0.188572\n",
      "epoch = 35 train_loss : 0.151587 , test loss : 0.187624\n",
      "epoch = 36 train_loss : 0.148979 , test loss : 0.185380\n",
      "epoch = 37 train_loss : 0.148657 , test loss : 0.181643\n",
      "epoch = 39 train_loss : 0.145501 , test loss : 0.179476\n",
      "epoch = 40 train_loss : 0.146145 , test loss : 0.177218\n",
      "epoch = 42 train_loss : 0.145205 , test loss : 0.177142\n",
      "epoch = 43 train_loss : 0.143564 , test loss : 0.175239\n",
      "epoch = 44 train_loss : 0.142488 , test loss : 0.174127\n",
      "epoch = 48 train_loss : 0.141245 , test loss : 0.173282\n",
      "epoch = 49 train_loss : 0.142599 , test loss : 0.171303\n",
      "epoch = 50 train_loss : 0.140163 , test loss : 0.168074\n",
      "epoch = 51 train_loss : 0.140536 , test loss : 0.166810\n",
      "epoch = 54 train_loss : 0.139534 , test loss : 0.165739\n",
      "epoch = 55 train_loss : 0.139519 , test loss : 0.164858\n",
      "epoch = 59 train_loss : 0.138110 , test loss : 0.164744\n",
      "epoch = 62 train_loss : 0.138907 , test loss : 0.163186\n",
      "epoch = 67 train_loss : 0.136197 , test loss : 0.162498\n",
      "epoch = 68 train_loss : 0.137188 , test loss : 0.160576\n",
      "epoch = 76 train_loss : 0.137296 , test loss : 0.159233\n",
      "epoch = 85 train_loss : 0.136042 , test loss : 0.159022\n",
      "epoch = 100 train_loss : 0.135428 , test loss : 0.158876\n",
      "epoch = 111 train_loss : 0.136610 , test loss : 0.158556\n",
      "epoch = 134 train_loss : 0.136249 , test loss : 0.158476\n",
      "epoch = 146 train_loss : 0.135700 , test loss : 0.158093\n",
      "epoch = 162 train_loss : 0.135020 , test loss : 0.158045\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.135020,test loss : 0.158045\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.535271 , test loss : 0.528477\n",
      "epoch = 2 train_loss : 0.445499 , test loss : 0.421174\n",
      "epoch = 3 train_loss : 0.395956 , test loss : 0.373387\n",
      "epoch = 4 train_loss : 0.362106 , test loss : 0.338644\n",
      "epoch = 5 train_loss : 0.337319 , test loss : 0.317200\n",
      "epoch = 6 train_loss : 0.317499 , test loss : 0.296865\n",
      "epoch = 7 train_loss : 0.300624 , test loss : 0.281816\n",
      "epoch = 8 train_loss : 0.286865 , test loss : 0.269273\n",
      "epoch = 9 train_loss : 0.275469 , test loss : 0.256574\n",
      "epoch = 10 train_loss : 0.264642 , test loss : 0.249499\n",
      "epoch = 11 train_loss : 0.255044 , test loss : 0.240792\n",
      "epoch = 12 train_loss : 0.246573 , test loss : 0.233091\n",
      "epoch = 13 train_loss : 0.238910 , test loss : 0.226452\n",
      "epoch = 14 train_loss : 0.231996 , test loss : 0.219812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 15 train_loss : 0.225175 , test loss : 0.213945\n",
      "epoch = 16 train_loss : 0.220176 , test loss : 0.208216\n",
      "epoch = 17 train_loss : 0.214336 , test loss : 0.206950\n",
      "epoch = 18 train_loss : 0.209063 , test loss : 0.198202\n",
      "epoch = 19 train_loss : 0.204218 , test loss : 0.196655\n",
      "epoch = 20 train_loss : 0.200515 , test loss : 0.195240\n",
      "epoch = 21 train_loss : 0.195628 , test loss : 0.190096\n",
      "epoch = 22 train_loss : 0.191101 , test loss : 0.185611\n",
      "epoch = 23 train_loss : 0.187525 , test loss : 0.181712\n",
      "epoch = 24 train_loss : 0.183711 , test loss : 0.179018\n",
      "epoch = 25 train_loss : 0.180987 , test loss : 0.174807\n",
      "epoch = 26 train_loss : 0.177771 , test loss : 0.173400\n",
      "epoch = 27 train_loss : 0.175270 , test loss : 0.172191\n",
      "epoch = 28 train_loss : 0.172424 , test loss : 0.168780\n",
      "epoch = 29 train_loss : 0.169567 , test loss : 0.167939\n",
      "epoch = 30 train_loss : 0.167697 , test loss : 0.165412\n",
      "epoch = 31 train_loss : 0.165859 , test loss : 0.163985\n",
      "epoch = 32 train_loss : 0.163104 , test loss : 0.160565\n",
      "epoch = 34 train_loss : 0.159162 , test loss : 0.158698\n",
      "epoch = 36 train_loss : 0.158043 , test loss : 0.157574\n",
      "epoch = 39 train_loss : 0.156109 , test loss : 0.156128\n",
      "epoch = 40 train_loss : 0.152899 , test loss : 0.154905\n",
      "epoch = 41 train_loss : 0.151734 , test loss : 0.153729\n",
      "epoch = 42 train_loss : 0.149931 , test loss : 0.152509\n",
      "epoch = 43 train_loss : 0.148746 , test loss : 0.152467\n",
      "epoch = 45 train_loss : 0.147490 , test loss : 0.151173\n",
      "epoch = 48 train_loss : 0.145603 , test loss : 0.149672\n",
      "epoch = 51 train_loss : 0.144692 , test loss : 0.149027\n",
      "epoch = 52 train_loss : 0.143287 , test loss : 0.148424\n",
      "epoch = 55 train_loss : 0.142797 , test loss : 0.148046\n",
      "epoch = 57 train_loss : 0.141919 , test loss : 0.147649\n",
      "epoch = 61 train_loss : 0.141175 , test loss : 0.147420\n",
      "epoch = 62 train_loss : 0.139870 , test loss : 0.147327\n",
      "epoch = 69 train_loss : 0.139494 , test loss : 0.147245\n",
      "epoch = 78 train_loss : 0.138310 , test loss : 0.146876\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.138310,test loss : 0.146876\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.515478 , test loss : 0.524372\n",
      "epoch = 2 train_loss : 0.437378 , test loss : 0.441923\n",
      "epoch = 3 train_loss : 0.403347 , test loss : 0.407548\n",
      "epoch = 4 train_loss : 0.376090 , test loss : 0.380107\n",
      "epoch = 5 train_loss : 0.353804 , test loss : 0.355129\n",
      "epoch = 6 train_loss : 0.335499 , test loss : 0.336147\n",
      "epoch = 7 train_loss : 0.320807 , test loss : 0.321017\n",
      "epoch = 8 train_loss : 0.306911 , test loss : 0.308130\n",
      "epoch = 9 train_loss : 0.295501 , test loss : 0.295646\n",
      "epoch = 10 train_loss : 0.284422 , test loss : 0.286282\n",
      "epoch = 11 train_loss : 0.273758 , test loss : 0.276104\n",
      "epoch = 12 train_loss : 0.265581 , test loss : 0.267678\n",
      "epoch = 13 train_loss : 0.254927 , test loss : 0.257206\n",
      "epoch = 14 train_loss : 0.246291 , test loss : 0.248724\n",
      "epoch = 15 train_loss : 0.238703 , test loss : 0.242108\n",
      "epoch = 16 train_loss : 0.231167 , test loss : 0.234134\n",
      "epoch = 17 train_loss : 0.224273 , test loss : 0.228476\n",
      "epoch = 18 train_loss : 0.218051 , test loss : 0.222740\n",
      "epoch = 19 train_loss : 0.213656 , test loss : 0.219152\n",
      "epoch = 20 train_loss : 0.207004 , test loss : 0.213100\n",
      "epoch = 21 train_loss : 0.203802 , test loss : 0.209756\n",
      "epoch = 23 train_loss : 0.193181 , test loss : 0.197859\n",
      "epoch = 24 train_loss : 0.189977 , test loss : 0.197450\n",
      "epoch = 25 train_loss : 0.185658 , test loss : 0.189441\n",
      "epoch = 26 train_loss : 0.184827 , test loss : 0.188177\n",
      "epoch = 27 train_loss : 0.178993 , test loss : 0.182937\n",
      "epoch = 29 train_loss : 0.173208 , test loss : 0.178515\n",
      "epoch = 30 train_loss : 0.171554 , test loss : 0.175629\n",
      "epoch = 31 train_loss : 0.168843 , test loss : 0.172366\n",
      "epoch = 33 train_loss : 0.167038 , test loss : 0.171885\n",
      "epoch = 34 train_loss : 0.163736 , test loss : 0.166408\n",
      "epoch = 37 train_loss : 0.158291 , test loss : 0.163489\n",
      "epoch = 39 train_loss : 0.156181 , test loss : 0.162202\n",
      "epoch = 40 train_loss : 0.154601 , test loss : 0.159828\n",
      "epoch = 41 train_loss : 0.154159 , test loss : 0.159527\n",
      "epoch = 42 train_loss : 0.152613 , test loss : 0.159147\n",
      "epoch = 44 train_loss : 0.152078 , test loss : 0.158784\n",
      "epoch = 45 train_loss : 0.150557 , test loss : 0.157409\n",
      "epoch = 47 train_loss : 0.152718 , test loss : 0.154434\n",
      "epoch = 48 train_loss : 0.149309 , test loss : 0.152024\n",
      "epoch = 51 train_loss : 0.148868 , test loss : 0.150183\n",
      "epoch = 52 train_loss : 0.146628 , test loss : 0.150075\n",
      "epoch = 53 train_loss : 0.145941 , test loss : 0.148618\n",
      "epoch = 60 train_loss : 0.144477 , test loss : 0.148256\n",
      "epoch = 61 train_loss : 0.143517 , test loss : 0.147110\n",
      "epoch = 62 train_loss : 0.143081 , test loss : 0.146625\n",
      "epoch = 65 train_loss : 0.142835 , test loss : 0.144888\n",
      "epoch = 68 train_loss : 0.142274 , test loss : 0.144870\n",
      "epoch = 71 train_loss : 0.141592 , test loss : 0.144257\n",
      "epoch = 73 train_loss : 0.141309 , test loss : 0.143628\n",
      "epoch = 75 train_loss : 0.141902 , test loss : 0.143344\n",
      "epoch = 83 train_loss : 0.140867 , test loss : 0.142884\n",
      "epoch = 95 train_loss : 0.140911 , test loss : 0.141044\n",
      "epoch = 129 train_loss : 0.140491 , test loss : 0.140591\n",
      "epoch = 157 train_loss : 0.139540 , test loss : 0.140454\n",
      "epoch = 159 train_loss : 0.140505 , test loss : 0.140005\n",
      "epoch = 176 train_loss : 0.139908 , test loss : 0.139832\n",
      "epoch = 306 train_loss : 0.139328 , test loss : 0.139831\n",
      "epoch = 571 train_loss : 0.140712 , test loss : 0.139719\n",
      "epoch = 847 train_loss : 0.140273 , test loss : 0.139411\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.140273,test loss : 0.139411\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.502530 , test loss : 0.480772\n",
      "epoch = 2 train_loss : 0.411426 , test loss : 0.403321\n",
      "epoch = 3 train_loss : 0.374989 , test loss : 0.363853\n",
      "epoch = 4 train_loss : 0.352344 , test loss : 0.343592\n",
      "epoch = 5 train_loss : 0.335348 , test loss : 0.326346\n",
      "epoch = 6 train_loss : 0.321667 , test loss : 0.315105\n",
      "epoch = 7 train_loss : 0.309695 , test loss : 0.303498\n",
      "epoch = 8 train_loss : 0.298985 , test loss : 0.291233\n",
      "epoch = 9 train_loss : 0.288809 , test loss : 0.280951\n",
      "epoch = 10 train_loss : 0.279503 , test loss : 0.273902\n",
      "epoch = 11 train_loss : 0.270688 , test loss : 0.264205\n",
      "epoch = 12 train_loss : 0.262981 , test loss : 0.257368\n",
      "epoch = 13 train_loss : 0.255914 , test loss : 0.248800\n",
      "epoch = 14 train_loss : 0.247556 , test loss : 0.240845\n",
      "epoch = 15 train_loss : 0.240513 , test loss : 0.237254\n",
      "epoch = 16 train_loss : 0.234277 , test loss : 0.229592\n",
      "epoch = 17 train_loss : 0.228296 , test loss : 0.220534\n",
      "epoch = 18 train_loss : 0.222178 , test loss : 0.214813\n",
      "epoch = 19 train_loss : 0.216261 , test loss : 0.212380\n",
      "epoch = 20 train_loss : 0.212372 , test loss : 0.206764\n",
      "epoch = 21 train_loss : 0.206645 , test loss : 0.203741\n",
      "epoch = 22 train_loss : 0.201112 , test loss : 0.195081\n",
      "epoch = 23 train_loss : 0.196605 , test loss : 0.193157\n",
      "epoch = 24 train_loss : 0.192221 , test loss : 0.187624\n",
      "epoch = 25 train_loss : 0.190338 , test loss : 0.187030\n",
      "epoch = 26 train_loss : 0.185442 , test loss : 0.179613\n",
      "epoch = 27 train_loss : 0.182025 , test loss : 0.177169\n",
      "epoch = 28 train_loss : 0.178549 , test loss : 0.174501\n",
      "epoch = 30 train_loss : 0.174215 , test loss : 0.170204\n",
      "epoch = 31 train_loss : 0.170439 , test loss : 0.167308\n",
      "epoch = 32 train_loss : 0.171515 , test loss : 0.166682\n",
      "epoch = 33 train_loss : 0.167147 , test loss : 0.164232\n",
      "epoch = 34 train_loss : 0.165353 , test loss : 0.163192\n",
      "epoch = 35 train_loss : 0.166386 , test loss : 0.161809\n",
      "epoch = 36 train_loss : 0.162469 , test loss : 0.161673\n",
      "epoch = 37 train_loss : 0.161667 , test loss : 0.160837\n",
      "epoch = 38 train_loss : 0.157727 , test loss : 0.155435\n",
      "epoch = 39 train_loss : 0.156879 , test loss : 0.152933\n",
      "epoch = 40 train_loss : 0.155498 , test loss : 0.152925\n",
      "epoch = 42 train_loss : 0.153002 , test loss : 0.152143\n",
      "epoch = 45 train_loss : 0.150255 , test loss : 0.150326\n",
      "epoch = 46 train_loss : 0.149900 , test loss : 0.146737\n",
      "epoch = 49 train_loss : 0.148221 , test loss : 0.146387\n",
      "epoch = 52 train_loss : 0.145881 , test loss : 0.145298\n",
      "epoch = 59 train_loss : 0.144266 , test loss : 0.144784\n",
      "epoch = 63 train_loss : 0.142967 , test loss : 0.144355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 64 train_loss : 0.142514 , test loss : 0.143034\n",
      "epoch = 74 train_loss : 0.142705 , test loss : 0.142481\n",
      "epoch = 75 train_loss : 0.140711 , test loss : 0.142381\n",
      "epoch = 88 train_loss : 0.140849 , test loss : 0.141006\n",
      "epoch = 91 train_loss : 0.140534 , test loss : 0.139904\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.140534,test loss : 0.139904\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.138157,total test loss mean : 0.146397 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],16),nn.Linear(16,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.0005,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T06:56:09.978810Z",
     "start_time": "2021-12-29T06:53:03.206128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.381629 , test loss : 0.399963\n",
      "epoch = 2 train_loss : 0.293572 , test loss : 0.312060\n",
      "epoch = 3 train_loss : 0.261381 , test loss : 0.282909\n",
      "epoch = 4 train_loss : 0.237863 , test loss : 0.260051\n",
      "epoch = 5 train_loss : 0.221804 , test loss : 0.240736\n",
      "epoch = 6 train_loss : 0.207388 , test loss : 0.226529\n",
      "epoch = 7 train_loss : 0.201104 , test loss : 0.221888\n",
      "epoch = 8 train_loss : 0.187545 , test loss : 0.205953\n",
      "epoch = 9 train_loss : 0.179314 , test loss : 0.197147\n",
      "epoch = 10 train_loss : 0.175913 , test loss : 0.189993\n",
      "epoch = 12 train_loss : 0.167336 , test loss : 0.185310\n",
      "epoch = 13 train_loss : 0.159530 , test loss : 0.175348\n",
      "epoch = 14 train_loss : 0.156213 , test loss : 0.170752\n",
      "epoch = 15 train_loss : 0.153288 , test loss : 0.166733\n",
      "epoch = 16 train_loss : 0.151911 , test loss : 0.164389\n",
      "epoch = 18 train_loss : 0.147388 , test loss : 0.159558\n",
      "epoch = 19 train_loss : 0.146350 , test loss : 0.159420\n",
      "epoch = 22 train_loss : 0.149217 , test loss : 0.159242\n",
      "epoch = 23 train_loss : 0.146371 , test loss : 0.157109\n",
      "epoch = 27 train_loss : 0.142368 , test loss : 0.155817\n",
      "epoch = 29 train_loss : 0.141419 , test loss : 0.153098\n",
      "epoch = 30 train_loss : 0.140114 , test loss : 0.152056\n",
      "epoch = 33 train_loss : 0.138962 , test loss : 0.150826\n",
      "epoch = 39 train_loss : 0.138964 , test loss : 0.150812\n",
      "epoch = 42 train_loss : 0.139567 , test loss : 0.150649\n",
      "epoch = 58 train_loss : 0.138480 , test loss : 0.149837\n",
      "epoch = 63 train_loss : 0.138885 , test loss : 0.149149\n",
      "epoch = 90 train_loss : 0.137783 , test loss : 0.148392\n",
      "epoch = 334 train_loss : 0.137025 , test loss : 0.148039\n",
      "epoch = 470 train_loss : 0.136937 , test loss : 0.148016\n",
      "epoch = 519 train_loss : 0.136725 , test loss : 0.148001\n",
      "epoch = 536 train_loss : 0.137219 , test loss : 0.147929\n",
      "epoch = 972 train_loss : 0.136580 , test loss : 0.147884\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.136580,test loss : 0.147884\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.405299 , test loss : 0.466230\n",
      "epoch = 2 train_loss : 0.340223 , test loss : 0.396715\n",
      "epoch = 3 train_loss : 0.291525 , test loss : 0.346468\n",
      "epoch = 4 train_loss : 0.265463 , test loss : 0.321199\n",
      "epoch = 5 train_loss : 0.246682 , test loss : 0.303268\n",
      "epoch = 6 train_loss : 0.230925 , test loss : 0.285337\n",
      "epoch = 7 train_loss : 0.215813 , test loss : 0.267678\n",
      "epoch = 8 train_loss : 0.203798 , test loss : 0.254424\n",
      "epoch = 9 train_loss : 0.195732 , test loss : 0.244741\n",
      "epoch = 10 train_loss : 0.186440 , test loss : 0.234258\n",
      "epoch = 11 train_loss : 0.186108 , test loss : 0.227451\n",
      "epoch = 12 train_loss : 0.176361 , test loss : 0.216925\n",
      "epoch = 13 train_loss : 0.168913 , test loss : 0.212470\n",
      "epoch = 14 train_loss : 0.166522 , test loss : 0.207643\n",
      "epoch = 15 train_loss : 0.161435 , test loss : 0.203901\n",
      "epoch = 16 train_loss : 0.156560 , test loss : 0.196267\n",
      "epoch = 18 train_loss : 0.155022 , test loss : 0.187318\n",
      "epoch = 21 train_loss : 0.147615 , test loss : 0.182454\n",
      "epoch = 22 train_loss : 0.148538 , test loss : 0.180545\n",
      "epoch = 23 train_loss : 0.146285 , test loss : 0.179824\n",
      "epoch = 24 train_loss : 0.145527 , test loss : 0.176799\n",
      "epoch = 25 train_loss : 0.142347 , test loss : 0.173485\n",
      "epoch = 26 train_loss : 0.145132 , test loss : 0.172957\n",
      "epoch = 27 train_loss : 0.141913 , test loss : 0.170541\n",
      "epoch = 29 train_loss : 0.141462 , test loss : 0.168398\n",
      "epoch = 33 train_loss : 0.139792 , test loss : 0.166374\n",
      "epoch = 34 train_loss : 0.139913 , test loss : 0.166070\n",
      "epoch = 35 train_loss : 0.140014 , test loss : 0.162241\n",
      "epoch = 46 train_loss : 0.137512 , test loss : 0.161882\n",
      "epoch = 47 train_loss : 0.136747 , test loss : 0.159532\n",
      "epoch = 70 train_loss : 0.136854 , test loss : 0.159082\n",
      "epoch = 108 train_loss : 0.136004 , test loss : 0.157958\n",
      "epoch = 140 train_loss : 0.136468 , test loss : 0.157827\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.136468,test loss : 0.157827\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.413448 , test loss : 0.388998\n",
      "epoch = 2 train_loss : 0.328863 , test loss : 0.313426\n",
      "epoch = 3 train_loss : 0.287716 , test loss : 0.267641\n",
      "epoch = 4 train_loss : 0.262512 , test loss : 0.248872\n",
      "epoch = 5 train_loss : 0.240911 , test loss : 0.226793\n",
      "epoch = 6 train_loss : 0.227201 , test loss : 0.218545\n",
      "epoch = 7 train_loss : 0.217104 , test loss : 0.207669\n",
      "epoch = 8 train_loss : 0.199465 , test loss : 0.192032\n",
      "epoch = 9 train_loss : 0.191204 , test loss : 0.184602\n",
      "epoch = 10 train_loss : 0.182834 , test loss : 0.176813\n",
      "epoch = 11 train_loss : 0.174256 , test loss : 0.173964\n",
      "epoch = 12 train_loss : 0.171772 , test loss : 0.172609\n",
      "epoch = 13 train_loss : 0.164493 , test loss : 0.165393\n",
      "epoch = 14 train_loss : 0.164225 , test loss : 0.162427\n",
      "epoch = 15 train_loss : 0.160285 , test loss : 0.158258\n",
      "epoch = 18 train_loss : 0.150694 , test loss : 0.153327\n",
      "epoch = 21 train_loss : 0.146541 , test loss : 0.150208\n",
      "epoch = 26 train_loss : 0.142281 , test loss : 0.149501\n",
      "epoch = 30 train_loss : 0.142499 , test loss : 0.148818\n",
      "epoch = 33 train_loss : 0.139623 , test loss : 0.148071\n",
      "epoch = 39 train_loss : 0.139948 , test loss : 0.147778\n",
      "epoch = 160 train_loss : 0.137494 , test loss : 0.147307\n",
      "epoch = 211 train_loss : 0.138482 , test loss : 0.147185\n",
      "epoch = 250 train_loss : 0.137832 , test loss : 0.147184\n",
      "epoch = 310 train_loss : 0.138991 , test loss : 0.147033\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.138991,test loss : 0.147033\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.397581 , test loss : 0.399014\n",
      "epoch = 2 train_loss : 0.325679 , test loss : 0.325460\n",
      "epoch = 3 train_loss : 0.285662 , test loss : 0.289245\n",
      "epoch = 4 train_loss : 0.261975 , test loss : 0.268303\n",
      "epoch = 5 train_loss : 0.241702 , test loss : 0.249571\n",
      "epoch = 6 train_loss : 0.221355 , test loss : 0.229925\n",
      "epoch = 7 train_loss : 0.206709 , test loss : 0.211003\n",
      "epoch = 8 train_loss : 0.196700 , test loss : 0.208316\n",
      "epoch = 9 train_loss : 0.186048 , test loss : 0.192384\n",
      "epoch = 10 train_loss : 0.178818 , test loss : 0.185392\n",
      "epoch = 11 train_loss : 0.172808 , test loss : 0.176525\n",
      "epoch = 12 train_loss : 0.166990 , test loss : 0.172511\n",
      "epoch = 13 train_loss : 0.162237 , test loss : 0.171741\n",
      "epoch = 14 train_loss : 0.157474 , test loss : 0.164053\n",
      "epoch = 15 train_loss : 0.156641 , test loss : 0.160786\n",
      "epoch = 17 train_loss : 0.153024 , test loss : 0.159408\n",
      "epoch = 19 train_loss : 0.149703 , test loss : 0.156888\n",
      "epoch = 20 train_loss : 0.149852 , test loss : 0.155460\n",
      "epoch = 23 train_loss : 0.148570 , test loss : 0.149491\n",
      "epoch = 24 train_loss : 0.145893 , test loss : 0.149340\n",
      "epoch = 29 train_loss : 0.142834 , test loss : 0.149134\n",
      "epoch = 30 train_loss : 0.146570 , test loss : 0.148815\n",
      "epoch = 34 train_loss : 0.145123 , test loss : 0.145689\n",
      "epoch = 36 train_loss : 0.140984 , test loss : 0.142644\n",
      "epoch = 37 train_loss : 0.141802 , test loss : 0.142560\n",
      "epoch = 50 train_loss : 0.140593 , test loss : 0.142220\n",
      "epoch = 58 train_loss : 0.142020 , test loss : 0.142016\n",
      "epoch = 70 train_loss : 0.140941 , test loss : 0.141286\n",
      "epoch = 79 train_loss : 0.141075 , test loss : 0.141237\n",
      "epoch = 122 train_loss : 0.141704 , test loss : 0.140673\n",
      "epoch = 133 train_loss : 0.142227 , test loss : 0.139208\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.142227,test loss : 0.139208\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.452395 , test loss : 0.458837\n",
      "epoch = 2 train_loss : 0.366324 , test loss : 0.343785\n",
      "epoch = 3 train_loss : 0.320331 , test loss : 0.315227\n",
      "epoch = 4 train_loss : 0.289558 , test loss : 0.279279\n",
      "epoch = 5 train_loss : 0.269844 , test loss : 0.260561\n",
      "epoch = 6 train_loss : 0.255504 , test loss : 0.251920\n",
      "epoch = 7 train_loss : 0.240548 , test loss : 0.230533\n",
      "epoch = 8 train_loss : 0.225676 , test loss : 0.219779\n",
      "epoch = 9 train_loss : 0.218097 , test loss : 0.212251\n",
      "epoch = 10 train_loss : 0.204871 , test loss : 0.202157\n",
      "epoch = 11 train_loss : 0.194176 , test loss : 0.186594\n",
      "epoch = 13 train_loss : 0.180412 , test loss : 0.174407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 14 train_loss : 0.175547 , test loss : 0.167802\n",
      "epoch = 16 train_loss : 0.166967 , test loss : 0.162763\n",
      "epoch = 17 train_loss : 0.162563 , test loss : 0.158650\n",
      "epoch = 18 train_loss : 0.157606 , test loss : 0.154868\n",
      "epoch = 19 train_loss : 0.159768 , test loss : 0.151749\n",
      "epoch = 22 train_loss : 0.152614 , test loss : 0.148502\n",
      "epoch = 23 train_loss : 0.149784 , test loss : 0.147605\n",
      "epoch = 26 train_loss : 0.149103 , test loss : 0.147063\n",
      "epoch = 27 train_loss : 0.150687 , test loss : 0.147041\n",
      "epoch = 29 train_loss : 0.145986 , test loss : 0.144530\n",
      "epoch = 44 train_loss : 0.142213 , test loss : 0.141785\n",
      "epoch = 65 train_loss : 0.140175 , test loss : 0.141721\n",
      "epoch = 70 train_loss : 0.140223 , test loss : 0.141248\n",
      "epoch = 73 train_loss : 0.140910 , test loss : 0.141089\n",
      "epoch = 83 train_loss : 0.140804 , test loss : 0.139512\n",
      "epoch = 378 train_loss : 0.140996 , test loss : 0.139362\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.140996,test loss : 0.139362\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.139052,total test loss mean : 0.146263 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],32),nn.Linear(32,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x44,y44,256,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:05:00.556991Z",
     "start_time": "2021-12-28T07:05:00.534989Z"
    }
   },
   "source": [
    "#### set lr = 0.0001 , batch_size = 64 , test loss <=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-31T05:30:20.169743Z",
     "start_time": "2021-12-31T05:30:20.044736Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cea41617a4be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx44\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnet1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx44\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my44\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cea41617a4be>\u001b[0m in \u001b[0;36mget_net\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx44\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnet1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx44\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my44\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],16),nn.ReLU(),nn.Linear(16,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,5000,0.0001,5,x44,y44,64,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T07:04:34.344658Z",
     "start_time": "2021-12-29T07:00:12.549685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.703851 , test loss : 0.723326\n",
      "epoch = 2 train_loss : 0.561331 , test loss : 0.585175\n",
      "epoch = 3 train_loss : 0.492634 , test loss : 0.519692\n",
      "epoch = 4 train_loss : 0.454616 , test loss : 0.483981\n",
      "epoch = 5 train_loss : 0.429250 , test loss : 0.460158\n",
      "epoch = 6 train_loss : 0.409460 , test loss : 0.441180\n",
      "epoch = 7 train_loss : 0.393354 , test loss : 0.425830\n",
      "epoch = 8 train_loss : 0.379418 , test loss : 0.412674\n",
      "epoch = 9 train_loss : 0.367053 , test loss : 0.401016\n",
      "epoch = 10 train_loss : 0.355819 , test loss : 0.390081\n",
      "epoch = 11 train_loss : 0.345574 , test loss : 0.380364\n",
      "epoch = 12 train_loss : 0.336413 , test loss : 0.371739\n",
      "epoch = 13 train_loss : 0.327649 , test loss : 0.362754\n",
      "epoch = 14 train_loss : 0.319542 , test loss : 0.354904\n",
      "epoch = 15 train_loss : 0.311942 , test loss : 0.347495\n",
      "epoch = 16 train_loss : 0.304844 , test loss : 0.340931\n",
      "epoch = 17 train_loss : 0.298329 , test loss : 0.334615\n",
      "epoch = 18 train_loss : 0.292040 , test loss : 0.328828\n",
      "epoch = 19 train_loss : 0.286258 , test loss : 0.323299\n",
      "epoch = 20 train_loss : 0.280959 , test loss : 0.318136\n",
      "epoch = 21 train_loss : 0.275972 , test loss : 0.313222\n",
      "epoch = 22 train_loss : 0.271344 , test loss : 0.308853\n",
      "epoch = 23 train_loss : 0.266869 , test loss : 0.304793\n",
      "epoch = 24 train_loss : 0.262491 , test loss : 0.300259\n",
      "epoch = 25 train_loss : 0.258394 , test loss : 0.296279\n",
      "epoch = 26 train_loss : 0.254417 , test loss : 0.292826\n",
      "epoch = 27 train_loss : 0.250532 , test loss : 0.288868\n",
      "epoch = 28 train_loss : 0.246815 , test loss : 0.285264\n",
      "epoch = 29 train_loss : 0.243348 , test loss : 0.281852\n",
      "epoch = 30 train_loss : 0.239997 , test loss : 0.278616\n",
      "epoch = 31 train_loss : 0.236755 , test loss : 0.275463\n",
      "epoch = 32 train_loss : 0.233638 , test loss : 0.272543\n",
      "epoch = 33 train_loss : 0.230561 , test loss : 0.269201\n",
      "epoch = 34 train_loss : 0.227750 , test loss : 0.266428\n",
      "epoch = 35 train_loss : 0.224956 , test loss : 0.263875\n",
      "epoch = 36 train_loss : 0.222363 , test loss : 0.261243\n",
      "epoch = 37 train_loss : 0.219622 , test loss : 0.258631\n",
      "epoch = 38 train_loss : 0.217082 , test loss : 0.256156\n",
      "epoch = 39 train_loss : 0.214596 , test loss : 0.253452\n",
      "epoch = 40 train_loss : 0.212199 , test loss : 0.251033\n",
      "epoch = 41 train_loss : 0.209796 , test loss : 0.248949\n",
      "epoch = 42 train_loss : 0.207530 , test loss : 0.246487\n",
      "epoch = 43 train_loss : 0.205343 , test loss : 0.244534\n",
      "epoch = 44 train_loss : 0.203227 , test loss : 0.242242\n",
      "epoch = 45 train_loss : 0.201222 , test loss : 0.240174\n",
      "epoch = 46 train_loss : 0.199220 , test loss : 0.238101\n",
      "epoch = 47 train_loss : 0.197273 , test loss : 0.236107\n",
      "epoch = 48 train_loss : 0.195430 , test loss : 0.234202\n",
      "epoch = 49 train_loss : 0.193517 , test loss : 0.232171\n",
      "epoch = 50 train_loss : 0.191695 , test loss : 0.230682\n",
      "epoch = 51 train_loss : 0.189938 , test loss : 0.228850\n",
      "epoch = 52 train_loss : 0.188224 , test loss : 0.227007\n",
      "epoch = 53 train_loss : 0.186678 , test loss : 0.225507\n",
      "epoch = 54 train_loss : 0.184820 , test loss : 0.223560\n",
      "epoch = 55 train_loss : 0.183222 , test loss : 0.222090\n",
      "epoch = 56 train_loss : 0.181611 , test loss : 0.220500\n",
      "epoch = 57 train_loss : 0.180110 , test loss : 0.219211\n",
      "epoch = 58 train_loss : 0.178695 , test loss : 0.217585\n",
      "epoch = 59 train_loss : 0.177210 , test loss : 0.216143\n",
      "epoch = 60 train_loss : 0.175843 , test loss : 0.214910\n",
      "epoch = 61 train_loss : 0.174509 , test loss : 0.213876\n",
      "epoch = 62 train_loss : 0.173184 , test loss : 0.212594\n",
      "epoch = 63 train_loss : 0.171732 , test loss : 0.210720\n",
      "epoch = 64 train_loss : 0.170404 , test loss : 0.209659\n",
      "epoch = 65 train_loss : 0.169294 , test loss : 0.208530\n",
      "epoch = 66 train_loss : 0.167988 , test loss : 0.207363\n",
      "epoch = 67 train_loss : 0.166918 , test loss : 0.206224\n",
      "epoch = 68 train_loss : 0.165622 , test loss : 0.204695\n",
      "epoch = 69 train_loss : 0.164766 , test loss : 0.203584\n",
      "epoch = 70 train_loss : 0.163434 , test loss : 0.202465\n",
      "epoch = 71 train_loss : 0.162406 , test loss : 0.201241\n",
      "epoch = 72 train_loss : 0.161425 , test loss : 0.200291\n",
      "epoch = 73 train_loss : 0.160325 , test loss : 0.199607\n",
      "epoch = 74 train_loss : 0.159481 , test loss : 0.198114\n",
      "epoch = 75 train_loss : 0.158358 , test loss : 0.197487\n",
      "epoch = 76 train_loss : 0.157428 , test loss : 0.196482\n",
      "epoch = 77 train_loss : 0.156507 , test loss : 0.195660\n",
      "epoch = 78 train_loss : 0.155649 , test loss : 0.194427\n",
      "epoch = 79 train_loss : 0.154754 , test loss : 0.193706\n",
      "epoch = 80 train_loss : 0.153875 , test loss : 0.193102\n",
      "epoch = 81 train_loss : 0.153114 , test loss : 0.192111\n",
      "epoch = 82 train_loss : 0.152431 , test loss : 0.191623\n",
      "epoch = 83 train_loss : 0.151508 , test loss : 0.191110\n",
      "epoch = 84 train_loss : 0.150859 , test loss : 0.190451\n",
      "epoch = 85 train_loss : 0.150027 , test loss : 0.189052\n",
      "epoch = 86 train_loss : 0.149250 , test loss : 0.188311\n",
      "epoch = 87 train_loss : 0.148594 , test loss : 0.187939\n",
      "epoch = 88 train_loss : 0.147920 , test loss : 0.186972\n",
      "epoch = 89 train_loss : 0.147618 , test loss : 0.186673\n",
      "epoch = 90 train_loss : 0.146652 , test loss : 0.185556\n",
      "epoch = 91 train_loss : 0.145940 , test loss : 0.185019\n",
      "epoch = 92 train_loss : 0.145363 , test loss : 0.184354\n",
      "epoch = 93 train_loss : 0.144772 , test loss : 0.183802\n",
      "epoch = 94 train_loss : 0.144183 , test loss : 0.183499\n",
      "epoch = 95 train_loss : 0.143750 , test loss : 0.182439\n",
      "epoch = 96 train_loss : 0.142997 , test loss : 0.182066\n",
      "epoch = 97 train_loss : 0.142504 , test loss : 0.181363\n",
      "epoch = 98 train_loss : 0.142132 , test loss : 0.180983\n",
      "epoch = 99 train_loss : 0.141512 , test loss : 0.180379\n",
      "epoch = 100 train_loss : 0.140963 , test loss : 0.180259\n",
      "epoch = 101 train_loss : 0.140674 , test loss : 0.179541\n",
      "epoch = 102 train_loss : 0.139918 , test loss : 0.178970\n",
      "epoch = 104 train_loss : 0.139028 , test loss : 0.178211\n",
      "epoch = 105 train_loss : 0.138629 , test loss : 0.178045\n",
      "epoch = 106 train_loss : 0.138120 , test loss : 0.177295\n",
      "epoch = 107 train_loss : 0.137749 , test loss : 0.177227\n",
      "epoch = 108 train_loss : 0.137365 , test loss : 0.176804\n",
      "epoch = 109 train_loss : 0.136801 , test loss : 0.175882\n",
      "epoch = 110 train_loss : 0.136436 , test loss : 0.175310\n",
      "epoch = 111 train_loss : 0.136036 , test loss : 0.175061\n",
      "epoch = 112 train_loss : 0.135629 , test loss : 0.174784\n",
      "epoch = 113 train_loss : 0.135220 , test loss : 0.174143\n",
      "epoch = 115 train_loss : 0.134431 , test loss : 0.173381\n",
      "epoch = 117 train_loss : 0.133647 , test loss : 0.172619\n",
      "epoch = 119 train_loss : 0.132965 , test loss : 0.171981\n",
      "epoch = 121 train_loss : 0.132253 , test loss : 0.171365\n",
      "epoch = 122 train_loss : 0.131924 , test loss : 0.171015\n",
      "epoch = 125 train_loss : 0.130912 , test loss : 0.170062\n",
      "epoch = 126 train_loss : 0.130601 , test loss : 0.169884\n",
      "epoch = 128 train_loss : 0.130009 , test loss : 0.169748\n",
      "epoch = 130 train_loss : 0.129377 , test loss : 0.169332\n",
      "epoch = 131 train_loss : 0.129254 , test loss : 0.168677\n",
      "epoch = 133 train_loss : 0.128665 , test loss : 0.168512\n",
      "epoch = 134 train_loss : 0.128311 , test loss : 0.167982\n",
      "epoch = 136 train_loss : 0.127786 , test loss : 0.167861\n",
      "epoch = 139 train_loss : 0.127092 , test loss : 0.167470\n",
      "epoch = 140 train_loss : 0.126742 , test loss : 0.167193\n",
      "epoch = 143 train_loss : 0.126268 , test loss : 0.166746\n",
      "epoch = 145 train_loss : 0.125661 , test loss : 0.166418\n",
      "epoch = 146 train_loss : 0.125397 , test loss : 0.166136\n",
      "epoch = 151 train_loss : 0.124315 , test loss : 0.165885\n",
      "epoch = 152 train_loss : 0.124214 , test loss : 0.165641\n",
      "epoch = 154 train_loss : 0.123726 , test loss : 0.165317\n",
      "epoch = 156 train_loss : 0.123350 , test loss : 0.165308\n",
      "epoch = 158 train_loss : 0.123045 , test loss : 0.164762\n",
      "epoch = 160 train_loss : 0.122607 , test loss : 0.164620\n",
      "epoch = 161 train_loss : 0.122955 , test loss : 0.164210\n",
      "epoch = 165 train_loss : 0.121854 , test loss : 0.163967\n",
      "epoch = 167 train_loss : 0.121488 , test loss : 0.163882\n",
      "epoch = 169 train_loss : 0.121197 , test loss : 0.163796\n",
      "epoch = 170 train_loss : 0.120962 , test loss : 0.163671\n",
      "epoch = 175 train_loss : 0.120222 , test loss : 0.163513\n",
      "epoch = 176 train_loss : 0.120186 , test loss : 0.163334\n",
      "epoch = 179 train_loss : 0.119980 , test loss : 0.163310\n",
      "epoch = 183 train_loss : 0.119256 , test loss : 0.162889\n",
      "epoch = 187 train_loss : 0.118714 , test loss : 0.162706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 194 train_loss : 0.117731 , test loss : 0.162437\n",
      "epoch = 197 train_loss : 0.117568 , test loss : 0.161968\n",
      "epoch = 211 train_loss : 0.116103 , test loss : 0.161848\n",
      "epoch = 216 train_loss : 0.115401 , test loss : 0.161605\n",
      "epoch = 218 train_loss : 0.115328 , test loss : 0.161537\n",
      "epoch = 220 train_loss : 0.115236 , test loss : 0.161385\n",
      "epoch = 224 train_loss : 0.114628 , test loss : 0.161285\n",
      "epoch = 227 train_loss : 0.114350 , test loss : 0.161242\n",
      "epoch = 232 train_loss : 0.113871 , test loss : 0.161222\n",
      "epoch = 242 train_loss : 0.113008 , test loss : 0.161131\n",
      "epoch = 245 train_loss : 0.112759 , test loss : 0.161078\n",
      "epoch = 272 train_loss : 0.111313 , test loss : 0.160960\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.111313,test loss : 0.160960\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.630170 , test loss : 0.641322\n",
      "epoch = 2 train_loss : 0.523336 , test loss : 0.542347\n",
      "epoch = 3 train_loss : 0.468554 , test loss : 0.493001\n",
      "epoch = 4 train_loss : 0.435521 , test loss : 0.463704\n",
      "epoch = 5 train_loss : 0.412775 , test loss : 0.443994\n",
      "epoch = 6 train_loss : 0.394898 , test loss : 0.428254\n",
      "epoch = 7 train_loss : 0.380448 , test loss : 0.415180\n",
      "epoch = 8 train_loss : 0.367718 , test loss : 0.404546\n",
      "epoch = 9 train_loss : 0.356242 , test loss : 0.395064\n",
      "epoch = 10 train_loss : 0.345954 , test loss : 0.386104\n",
      "epoch = 11 train_loss : 0.336721 , test loss : 0.378343\n",
      "epoch = 12 train_loss : 0.327981 , test loss : 0.370221\n",
      "epoch = 13 train_loss : 0.320164 , test loss : 0.363833\n",
      "epoch = 14 train_loss : 0.312543 , test loss : 0.357128\n",
      "epoch = 15 train_loss : 0.305409 , test loss : 0.350788\n",
      "epoch = 16 train_loss : 0.298509 , test loss : 0.344561\n",
      "epoch = 17 train_loss : 0.291957 , test loss : 0.339340\n",
      "epoch = 18 train_loss : 0.285802 , test loss : 0.333881\n",
      "epoch = 19 train_loss : 0.279887 , test loss : 0.329064\n",
      "epoch = 20 train_loss : 0.274342 , test loss : 0.324748\n",
      "epoch = 21 train_loss : 0.268941 , test loss : 0.319979\n",
      "epoch = 22 train_loss : 0.263847 , test loss : 0.315405\n",
      "epoch = 23 train_loss : 0.259237 , test loss : 0.311154\n",
      "epoch = 24 train_loss : 0.254518 , test loss : 0.307661\n",
      "epoch = 25 train_loss : 0.250162 , test loss : 0.303851\n",
      "epoch = 26 train_loss : 0.245676 , test loss : 0.299998\n",
      "epoch = 27 train_loss : 0.241666 , test loss : 0.296509\n",
      "epoch = 28 train_loss : 0.237844 , test loss : 0.293537\n",
      "epoch = 29 train_loss : 0.234203 , test loss : 0.289817\n",
      "epoch = 30 train_loss : 0.230390 , test loss : 0.286823\n",
      "epoch = 31 train_loss : 0.227014 , test loss : 0.283478\n",
      "epoch = 32 train_loss : 0.223593 , test loss : 0.280534\n",
      "epoch = 33 train_loss : 0.220403 , test loss : 0.277829\n",
      "epoch = 34 train_loss : 0.217374 , test loss : 0.274774\n",
      "epoch = 35 train_loss : 0.214322 , test loss : 0.271712\n",
      "epoch = 36 train_loss : 0.211602 , test loss : 0.269605\n",
      "epoch = 37 train_loss : 0.208663 , test loss : 0.267275\n",
      "epoch = 38 train_loss : 0.206062 , test loss : 0.263391\n",
      "epoch = 39 train_loss : 0.203478 , test loss : 0.260894\n",
      "epoch = 40 train_loss : 0.200877 , test loss : 0.258845\n",
      "epoch = 41 train_loss : 0.198319 , test loss : 0.256792\n",
      "epoch = 42 train_loss : 0.195986 , test loss : 0.254528\n",
      "epoch = 43 train_loss : 0.193840 , test loss : 0.252496\n",
      "epoch = 44 train_loss : 0.191557 , test loss : 0.249750\n",
      "epoch = 45 train_loss : 0.189486 , test loss : 0.247806\n",
      "epoch = 46 train_loss : 0.187481 , test loss : 0.245991\n",
      "epoch = 47 train_loss : 0.185458 , test loss : 0.243129\n",
      "epoch = 48 train_loss : 0.183464 , test loss : 0.241795\n",
      "epoch = 49 train_loss : 0.181657 , test loss : 0.239807\n",
      "epoch = 50 train_loss : 0.179850 , test loss : 0.238271\n",
      "epoch = 51 train_loss : 0.178140 , test loss : 0.236405\n",
      "epoch = 52 train_loss : 0.176448 , test loss : 0.234487\n",
      "epoch = 53 train_loss : 0.174860 , test loss : 0.233240\n",
      "epoch = 54 train_loss : 0.173264 , test loss : 0.232246\n",
      "epoch = 55 train_loss : 0.171755 , test loss : 0.230635\n",
      "epoch = 56 train_loss : 0.170309 , test loss : 0.228550\n",
      "epoch = 57 train_loss : 0.168931 , test loss : 0.227225\n",
      "epoch = 58 train_loss : 0.167594 , test loss : 0.226277\n",
      "epoch = 59 train_loss : 0.166444 , test loss : 0.225220\n",
      "epoch = 60 train_loss : 0.165088 , test loss : 0.223214\n",
      "epoch = 61 train_loss : 0.163801 , test loss : 0.221774\n",
      "epoch = 62 train_loss : 0.162742 , test loss : 0.220612\n",
      "epoch = 63 train_loss : 0.161471 , test loss : 0.219512\n",
      "epoch = 64 train_loss : 0.160359 , test loss : 0.218104\n",
      "epoch = 65 train_loss : 0.159287 , test loss : 0.217263\n",
      "epoch = 66 train_loss : 0.158239 , test loss : 0.215761\n",
      "epoch = 67 train_loss : 0.157218 , test loss : 0.215177\n",
      "epoch = 68 train_loss : 0.156210 , test loss : 0.213930\n",
      "epoch = 69 train_loss : 0.155359 , test loss : 0.211759\n",
      "epoch = 70 train_loss : 0.154320 , test loss : 0.211395\n",
      "epoch = 71 train_loss : 0.153449 , test loss : 0.210661\n",
      "epoch = 72 train_loss : 0.152657 , test loss : 0.209508\n",
      "epoch = 73 train_loss : 0.151895 , test loss : 0.209069\n",
      "epoch = 74 train_loss : 0.151028 , test loss : 0.206872\n",
      "epoch = 75 train_loss : 0.150075 , test loss : 0.206305\n",
      "epoch = 76 train_loss : 0.149353 , test loss : 0.206221\n",
      "epoch = 77 train_loss : 0.148525 , test loss : 0.204625\n",
      "epoch = 78 train_loss : 0.147790 , test loss : 0.204409\n",
      "epoch = 79 train_loss : 0.147157 , test loss : 0.204073\n",
      "epoch = 80 train_loss : 0.146596 , test loss : 0.202385\n",
      "epoch = 82 train_loss : 0.144993 , test loss : 0.201016\n",
      "epoch = 83 train_loss : 0.144363 , test loss : 0.200148\n",
      "epoch = 85 train_loss : 0.143506 , test loss : 0.199851\n",
      "epoch = 86 train_loss : 0.142549 , test loss : 0.198345\n",
      "epoch = 88 train_loss : 0.141419 , test loss : 0.196765\n",
      "epoch = 89 train_loss : 0.141079 , test loss : 0.196388\n",
      "epoch = 91 train_loss : 0.139853 , test loss : 0.196187\n",
      "epoch = 92 train_loss : 0.139198 , test loss : 0.195148\n",
      "epoch = 93 train_loss : 0.138735 , test loss : 0.193908\n",
      "epoch = 94 train_loss : 0.138342 , test loss : 0.192955\n",
      "epoch = 96 train_loss : 0.137297 , test loss : 0.192546\n",
      "epoch = 97 train_loss : 0.136934 , test loss : 0.192221\n",
      "epoch = 99 train_loss : 0.135895 , test loss : 0.191938\n",
      "epoch = 100 train_loss : 0.135681 , test loss : 0.191483\n",
      "epoch = 101 train_loss : 0.135167 , test loss : 0.191256\n",
      "epoch = 102 train_loss : 0.134553 , test loss : 0.189953\n",
      "epoch = 103 train_loss : 0.134168 , test loss : 0.189605\n",
      "epoch = 105 train_loss : 0.133464 , test loss : 0.188399\n",
      "epoch = 107 train_loss : 0.132600 , test loss : 0.188363\n",
      "epoch = 108 train_loss : 0.132172 , test loss : 0.188033\n",
      "epoch = 109 train_loss : 0.131840 , test loss : 0.186925\n",
      "epoch = 110 train_loss : 0.131381 , test loss : 0.186652\n",
      "epoch = 111 train_loss : 0.131063 , test loss : 0.186432\n",
      "epoch = 112 train_loss : 0.130803 , test loss : 0.185421\n",
      "epoch = 115 train_loss : 0.129846 , test loss : 0.184405\n",
      "epoch = 116 train_loss : 0.129360 , test loss : 0.184015\n",
      "epoch = 117 train_loss : 0.129156 , test loss : 0.183454\n",
      "epoch = 120 train_loss : 0.128139 , test loss : 0.182784\n",
      "epoch = 122 train_loss : 0.127611 , test loss : 0.182300\n",
      "epoch = 124 train_loss : 0.127014 , test loss : 0.181734\n",
      "epoch = 126 train_loss : 0.126479 , test loss : 0.180912\n",
      "epoch = 128 train_loss : 0.126351 , test loss : 0.179939\n",
      "epoch = 131 train_loss : 0.125214 , test loss : 0.179580\n",
      "epoch = 132 train_loss : 0.125107 , test loss : 0.179404\n",
      "epoch = 133 train_loss : 0.124709 , test loss : 0.179372\n",
      "epoch = 134 train_loss : 0.124645 , test loss : 0.178538\n",
      "epoch = 136 train_loss : 0.124395 , test loss : 0.178350\n",
      "epoch = 137 train_loss : 0.124056 , test loss : 0.177986\n",
      "epoch = 140 train_loss : 0.123173 , test loss : 0.177791\n",
      "epoch = 141 train_loss : 0.122938 , test loss : 0.177633\n",
      "epoch = 142 train_loss : 0.122846 , test loss : 0.177607\n",
      "epoch = 143 train_loss : 0.122586 , test loss : 0.176997\n",
      "epoch = 144 train_loss : 0.122567 , test loss : 0.176251\n",
      "epoch = 145 train_loss : 0.122267 , test loss : 0.176196\n",
      "epoch = 150 train_loss : 0.121406 , test loss : 0.175133\n",
      "epoch = 152 train_loss : 0.121083 , test loss : 0.174865\n",
      "epoch = 154 train_loss : 0.120648 , test loss : 0.174824\n",
      "epoch = 156 train_loss : 0.120419 , test loss : 0.174500\n",
      "epoch = 160 train_loss : 0.119678 , test loss : 0.173894\n",
      "epoch = 167 train_loss : 0.118557 , test loss : 0.173703\n",
      "epoch = 168 train_loss : 0.119282 , test loss : 0.173236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 172 train_loss : 0.117997 , test loss : 0.172827\n",
      "epoch = 174 train_loss : 0.117630 , test loss : 0.172819\n",
      "epoch = 181 train_loss : 0.116951 , test loss : 0.172752\n",
      "epoch = 182 train_loss : 0.116715 , test loss : 0.172351\n",
      "epoch = 184 train_loss : 0.117295 , test loss : 0.172228\n",
      "epoch = 185 train_loss : 0.116256 , test loss : 0.172043\n",
      "epoch = 186 train_loss : 0.116300 , test loss : 0.171440\n",
      "epoch = 194 train_loss : 0.115404 , test loss : 0.170744\n",
      "epoch = 211 train_loss : 0.113645 , test loss : 0.170540\n",
      "epoch = 213 train_loss : 0.113665 , test loss : 0.170418\n",
      "epoch = 219 train_loss : 0.113181 , test loss : 0.169849\n",
      "epoch = 235 train_loss : 0.111848 , test loss : 0.169648\n",
      "epoch = 270 train_loss : 0.109707 , test loss : 0.169623\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.109707,test loss : 0.169623\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.846754 , test loss : 0.858632\n",
      "epoch = 2 train_loss : 0.733749 , test loss : 0.745467\n",
      "epoch = 3 train_loss : 0.639501 , test loss : 0.649520\n",
      "epoch = 4 train_loss : 0.569314 , test loss : 0.576006\n",
      "epoch = 5 train_loss : 0.520318 , test loss : 0.522567\n",
      "epoch = 6 train_loss : 0.486856 , test loss : 0.484024\n",
      "epoch = 7 train_loss : 0.461672 , test loss : 0.453829\n",
      "epoch = 8 train_loss : 0.443087 , test loss : 0.430827\n",
      "epoch = 9 train_loss : 0.427535 , test loss : 0.411739\n",
      "epoch = 10 train_loss : 0.415090 , test loss : 0.396425\n",
      "epoch = 11 train_loss : 0.404465 , test loss : 0.383788\n",
      "epoch = 12 train_loss : 0.395296 , test loss : 0.373343\n",
      "epoch = 13 train_loss : 0.387236 , test loss : 0.364341\n",
      "epoch = 14 train_loss : 0.379226 , test loss : 0.355372\n",
      "epoch = 15 train_loss : 0.372164 , test loss : 0.348162\n",
      "epoch = 16 train_loss : 0.365639 , test loss : 0.341809\n",
      "epoch = 17 train_loss : 0.359550 , test loss : 0.335748\n",
      "epoch = 18 train_loss : 0.353694 , test loss : 0.330571\n",
      "epoch = 19 train_loss : 0.348039 , test loss : 0.325063\n",
      "epoch = 20 train_loss : 0.342587 , test loss : 0.319952\n",
      "epoch = 21 train_loss : 0.337470 , test loss : 0.315211\n",
      "epoch = 22 train_loss : 0.332404 , test loss : 0.310592\n",
      "epoch = 23 train_loss : 0.327591 , test loss : 0.306334\n",
      "epoch = 24 train_loss : 0.322905 , test loss : 0.301901\n",
      "epoch = 25 train_loss : 0.318324 , test loss : 0.297789\n",
      "epoch = 26 train_loss : 0.313836 , test loss : 0.293541\n",
      "epoch = 27 train_loss : 0.309513 , test loss : 0.290314\n",
      "epoch = 28 train_loss : 0.305238 , test loss : 0.286228\n",
      "epoch = 29 train_loss : 0.301175 , test loss : 0.283131\n",
      "epoch = 30 train_loss : 0.297178 , test loss : 0.279605\n",
      "epoch = 31 train_loss : 0.293455 , test loss : 0.276658\n",
      "epoch = 32 train_loss : 0.289721 , test loss : 0.273428\n",
      "epoch = 33 train_loss : 0.286062 , test loss : 0.270144\n",
      "epoch = 34 train_loss : 0.282537 , test loss : 0.267286\n",
      "epoch = 35 train_loss : 0.279016 , test loss : 0.263983\n",
      "epoch = 36 train_loss : 0.275773 , test loss : 0.261377\n",
      "epoch = 37 train_loss : 0.272399 , test loss : 0.258948\n",
      "epoch = 38 train_loss : 0.269057 , test loss : 0.255958\n",
      "epoch = 39 train_loss : 0.265807 , test loss : 0.253117\n",
      "epoch = 40 train_loss : 0.262566 , test loss : 0.250778\n",
      "epoch = 41 train_loss : 0.259502 , test loss : 0.248109\n",
      "epoch = 42 train_loss : 0.256441 , test loss : 0.245891\n",
      "epoch = 43 train_loss : 0.253396 , test loss : 0.243634\n",
      "epoch = 44 train_loss : 0.250448 , test loss : 0.241425\n",
      "epoch = 45 train_loss : 0.247573 , test loss : 0.239307\n",
      "epoch = 46 train_loss : 0.244753 , test loss : 0.237216\n",
      "epoch = 47 train_loss : 0.242055 , test loss : 0.234887\n",
      "epoch = 48 train_loss : 0.239478 , test loss : 0.233441\n",
      "epoch = 49 train_loss : 0.236820 , test loss : 0.231214\n",
      "epoch = 50 train_loss : 0.234421 , test loss : 0.228965\n",
      "epoch = 51 train_loss : 0.231784 , test loss : 0.227311\n",
      "epoch = 52 train_loss : 0.229262 , test loss : 0.225833\n",
      "epoch = 53 train_loss : 0.226889 , test loss : 0.224127\n",
      "epoch = 54 train_loss : 0.224575 , test loss : 0.222804\n",
      "epoch = 55 train_loss : 0.222271 , test loss : 0.220656\n",
      "epoch = 56 train_loss : 0.220077 , test loss : 0.219653\n",
      "epoch = 57 train_loss : 0.217830 , test loss : 0.217817\n",
      "epoch = 58 train_loss : 0.215724 , test loss : 0.216490\n",
      "epoch = 59 train_loss : 0.213807 , test loss : 0.215578\n",
      "epoch = 60 train_loss : 0.211603 , test loss : 0.213247\n",
      "epoch = 61 train_loss : 0.209625 , test loss : 0.211775\n",
      "epoch = 62 train_loss : 0.207762 , test loss : 0.210140\n",
      "epoch = 63 train_loss : 0.205851 , test loss : 0.209131\n",
      "epoch = 64 train_loss : 0.203961 , test loss : 0.207787\n",
      "epoch = 65 train_loss : 0.202196 , test loss : 0.206756\n",
      "epoch = 66 train_loss : 0.200425 , test loss : 0.205480\n",
      "epoch = 67 train_loss : 0.198914 , test loss : 0.204107\n",
      "epoch = 68 train_loss : 0.196982 , test loss : 0.203262\n",
      "epoch = 69 train_loss : 0.195329 , test loss : 0.201941\n",
      "epoch = 70 train_loss : 0.193571 , test loss : 0.200591\n",
      "epoch = 71 train_loss : 0.192067 , test loss : 0.199459\n",
      "epoch = 72 train_loss : 0.190443 , test loss : 0.198920\n",
      "epoch = 73 train_loss : 0.188797 , test loss : 0.197320\n",
      "epoch = 74 train_loss : 0.187315 , test loss : 0.196374\n",
      "epoch = 75 train_loss : 0.185860 , test loss : 0.194972\n",
      "epoch = 76 train_loss : 0.184252 , test loss : 0.194062\n",
      "epoch = 77 train_loss : 0.182798 , test loss : 0.193046\n",
      "epoch = 78 train_loss : 0.181407 , test loss : 0.192439\n",
      "epoch = 79 train_loss : 0.180081 , test loss : 0.191398\n",
      "epoch = 80 train_loss : 0.178727 , test loss : 0.190136\n",
      "epoch = 81 train_loss : 0.177439 , test loss : 0.189984\n",
      "epoch = 82 train_loss : 0.176086 , test loss : 0.188212\n",
      "epoch = 83 train_loss : 0.174843 , test loss : 0.187814\n",
      "epoch = 84 train_loss : 0.173567 , test loss : 0.186560\n",
      "epoch = 85 train_loss : 0.172467 , test loss : 0.186168\n",
      "epoch = 86 train_loss : 0.171476 , test loss : 0.186121\n",
      "epoch = 87 train_loss : 0.170118 , test loss : 0.184212\n",
      "epoch = 88 train_loss : 0.169041 , test loss : 0.183671\n",
      "epoch = 89 train_loss : 0.167953 , test loss : 0.182715\n",
      "epoch = 90 train_loss : 0.166994 , test loss : 0.182337\n",
      "epoch = 91 train_loss : 0.165823 , test loss : 0.181802\n",
      "epoch = 92 train_loss : 0.164838 , test loss : 0.180325\n",
      "epoch = 94 train_loss : 0.162928 , test loss : 0.179443\n",
      "epoch = 95 train_loss : 0.162002 , test loss : 0.178566\n",
      "epoch = 96 train_loss : 0.161055 , test loss : 0.178266\n",
      "epoch = 97 train_loss : 0.160174 , test loss : 0.177645\n",
      "epoch = 98 train_loss : 0.159341 , test loss : 0.177300\n",
      "epoch = 99 train_loss : 0.158436 , test loss : 0.176193\n",
      "epoch = 100 train_loss : 0.157583 , test loss : 0.175559\n",
      "epoch = 101 train_loss : 0.156812 , test loss : 0.175405\n",
      "epoch = 103 train_loss : 0.155210 , test loss : 0.174102\n",
      "epoch = 105 train_loss : 0.153660 , test loss : 0.173196\n",
      "epoch = 106 train_loss : 0.152899 , test loss : 0.172801\n",
      "epoch = 107 train_loss : 0.152167 , test loss : 0.172125\n",
      "epoch = 108 train_loss : 0.151459 , test loss : 0.171824\n",
      "epoch = 109 train_loss : 0.150756 , test loss : 0.171389\n",
      "epoch = 110 train_loss : 0.150114 , test loss : 0.170885\n",
      "epoch = 111 train_loss : 0.149432 , test loss : 0.170440\n",
      "epoch = 112 train_loss : 0.148745 , test loss : 0.170243\n",
      "epoch = 113 train_loss : 0.148232 , test loss : 0.170048\n",
      "epoch = 115 train_loss : 0.147005 , test loss : 0.168684\n",
      "epoch = 116 train_loss : 0.146293 , test loss : 0.168610\n",
      "epoch = 117 train_loss : 0.145698 , test loss : 0.168119\n",
      "epoch = 118 train_loss : 0.145241 , test loss : 0.167905\n",
      "epoch = 119 train_loss : 0.144547 , test loss : 0.167511\n",
      "epoch = 121 train_loss : 0.143440 , test loss : 0.167220\n",
      "epoch = 123 train_loss : 0.142322 , test loss : 0.166618\n",
      "epoch = 124 train_loss : 0.141777 , test loss : 0.166456\n",
      "epoch = 126 train_loss : 0.140784 , test loss : 0.165972\n",
      "epoch = 127 train_loss : 0.140301 , test loss : 0.165696\n",
      "epoch = 128 train_loss : 0.139878 , test loss : 0.165260\n",
      "epoch = 129 train_loss : 0.139380 , test loss : 0.165049\n",
      "epoch = 131 train_loss : 0.138480 , test loss : 0.164865\n",
      "epoch = 132 train_loss : 0.138118 , test loss : 0.164328\n",
      "epoch = 133 train_loss : 0.137629 , test loss : 0.164206\n",
      "epoch = 134 train_loss : 0.137246 , test loss : 0.163697\n",
      "epoch = 135 train_loss : 0.136831 , test loss : 0.163608\n",
      "epoch = 137 train_loss : 0.135965 , test loss : 0.163595\n",
      "epoch = 139 train_loss : 0.135228 , test loss : 0.163041\n",
      "epoch = 140 train_loss : 0.134857 , test loss : 0.163004\n",
      "epoch = 142 train_loss : 0.134049 , test loss : 0.162551\n",
      "epoch = 143 train_loss : 0.133669 , test loss : 0.162512\n",
      "epoch = 144 train_loss : 0.133330 , test loss : 0.162453\n",
      "epoch = 146 train_loss : 0.132590 , test loss : 0.162045\n",
      "epoch = 147 train_loss : 0.132381 , test loss : 0.162038\n",
      "epoch = 148 train_loss : 0.131989 , test loss : 0.161893\n",
      "epoch = 149 train_loss : 0.131601 , test loss : 0.161414\n",
      "epoch = 151 train_loss : 0.131002 , test loss : 0.161107\n",
      "epoch = 152 train_loss : 0.130663 , test loss : 0.160944\n",
      "epoch = 154 train_loss : 0.130073 , test loss : 0.160933\n",
      "epoch = 155 train_loss : 0.129781 , test loss : 0.160507\n",
      "epoch = 159 train_loss : 0.128650 , test loss : 0.160163\n",
      "epoch = 162 train_loss : 0.127967 , test loss : 0.160125\n",
      "epoch = 163 train_loss : 0.127570 , test loss : 0.159851\n",
      "epoch = 164 train_loss : 0.127346 , test loss : 0.159665\n",
      "epoch = 166 train_loss : 0.127006 , test loss : 0.159170\n",
      "epoch = 173 train_loss : 0.125247 , test loss : 0.159020\n",
      "epoch = 177 train_loss : 0.124438 , test loss : 0.158881\n",
      "epoch = 186 train_loss : 0.122662 , test loss : 0.158874\n",
      "epoch = 187 train_loss : 0.122561 , test loss : 0.158775\n",
      "epoch = 188 train_loss : 0.122493 , test loss : 0.158638\n",
      "epoch = 189 train_loss : 0.122289 , test loss : 0.158465\n",
      "epoch = 190 train_loss : 0.122047 , test loss : 0.158346\n",
      "epoch = 194 train_loss : 0.121349 , test loss : 0.158280\n",
      "epoch = 203 train_loss : 0.119991 , test loss : 0.157930\n",
      "epoch = 218 train_loss : 0.117987 , test loss : 0.157926\n",
      "epoch = 219 train_loss : 0.117905 , test loss : 0.157803\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.117905,test loss : 0.157803\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.717966 , test loss : 0.688274\n",
      "epoch = 2 train_loss : 0.584517 , test loss : 0.559378\n",
      "epoch = 3 train_loss : 0.512192 , test loss : 0.492005\n",
      "epoch = 4 train_loss : 0.467697 , test loss : 0.449717\n",
      "epoch = 5 train_loss : 0.438204 , test loss : 0.421020\n",
      "epoch = 6 train_loss : 0.415634 , test loss : 0.399061\n",
      "epoch = 7 train_loss : 0.397822 , test loss : 0.382137\n",
      "epoch = 8 train_loss : 0.383133 , test loss : 0.368415\n",
      "epoch = 9 train_loss : 0.370371 , test loss : 0.356898\n",
      "epoch = 10 train_loss : 0.358797 , test loss : 0.346597\n",
      "epoch = 11 train_loss : 0.348383 , test loss : 0.337464\n",
      "epoch = 12 train_loss : 0.339016 , test loss : 0.329865\n",
      "epoch = 13 train_loss : 0.330068 , test loss : 0.322575\n",
      "epoch = 14 train_loss : 0.321947 , test loss : 0.316028\n",
      "epoch = 15 train_loss : 0.314427 , test loss : 0.309922\n",
      "epoch = 16 train_loss : 0.307239 , test loss : 0.304360\n",
      "epoch = 17 train_loss : 0.300688 , test loss : 0.299252\n",
      "epoch = 18 train_loss : 0.294515 , test loss : 0.294577\n",
      "epoch = 19 train_loss : 0.288534 , test loss : 0.289728\n",
      "epoch = 20 train_loss : 0.283187 , test loss : 0.285616\n",
      "epoch = 21 train_loss : 0.278156 , test loss : 0.281444\n",
      "epoch = 22 train_loss : 0.273319 , test loss : 0.277630\n",
      "epoch = 23 train_loss : 0.268758 , test loss : 0.274286\n",
      "epoch = 24 train_loss : 0.264392 , test loss : 0.270581\n",
      "epoch = 25 train_loss : 0.260132 , test loss : 0.267174\n",
      "epoch = 26 train_loss : 0.256026 , test loss : 0.263800\n",
      "epoch = 27 train_loss : 0.252147 , test loss : 0.260653\n",
      "epoch = 28 train_loss : 0.248419 , test loss : 0.257612\n",
      "epoch = 29 train_loss : 0.244810 , test loss : 0.254665\n",
      "epoch = 30 train_loss : 0.241559 , test loss : 0.252262\n",
      "epoch = 31 train_loss : 0.238153 , test loss : 0.249253\n",
      "epoch = 32 train_loss : 0.234836 , test loss : 0.246536\n",
      "epoch = 33 train_loss : 0.231717 , test loss : 0.243585\n",
      "epoch = 34 train_loss : 0.228948 , test loss : 0.242053\n",
      "epoch = 35 train_loss : 0.225911 , test loss : 0.239013\n",
      "epoch = 36 train_loss : 0.223012 , test loss : 0.236937\n",
      "epoch = 37 train_loss : 0.220238 , test loss : 0.234705\n",
      "epoch = 38 train_loss : 0.217663 , test loss : 0.232556\n",
      "epoch = 39 train_loss : 0.215041 , test loss : 0.230465\n",
      "epoch = 40 train_loss : 0.212598 , test loss : 0.228677\n",
      "epoch = 41 train_loss : 0.210225 , test loss : 0.226536\n",
      "epoch = 42 train_loss : 0.207945 , test loss : 0.224768\n",
      "epoch = 43 train_loss : 0.205534 , test loss : 0.222799\n",
      "epoch = 44 train_loss : 0.203260 , test loss : 0.220805\n",
      "epoch = 45 train_loss : 0.201081 , test loss : 0.219022\n",
      "epoch = 46 train_loss : 0.199007 , test loss : 0.217295\n",
      "epoch = 47 train_loss : 0.196967 , test loss : 0.215739\n",
      "epoch = 48 train_loss : 0.195135 , test loss : 0.214030\n",
      "epoch = 49 train_loss : 0.192976 , test loss : 0.212642\n",
      "epoch = 50 train_loss : 0.191061 , test loss : 0.211428\n",
      "epoch = 51 train_loss : 0.189261 , test loss : 0.209941\n",
      "epoch = 52 train_loss : 0.187419 , test loss : 0.208049\n",
      "epoch = 53 train_loss : 0.185691 , test loss : 0.207202\n",
      "epoch = 54 train_loss : 0.183968 , test loss : 0.205484\n",
      "epoch = 55 train_loss : 0.182392 , test loss : 0.204258\n",
      "epoch = 56 train_loss : 0.180880 , test loss : 0.202699\n",
      "epoch = 57 train_loss : 0.179369 , test loss : 0.201741\n",
      "epoch = 58 train_loss : 0.177817 , test loss : 0.199847\n",
      "epoch = 59 train_loss : 0.176685 , test loss : 0.199667\n",
      "epoch = 60 train_loss : 0.174991 , test loss : 0.198365\n",
      "epoch = 61 train_loss : 0.173600 , test loss : 0.197002\n",
      "epoch = 62 train_loss : 0.172329 , test loss : 0.196108\n",
      "epoch = 63 train_loss : 0.170981 , test loss : 0.195230\n",
      "epoch = 64 train_loss : 0.169769 , test loss : 0.194440\n",
      "epoch = 65 train_loss : 0.168501 , test loss : 0.193271\n",
      "epoch = 66 train_loss : 0.167363 , test loss : 0.192574\n",
      "epoch = 67 train_loss : 0.166268 , test loss : 0.191454\n",
      "epoch = 68 train_loss : 0.165161 , test loss : 0.190771\n",
      "epoch = 69 train_loss : 0.164085 , test loss : 0.189900\n",
      "epoch = 70 train_loss : 0.162978 , test loss : 0.188975\n",
      "epoch = 71 train_loss : 0.162030 , test loss : 0.188634\n",
      "epoch = 72 train_loss : 0.160966 , test loss : 0.187828\n",
      "epoch = 73 train_loss : 0.160064 , test loss : 0.186796\n",
      "epoch = 74 train_loss : 0.159179 , test loss : 0.186777\n",
      "epoch = 75 train_loss : 0.158038 , test loss : 0.185586\n",
      "epoch = 76 train_loss : 0.157221 , test loss : 0.184925\n",
      "epoch = 77 train_loss : 0.156376 , test loss : 0.184466\n",
      "epoch = 78 train_loss : 0.155448 , test loss : 0.183889\n",
      "epoch = 79 train_loss : 0.154993 , test loss : 0.182717\n",
      "epoch = 80 train_loss : 0.153693 , test loss : 0.182458\n",
      "epoch = 81 train_loss : 0.152961 , test loss : 0.182116\n",
      "epoch = 82 train_loss : 0.152317 , test loss : 0.181374\n",
      "epoch = 83 train_loss : 0.151462 , test loss : 0.180181\n",
      "epoch = 85 train_loss : 0.150051 , test loss : 0.179759\n",
      "epoch = 86 train_loss : 0.149299 , test loss : 0.179524\n",
      "epoch = 87 train_loss : 0.148571 , test loss : 0.178734\n",
      "epoch = 88 train_loss : 0.147949 , test loss : 0.178411\n",
      "epoch = 90 train_loss : 0.146588 , test loss : 0.177079\n",
      "epoch = 92 train_loss : 0.145612 , test loss : 0.176421\n",
      "epoch = 94 train_loss : 0.144235 , test loss : 0.175408\n",
      "epoch = 96 train_loss : 0.143238 , test loss : 0.174198\n",
      "epoch = 98 train_loss : 0.142217 , test loss : 0.173273\n",
      "epoch = 100 train_loss : 0.140966 , test loss : 0.172799\n",
      "epoch = 102 train_loss : 0.139960 , test loss : 0.172068\n",
      "epoch = 104 train_loss : 0.139079 , test loss : 0.172008\n",
      "epoch = 105 train_loss : 0.138596 , test loss : 0.171614\n",
      "epoch = 106 train_loss : 0.138172 , test loss : 0.170727\n",
      "epoch = 108 train_loss : 0.137649 , test loss : 0.170427\n",
      "epoch = 110 train_loss : 0.136763 , test loss : 0.169811\n",
      "epoch = 111 train_loss : 0.136158 , test loss : 0.169673\n",
      "epoch = 112 train_loss : 0.135854 , test loss : 0.169290\n",
      "epoch = 114 train_loss : 0.135269 , test loss : 0.168954\n",
      "epoch = 115 train_loss : 0.134700 , test loss : 0.168447\n",
      "epoch = 117 train_loss : 0.133971 , test loss : 0.168345\n",
      "epoch = 118 train_loss : 0.133607 , test loss : 0.168187\n",
      "epoch = 120 train_loss : 0.133462 , test loss : 0.167222\n",
      "epoch = 122 train_loss : 0.132392 , test loss : 0.166676\n",
      "epoch = 123 train_loss : 0.132126 , test loss : 0.166620\n",
      "epoch = 125 train_loss : 0.131580 , test loss : 0.166532\n",
      "epoch = 126 train_loss : 0.131279 , test loss : 0.166313\n",
      "epoch = 127 train_loss : 0.130838 , test loss : 0.166006\n",
      "epoch = 128 train_loss : 0.130892 , test loss : 0.165918\n",
      "epoch = 130 train_loss : 0.130064 , test loss : 0.165661\n",
      "epoch = 131 train_loss : 0.129686 , test loss : 0.165167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 135 train_loss : 0.128916 , test loss : 0.165151\n",
      "epoch = 136 train_loss : 0.128497 , test loss : 0.164958\n",
      "epoch = 137 train_loss : 0.128157 , test loss : 0.164678\n",
      "epoch = 139 train_loss : 0.127695 , test loss : 0.163780\n",
      "epoch = 140 train_loss : 0.127509 , test loss : 0.163505\n",
      "epoch = 141 train_loss : 0.127251 , test loss : 0.163357\n",
      "epoch = 145 train_loss : 0.126415 , test loss : 0.163124\n",
      "epoch = 146 train_loss : 0.126099 , test loss : 0.163027\n",
      "epoch = 148 train_loss : 0.125832 , test loss : 0.162584\n",
      "epoch = 149 train_loss : 0.125787 , test loss : 0.162564\n",
      "epoch = 150 train_loss : 0.125745 , test loss : 0.162313\n",
      "epoch = 154 train_loss : 0.124483 , test loss : 0.161981\n",
      "epoch = 155 train_loss : 0.124475 , test loss : 0.161489\n",
      "epoch = 158 train_loss : 0.124135 , test loss : 0.161389\n",
      "epoch = 168 train_loss : 0.122041 , test loss : 0.161278\n",
      "epoch = 170 train_loss : 0.121886 , test loss : 0.161270\n",
      "epoch = 171 train_loss : 0.121670 , test loss : 0.160916\n",
      "epoch = 172 train_loss : 0.121543 , test loss : 0.160575\n",
      "epoch = 178 train_loss : 0.120576 , test loss : 0.160354\n",
      "epoch = 182 train_loss : 0.120070 , test loss : 0.160215\n",
      "epoch = 191 train_loss : 0.118753 , test loss : 0.160057\n",
      "epoch = 197 train_loss : 0.118301 , test loss : 0.159923\n",
      "epoch = 204 train_loss : 0.117359 , test loss : 0.159765\n",
      "epoch = 220 train_loss : 0.115704 , test loss : 0.159389\n",
      "epoch = 232 train_loss : 0.114775 , test loss : 0.159315\n",
      "epoch = 242 train_loss : 0.114160 , test loss : 0.159310\n",
      "epoch = 284 train_loss : 0.111101 , test loss : 0.159269\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.111101,test loss : 0.159269\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.841372 , test loss : 0.786004\n",
      "epoch = 2 train_loss : 0.658155 , test loss : 0.607908\n",
      "epoch = 3 train_loss : 0.565964 , test loss : 0.521886\n",
      "epoch = 4 train_loss : 0.511629 , test loss : 0.474230\n",
      "epoch = 5 train_loss : 0.475533 , test loss : 0.444290\n",
      "epoch = 6 train_loss : 0.449563 , test loss : 0.423449\n",
      "epoch = 7 train_loss : 0.431114 , test loss : 0.408771\n",
      "epoch = 8 train_loss : 0.416406 , test loss : 0.396520\n",
      "epoch = 9 train_loss : 0.403801 , test loss : 0.385454\n",
      "epoch = 10 train_loss : 0.392648 , test loss : 0.376067\n",
      "epoch = 11 train_loss : 0.382625 , test loss : 0.366928\n",
      "epoch = 12 train_loss : 0.373280 , test loss : 0.358353\n",
      "epoch = 13 train_loss : 0.364500 , test loss : 0.350425\n",
      "epoch = 14 train_loss : 0.355934 , test loss : 0.342292\n",
      "epoch = 15 train_loss : 0.347716 , test loss : 0.334762\n",
      "epoch = 16 train_loss : 0.340009 , test loss : 0.327633\n",
      "epoch = 17 train_loss : 0.332428 , test loss : 0.320746\n",
      "epoch = 18 train_loss : 0.325393 , test loss : 0.314170\n",
      "epoch = 19 train_loss : 0.318296 , test loss : 0.307985\n",
      "epoch = 20 train_loss : 0.311556 , test loss : 0.302361\n",
      "epoch = 21 train_loss : 0.305285 , test loss : 0.297201\n",
      "epoch = 22 train_loss : 0.299394 , test loss : 0.292299\n",
      "epoch = 23 train_loss : 0.293752 , test loss : 0.287347\n",
      "epoch = 24 train_loss : 0.288397 , test loss : 0.282882\n",
      "epoch = 25 train_loss : 0.283448 , test loss : 0.279260\n",
      "epoch = 26 train_loss : 0.278660 , test loss : 0.274794\n",
      "epoch = 27 train_loss : 0.274266 , test loss : 0.271010\n",
      "epoch = 28 train_loss : 0.269788 , test loss : 0.267568\n",
      "epoch = 29 train_loss : 0.265639 , test loss : 0.263944\n",
      "epoch = 30 train_loss : 0.261835 , test loss : 0.260415\n",
      "epoch = 31 train_loss : 0.257862 , test loss : 0.257526\n",
      "epoch = 32 train_loss : 0.254274 , test loss : 0.254746\n",
      "epoch = 33 train_loss : 0.250540 , test loss : 0.251399\n",
      "epoch = 34 train_loss : 0.247115 , test loss : 0.248515\n",
      "epoch = 35 train_loss : 0.244008 , test loss : 0.245871\n",
      "epoch = 36 train_loss : 0.240475 , test loss : 0.243189\n",
      "epoch = 37 train_loss : 0.237389 , test loss : 0.240693\n",
      "epoch = 38 train_loss : 0.234395 , test loss : 0.238484\n",
      "epoch = 39 train_loss : 0.231429 , test loss : 0.236112\n",
      "epoch = 40 train_loss : 0.228537 , test loss : 0.233616\n",
      "epoch = 41 train_loss : 0.225824 , test loss : 0.231485\n",
      "epoch = 42 train_loss : 0.223274 , test loss : 0.229702\n",
      "epoch = 43 train_loss : 0.220591 , test loss : 0.227346\n",
      "epoch = 44 train_loss : 0.218101 , test loss : 0.225334\n",
      "epoch = 45 train_loss : 0.215603 , test loss : 0.223585\n",
      "epoch = 46 train_loss : 0.213228 , test loss : 0.221239\n",
      "epoch = 47 train_loss : 0.210942 , test loss : 0.219120\n",
      "epoch = 48 train_loss : 0.208693 , test loss : 0.217757\n",
      "epoch = 49 train_loss : 0.206529 , test loss : 0.215951\n",
      "epoch = 50 train_loss : 0.204382 , test loss : 0.214138\n",
      "epoch = 51 train_loss : 0.202260 , test loss : 0.212416\n",
      "epoch = 52 train_loss : 0.200229 , test loss : 0.210932\n",
      "epoch = 53 train_loss : 0.198261 , test loss : 0.209267\n",
      "epoch = 54 train_loss : 0.196402 , test loss : 0.207647\n",
      "epoch = 55 train_loss : 0.194530 , test loss : 0.206549\n",
      "epoch = 56 train_loss : 0.192728 , test loss : 0.204793\n",
      "epoch = 57 train_loss : 0.191004 , test loss : 0.203635\n",
      "epoch = 58 train_loss : 0.189305 , test loss : 0.202176\n",
      "epoch = 59 train_loss : 0.187763 , test loss : 0.200956\n",
      "epoch = 60 train_loss : 0.186058 , test loss : 0.199437\n",
      "epoch = 61 train_loss : 0.184817 , test loss : 0.199298\n",
      "epoch = 62 train_loss : 0.183093 , test loss : 0.197099\n",
      "epoch = 63 train_loss : 0.181498 , test loss : 0.195918\n",
      "epoch = 64 train_loss : 0.180333 , test loss : 0.194875\n",
      "epoch = 65 train_loss : 0.178663 , test loss : 0.194036\n",
      "epoch = 66 train_loss : 0.177313 , test loss : 0.193134\n",
      "epoch = 67 train_loss : 0.175925 , test loss : 0.191284\n",
      "epoch = 68 train_loss : 0.174668 , test loss : 0.190297\n",
      "epoch = 69 train_loss : 0.173355 , test loss : 0.189659\n",
      "epoch = 70 train_loss : 0.172215 , test loss : 0.188469\n",
      "epoch = 71 train_loss : 0.170836 , test loss : 0.187301\n",
      "epoch = 72 train_loss : 0.169627 , test loss : 0.186291\n",
      "epoch = 74 train_loss : 0.167558 , test loss : 0.184969\n",
      "epoch = 75 train_loss : 0.166469 , test loss : 0.183874\n",
      "epoch = 76 train_loss : 0.165117 , test loss : 0.183275\n",
      "epoch = 77 train_loss : 0.164088 , test loss : 0.181665\n",
      "epoch = 78 train_loss : 0.163061 , test loss : 0.181518\n",
      "epoch = 79 train_loss : 0.161972 , test loss : 0.180668\n",
      "epoch = 80 train_loss : 0.161061 , test loss : 0.179864\n",
      "epoch = 81 train_loss : 0.160035 , test loss : 0.178658\n",
      "epoch = 82 train_loss : 0.159094 , test loss : 0.178039\n",
      "epoch = 83 train_loss : 0.158196 , test loss : 0.177168\n",
      "epoch = 84 train_loss : 0.157392 , test loss : 0.176668\n",
      "epoch = 85 train_loss : 0.156392 , test loss : 0.175711\n",
      "epoch = 86 train_loss : 0.155639 , test loss : 0.175103\n",
      "epoch = 87 train_loss : 0.154734 , test loss : 0.174837\n",
      "epoch = 88 train_loss : 0.153830 , test loss : 0.174028\n",
      "epoch = 89 train_loss : 0.153174 , test loss : 0.173653\n",
      "epoch = 90 train_loss : 0.152596 , test loss : 0.173164\n",
      "epoch = 91 train_loss : 0.151709 , test loss : 0.172109\n",
      "epoch = 92 train_loss : 0.150779 , test loss : 0.171733\n",
      "epoch = 93 train_loss : 0.150024 , test loss : 0.171097\n",
      "epoch = 94 train_loss : 0.149365 , test loss : 0.170353\n",
      "epoch = 95 train_loss : 0.148629 , test loss : 0.170200\n",
      "epoch = 96 train_loss : 0.148131 , test loss : 0.169788\n",
      "epoch = 97 train_loss : 0.147698 , test loss : 0.169351\n",
      "epoch = 98 train_loss : 0.146634 , test loss : 0.168139\n",
      "epoch = 99 train_loss : 0.145988 , test loss : 0.167857\n",
      "epoch = 101 train_loss : 0.144887 , test loss : 0.167819\n",
      "epoch = 102 train_loss : 0.144259 , test loss : 0.167251\n",
      "epoch = 103 train_loss : 0.143772 , test loss : 0.166306\n",
      "epoch = 104 train_loss : 0.143029 , test loss : 0.166087\n",
      "epoch = 105 train_loss : 0.142475 , test loss : 0.165744\n",
      "epoch = 106 train_loss : 0.141987 , test loss : 0.165457\n",
      "epoch = 107 train_loss : 0.141382 , test loss : 0.164757\n",
      "epoch = 109 train_loss : 0.140349 , test loss : 0.164636\n",
      "epoch = 110 train_loss : 0.139929 , test loss : 0.163941\n",
      "epoch = 112 train_loss : 0.138979 , test loss : 0.163404\n",
      "epoch = 113 train_loss : 0.138404 , test loss : 0.163244\n",
      "epoch = 114 train_loss : 0.137912 , test loss : 0.163006\n",
      "epoch = 115 train_loss : 0.137471 , test loss : 0.162700\n",
      "epoch = 116 train_loss : 0.137216 , test loss : 0.162575\n",
      "epoch = 117 train_loss : 0.136606 , test loss : 0.162529\n",
      "epoch = 118 train_loss : 0.136263 , test loss : 0.162169\n",
      "epoch = 120 train_loss : 0.135501 , test loss : 0.162001\n",
      "epoch = 121 train_loss : 0.135124 , test loss : 0.161694\n",
      "epoch = 122 train_loss : 0.134698 , test loss : 0.161269\n",
      "epoch = 123 train_loss : 0.134302 , test loss : 0.161229\n",
      "epoch = 124 train_loss : 0.133910 , test loss : 0.160825\n",
      "epoch = 126 train_loss : 0.133208 , test loss : 0.160482\n",
      "epoch = 128 train_loss : 0.132529 , test loss : 0.160385\n",
      "epoch = 129 train_loss : 0.132239 , test loss : 0.160047\n",
      "epoch = 130 train_loss : 0.131765 , test loss : 0.159411\n",
      "epoch = 133 train_loss : 0.130776 , test loss : 0.159378\n",
      "epoch = 134 train_loss : 0.130498 , test loss : 0.159164\n",
      "epoch = 135 train_loss : 0.130298 , test loss : 0.158759\n",
      "epoch = 137 train_loss : 0.129770 , test loss : 0.158475\n",
      "epoch = 139 train_loss : 0.129033 , test loss : 0.158359\n",
      "epoch = 140 train_loss : 0.128901 , test loss : 0.158010\n",
      "epoch = 145 train_loss : 0.127688 , test loss : 0.157730\n",
      "epoch = 148 train_loss : 0.126830 , test loss : 0.157322\n",
      "epoch = 149 train_loss : 0.126496 , test loss : 0.157250\n",
      "epoch = 154 train_loss : 0.125512 , test loss : 0.157169\n",
      "epoch = 156 train_loss : 0.125002 , test loss : 0.156679\n",
      "epoch = 163 train_loss : 0.123704 , test loss : 0.156576\n",
      "epoch = 169 train_loss : 0.122748 , test loss : 0.156387\n",
      "epoch = 179 train_loss : 0.121148 , test loss : 0.156383\n",
      "epoch = 182 train_loss : 0.120397 , test loss : 0.156209\n",
      "epoch = 189 train_loss : 0.119613 , test loss : 0.156079\n",
      "epoch = 222 train_loss : 0.115879 , test loss : 0.156049\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.115879,test loss : 0.156049\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.113181,total test loss mean : 0.160741 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],8),nn.ReLU(),nn.Linear(8,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,5000,0.0001,5,x44,y44,64,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear function  test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:10:09.977821Z",
     "start_time": "2021-12-30T02:10:09.963820Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_cv(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x4)\n",
    "    rmse=np.sqrt(-cross_val_score(model,x4,y4,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:10:11.536910Z",
     "start_time": "2021-12-30T02:10:10.584856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.3851 (0.0225)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.0005,random_state=1))\n",
    "score=rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:10:13.454020Z",
     "start_time": "2021-12-30T02:10:12.347957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " enet score: 0.3851 (0.0225)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enet=make_pipeline(RobustScaler(),ElasticNet(alpha=0.0005,l1_ratio=0.9))\n",
    "scoreo=rmsle_cv(enet)\n",
    "print(\"\\n enet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:10:13.799040Z",
     "start_time": "2021-12-30T02:10:13.461020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ridge score: 0.3876 (0.0225)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge=make_pipeline(RobustScaler(),Ridge(alpha=0.5))\n",
    "score=rmsle_cv(ridge)\n",
    "print(\"\\n ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:10:20.282410Z",
     "start_time": "2021-12-30T02:10:20.100400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ridge score: 0.3876 (0.0224)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge=make_pipeline(Ridge(alpha=0.5))\n",
    "score=rmsle_cv(ridge)\n",
    "print(\"\\n ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:11:39.432937Z",
     "start_time": "2021-12-30T02:10:21.971507Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.4412 (0.0296)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000,\n",
    "                                   learning_rate=0.05,\n",
    "                                   max_depth=4,\n",
    "                                   max_features='sqrt',\n",
    "                                   min_samples_leaf=15,\n",
    "                                   min_samples_split=10,\n",
    "                                   loss='huber',\n",
    "                                   random_state=5)\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:12:22.931425Z",
     "start_time": "2021-12-30T02:11:39.434938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:11:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:12:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:12:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Xgboost score: 0.4146 (0.0227)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:12:50.820021Z",
     "start_time": "2021-12-30T02:12:49.420941Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 0.4184 (0.0266)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-24T09:33:30.208720Z",
     "start_time": "2021-12-24T09:33:28.560626Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x4_cxv=pd.DataFrame(x4.reshape(-1,9))\n",
    "# x4_cxv.to_csv(r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\wx_x_cxv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:16.613496Z",
     "start_time": "2021-12-30T02:13:16.604495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79645675, -0.60553382, -1.27240954, -1.8175533 , -1.8175533 ,\n",
       "       -0.90134018,  0.3641883 ,  1.00139281,  1.48322449, -0.25412602])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-5,81:91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:17.163527Z",
     "start_time": "2021-12-30T02:13:17.153527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.60553382, -1.27240954, -1.8175533 , -1.8175533 , -0.90134018,\n",
       "        0.3641883 ,  1.00139281,  1.48322449,  1.00139281, -0.25412602])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-4,81:91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:17.621554Z",
     "start_time": "2021-12-30T02:13:17.614553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.27240954, -1.8175533 , -1.8175533 , -0.90134018,  0.3641883 ,\n",
       "        1.00139281,  1.48322449,  1.00139281,  0.57751679, -0.25412602])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[-3,81:91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:18.119582Z",
     "start_time": "2021-12-30T02:13:18.112582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00139281],\n",
       "       [ 0.57751679],\n",
       "       [-0.06379855],\n",
       "       [ 0.3641883 ],\n",
       "       [ 0.6281137 ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:13:19.200644Z",
     "start_time": "2021-12-30T02:13:19.148641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "      <td>5.760000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.019875e-13</td>\n",
       "      <td>-5.144712e-14</td>\n",
       "      <td>6.653925e-14</td>\n",
       "      <td>2.549689e-14</td>\n",
       "      <td>2.334629e-15</td>\n",
       "      <td>-6.727368e-14</td>\n",
       "      <td>-4.221841e-14</td>\n",
       "      <td>2.062856e-15</td>\n",
       "      <td>5.215490e-14</td>\n",
       "      <td>1.772519e-14</td>\n",
       "      <td>-1.659610e-15</td>\n",
       "      <td>6.245795e-14</td>\n",
       "      <td>-9.682569e-15</td>\n",
       "      <td>-1.537578e-14</td>\n",
       "      <td>1.616595e-14</td>\n",
       "      <td>-8.086471e-15</td>\n",
       "      <td>3.354384e-14</td>\n",
       "      <td>3.181464e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.255345e+00</td>\n",
       "      <td>-5.306764e+00</td>\n",
       "      <td>-2.846587e+00</td>\n",
       "      <td>-2.447008e+00</td>\n",
       "      <td>-3.818917e+00</td>\n",
       "      <td>-4.363104e+00</td>\n",
       "      <td>-3.808196e+00</td>\n",
       "      <td>-3.063532e+00</td>\n",
       "      <td>-2.833784e+00</td>\n",
       "      <td>-2.112201e+00</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-2.286725e+00</td>\n",
       "      <td>-3.466795e+00</td>\n",
       "      <td>-7.641412e+00</td>\n",
       "      <td>-3.527271e+00</td>\n",
       "      <td>-3.868786e+00</td>\n",
       "      <td>-3.965265e+00</td>\n",
       "      <td>-2.782619e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.027755e-01</td>\n",
       "      <td>-1.199461e+00</td>\n",
       "      <td>-6.693840e-01</td>\n",
       "      <td>-7.516859e-01</td>\n",
       "      <td>-6.222681e-01</td>\n",
       "      <td>-6.602794e-01</td>\n",
       "      <td>-6.587790e-01</td>\n",
       "      <td>-6.921282e-01</td>\n",
       "      <td>-6.450364e-01</td>\n",
       "      <td>-6.981957e-01</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>-8.022974e-01</td>\n",
       "      <td>-6.567335e-01</td>\n",
       "      <td>-8.957229e-01</td>\n",
       "      <td>-8.471015e-01</td>\n",
       "      <td>-8.284860e-01</td>\n",
       "      <td>-7.175293e-01</td>\n",
       "      <td>-7.554874e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.868283e-03</td>\n",
       "      <td>-1.540203e-01</td>\n",
       "      <td>5.390355e-02</td>\n",
       "      <td>-8.905258e-02</td>\n",
       "      <td>2.767230e-03</td>\n",
       "      <td>-2.466757e-02</td>\n",
       "      <td>-6.652185e-02</td>\n",
       "      <td>9.398760e-03</td>\n",
       "      <td>-1.337080e-02</td>\n",
       "      <td>2.696880e-03</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.566150e-03</td>\n",
       "      <td>-5.175865e-02</td>\n",
       "      <td>-2.955772e-01</td>\n",
       "      <td>-1.955858e-01</td>\n",
       "      <td>-1.918681e-01</td>\n",
       "      <td>-1.644871e-02</td>\n",
       "      <td>1.601343e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.085792e-01</td>\n",
       "      <td>1.103605e+00</td>\n",
       "      <td>6.987095e-01</td>\n",
       "      <td>7.299705e-01</td>\n",
       "      <td>5.875442e-01</td>\n",
       "      <td>7.024097e-01</td>\n",
       "      <td>6.728357e-01</td>\n",
       "      <td>6.640201e-01</td>\n",
       "      <td>6.670347e-01</td>\n",
       "      <td>6.777326e-01</td>\n",
       "      <td>-2.541260e-01</td>\n",
       "      <td>8.107297e-01</td>\n",
       "      <td>6.329803e-01</td>\n",
       "      <td>3.274645e-01</td>\n",
       "      <td>7.160547e-01</td>\n",
       "      <td>7.535070e-01</td>\n",
       "      <td>7.077023e-01</td>\n",
       "      <td>7.440291e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.465256e+00</td>\n",
       "      <td>4.391621e+00</td>\n",
       "      <td>2.890982e+00</td>\n",
       "      <td>2.483615e+00</td>\n",
       "      <td>2.956513e+00</td>\n",
       "      <td>3.042810e+00</td>\n",
       "      <td>3.154037e+00</td>\n",
       "      <td>5.440292e+00</td>\n",
       "      <td>3.461476e+00</td>\n",
       "      <td>3.285175e+00</td>\n",
       "      <td>4.321989e+00</td>\n",
       "      <td>2.443003e+00</td>\n",
       "      <td>3.760984e+00</td>\n",
       "      <td>8.702351e+00</td>\n",
       "      <td>1.710428e+00</td>\n",
       "      <td>1.698787e+00</td>\n",
       "      <td>3.054866e+00</td>\n",
       "      <td>2.753135e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean   1.019875e-13 -5.144712e-14  6.653925e-14  2.549689e-14  2.334629e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.255345e+00 -5.306764e+00 -2.846587e+00 -2.447008e+00 -3.818917e+00   \n",
       "25%   -8.027755e-01 -1.199461e+00 -6.693840e-01 -7.516859e-01 -6.222681e-01   \n",
       "50%    3.868283e-03 -1.540203e-01  5.390355e-02 -8.905258e-02  2.767230e-03   \n",
       "75%    7.085792e-01  1.103605e+00  6.987095e-01  7.299705e-01  5.875442e-01   \n",
       "max    2.465256e+00  4.391621e+00  2.890982e+00  2.483615e+00  2.956513e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean  -6.727368e-14 -4.221841e-14  2.062856e-15  5.215490e-14  1.772519e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -4.363104e+00 -3.808196e+00 -3.063532e+00 -2.833784e+00 -2.112201e+00   \n",
       "25%   -6.602794e-01 -6.587790e-01 -6.921282e-01 -6.450364e-01 -6.981957e-01   \n",
       "50%   -2.466757e-02 -6.652185e-02  9.398760e-03 -1.337080e-02  2.696880e-03   \n",
       "75%    7.024097e-01  6.728357e-01  6.640201e-01  6.670347e-01  6.777326e-01   \n",
       "max    3.042810e+00  3.154037e+00  5.440292e+00  3.461476e+00  3.285175e+00   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03  5.760000e+03   \n",
       "mean  -1.659610e-15  6.245795e-14 -9.682569e-15 -1.537578e-14  1.616595e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.541260e-01 -2.286725e+00 -3.466795e+00 -7.641412e+00 -3.527271e+00   \n",
       "25%   -2.541260e-01 -8.022974e-01 -6.567335e-01 -8.957229e-01 -8.471015e-01   \n",
       "50%   -2.541260e-01  8.566150e-03 -5.175865e-02 -2.955772e-01 -1.955858e-01   \n",
       "75%   -2.541260e-01  8.107297e-01  6.329803e-01  3.274645e-01  7.160547e-01   \n",
       "max    4.321989e+00  2.443003e+00  3.760984e+00  8.702351e+00  1.710428e+00   \n",
       "\n",
       "                 15            16            17  \n",
       "count  5.760000e+03  5.760000e+03  5.760000e+03  \n",
       "mean  -8.086471e-15  3.354384e-14  3.181464e-15  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -3.868786e+00 -3.965265e+00 -2.782619e+00  \n",
       "25%   -8.284860e-01 -7.175293e-01 -7.554874e-01  \n",
       "50%   -1.918681e-01 -1.644871e-02  1.601343e-02  \n",
       "75%    7.535070e-01  7.077023e-01  7.440291e-01  \n",
       "max    1.698787e+00  3.054866e+00  2.753135e+00  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:02.102098Z",
     "start_time": "2021-12-30T02:14:02.093097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4681776384963"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 0.6281137*2.725299+5.756380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:02.665130Z",
     "start_time": "2021-12-30T02:14:02.661130Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import inv_boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:03.244163Z",
     "start_time": "2021-12-30T02:14:03.236163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.999999855599405"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox1p(7.4681776384963,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:04.158215Z",
     "start_time": "2021-12-30T02:14:04.148215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5825098754835505"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.06379855*2.725299+5.756380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:06.111327Z",
     "start_time": "2021-12-30T02:14:06.099326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.000000800694327"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox1p(5.5825098754835505,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:07.613413Z",
     "start_time": "2021-12-30T02:14:07.603412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1444"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.38*0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:18.224020Z",
     "start_time": "2021-12-30T02:14:18.204019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4521\n"
     ]
    }
   ],
   "source": [
    "x4_len=x4.shape[0]\n",
    "print(int(0.8*x4_len))\n",
    "x4_train=x4[:int(0.8*x4_len),:]\n",
    "y4_train=y4[:int(0.8*x4_len),:]\n",
    "x4_test=x4[int(0.8*x4_len):,:]\n",
    "y4_test=y4[int(0.8*x4_len):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:18.774051Z",
     "start_time": "2021-12-30T02:14:18.765051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 162)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:19.264079Z",
     "start_time": "2021-12-30T02:14:19.258079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:20.237135Z",
     "start_time": "2021-12-30T02:14:19.946118Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso=Lasso(alpha=0.0005,random_state=1)\n",
    "lasso.fit(x4_train,y4_train)\n",
    "y4_hat=lasso.predict(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:20.996178Z",
     "start_time": "2021-12-30T02:14:20.988178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14616487, 0.81584775, 0.2574312 , 0.04508735, 0.34347021])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_hat[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:21.481206Z",
     "start_time": "2021-12-30T02:14:21.475206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00139281],\n",
       "       [ 0.57751679],\n",
       "       [-0.06379855],\n",
       "       [ 0.3641883 ],\n",
       "       [ 0.6281137 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_test[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:22.110242Z",
     "start_time": "2021-12-30T02:14:22.099241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.87925650986765"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.04508735*2.725299+5.756380\n",
    "\n",
    "inv_boxcox1p(5.87925650986765,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:14:25.437432Z",
     "start_time": "2021-12-30T02:14:25.433432Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:19:58.933358Z",
     "start_time": "2021-12-29T09:19:58.924358Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_cv_predict(model):\n",
    "    kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x4_train)\n",
    "    rmse=np.sqrt(-cross_val_predict(model,x4_train,y4_train,scoring='neg_mean_squared_error',cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:21:58.324336Z",
     "start_time": "2021-12-30T02:21:58.012318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39542851])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso=Lasso(alpha=0.0005,random_state=1)\n",
    "lasso.fit(x4_train,y4_train)\n",
    "y4_hat=lasso.predict(x4_test).reshape(-1,1)\n",
    "np.sqrt(np.sum(np.power(y4_hat-y4_test,2),axis=0)/y4_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:27:27.145144Z",
     "start_time": "2021-12-30T02:27:27.126142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.51428678])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4_hat_orig=y4_hat*2.725299+5.756380\n",
    "y4_test_orig=y4_test*2.725299+5.756380\n",
    "y4_hat_orig=inv_boxcox1p(y4_hat_orig,0.4145678510523434)\n",
    "y4_test_orig=inv_boxcox1p(y4_test_orig,0.4145678510523434)\n",
    "np.sqrt(np.sum(np.power(y4_hat_orig-y4_test_orig,2),axis=0)/y4_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-30T02:43:46.807177Z",
     "start_time": "2021-12-30T02:43:46.797176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3909286462303396"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox1p(1.05,0.4145678510523434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:37:28.812408Z",
     "start_time": "2021-12-29T09:37:28.656399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge=Ridge(alpha=0.5)\n",
    "ridge.fit(x4_train,y4_train)\n",
    "y_hat=ridge.predict(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:37:41.302122Z",
     "start_time": "2021-12-29T09:37:41.294122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16289152],\n",
       "       [0.78155887],\n",
       "       [0.25523402],\n",
       "       [0.07791427],\n",
       "       [0.35014741]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:52:27.554813Z",
     "start_time": "2021-12-29T09:52:27.537812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x44_train=torch.Tensor(x4_train)\n",
    "y44_train=torch.Tensor(y4_train)\n",
    "x44_test=torch.Tensor(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:52:29.186906Z",
     "start_time": "2021-12-29T09:52:29.136904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold_pred(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd,test_features):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    preds=net(test_features).detach().numpy()\n",
    "    print('pred :\\n', preds[-5:])\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T09:57:40.688723Z",
     "start_time": "2021-12-29T09:52:37.955408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.974191 , test loss : 0.991456\n",
      "epoch = 2 train_loss : 0.741834 , test loss : 0.757175\n",
      "epoch = 3 train_loss : 0.601612 , test loss : 0.618431\n",
      "epoch = 4 train_loss : 0.526269 , test loss : 0.546513\n",
      "epoch = 5 train_loss : 0.484943 , test loss : 0.508254\n",
      "epoch = 6 train_loss : 0.456718 , test loss : 0.482930\n",
      "epoch = 7 train_loss : 0.434904 , test loss : 0.463773\n",
      "epoch = 8 train_loss : 0.417073 , test loss : 0.447909\n",
      "epoch = 9 train_loss : 0.401582 , test loss : 0.433991\n",
      "epoch = 10 train_loss : 0.387928 , test loss : 0.421180\n",
      "epoch = 11 train_loss : 0.376064 , test loss : 0.409798\n",
      "epoch = 12 train_loss : 0.365388 , test loss : 0.399940\n",
      "epoch = 13 train_loss : 0.355818 , test loss : 0.390764\n",
      "epoch = 14 train_loss : 0.346839 , test loss : 0.382016\n",
      "epoch = 15 train_loss : 0.338422 , test loss : 0.373656\n",
      "epoch = 16 train_loss : 0.330679 , test loss : 0.366201\n",
      "epoch = 17 train_loss : 0.323433 , test loss : 0.359235\n",
      "epoch = 18 train_loss : 0.316660 , test loss : 0.352880\n",
      "epoch = 19 train_loss : 0.310033 , test loss : 0.346734\n",
      "epoch = 20 train_loss : 0.303927 , test loss : 0.340848\n",
      "epoch = 21 train_loss : 0.297967 , test loss : 0.335151\n",
      "epoch = 22 train_loss : 0.292399 , test loss : 0.329497\n",
      "epoch = 23 train_loss : 0.286885 , test loss : 0.324540\n",
      "epoch = 24 train_loss : 0.281678 , test loss : 0.319288\n",
      "epoch = 25 train_loss : 0.276744 , test loss : 0.314681\n",
      "epoch = 26 train_loss : 0.271906 , test loss : 0.309983\n",
      "epoch = 27 train_loss : 0.267282 , test loss : 0.305389\n",
      "epoch = 28 train_loss : 0.262815 , test loss : 0.301027\n",
      "epoch = 29 train_loss : 0.258399 , test loss : 0.296615\n",
      "epoch = 30 train_loss : 0.254181 , test loss : 0.292465\n",
      "epoch = 31 train_loss : 0.249947 , test loss : 0.288378\n",
      "epoch = 32 train_loss : 0.246053 , test loss : 0.284895\n",
      "epoch = 33 train_loss : 0.242065 , test loss : 0.280817\n",
      "epoch = 34 train_loss : 0.238323 , test loss : 0.277058\n",
      "epoch = 35 train_loss : 0.234833 , test loss : 0.273443\n",
      "epoch = 36 train_loss : 0.231370 , test loss : 0.269999\n",
      "epoch = 37 train_loss : 0.227820 , test loss : 0.266658\n",
      "epoch = 38 train_loss : 0.224514 , test loss : 0.263339\n",
      "epoch = 39 train_loss : 0.221381 , test loss : 0.259840\n",
      "epoch = 40 train_loss : 0.218319 , test loss : 0.256822\n",
      "epoch = 41 train_loss : 0.215339 , test loss : 0.253966\n",
      "epoch = 42 train_loss : 0.212285 , test loss : 0.250863\n",
      "epoch = 43 train_loss : 0.209421 , test loss : 0.247899\n",
      "epoch = 44 train_loss : 0.206692 , test loss : 0.245298\n",
      "epoch = 45 train_loss : 0.204186 , test loss : 0.242565\n",
      "epoch = 46 train_loss : 0.201724 , test loss : 0.240088\n",
      "epoch = 47 train_loss : 0.199198 , test loss : 0.237672\n",
      "epoch = 48 train_loss : 0.196972 , test loss : 0.235029\n",
      "epoch = 49 train_loss : 0.194721 , test loss : 0.232793\n",
      "epoch = 50 train_loss : 0.192571 , test loss : 0.230813\n",
      "epoch = 51 train_loss : 0.190481 , test loss : 0.228488\n",
      "epoch = 52 train_loss : 0.188513 , test loss : 0.226509\n",
      "epoch = 53 train_loss : 0.186500 , test loss : 0.224612\n",
      "epoch = 54 train_loss : 0.184655 , test loss : 0.222812\n",
      "epoch = 55 train_loss : 0.182736 , test loss : 0.220610\n",
      "epoch = 56 train_loss : 0.181004 , test loss : 0.219083\n",
      "epoch = 57 train_loss : 0.179196 , test loss : 0.217022\n",
      "epoch = 58 train_loss : 0.177692 , test loss : 0.215164\n",
      "epoch = 59 train_loss : 0.176148 , test loss : 0.213946\n",
      "epoch = 60 train_loss : 0.174379 , test loss : 0.212040\n",
      "epoch = 61 train_loss : 0.172854 , test loss : 0.210500\n",
      "epoch = 62 train_loss : 0.171455 , test loss : 0.208963\n",
      "epoch = 63 train_loss : 0.170030 , test loss : 0.207974\n",
      "epoch = 64 train_loss : 0.168624 , test loss : 0.206187\n",
      "epoch = 65 train_loss : 0.167228 , test loss : 0.204762\n",
      "epoch = 66 train_loss : 0.166019 , test loss : 0.203583\n",
      "epoch = 67 train_loss : 0.164644 , test loss : 0.202302\n",
      "epoch = 68 train_loss : 0.163524 , test loss : 0.200794\n",
      "epoch = 69 train_loss : 0.162281 , test loss : 0.199852\n",
      "epoch = 70 train_loss : 0.161408 , test loss : 0.198209\n",
      "epoch = 71 train_loss : 0.160270 , test loss : 0.198172\n",
      "epoch = 72 train_loss : 0.159398 , test loss : 0.196293\n",
      "epoch = 73 train_loss : 0.158136 , test loss : 0.195570\n",
      "epoch = 74 train_loss : 0.157132 , test loss : 0.194273\n",
      "epoch = 75 train_loss : 0.155804 , test loss : 0.193161\n",
      "epoch = 76 train_loss : 0.154862 , test loss : 0.192204\n",
      "epoch = 77 train_loss : 0.153869 , test loss : 0.191184\n",
      "epoch = 78 train_loss : 0.152999 , test loss : 0.190291\n",
      "epoch = 79 train_loss : 0.152056 , test loss : 0.189614\n",
      "epoch = 80 train_loss : 0.151104 , test loss : 0.188552\n",
      "epoch = 81 train_loss : 0.150329 , test loss : 0.187881\n",
      "epoch = 82 train_loss : 0.149421 , test loss : 0.186787\n",
      "epoch = 83 train_loss : 0.148604 , test loss : 0.185932\n",
      "epoch = 84 train_loss : 0.147796 , test loss : 0.185429\n",
      "epoch = 85 train_loss : 0.147371 , test loss : 0.184554\n",
      "epoch = 86 train_loss : 0.146549 , test loss : 0.183929\n",
      "epoch = 87 train_loss : 0.145626 , test loss : 0.183323\n",
      "epoch = 88 train_loss : 0.144868 , test loss : 0.182527\n",
      "epoch = 89 train_loss : 0.144131 , test loss : 0.181867\n",
      "epoch = 91 train_loss : 0.142890 , test loss : 0.180839\n",
      "epoch = 92 train_loss : 0.142418 , test loss : 0.180370\n",
      "epoch = 94 train_loss : 0.141026 , test loss : 0.179450\n",
      "epoch = 95 train_loss : 0.140431 , test loss : 0.178630\n",
      "epoch = 96 train_loss : 0.139779 , test loss : 0.178187\n",
      "epoch = 98 train_loss : 0.138844 , test loss : 0.177374\n",
      "epoch = 99 train_loss : 0.138313 , test loss : 0.176994\n",
      "epoch = 100 train_loss : 0.137664 , test loss : 0.176498\n",
      "epoch = 101 train_loss : 0.137234 , test loss : 0.176068\n",
      "epoch = 102 train_loss : 0.136632 , test loss : 0.175473\n",
      "epoch = 103 train_loss : 0.136132 , test loss : 0.175195\n",
      "epoch = 104 train_loss : 0.135734 , test loss : 0.174936\n",
      "epoch = 105 train_loss : 0.135386 , test loss : 0.174194\n",
      "epoch = 107 train_loss : 0.134300 , test loss : 0.173860\n",
      "epoch = 108 train_loss : 0.133866 , test loss : 0.173593\n",
      "epoch = 109 train_loss : 0.133405 , test loss : 0.173067\n",
      "epoch = 110 train_loss : 0.133035 , test loss : 0.173060\n",
      "epoch = 111 train_loss : 0.132646 , test loss : 0.172833\n",
      "epoch = 112 train_loss : 0.132402 , test loss : 0.172267\n",
      "epoch = 113 train_loss : 0.131734 , test loss : 0.171859\n",
      "epoch = 116 train_loss : 0.130680 , test loss : 0.171281\n",
      "epoch = 118 train_loss : 0.129926 , test loss : 0.170648\n",
      "epoch = 120 train_loss : 0.129238 , test loss : 0.169971\n",
      "epoch = 121 train_loss : 0.128997 , test loss : 0.169786\n",
      "epoch = 122 train_loss : 0.128844 , test loss : 0.169761\n",
      "epoch = 124 train_loss : 0.127943 , test loss : 0.169355\n",
      "epoch = 125 train_loss : 0.127773 , test loss : 0.168844\n",
      "epoch = 126 train_loss : 0.127380 , test loss : 0.168588\n",
      "epoch = 127 train_loss : 0.127190 , test loss : 0.168460\n",
      "epoch = 129 train_loss : 0.126559 , test loss : 0.167892\n",
      "epoch = 130 train_loss : 0.126498 , test loss : 0.167823\n",
      "epoch = 131 train_loss : 0.125967 , test loss : 0.167599\n",
      "epoch = 134 train_loss : 0.125068 , test loss : 0.167527\n",
      "epoch = 137 train_loss : 0.124270 , test loss : 0.167130\n",
      "epoch = 140 train_loss : 0.123578 , test loss : 0.166824\n",
      "epoch = 142 train_loss : 0.123050 , test loss : 0.166598\n",
      "epoch = 144 train_loss : 0.122881 , test loss : 0.166262\n",
      "epoch = 146 train_loss : 0.122448 , test loss : 0.165993\n",
      "epoch = 148 train_loss : 0.121904 , test loss : 0.165624\n",
      "epoch = 153 train_loss : 0.120611 , test loss : 0.165417\n",
      "epoch = 154 train_loss : 0.120501 , test loss : 0.165328\n",
      "epoch = 155 train_loss : 0.120550 , test loss : 0.164811\n",
      "epoch = 161 train_loss : 0.119324 , test loss : 0.164385\n",
      "epoch = 162 train_loss : 0.119113 , test loss : 0.164303\n",
      "epoch = 165 train_loss : 0.118803 , test loss : 0.164034\n",
      "epoch = 172 train_loss : 0.117515 , test loss : 0.163601\n",
      "epoch = 182 train_loss : 0.116310 , test loss : 0.163468\n",
      "epoch = 186 train_loss : 0.115626 , test loss : 0.163413\n",
      "epoch = 189 train_loss : 0.115277 , test loss : 0.163191\n",
      "epoch = 190 train_loss : 0.115505 , test loss : 0.163025\n",
      "epoch = 195 train_loss : 0.114742 , test loss : 0.162958\n",
      "epoch = 202 train_loss : 0.114389 , test loss : 0.162894\n",
      "epoch = 207 train_loss : 0.113531 , test loss : 0.162795\n",
      "epoch = 210 train_loss : 0.113296 , test loss : 0.162738\n",
      "epoch = 213 train_loss : 0.112877 , test loss : 0.162706\n",
      "epoch = 229 train_loss : 0.112205 , test loss : 0.162703\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.112205,test loss : 0.162703\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.940339 , test loss : 1.001383\n",
      "epoch = 2 train_loss : 0.710311 , test loss : 0.767712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3 train_loss : 0.583636 , test loss : 0.643681\n",
      "epoch = 4 train_loss : 0.513431 , test loss : 0.575133\n",
      "epoch = 5 train_loss : 0.473913 , test loss : 0.537210\n",
      "epoch = 6 train_loss : 0.449237 , test loss : 0.513542\n",
      "epoch = 7 train_loss : 0.431348 , test loss : 0.496913\n",
      "epoch = 8 train_loss : 0.416752 , test loss : 0.483396\n",
      "epoch = 9 train_loss : 0.404074 , test loss : 0.471418\n",
      "epoch = 10 train_loss : 0.392451 , test loss : 0.459390\n",
      "epoch = 11 train_loss : 0.382106 , test loss : 0.449323\n",
      "epoch = 12 train_loss : 0.372442 , test loss : 0.439136\n",
      "epoch = 13 train_loss : 0.363195 , test loss : 0.429782\n",
      "epoch = 14 train_loss : 0.354842 , test loss : 0.421697\n",
      "epoch = 15 train_loss : 0.347060 , test loss : 0.414091\n",
      "epoch = 16 train_loss : 0.339808 , test loss : 0.407107\n",
      "epoch = 17 train_loss : 0.333109 , test loss : 0.400208\n",
      "epoch = 18 train_loss : 0.326489 , test loss : 0.394170\n",
      "epoch = 19 train_loss : 0.320287 , test loss : 0.387891\n",
      "epoch = 20 train_loss : 0.314319 , test loss : 0.381793\n",
      "epoch = 21 train_loss : 0.308702 , test loss : 0.377100\n",
      "epoch = 22 train_loss : 0.303206 , test loss : 0.371790\n",
      "epoch = 23 train_loss : 0.297984 , test loss : 0.366543\n",
      "epoch = 24 train_loss : 0.292944 , test loss : 0.361850\n",
      "epoch = 25 train_loss : 0.288048 , test loss : 0.357753\n",
      "epoch = 26 train_loss : 0.283408 , test loss : 0.353488\n",
      "epoch = 27 train_loss : 0.278932 , test loss : 0.348970\n",
      "epoch = 28 train_loss : 0.274581 , test loss : 0.344649\n",
      "epoch = 29 train_loss : 0.270433 , test loss : 0.340516\n",
      "epoch = 30 train_loss : 0.266347 , test loss : 0.337068\n",
      "epoch = 31 train_loss : 0.262394 , test loss : 0.332831\n",
      "epoch = 32 train_loss : 0.258760 , test loss : 0.329317\n",
      "epoch = 33 train_loss : 0.254931 , test loss : 0.326375\n",
      "epoch = 34 train_loss : 0.251641 , test loss : 0.323262\n",
      "epoch = 35 train_loss : 0.248098 , test loss : 0.319069\n",
      "epoch = 36 train_loss : 0.244889 , test loss : 0.316251\n",
      "epoch = 37 train_loss : 0.241833 , test loss : 0.312937\n",
      "epoch = 38 train_loss : 0.238732 , test loss : 0.309571\n",
      "epoch = 39 train_loss : 0.235720 , test loss : 0.306926\n",
      "epoch = 40 train_loss : 0.232774 , test loss : 0.303703\n",
      "epoch = 41 train_loss : 0.229952 , test loss : 0.301060\n",
      "epoch = 42 train_loss : 0.227149 , test loss : 0.298021\n",
      "epoch = 43 train_loss : 0.224380 , test loss : 0.295154\n",
      "epoch = 44 train_loss : 0.221740 , test loss : 0.292490\n",
      "epoch = 45 train_loss : 0.219272 , test loss : 0.290040\n",
      "epoch = 46 train_loss : 0.216925 , test loss : 0.287401\n",
      "epoch = 47 train_loss : 0.214336 , test loss : 0.285164\n",
      "epoch = 48 train_loss : 0.212054 , test loss : 0.282911\n",
      "epoch = 49 train_loss : 0.209716 , test loss : 0.280922\n",
      "epoch = 50 train_loss : 0.207527 , test loss : 0.277962\n",
      "epoch = 51 train_loss : 0.205337 , test loss : 0.275892\n",
      "epoch = 52 train_loss : 0.203232 , test loss : 0.273666\n",
      "epoch = 53 train_loss : 0.201147 , test loss : 0.271307\n",
      "epoch = 54 train_loss : 0.199091 , test loss : 0.270129\n",
      "epoch = 55 train_loss : 0.197204 , test loss : 0.267647\n",
      "epoch = 56 train_loss : 0.195190 , test loss : 0.265448\n",
      "epoch = 57 train_loss : 0.193401 , test loss : 0.263149\n",
      "epoch = 58 train_loss : 0.191542 , test loss : 0.261561\n",
      "epoch = 59 train_loss : 0.189806 , test loss : 0.259556\n",
      "epoch = 60 train_loss : 0.188048 , test loss : 0.258432\n",
      "epoch = 61 train_loss : 0.186399 , test loss : 0.256418\n",
      "epoch = 62 train_loss : 0.184701 , test loss : 0.255147\n",
      "epoch = 63 train_loss : 0.183077 , test loss : 0.253179\n",
      "epoch = 64 train_loss : 0.181481 , test loss : 0.251573\n",
      "epoch = 65 train_loss : 0.179992 , test loss : 0.250446\n",
      "epoch = 66 train_loss : 0.178565 , test loss : 0.248512\n",
      "epoch = 67 train_loss : 0.177097 , test loss : 0.248109\n",
      "epoch = 68 train_loss : 0.175547 , test loss : 0.246200\n",
      "epoch = 69 train_loss : 0.174118 , test loss : 0.244145\n",
      "epoch = 70 train_loss : 0.172831 , test loss : 0.243477\n",
      "epoch = 71 train_loss : 0.171447 , test loss : 0.241012\n",
      "epoch = 72 train_loss : 0.170173 , test loss : 0.240400\n",
      "epoch = 73 train_loss : 0.168871 , test loss : 0.239311\n",
      "epoch = 74 train_loss : 0.167607 , test loss : 0.237736\n",
      "epoch = 75 train_loss : 0.166358 , test loss : 0.236200\n",
      "epoch = 76 train_loss : 0.165193 , test loss : 0.235215\n",
      "epoch = 77 train_loss : 0.164114 , test loss : 0.233101\n",
      "epoch = 78 train_loss : 0.163306 , test loss : 0.232534\n",
      "epoch = 79 train_loss : 0.162017 , test loss : 0.232178\n",
      "epoch = 80 train_loss : 0.160934 , test loss : 0.230560\n",
      "epoch = 81 train_loss : 0.159797 , test loss : 0.229230\n",
      "epoch = 82 train_loss : 0.158870 , test loss : 0.227869\n",
      "epoch = 83 train_loss : 0.157969 , test loss : 0.227379\n",
      "epoch = 84 train_loss : 0.157036 , test loss : 0.226048\n",
      "epoch = 85 train_loss : 0.156070 , test loss : 0.225206\n",
      "epoch = 86 train_loss : 0.155050 , test loss : 0.223489\n",
      "epoch = 87 train_loss : 0.154154 , test loss : 0.222733\n",
      "epoch = 88 train_loss : 0.153374 , test loss : 0.222290\n",
      "epoch = 89 train_loss : 0.152484 , test loss : 0.220616\n",
      "epoch = 90 train_loss : 0.151696 , test loss : 0.219551\n",
      "epoch = 91 train_loss : 0.150934 , test loss : 0.218471\n",
      "epoch = 92 train_loss : 0.150085 , test loss : 0.217826\n",
      "epoch = 93 train_loss : 0.149451 , test loss : 0.216300\n",
      "epoch = 94 train_loss : 0.148606 , test loss : 0.215885\n",
      "epoch = 95 train_loss : 0.147893 , test loss : 0.215380\n",
      "epoch = 96 train_loss : 0.147136 , test loss : 0.214741\n",
      "epoch = 97 train_loss : 0.146448 , test loss : 0.213705\n",
      "epoch = 98 train_loss : 0.145711 , test loss : 0.212965\n",
      "epoch = 99 train_loss : 0.145231 , test loss : 0.212350\n",
      "epoch = 100 train_loss : 0.144592 , test loss : 0.211932\n",
      "epoch = 101 train_loss : 0.143825 , test loss : 0.211346\n",
      "epoch = 102 train_loss : 0.143131 , test loss : 0.210322\n",
      "epoch = 103 train_loss : 0.142476 , test loss : 0.209912\n",
      "epoch = 104 train_loss : 0.141890 , test loss : 0.208921\n",
      "epoch = 106 train_loss : 0.140771 , test loss : 0.208347\n",
      "epoch = 107 train_loss : 0.140226 , test loss : 0.207164\n",
      "epoch = 108 train_loss : 0.139674 , test loss : 0.206727\n",
      "epoch = 109 train_loss : 0.139071 , test loss : 0.205856\n",
      "epoch = 110 train_loss : 0.138612 , test loss : 0.205163\n",
      "epoch = 112 train_loss : 0.137670 , test loss : 0.204399\n",
      "epoch = 113 train_loss : 0.137182 , test loss : 0.204081\n",
      "epoch = 114 train_loss : 0.136727 , test loss : 0.203903\n",
      "epoch = 115 train_loss : 0.136364 , test loss : 0.203694\n",
      "epoch = 116 train_loss : 0.135860 , test loss : 0.201587\n",
      "epoch = 118 train_loss : 0.134895 , test loss : 0.201410\n",
      "epoch = 119 train_loss : 0.134532 , test loss : 0.200583\n",
      "epoch = 120 train_loss : 0.134024 , test loss : 0.200536\n",
      "epoch = 121 train_loss : 0.133793 , test loss : 0.199891\n",
      "epoch = 122 train_loss : 0.133297 , test loss : 0.199624\n",
      "epoch = 123 train_loss : 0.133140 , test loss : 0.199246\n",
      "epoch = 125 train_loss : 0.132352 , test loss : 0.198358\n",
      "epoch = 126 train_loss : 0.131806 , test loss : 0.197645\n",
      "epoch = 128 train_loss : 0.131205 , test loss : 0.197195\n",
      "epoch = 129 train_loss : 0.130875 , test loss : 0.197068\n",
      "epoch = 130 train_loss : 0.130522 , test loss : 0.196426\n",
      "epoch = 131 train_loss : 0.130338 , test loss : 0.195857\n",
      "epoch = 133 train_loss : 0.129662 , test loss : 0.194935\n",
      "epoch = 136 train_loss : 0.128770 , test loss : 0.194219\n",
      "epoch = 139 train_loss : 0.127828 , test loss : 0.193848\n",
      "epoch = 140 train_loss : 0.127500 , test loss : 0.193175\n",
      "epoch = 142 train_loss : 0.127222 , test loss : 0.192975\n",
      "epoch = 144 train_loss : 0.126555 , test loss : 0.192367\n",
      "epoch = 145 train_loss : 0.126354 , test loss : 0.191871\n",
      "epoch = 147 train_loss : 0.125968 , test loss : 0.191461\n",
      "epoch = 149 train_loss : 0.125335 , test loss : 0.191021\n",
      "epoch = 151 train_loss : 0.125183 , test loss : 0.190822\n",
      "epoch = 152 train_loss : 0.124631 , test loss : 0.190582\n",
      "epoch = 154 train_loss : 0.124261 , test loss : 0.190534\n",
      "epoch = 155 train_loss : 0.124132 , test loss : 0.189561\n",
      "epoch = 156 train_loss : 0.124034 , test loss : 0.189367\n",
      "epoch = 158 train_loss : 0.123578 , test loss : 0.189175\n",
      "epoch = 161 train_loss : 0.122876 , test loss : 0.189119\n",
      "epoch = 162 train_loss : 0.122653 , test loss : 0.188638\n",
      "epoch = 163 train_loss : 0.122471 , test loss : 0.187950\n",
      "epoch = 164 train_loss : 0.122277 , test loss : 0.187859\n",
      "epoch = 165 train_loss : 0.122106 , test loss : 0.187823\n",
      "epoch = 166 train_loss : 0.122113 , test loss : 0.187596\n",
      "epoch = 168 train_loss : 0.121595 , test loss : 0.187596\n",
      "epoch = 170 train_loss : 0.121344 , test loss : 0.186680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 172 train_loss : 0.120981 , test loss : 0.185920\n",
      "epoch = 174 train_loss : 0.120641 , test loss : 0.185668\n",
      "epoch = 176 train_loss : 0.120437 , test loss : 0.185454\n",
      "epoch = 181 train_loss : 0.119484 , test loss : 0.185201\n",
      "epoch = 184 train_loss : 0.119030 , test loss : 0.184822\n",
      "epoch = 187 train_loss : 0.118621 , test loss : 0.184799\n",
      "epoch = 189 train_loss : 0.118542 , test loss : 0.184041\n",
      "epoch = 192 train_loss : 0.117912 , test loss : 0.183725\n",
      "epoch = 197 train_loss : 0.117262 , test loss : 0.183299\n",
      "epoch = 198 train_loss : 0.117197 , test loss : 0.182915\n",
      "epoch = 207 train_loss : 0.115993 , test loss : 0.182638\n",
      "epoch = 208 train_loss : 0.115840 , test loss : 0.182569\n",
      "epoch = 209 train_loss : 0.116011 , test loss : 0.182203\n",
      "epoch = 212 train_loss : 0.115482 , test loss : 0.182177\n",
      "epoch = 216 train_loss : 0.115066 , test loss : 0.182146\n",
      "epoch = 218 train_loss : 0.115089 , test loss : 0.181773\n",
      "epoch = 221 train_loss : 0.114529 , test loss : 0.181560\n",
      "epoch = 226 train_loss : 0.114002 , test loss : 0.181319\n",
      "epoch = 236 train_loss : 0.113086 , test loss : 0.180694\n",
      "epoch = 238 train_loss : 0.112917 , test loss : 0.180646\n",
      "epoch = 239 train_loss : 0.113000 , test loss : 0.180199\n",
      "epoch = 248 train_loss : 0.112418 , test loss : 0.179733\n",
      "epoch = 249 train_loss : 0.112480 , test loss : 0.179491\n",
      "epoch = 251 train_loss : 0.111921 , test loss : 0.179397\n",
      "epoch = 259 train_loss : 0.111392 , test loss : 0.179032\n",
      "epoch = 262 train_loss : 0.111064 , test loss : 0.179024\n",
      "epoch = 265 train_loss : 0.110872 , test loss : 0.178936\n",
      "epoch = 266 train_loss : 0.110810 , test loss : 0.178773\n",
      "epoch = 271 train_loss : 0.110470 , test loss : 0.178636\n",
      "epoch = 280 train_loss : 0.110040 , test loss : 0.178594\n",
      "epoch = 286 train_loss : 0.109543 , test loss : 0.178239\n",
      "epoch = 296 train_loss : 0.108857 , test loss : 0.178190\n",
      "epoch = 297 train_loss : 0.109046 , test loss : 0.178015\n",
      "epoch = 307 train_loss : 0.108472 , test loss : 0.177559\n",
      "epoch = 325 train_loss : 0.107422 , test loss : 0.177427\n",
      "epoch = 344 train_loss : 0.106736 , test loss : 0.176958\n",
      "epoch = 354 train_loss : 0.106428 , test loss : 0.176818\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.106428,test loss : 0.176818\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.744787 , test loss : 0.770667\n",
      "epoch = 2 train_loss : 0.595239 , test loss : 0.615533\n",
      "epoch = 3 train_loss : 0.527985 , test loss : 0.539540\n",
      "epoch = 4 train_loss : 0.489996 , test loss : 0.494104\n",
      "epoch = 5 train_loss : 0.463723 , test loss : 0.462035\n",
      "epoch = 6 train_loss : 0.443705 , test loss : 0.437558\n",
      "epoch = 7 train_loss : 0.428694 , test loss : 0.420214\n",
      "epoch = 8 train_loss : 0.415552 , test loss : 0.404427\n",
      "epoch = 9 train_loss : 0.404503 , test loss : 0.392562\n",
      "epoch = 10 train_loss : 0.394481 , test loss : 0.381667\n",
      "epoch = 11 train_loss : 0.385393 , test loss : 0.371911\n",
      "epoch = 12 train_loss : 0.376840 , test loss : 0.362666\n",
      "epoch = 13 train_loss : 0.368548 , test loss : 0.354917\n",
      "epoch = 14 train_loss : 0.360787 , test loss : 0.346830\n",
      "epoch = 15 train_loss : 0.353474 , test loss : 0.339295\n",
      "epoch = 16 train_loss : 0.346418 , test loss : 0.332695\n",
      "epoch = 17 train_loss : 0.339794 , test loss : 0.325712\n",
      "epoch = 18 train_loss : 0.333368 , test loss : 0.319912\n",
      "epoch = 19 train_loss : 0.327254 , test loss : 0.313528\n",
      "epoch = 20 train_loss : 0.321433 , test loss : 0.307719\n",
      "epoch = 21 train_loss : 0.315885 , test loss : 0.302671\n",
      "epoch = 22 train_loss : 0.310450 , test loss : 0.297126\n",
      "epoch = 23 train_loss : 0.305369 , test loss : 0.292436\n",
      "epoch = 24 train_loss : 0.300319 , test loss : 0.287812\n",
      "epoch = 25 train_loss : 0.295508 , test loss : 0.283368\n",
      "epoch = 26 train_loss : 0.290842 , test loss : 0.279442\n",
      "epoch = 27 train_loss : 0.286449 , test loss : 0.275586\n",
      "epoch = 28 train_loss : 0.282387 , test loss : 0.271984\n",
      "epoch = 29 train_loss : 0.278119 , test loss : 0.268049\n",
      "epoch = 30 train_loss : 0.274261 , test loss : 0.264545\n",
      "epoch = 31 train_loss : 0.270592 , test loss : 0.262166\n",
      "epoch = 32 train_loss : 0.266879 , test loss : 0.258900\n",
      "epoch = 33 train_loss : 0.263234 , test loss : 0.255964\n",
      "epoch = 34 train_loss : 0.259847 , test loss : 0.252842\n",
      "epoch = 35 train_loss : 0.256522 , test loss : 0.250060\n",
      "epoch = 36 train_loss : 0.253256 , test loss : 0.247581\n",
      "epoch = 37 train_loss : 0.249949 , test loss : 0.245284\n",
      "epoch = 38 train_loss : 0.246893 , test loss : 0.242367\n",
      "epoch = 39 train_loss : 0.243759 , test loss : 0.239895\n",
      "epoch = 40 train_loss : 0.240875 , test loss : 0.237788\n",
      "epoch = 41 train_loss : 0.237862 , test loss : 0.235447\n",
      "epoch = 42 train_loss : 0.235059 , test loss : 0.233063\n",
      "epoch = 43 train_loss : 0.232258 , test loss : 0.231078\n",
      "epoch = 44 train_loss : 0.229617 , test loss : 0.229298\n",
      "epoch = 45 train_loss : 0.227019 , test loss : 0.226640\n",
      "epoch = 46 train_loss : 0.224436 , test loss : 0.224556\n",
      "epoch = 47 train_loss : 0.221881 , test loss : 0.222988\n",
      "epoch = 48 train_loss : 0.219582 , test loss : 0.221327\n",
      "epoch = 49 train_loss : 0.217099 , test loss : 0.219456\n",
      "epoch = 50 train_loss : 0.214846 , test loss : 0.217755\n",
      "epoch = 51 train_loss : 0.212479 , test loss : 0.216118\n",
      "epoch = 52 train_loss : 0.210246 , test loss : 0.214651\n",
      "epoch = 53 train_loss : 0.208157 , test loss : 0.212647\n",
      "epoch = 54 train_loss : 0.206010 , test loss : 0.211567\n",
      "epoch = 55 train_loss : 0.203977 , test loss : 0.210072\n",
      "epoch = 56 train_loss : 0.201994 , test loss : 0.208260\n",
      "epoch = 57 train_loss : 0.199962 , test loss : 0.207062\n",
      "epoch = 58 train_loss : 0.197991 , test loss : 0.205669\n",
      "epoch = 59 train_loss : 0.196171 , test loss : 0.204527\n",
      "epoch = 60 train_loss : 0.194395 , test loss : 0.203212\n",
      "epoch = 61 train_loss : 0.192456 , test loss : 0.201484\n",
      "epoch = 62 train_loss : 0.190687 , test loss : 0.200135\n",
      "epoch = 63 train_loss : 0.188878 , test loss : 0.198949\n",
      "epoch = 64 train_loss : 0.187190 , test loss : 0.198040\n",
      "epoch = 65 train_loss : 0.185699 , test loss : 0.197253\n",
      "epoch = 66 train_loss : 0.183893 , test loss : 0.195277\n",
      "epoch = 67 train_loss : 0.182227 , test loss : 0.194278\n",
      "epoch = 68 train_loss : 0.180743 , test loss : 0.192959\n",
      "epoch = 69 train_loss : 0.179182 , test loss : 0.191777\n",
      "epoch = 70 train_loss : 0.177788 , test loss : 0.190898\n",
      "epoch = 71 train_loss : 0.176309 , test loss : 0.190041\n",
      "epoch = 72 train_loss : 0.174798 , test loss : 0.188873\n",
      "epoch = 73 train_loss : 0.173458 , test loss : 0.187507\n",
      "epoch = 74 train_loss : 0.172083 , test loss : 0.187016\n",
      "epoch = 75 train_loss : 0.170884 , test loss : 0.185711\n",
      "epoch = 76 train_loss : 0.169456 , test loss : 0.185019\n",
      "epoch = 77 train_loss : 0.168190 , test loss : 0.184446\n",
      "epoch = 78 train_loss : 0.166844 , test loss : 0.183153\n",
      "epoch = 79 train_loss : 0.165692 , test loss : 0.182285\n",
      "epoch = 80 train_loss : 0.164467 , test loss : 0.181402\n",
      "epoch = 81 train_loss : 0.163538 , test loss : 0.181260\n",
      "epoch = 82 train_loss : 0.162215 , test loss : 0.179803\n",
      "epoch = 83 train_loss : 0.161059 , test loss : 0.178926\n",
      "epoch = 84 train_loss : 0.160146 , test loss : 0.178306\n",
      "epoch = 85 train_loss : 0.158951 , test loss : 0.177625\n",
      "epoch = 86 train_loss : 0.158181 , test loss : 0.176476\n",
      "epoch = 87 train_loss : 0.157116 , test loss : 0.176448\n",
      "epoch = 88 train_loss : 0.156074 , test loss : 0.175670\n",
      "epoch = 89 train_loss : 0.154987 , test loss : 0.174698\n",
      "epoch = 90 train_loss : 0.154082 , test loss : 0.174139\n",
      "epoch = 91 train_loss : 0.153467 , test loss : 0.173238\n",
      "epoch = 92 train_loss : 0.152352 , test loss : 0.172803\n",
      "epoch = 93 train_loss : 0.151422 , test loss : 0.172553\n",
      "epoch = 94 train_loss : 0.150580 , test loss : 0.171687\n",
      "epoch = 95 train_loss : 0.149842 , test loss : 0.171078\n",
      "epoch = 96 train_loss : 0.148917 , test loss : 0.170565\n",
      "epoch = 97 train_loss : 0.148068 , test loss : 0.170204\n",
      "epoch = 98 train_loss : 0.147191 , test loss : 0.169437\n",
      "epoch = 99 train_loss : 0.146361 , test loss : 0.169134\n",
      "epoch = 100 train_loss : 0.145693 , test loss : 0.168291\n",
      "epoch = 101 train_loss : 0.144867 , test loss : 0.168144\n",
      "epoch = 102 train_loss : 0.144097 , test loss : 0.167515\n",
      "epoch = 104 train_loss : 0.142888 , test loss : 0.166932\n",
      "epoch = 106 train_loss : 0.141404 , test loss : 0.166072\n",
      "epoch = 107 train_loss : 0.140770 , test loss : 0.165731\n",
      "epoch = 108 train_loss : 0.140297 , test loss : 0.165689\n",
      "epoch = 109 train_loss : 0.139521 , test loss : 0.165078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 110 train_loss : 0.139003 , test loss : 0.164566\n",
      "epoch = 111 train_loss : 0.138357 , test loss : 0.164370\n",
      "epoch = 112 train_loss : 0.137902 , test loss : 0.163800\n",
      "epoch = 113 train_loss : 0.137280 , test loss : 0.163779\n",
      "epoch = 114 train_loss : 0.136751 , test loss : 0.163284\n",
      "epoch = 116 train_loss : 0.135627 , test loss : 0.163061\n",
      "epoch = 117 train_loss : 0.135458 , test loss : 0.162951\n",
      "epoch = 118 train_loss : 0.134686 , test loss : 0.162680\n",
      "epoch = 119 train_loss : 0.134189 , test loss : 0.162343\n",
      "epoch = 120 train_loss : 0.133763 , test loss : 0.161963\n",
      "epoch = 122 train_loss : 0.132951 , test loss : 0.161896\n",
      "epoch = 123 train_loss : 0.132572 , test loss : 0.161460\n",
      "epoch = 124 train_loss : 0.131962 , test loss : 0.161269\n",
      "epoch = 125 train_loss : 0.131581 , test loss : 0.160611\n",
      "epoch = 127 train_loss : 0.130719 , test loss : 0.160542\n",
      "epoch = 128 train_loss : 0.130348 , test loss : 0.160313\n",
      "epoch = 129 train_loss : 0.130064 , test loss : 0.160062\n",
      "epoch = 130 train_loss : 0.129684 , test loss : 0.159856\n",
      "epoch = 133 train_loss : 0.128548 , test loss : 0.159710\n",
      "epoch = 135 train_loss : 0.127988 , test loss : 0.159243\n",
      "epoch = 136 train_loss : 0.127717 , test loss : 0.159153\n",
      "epoch = 137 train_loss : 0.127634 , test loss : 0.158785\n",
      "epoch = 141 train_loss : 0.126264 , test loss : 0.158691\n",
      "epoch = 143 train_loss : 0.125533 , test loss : 0.158557\n",
      "epoch = 144 train_loss : 0.125221 , test loss : 0.158356\n",
      "epoch = 146 train_loss : 0.124698 , test loss : 0.158329\n",
      "epoch = 148 train_loss : 0.124187 , test loss : 0.158231\n",
      "epoch = 150 train_loss : 0.123651 , test loss : 0.158200\n",
      "epoch = 151 train_loss : 0.123451 , test loss : 0.158000\n",
      "epoch = 152 train_loss : 0.123253 , test loss : 0.157710\n",
      "epoch = 158 train_loss : 0.121788 , test loss : 0.157249\n",
      "epoch = 159 train_loss : 0.121609 , test loss : 0.157185\n",
      "epoch = 161 train_loss : 0.121404 , test loss : 0.157120\n",
      "epoch = 162 train_loss : 0.120934 , test loss : 0.157023\n",
      "epoch = 164 train_loss : 0.120608 , test loss : 0.157014\n",
      "epoch = 165 train_loss : 0.120336 , test loss : 0.156890\n",
      "epoch = 166 train_loss : 0.120151 , test loss : 0.156826\n",
      "epoch = 167 train_loss : 0.120239 , test loss : 0.156667\n",
      "epoch = 168 train_loss : 0.119763 , test loss : 0.156470\n",
      "epoch = 170 train_loss : 0.119385 , test loss : 0.156431\n",
      "epoch = 177 train_loss : 0.118393 , test loss : 0.156330\n",
      "epoch = 180 train_loss : 0.117775 , test loss : 0.156130\n",
      "epoch = 183 train_loss : 0.117357 , test loss : 0.156015\n",
      "epoch = 191 train_loss : 0.116065 , test loss : 0.155862\n",
      "epoch = 195 train_loss : 0.115694 , test loss : 0.155540\n",
      "epoch = 200 train_loss : 0.115089 , test loss : 0.155366\n",
      "epoch = 212 train_loss : 0.113503 , test loss : 0.155345\n",
      "epoch = 218 train_loss : 0.112966 , test loss : 0.155293\n",
      "epoch = 224 train_loss : 0.112339 , test loss : 0.155281\n",
      "epoch = 226 train_loss : 0.112184 , test loss : 0.155233\n",
      "epoch = 229 train_loss : 0.111860 , test loss : 0.155142\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.111860,test loss : 0.155142\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.671345 , test loss : 0.658892\n",
      "epoch = 2 train_loss : 0.568516 , test loss : 0.560983\n",
      "epoch = 3 train_loss : 0.508502 , test loss : 0.503790\n",
      "epoch = 4 train_loss : 0.468374 , test loss : 0.463950\n",
      "epoch = 5 train_loss : 0.440337 , test loss : 0.435995\n",
      "epoch = 6 train_loss : 0.418924 , test loss : 0.414623\n",
      "epoch = 7 train_loss : 0.402837 , test loss : 0.398406\n",
      "epoch = 8 train_loss : 0.389298 , test loss : 0.384507\n",
      "epoch = 9 train_loss : 0.377737 , test loss : 0.373054\n",
      "epoch = 10 train_loss : 0.367708 , test loss : 0.363512\n",
      "epoch = 11 train_loss : 0.358524 , test loss : 0.355117\n",
      "epoch = 12 train_loss : 0.350170 , test loss : 0.347787\n",
      "epoch = 13 train_loss : 0.342351 , test loss : 0.340631\n",
      "epoch = 14 train_loss : 0.335008 , test loss : 0.333904\n",
      "epoch = 15 train_loss : 0.327985 , test loss : 0.327789\n",
      "epoch = 16 train_loss : 0.321254 , test loss : 0.321797\n",
      "epoch = 17 train_loss : 0.314976 , test loss : 0.316773\n",
      "epoch = 18 train_loss : 0.309054 , test loss : 0.311771\n",
      "epoch = 19 train_loss : 0.303178 , test loss : 0.306696\n",
      "epoch = 20 train_loss : 0.297600 , test loss : 0.302027\n",
      "epoch = 21 train_loss : 0.292405 , test loss : 0.297731\n",
      "epoch = 22 train_loss : 0.287322 , test loss : 0.292960\n",
      "epoch = 23 train_loss : 0.282508 , test loss : 0.289208\n",
      "epoch = 24 train_loss : 0.277992 , test loss : 0.285036\n",
      "epoch = 25 train_loss : 0.273643 , test loss : 0.281318\n",
      "epoch = 26 train_loss : 0.269411 , test loss : 0.277534\n",
      "epoch = 27 train_loss : 0.265390 , test loss : 0.273616\n",
      "epoch = 28 train_loss : 0.261397 , test loss : 0.270338\n",
      "epoch = 29 train_loss : 0.257502 , test loss : 0.266823\n",
      "epoch = 30 train_loss : 0.253830 , test loss : 0.264064\n",
      "epoch = 31 train_loss : 0.250234 , test loss : 0.260987\n",
      "epoch = 32 train_loss : 0.246539 , test loss : 0.257187\n",
      "epoch = 33 train_loss : 0.243215 , test loss : 0.255057\n",
      "epoch = 34 train_loss : 0.239753 , test loss : 0.251387\n",
      "epoch = 35 train_loss : 0.236552 , test loss : 0.248934\n",
      "epoch = 36 train_loss : 0.233366 , test loss : 0.245842\n",
      "epoch = 37 train_loss : 0.230362 , test loss : 0.243208\n",
      "epoch = 38 train_loss : 0.227306 , test loss : 0.240824\n",
      "epoch = 39 train_loss : 0.224488 , test loss : 0.238138\n",
      "epoch = 40 train_loss : 0.221838 , test loss : 0.235312\n",
      "epoch = 41 train_loss : 0.218756 , test loss : 0.233549\n",
      "epoch = 42 train_loss : 0.216038 , test loss : 0.230883\n",
      "epoch = 43 train_loss : 0.213447 , test loss : 0.228825\n",
      "epoch = 44 train_loss : 0.210908 , test loss : 0.227210\n",
      "epoch = 45 train_loss : 0.208242 , test loss : 0.224517\n",
      "epoch = 46 train_loss : 0.205875 , test loss : 0.222774\n",
      "epoch = 47 train_loss : 0.203531 , test loss : 0.220444\n",
      "epoch = 48 train_loss : 0.201197 , test loss : 0.218689\n",
      "epoch = 49 train_loss : 0.199102 , test loss : 0.217581\n",
      "epoch = 50 train_loss : 0.196778 , test loss : 0.215017\n",
      "epoch = 51 train_loss : 0.194696 , test loss : 0.213167\n",
      "epoch = 52 train_loss : 0.192576 , test loss : 0.211131\n",
      "epoch = 53 train_loss : 0.190990 , test loss : 0.209730\n",
      "epoch = 54 train_loss : 0.188763 , test loss : 0.208689\n",
      "epoch = 55 train_loss : 0.187112 , test loss : 0.206924\n",
      "epoch = 56 train_loss : 0.184936 , test loss : 0.205201\n",
      "epoch = 57 train_loss : 0.183223 , test loss : 0.203740\n",
      "epoch = 58 train_loss : 0.181458 , test loss : 0.202648\n",
      "epoch = 59 train_loss : 0.179856 , test loss : 0.200923\n",
      "epoch = 60 train_loss : 0.178275 , test loss : 0.199831\n",
      "epoch = 61 train_loss : 0.176674 , test loss : 0.198483\n",
      "epoch = 62 train_loss : 0.175057 , test loss : 0.197281\n",
      "epoch = 63 train_loss : 0.173554 , test loss : 0.195570\n",
      "epoch = 64 train_loss : 0.172369 , test loss : 0.194425\n",
      "epoch = 65 train_loss : 0.170768 , test loss : 0.193621\n",
      "epoch = 66 train_loss : 0.169304 , test loss : 0.192508\n",
      "epoch = 67 train_loss : 0.167982 , test loss : 0.191206\n",
      "epoch = 68 train_loss : 0.166604 , test loss : 0.189929\n",
      "epoch = 69 train_loss : 0.165375 , test loss : 0.189445\n",
      "epoch = 70 train_loss : 0.164153 , test loss : 0.188763\n",
      "epoch = 71 train_loss : 0.163053 , test loss : 0.187772\n",
      "epoch = 72 train_loss : 0.161915 , test loss : 0.185923\n",
      "epoch = 73 train_loss : 0.160760 , test loss : 0.185874\n",
      "epoch = 74 train_loss : 0.159763 , test loss : 0.184769\n",
      "epoch = 75 train_loss : 0.158764 , test loss : 0.183019\n",
      "epoch = 76 train_loss : 0.157553 , test loss : 0.182699\n",
      "epoch = 77 train_loss : 0.156518 , test loss : 0.181652\n",
      "epoch = 78 train_loss : 0.155536 , test loss : 0.180972\n",
      "epoch = 79 train_loss : 0.154622 , test loss : 0.179816\n",
      "epoch = 80 train_loss : 0.153698 , test loss : 0.179067\n",
      "epoch = 81 train_loss : 0.152919 , test loss : 0.178101\n",
      "epoch = 82 train_loss : 0.151983 , test loss : 0.177166\n",
      "epoch = 83 train_loss : 0.151157 , test loss : 0.177024\n",
      "epoch = 84 train_loss : 0.150316 , test loss : 0.176496\n",
      "epoch = 85 train_loss : 0.149528 , test loss : 0.175387\n",
      "epoch = 86 train_loss : 0.148685 , test loss : 0.175281\n",
      "epoch = 87 train_loss : 0.147951 , test loss : 0.174147\n",
      "epoch = 88 train_loss : 0.147330 , test loss : 0.174066\n",
      "epoch = 89 train_loss : 0.146721 , test loss : 0.172712\n",
      "epoch = 91 train_loss : 0.145154 , test loss : 0.171533\n",
      "epoch = 92 train_loss : 0.144450 , test loss : 0.170814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 94 train_loss : 0.143148 , test loss : 0.169778\n",
      "epoch = 95 train_loss : 0.142626 , test loss : 0.169212\n",
      "epoch = 96 train_loss : 0.141995 , test loss : 0.169157\n",
      "epoch = 97 train_loss : 0.141408 , test loss : 0.168478\n",
      "epoch = 99 train_loss : 0.140306 , test loss : 0.167699\n",
      "epoch = 100 train_loss : 0.139708 , test loss : 0.167515\n",
      "epoch = 101 train_loss : 0.139331 , test loss : 0.167430\n",
      "epoch = 102 train_loss : 0.139129 , test loss : 0.167363\n",
      "epoch = 103 train_loss : 0.138228 , test loss : 0.166094\n",
      "epoch = 104 train_loss : 0.137911 , test loss : 0.165501\n",
      "epoch = 105 train_loss : 0.137314 , test loss : 0.165234\n",
      "epoch = 106 train_loss : 0.136872 , test loss : 0.165146\n",
      "epoch = 107 train_loss : 0.136498 , test loss : 0.164997\n",
      "epoch = 108 train_loss : 0.135976 , test loss : 0.164525\n",
      "epoch = 109 train_loss : 0.135578 , test loss : 0.164159\n",
      "epoch = 111 train_loss : 0.134738 , test loss : 0.163316\n",
      "epoch = 113 train_loss : 0.133945 , test loss : 0.163092\n",
      "epoch = 114 train_loss : 0.133941 , test loss : 0.162838\n",
      "epoch = 115 train_loss : 0.133203 , test loss : 0.161880\n",
      "epoch = 118 train_loss : 0.132258 , test loss : 0.161507\n",
      "epoch = 120 train_loss : 0.131741 , test loss : 0.161424\n",
      "epoch = 121 train_loss : 0.131258 , test loss : 0.161059\n",
      "epoch = 122 train_loss : 0.130971 , test loss : 0.160430\n",
      "epoch = 124 train_loss : 0.130201 , test loss : 0.160357\n",
      "epoch = 126 train_loss : 0.129771 , test loss : 0.160126\n",
      "epoch = 127 train_loss : 0.129424 , test loss : 0.160085\n",
      "epoch = 128 train_loss : 0.129020 , test loss : 0.159954\n",
      "epoch = 129 train_loss : 0.128835 , test loss : 0.159476\n",
      "epoch = 131 train_loss : 0.128304 , test loss : 0.159060\n",
      "epoch = 133 train_loss : 0.127758 , test loss : 0.159010\n",
      "epoch = 135 train_loss : 0.127371 , test loss : 0.158614\n",
      "epoch = 136 train_loss : 0.127015 , test loss : 0.158219\n",
      "epoch = 140 train_loss : 0.126247 , test loss : 0.157776\n",
      "epoch = 143 train_loss : 0.125403 , test loss : 0.157668\n",
      "epoch = 147 train_loss : 0.124592 , test loss : 0.157474\n",
      "epoch = 149 train_loss : 0.124268 , test loss : 0.157263\n",
      "epoch = 150 train_loss : 0.124032 , test loss : 0.157122\n",
      "epoch = 151 train_loss : 0.123829 , test loss : 0.157017\n",
      "epoch = 152 train_loss : 0.123615 , test loss : 0.156916\n",
      "epoch = 155 train_loss : 0.123246 , test loss : 0.156702\n",
      "epoch = 156 train_loss : 0.123007 , test loss : 0.156343\n",
      "epoch = 162 train_loss : 0.122088 , test loss : 0.155561\n",
      "epoch = 178 train_loss : 0.119791 , test loss : 0.155355\n",
      "epoch = 184 train_loss : 0.119110 , test loss : 0.155278\n",
      "epoch = 191 train_loss : 0.118212 , test loss : 0.155146\n",
      "epoch = 206 train_loss : 0.116741 , test loss : 0.154863\n",
      "epoch = 213 train_loss : 0.116203 , test loss : 0.154795\n",
      "epoch = 221 train_loss : 0.115686 , test loss : 0.154658\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.115686,test loss : 0.154658\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.719017 , test loss : 0.653916\n",
      "epoch = 2 train_loss : 0.586774 , test loss : 0.524794\n",
      "epoch = 3 train_loss : 0.506236 , test loss : 0.452933\n",
      "epoch = 4 train_loss : 0.458477 , test loss : 0.414516\n",
      "epoch = 5 train_loss : 0.427957 , test loss : 0.391584\n",
      "epoch = 6 train_loss : 0.407080 , test loss : 0.377057\n",
      "epoch = 7 train_loss : 0.391746 , test loss : 0.365911\n",
      "epoch = 8 train_loss : 0.378936 , test loss : 0.356467\n",
      "epoch = 9 train_loss : 0.368017 , test loss : 0.348169\n",
      "epoch = 10 train_loss : 0.358169 , test loss : 0.340904\n",
      "epoch = 11 train_loss : 0.349147 , test loss : 0.333627\n",
      "epoch = 12 train_loss : 0.340938 , test loss : 0.326877\n",
      "epoch = 13 train_loss : 0.333084 , test loss : 0.320749\n",
      "epoch = 14 train_loss : 0.325972 , test loss : 0.315186\n",
      "epoch = 15 train_loss : 0.319090 , test loss : 0.309657\n",
      "epoch = 16 train_loss : 0.312263 , test loss : 0.304133\n",
      "epoch = 17 train_loss : 0.306099 , test loss : 0.299399\n",
      "epoch = 18 train_loss : 0.300240 , test loss : 0.294170\n",
      "epoch = 19 train_loss : 0.294519 , test loss : 0.289805\n",
      "epoch = 20 train_loss : 0.289090 , test loss : 0.285538\n",
      "epoch = 21 train_loss : 0.283879 , test loss : 0.281535\n",
      "epoch = 22 train_loss : 0.278844 , test loss : 0.277847\n",
      "epoch = 23 train_loss : 0.274097 , test loss : 0.273973\n",
      "epoch = 24 train_loss : 0.269532 , test loss : 0.269945\n",
      "epoch = 25 train_loss : 0.265257 , test loss : 0.266638\n",
      "epoch = 26 train_loss : 0.261193 , test loss : 0.262805\n",
      "epoch = 27 train_loss : 0.257245 , test loss : 0.259290\n",
      "epoch = 28 train_loss : 0.253462 , test loss : 0.256160\n",
      "epoch = 29 train_loss : 0.249898 , test loss : 0.253183\n",
      "epoch = 30 train_loss : 0.246462 , test loss : 0.250124\n",
      "epoch = 31 train_loss : 0.243149 , test loss : 0.247793\n",
      "epoch = 32 train_loss : 0.239943 , test loss : 0.244521\n",
      "epoch = 33 train_loss : 0.236818 , test loss : 0.242336\n",
      "epoch = 34 train_loss : 0.233844 , test loss : 0.239715\n",
      "epoch = 35 train_loss : 0.230900 , test loss : 0.237075\n",
      "epoch = 36 train_loss : 0.227986 , test loss : 0.234623\n",
      "epoch = 37 train_loss : 0.225281 , test loss : 0.232132\n",
      "epoch = 38 train_loss : 0.222545 , test loss : 0.229995\n",
      "epoch = 39 train_loss : 0.219893 , test loss : 0.227657\n",
      "epoch = 40 train_loss : 0.217297 , test loss : 0.225606\n",
      "epoch = 41 train_loss : 0.214881 , test loss : 0.223819\n",
      "epoch = 42 train_loss : 0.212483 , test loss : 0.221729\n",
      "epoch = 43 train_loss : 0.210084 , test loss : 0.219937\n",
      "epoch = 44 train_loss : 0.207762 , test loss : 0.217489\n",
      "epoch = 45 train_loss : 0.205545 , test loss : 0.215885\n",
      "epoch = 46 train_loss : 0.203484 , test loss : 0.214232\n",
      "epoch = 47 train_loss : 0.201290 , test loss : 0.212214\n",
      "epoch = 48 train_loss : 0.199191 , test loss : 0.210288\n",
      "epoch = 49 train_loss : 0.197353 , test loss : 0.208654\n",
      "epoch = 50 train_loss : 0.195274 , test loss : 0.207136\n",
      "epoch = 51 train_loss : 0.193517 , test loss : 0.206108\n",
      "epoch = 52 train_loss : 0.191609 , test loss : 0.204146\n",
      "epoch = 53 train_loss : 0.189728 , test loss : 0.202410\n",
      "epoch = 54 train_loss : 0.188218 , test loss : 0.200733\n",
      "epoch = 55 train_loss : 0.186370 , test loss : 0.199583\n",
      "epoch = 56 train_loss : 0.184676 , test loss : 0.198277\n",
      "epoch = 57 train_loss : 0.183122 , test loss : 0.197202\n",
      "epoch = 58 train_loss : 0.181499 , test loss : 0.195707\n",
      "epoch = 59 train_loss : 0.180276 , test loss : 0.193983\n",
      "epoch = 60 train_loss : 0.178598 , test loss : 0.193183\n",
      "epoch = 61 train_loss : 0.177163 , test loss : 0.191530\n",
      "epoch = 62 train_loss : 0.175789 , test loss : 0.190883\n",
      "epoch = 63 train_loss : 0.174437 , test loss : 0.189627\n",
      "epoch = 64 train_loss : 0.173159 , test loss : 0.188859\n",
      "epoch = 65 train_loss : 0.171904 , test loss : 0.187099\n",
      "epoch = 66 train_loss : 0.170717 , test loss : 0.186568\n",
      "epoch = 67 train_loss : 0.169525 , test loss : 0.185525\n",
      "epoch = 68 train_loss : 0.168439 , test loss : 0.184793\n",
      "epoch = 69 train_loss : 0.167118 , test loss : 0.183351\n",
      "epoch = 70 train_loss : 0.166004 , test loss : 0.182181\n",
      "epoch = 71 train_loss : 0.164904 , test loss : 0.181768\n",
      "epoch = 72 train_loss : 0.163858 , test loss : 0.180850\n",
      "epoch = 73 train_loss : 0.162816 , test loss : 0.180344\n",
      "epoch = 74 train_loss : 0.162030 , test loss : 0.179683\n",
      "epoch = 75 train_loss : 0.160814 , test loss : 0.178441\n",
      "epoch = 76 train_loss : 0.159921 , test loss : 0.177810\n",
      "epoch = 77 train_loss : 0.158910 , test loss : 0.177186\n",
      "epoch = 78 train_loss : 0.158567 , test loss : 0.176761\n",
      "epoch = 79 train_loss : 0.157127 , test loss : 0.176018\n",
      "epoch = 80 train_loss : 0.156309 , test loss : 0.175233\n",
      "epoch = 81 train_loss : 0.155549 , test loss : 0.174926\n",
      "epoch = 82 train_loss : 0.154676 , test loss : 0.174048\n",
      "epoch = 83 train_loss : 0.153819 , test loss : 0.173180\n",
      "epoch = 84 train_loss : 0.153006 , test loss : 0.172597\n",
      "epoch = 85 train_loss : 0.152283 , test loss : 0.172154\n",
      "epoch = 86 train_loss : 0.151705 , test loss : 0.171716\n",
      "epoch = 87 train_loss : 0.150771 , test loss : 0.171298\n",
      "epoch = 88 train_loss : 0.150199 , test loss : 0.170919\n",
      "epoch = 89 train_loss : 0.149316 , test loss : 0.170544\n",
      "epoch = 90 train_loss : 0.148606 , test loss : 0.169963\n",
      "epoch = 91 train_loss : 0.148055 , test loss : 0.169566\n",
      "epoch = 92 train_loss : 0.147307 , test loss : 0.168647\n",
      "epoch = 94 train_loss : 0.146135 , test loss : 0.168378\n",
      "epoch = 95 train_loss : 0.145715 , test loss : 0.166973\n",
      "epoch = 98 train_loss : 0.143678 , test loss : 0.166431\n",
      "epoch = 99 train_loss : 0.143135 , test loss : 0.165947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 102 train_loss : 0.141434 , test loss : 0.165588\n",
      "epoch = 103 train_loss : 0.140952 , test loss : 0.165348\n",
      "epoch = 104 train_loss : 0.140454 , test loss : 0.165090\n",
      "epoch = 105 train_loss : 0.140005 , test loss : 0.164674\n",
      "epoch = 106 train_loss : 0.139464 , test loss : 0.164411\n",
      "epoch = 107 train_loss : 0.139000 , test loss : 0.164074\n",
      "epoch = 108 train_loss : 0.138485 , test loss : 0.163481\n",
      "epoch = 111 train_loss : 0.137168 , test loss : 0.163246\n",
      "epoch = 112 train_loss : 0.136872 , test loss : 0.163185\n",
      "epoch = 113 train_loss : 0.136225 , test loss : 0.162948\n",
      "epoch = 114 train_loss : 0.135878 , test loss : 0.162920\n",
      "epoch = 115 train_loss : 0.135622 , test loss : 0.162855\n",
      "epoch = 116 train_loss : 0.135013 , test loss : 0.162301\n",
      "epoch = 117 train_loss : 0.134638 , test loss : 0.162295\n",
      "epoch = 118 train_loss : 0.134264 , test loss : 0.162101\n",
      "epoch = 119 train_loss : 0.133991 , test loss : 0.161651\n",
      "epoch = 121 train_loss : 0.133007 , test loss : 0.161467\n",
      "epoch = 123 train_loss : 0.132324 , test loss : 0.160973\n",
      "epoch = 125 train_loss : 0.131685 , test loss : 0.160968\n",
      "epoch = 126 train_loss : 0.131362 , test loss : 0.160850\n",
      "epoch = 128 train_loss : 0.130632 , test loss : 0.160720\n",
      "epoch = 130 train_loss : 0.129970 , test loss : 0.160415\n",
      "epoch = 132 train_loss : 0.129508 , test loss : 0.160089\n",
      "epoch = 134 train_loss : 0.128746 , test loss : 0.159607\n",
      "epoch = 138 train_loss : 0.127783 , test loss : 0.159551\n",
      "epoch = 143 train_loss : 0.126414 , test loss : 0.159473\n",
      "epoch = 144 train_loss : 0.126333 , test loss : 0.159339\n",
      "epoch = 148 train_loss : 0.125416 , test loss : 0.159317\n",
      "epoch = 149 train_loss : 0.125049 , test loss : 0.159133\n",
      "epoch = 153 train_loss : 0.124213 , test loss : 0.159019\n",
      "epoch = 156 train_loss : 0.123798 , test loss : 0.158791\n",
      "epoch = 160 train_loss : 0.123077 , test loss : 0.158438\n",
      "epoch = 178 train_loss : 0.120266 , test loss : 0.158433\n",
      "epoch = 180 train_loss : 0.120055 , test loss : 0.158145\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.120055,test loss : 0.158145\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.113247,total test loss mean : 0.161493 \n",
      "-----------------------------------------------------------------------------\n",
      "pred :\n",
      " [[ 1.0064764 ]\n",
      " [ 0.49801496]\n",
      " [-0.00561502]\n",
      " [ 0.27099374]\n",
      " [ 0.10155676]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.719016969203949,\n",
       "  0.5867739319801331,\n",
       "  0.5062360763549805,\n",
       "  0.4584769606590271,\n",
       "  0.42795678973197937,\n",
       "  0.40707987546920776,\n",
       "  0.39174550771713257,\n",
       "  0.378935843706131,\n",
       "  0.3680165112018585,\n",
       "  0.3581693768501282,\n",
       "  0.3491467237472534,\n",
       "  0.3409375250339508,\n",
       "  0.33308395743370056,\n",
       "  0.3259718120098114,\n",
       "  0.3190900385379791,\n",
       "  0.3122630715370178,\n",
       "  0.306098610162735,\n",
       "  0.3002399802207947,\n",
       "  0.29451921582221985,\n",
       "  0.28908973932266235,\n",
       "  0.28387880325317383,\n",
       "  0.27884432673454285,\n",
       "  0.2740970849990845,\n",
       "  0.26953208446502686,\n",
       "  0.26525694131851196,\n",
       "  0.26119303703308105,\n",
       "  0.2572445571422577,\n",
       "  0.253462016582489,\n",
       "  0.24989835917949677,\n",
       "  0.2464621663093567,\n",
       "  0.2431492805480957,\n",
       "  0.2399432212114334,\n",
       "  0.23681803047657013,\n",
       "  0.23384425044059753,\n",
       "  0.23089995980262756,\n",
       "  0.22798557579517365,\n",
       "  0.22528132796287537,\n",
       "  0.22254489362239838,\n",
       "  0.21989288926124573,\n",
       "  0.2172972410917282,\n",
       "  0.21488076448440552,\n",
       "  0.21248282492160797,\n",
       "  0.2100844383239746,\n",
       "  0.20776183903217316,\n",
       "  0.20554494857788086,\n",
       "  0.20348365604877472,\n",
       "  0.2012898474931717,\n",
       "  0.19919098913669586,\n",
       "  0.19735342264175415,\n",
       "  0.19527404010295868,\n",
       "  0.19351714849472046,\n",
       "  0.19160941243171692,\n",
       "  0.18972831964492798,\n",
       "  0.1882176399230957,\n",
       "  0.18636982142925262,\n",
       "  0.18467578291893005,\n",
       "  0.1831216663122177,\n",
       "  0.1814989596605301,\n",
       "  0.18027564883232117,\n",
       "  0.17859800159931183,\n",
       "  0.17716316878795624,\n",
       "  0.1757885366678238,\n",
       "  0.17443706095218658,\n",
       "  0.1731589138507843,\n",
       "  0.17190362513065338,\n",
       "  0.17071741819381714,\n",
       "  0.1695249080657959,\n",
       "  0.16843898594379425,\n",
       "  0.16711781919002533,\n",
       "  0.16600419580936432,\n",
       "  0.16490410268306732,\n",
       "  0.16385821998119354,\n",
       "  0.1628158688545227,\n",
       "  0.16203029453754425,\n",
       "  0.16081444919109344,\n",
       "  0.15992121398448944,\n",
       "  0.1589103490114212,\n",
       "  0.1585673838853836,\n",
       "  0.1571265310049057,\n",
       "  0.1563093066215515,\n",
       "  0.1555485725402832,\n",
       "  0.15467581152915955,\n",
       "  0.15381929278373718,\n",
       "  0.15300630033016205,\n",
       "  0.15228299796581268,\n",
       "  0.15170541405677795,\n",
       "  0.15077131986618042,\n",
       "  0.1501985341310501,\n",
       "  0.1493159830570221,\n",
       "  0.14860643446445465,\n",
       "  0.1480553299188614,\n",
       "  0.14730677008628845,\n",
       "  0.1461348533630371,\n",
       "  0.14571517705917358,\n",
       "  0.1436777561903,\n",
       "  0.14313480257987976,\n",
       "  0.14143384993076324,\n",
       "  0.14095167815685272,\n",
       "  0.1404535472393036,\n",
       "  0.14000459015369415,\n",
       "  0.13946399092674255,\n",
       "  0.13899962604045868,\n",
       "  0.13848534226417542,\n",
       "  0.13716809451580048,\n",
       "  0.13687220215797424,\n",
       "  0.13622474670410156,\n",
       "  0.1358782947063446,\n",
       "  0.13562209904193878,\n",
       "  0.1350128948688507,\n",
       "  0.13463826477527618,\n",
       "  0.1342635303735733,\n",
       "  0.1339908391237259,\n",
       "  0.13300693035125732,\n",
       "  0.13232368230819702,\n",
       "  0.13168540596961975,\n",
       "  0.13136158883571625,\n",
       "  0.1306319236755371,\n",
       "  0.12996995449066162,\n",
       "  0.12950819730758667,\n",
       "  0.12874647974967957,\n",
       "  0.12778319418430328,\n",
       "  0.12641406059265137,\n",
       "  0.12633255124092102,\n",
       "  0.12541572749614716,\n",
       "  0.12504911422729492,\n",
       "  0.12421286106109619,\n",
       "  0.1237984225153923,\n",
       "  0.12307703495025635,\n",
       "  0.12026633322238922,\n",
       "  0.12005453556776047],\n",
       " [0.6539158821105957,\n",
       "  0.524793803691864,\n",
       "  0.45293325185775757,\n",
       "  0.41451573371887207,\n",
       "  0.3915841281414032,\n",
       "  0.37705671787261963,\n",
       "  0.3659110963344574,\n",
       "  0.356466680765152,\n",
       "  0.34816890954971313,\n",
       "  0.3409040868282318,\n",
       "  0.3336274027824402,\n",
       "  0.32687684893608093,\n",
       "  0.3207489252090454,\n",
       "  0.31518635153770447,\n",
       "  0.3096572458744049,\n",
       "  0.30413293838500977,\n",
       "  0.2993992567062378,\n",
       "  0.29416993260383606,\n",
       "  0.28980493545532227,\n",
       "  0.28553763031959534,\n",
       "  0.28153473138809204,\n",
       "  0.2778465747833252,\n",
       "  0.27397289872169495,\n",
       "  0.26994502544403076,\n",
       "  0.2666381299495697,\n",
       "  0.2628054916858673,\n",
       "  0.2592901289463043,\n",
       "  0.25616002082824707,\n",
       "  0.2531825602054596,\n",
       "  0.250124454498291,\n",
       "  0.24779333174228668,\n",
       "  0.24452058970928192,\n",
       "  0.24233625829219818,\n",
       "  0.23971499502658844,\n",
       "  0.23707526922225952,\n",
       "  0.2346232384443283,\n",
       "  0.23213204741477966,\n",
       "  0.2299949824810028,\n",
       "  0.2276567667722702,\n",
       "  0.22560562193393707,\n",
       "  0.2238186001777649,\n",
       "  0.22172889113426208,\n",
       "  0.21993674337863922,\n",
       "  0.2174893021583557,\n",
       "  0.21588513255119324,\n",
       "  0.21423181891441345,\n",
       "  0.21221444010734558,\n",
       "  0.2102876454591751,\n",
       "  0.20865385234355927,\n",
       "  0.2071361094713211,\n",
       "  0.20610783994197845,\n",
       "  0.20414642989635468,\n",
       "  0.20240959525108337,\n",
       "  0.20073345303535461,\n",
       "  0.19958259165287018,\n",
       "  0.19827720522880554,\n",
       "  0.1972017139196396,\n",
       "  0.1957065314054489,\n",
       "  0.19398300349712372,\n",
       "  0.19318272173404694,\n",
       "  0.19153009355068207,\n",
       "  0.19088299572467804,\n",
       "  0.1896272599697113,\n",
       "  0.18885894119739532,\n",
       "  0.18709896504878998,\n",
       "  0.1865677386522293,\n",
       "  0.18552498519420624,\n",
       "  0.18479318916797638,\n",
       "  0.1833505481481552,\n",
       "  0.18218055367469788,\n",
       "  0.18176805973052979,\n",
       "  0.18084999918937683,\n",
       "  0.1803438365459442,\n",
       "  0.179683119058609,\n",
       "  0.1784408539533615,\n",
       "  0.17780998349189758,\n",
       "  0.177185520529747,\n",
       "  0.1767614483833313,\n",
       "  0.17601844668388367,\n",
       "  0.17523349821567535,\n",
       "  0.17492583394050598,\n",
       "  0.1740480363368988,\n",
       "  0.17318008840084076,\n",
       "  0.17259745299816132,\n",
       "  0.17215433716773987,\n",
       "  0.17171575129032135,\n",
       "  0.17129817605018616,\n",
       "  0.17091931402683258,\n",
       "  0.17054365575313568,\n",
       "  0.1699628084897995,\n",
       "  0.16956616938114166,\n",
       "  0.16864721477031708,\n",
       "  0.16837771236896515,\n",
       "  0.16697344183921814,\n",
       "  0.16643087565898895,\n",
       "  0.1659470647573471,\n",
       "  0.16558820009231567,\n",
       "  0.16534824669361115,\n",
       "  0.16508984565734863,\n",
       "  0.1646736115217209,\n",
       "  0.16441094875335693,\n",
       "  0.1640743911266327,\n",
       "  0.16348059475421906,\n",
       "  0.16324591636657715,\n",
       "  0.1631850153207779,\n",
       "  0.16294768452644348,\n",
       "  0.16291990876197815,\n",
       "  0.1628551036119461,\n",
       "  0.1623009890317917,\n",
       "  0.16229479014873505,\n",
       "  0.16210147738456726,\n",
       "  0.16165056824684143,\n",
       "  0.1614668369293213,\n",
       "  0.1609732210636139,\n",
       "  0.16096767783164978,\n",
       "  0.16085033118724823,\n",
       "  0.16072028875350952,\n",
       "  0.16041457653045654,\n",
       "  0.16008880734443665,\n",
       "  0.15960681438446045,\n",
       "  0.15955056250095367,\n",
       "  0.15947259962558746,\n",
       "  0.15933874249458313,\n",
       "  0.15931661427021027,\n",
       "  0.15913322567939758,\n",
       "  0.1590193212032318,\n",
       "  0.15879110991954803,\n",
       "  0.15843823552131653,\n",
       "  0.15843302011489868,\n",
       "  0.1581454575061798])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x44.shape[1],8),nn.ReLU(),nn.Linear(8,1))\n",
    "net1=get_net()\n",
    "y4_hat=train_kfold_pred(net1,5000,0.0001,5,x44_train,y44_train,64,0,0,x44_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
