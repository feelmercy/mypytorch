{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:01:57.716326Z",
     "start_time": "2022-04-19T02:01:57.618313Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:01:58.717953Z",
     "start_time": "2022-04-19T02:01:58.709452Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path=r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\train.csv'\n",
    "test_path=r'F:\\study\\ml\\HonyiLee2020\\hw1\\data\\test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T02:02:00.166137Z",
     "start_time": "2022-04-19T02:02:00.027619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_raw = np.loadtxt(train_path, delimiter= ',', dtype = str, skiprows = 1,encoding='big5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:43:58.491306Z",
     "start_time": "2022-01-12T02:43:58.460305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 27)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:43:59.182346Z",
     "start_time": "2022-01-12T02:43:59.101341Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_parameters = 18\n",
    "n_date = len(Counter(train_data_raw[:, 0]).keys())\n",
    "train_data_raw[train_data_raw == 'NR'] = 0\n",
    "train_data_raw = train_data_raw[:, 3:].astype(np.float64)\n",
    "train_data = train_data_raw[:n_parameters, :]\n",
    "for i in range(1, n_date):\n",
    "    temp = train_data_raw[(n_parameters * (i - 1)): (n_parameters * i), :]\n",
    "    train_data = np.hstack((train_data, temp))\n",
    "n_series = 9\n",
    "target_row = 9    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:00.363413Z",
     "start_time": "2022-01-12T02:44:00.356413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_x = np.mean(train_data, axis = 1)\n",
    "std_x = np.std(train_data, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:00.944447Z",
     "start_time": "2022-01-12T02:44:00.933446Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_parameters):\n",
    "    if std_x[i] != 0:\n",
    "        train_data[i, :] = (train_data[i, :] - mean_x[i])/std_x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:02.183517Z",
     "start_time": "2022-01-12T02:44:02.132515Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = []\n",
    "for j in range(train_data.shape[1] - n_series):\n",
    "    key = train_data[:, j:j+n_series].reshape(18*9, )\n",
    "    value = train_data[target_row, j+n_series]\n",
    "    final_data.append([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:03.315582Z",
     "start_time": "2022-01-12T02:44:03.308582Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:04.015622Z",
     "start_time": "2022-01-12T02:44:04.004622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:06.059739Z",
     "start_time": "2022-01-12T02:44:06.053739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_shape=(1,18*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:07.110799Z",
     "start_time": "2022-01-12T02:44:07.100799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5751"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:24.903817Z",
     "start_time": "2022-01-12T02:44:24.892816Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(train_data)\n",
    "test_data=train_data[:500]\n",
    "train_data = train_data[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:32.607258Z",
     "start_time": "2022-01-12T02:44:32.596257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5251"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:45.341986Z",
     "start_time": "2022-01-12T02:44:45.332985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.zeros(w_shape, dtype = float)\n",
    "b = 0\n",
    "eta = 0.0006 #learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:46.254038Z",
     "start_time": "2022-01-12T02:44:46.244038Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter = 1000 #iteration time\n",
    "train_loss = 0\n",
    "test_loss = 0\n",
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:44:49.736237Z",
     "start_time": "2022-01-12T02:44:49.724237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5251"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:46:10.849877Z",
     "start_time": "2022-01-12T02:44:52.205379Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_iter):\n",
    "    train_loss = 0\n",
    "    for j in range(len(train_data)):\n",
    "        x = train_data[j][0]\n",
    "        y = np.dot(w, x) + b\n",
    "        target = train_data[j][1]\n",
    "\n",
    "        w_gradient = 2 * (y - target) * x.T\n",
    "        b_gradient = 2 * (y - target)\n",
    "\n",
    "        w = w - eta * w_gradient\n",
    "        b = b - eta * b_gradient\n",
    "\n",
    "        train_loss += (target - y) ** 2\n",
    "\n",
    "    result.append(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:46:23.422596Z",
     "start_time": "2022-01-12T02:46:23.412595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:46:26.275759Z",
     "start_time": "2022-01-12T02:46:26.251758Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    x_train.append(i[0])\n",
    "    y_train.append(i[1])\n",
    "\n",
    "for j in test_data:\n",
    "    x_test.append(j[0])\n",
    "    y_test.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:46:28.791903Z",
     "start_time": "2022-01-12T02:46:27.972856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14577855059070804\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = linear_model.LinearRegression()\n",
    "LR.fit(x_train, y_train)\n",
    "y_pred = LR.predict(x_test)\n",
    "print(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:47:48.722475Z",
     "start_time": "2022-01-12T02:47:48.717474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:49:15.741452Z",
     "start_time": "2022-01-12T02:49:03.716764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso,ElasticNet,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:49:49.971410Z",
     "start_time": "2022-01-12T02:49:45.950180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- start ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.3594 (0.0152)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "n_folds=5\n",
    "print('-----------------------------------','start','----------------------------------------')\n",
    "lasso=make_pipeline(RobustScaler(),Lasso(alpha=0.0001,random_state=1))\n",
    "kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x_train)\n",
    "rmse=np.sqrt(-cross_val_score(lasso,x_train,y_train,scoring='neg_mean_squared_error',cv=kf))\n",
    "score=rmse\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:05.842658Z",
     "start_time": "2022-01-12T03:07:03.894547Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch import optim,nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:07.486752Z",
     "start_time": "2022-01-12T03:07:07.391747Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_k_fold_data(net,num_epochs,lr,train_features,train_labels,test_features,test_labels,batch_size,montum,wd):\n",
    "#     net=nn.Linear(train_features.shape[1],1)\n",
    "#     net=nn.Sequential(nn.Linear(train_features.shape[1],1))\n",
    "    loss=nn.MSELoss()\n",
    "#     optimizer=optim.SGD(net.parameters(),lr=lr,momentum=montum,weight_decay=wd)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=lr,weight_decay=wd)\n",
    "    dataset=torch.utils.data.TensorDataset(train_features,train_labels)\n",
    "    data_iter=torch.utils.data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    train_l,test_l=[],[]\n",
    "    \n",
    "    min_test_loss=1000\n",
    "    early_stop_cnt=0\n",
    "    train_loss,test_loss=0,0\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        net.train()\n",
    "        for x,y in data_iter:\n",
    "            l=loss(net(x),y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "#         if (e+1) %1000==0 and test_features is not  None:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss=loss(net(test_features),test_labels).item()\n",
    "            if test_loss<min_test_loss:\n",
    "                min_test_loss=test_loss\n",
    "#                 test_l.append(test_loss)\n",
    "                train_loss=loss(net(train_features),train_labels).item()\n",
    "                test_l.append(test_loss)\n",
    "                train_l.append(train_loss)\n",
    "                print('epoch = %d train_loss : %f , test loss : %f' % (e+1,train_loss,test_loss))\n",
    "                early_stop_cnt=0\n",
    "            else:\n",
    "                early_stop_cnt+=1\n",
    "        if early_stop_cnt > 500:\n",
    "            \n",
    "            break\n",
    "                \n",
    "#             net.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 train_l.append(loss(net(train_features),train_labels).item())\n",
    "#                 test_l.append(loss(net(test_features),test_labels).item())\n",
    "# #                 print('epoch ',(e+1),'train loss : ',train_l[-1],'test loss : ',test_l[-1])\n",
    "\n",
    "    return train_l,test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:07.750767Z",
     "start_time": "2022-01-12T03:07:07.714765Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kfold_data(k,j,x,y,random_state=13):\n",
    "    assert k>=1, 'k must >=1'\n",
    "    fold_size = x.shape[0] // k\n",
    "    x_train,y_train=None,None\n",
    "    row_list=list(range(x.shape[0]))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(row_list)\n",
    "    for i in range(k):\n",
    "        idx=slice(fold_size*i,fold_size*(i+1))\n",
    "        x_part,y_part=x[row_list[idx],:],y[row_list[idx],:]\n",
    "        if i==j:\n",
    "            x_val,y_val=x_part,y_part\n",
    "        elif x_train is None:\n",
    "            x_train,y_train=x_part,y_part\n",
    "        else:\n",
    "            x_train=torch.cat((x_train,x_part))\n",
    "            y_train=torch.cat((y_train,y_part))\n",
    "    return x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:08.041784Z",
     "start_time": "2022-01-12T03:07:08.002782Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_kfold(net1,num_epochs,lr,k,x_data,y_data,batch_size,montum,wd):\n",
    "    train_sum_l,test_sum_l=[],[]\n",
    "    train_l,test_l=[],[]\n",
    "#     net=nn.Linear(x_data.shape[1])\n",
    "    for j in range(k):\n",
    "        net1=get_net()\n",
    "#         for p in net1.parameters():\n",
    "#             torch.nn.init.normal_(p)\n",
    "        net=net1\n",
    "        data=get_kfold_data(k,j,x_data,y_data)\n",
    "        train_l,test_l=train_k_fold_data(net,num_epochs,lr,*data,batch_size,montum,wd)\n",
    "        train_sum_l.append(train_l[-1])\n",
    "        test_sum_l.append(test_l[-1])\n",
    "        print('--------------------------------------------------------------------------')\n",
    "        print('fold %d,train loss mean : %f,test loss : %f' % (j+1,train_l[-1],test_l[-1]))\n",
    "        print('-------------------------------------------------------------------------')\n",
    "    print('%d fold ,total train loss mean : %f,total test loss mean : %f ' % (k,np.mean(train_sum_l),np.mean(test_sum_l)))\n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:08.537812Z",
     "start_time": "2022-01-12T03:07:08.527812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5251"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:09.974895Z",
     "start_time": "2022-01-12T03:07:09.966894Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=np.empty((5251,162))\n",
    "y1=np.empty((5251,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:10.639933Z",
     "start_time": "2022-01-12T03:07:10.525926Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    x1[i,:]=x_train[i].reshape(1,-1)\n",
    "    y1[i,:]=y_train[i].reshape(1,-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:07:11.365974Z",
     "start_time": "2022-01-12T03:07:11.341973Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x11=torch.Tensor(x1)\n",
    "y11=torch.Tensor(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T03:10:47.385330Z",
     "start_time": "2022-01-12T03:07:11.970009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 train_loss : 0.330142 , test loss : 0.334362\n",
      "epoch = 2 train_loss : 0.252079 , test loss : 0.275748\n",
      "epoch = 3 train_loss : 0.212178 , test loss : 0.224603\n",
      "epoch = 4 train_loss : 0.192076 , test loss : 0.204036\n",
      "epoch = 5 train_loss : 0.175381 , test loss : 0.186812\n",
      "epoch = 6 train_loss : 0.165759 , test loss : 0.174996\n",
      "epoch = 7 train_loss : 0.153927 , test loss : 0.164367\n",
      "epoch = 9 train_loss : 0.142621 , test loss : 0.150846\n",
      "epoch = 10 train_loss : 0.141071 , test loss : 0.148699\n",
      "epoch = 11 train_loss : 0.137886 , test loss : 0.145355\n",
      "epoch = 12 train_loss : 0.140354 , test loss : 0.140552\n",
      "epoch = 14 train_loss : 0.136109 , test loss : 0.139868\n",
      "epoch = 16 train_loss : 0.130760 , test loss : 0.137073\n",
      "epoch = 17 train_loss : 0.130484 , test loss : 0.135370\n",
      "epoch = 19 train_loss : 0.129300 , test loss : 0.133484\n",
      "epoch = 20 train_loss : 0.125682 , test loss : 0.132210\n",
      "epoch = 21 train_loss : 0.126706 , test loss : 0.131220\n",
      "epoch = 33 train_loss : 0.123907 , test loss : 0.127308\n",
      "epoch = 38 train_loss : 0.124018 , test loss : 0.126433\n",
      "epoch = 43 train_loss : 0.121464 , test loss : 0.125479\n",
      "epoch = 47 train_loss : 0.121551 , test loss : 0.125460\n",
      "epoch = 48 train_loss : 0.121197 , test loss : 0.124112\n",
      "epoch = 117 train_loss : 0.120487 , test loss : 0.123134\n",
      "--------------------------------------------------------------------------\n",
      "fold 1,train loss mean : 0.120487,test loss : 0.123134\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.306533 , test loss : 0.359845\n",
      "epoch = 2 train_loss : 0.240749 , test loss : 0.280904\n",
      "epoch = 3 train_loss : 0.206381 , test loss : 0.240375\n",
      "epoch = 4 train_loss : 0.191004 , test loss : 0.224566\n",
      "epoch = 5 train_loss : 0.177881 , test loss : 0.207730\n",
      "epoch = 6 train_loss : 0.161129 , test loss : 0.192984\n",
      "epoch = 7 train_loss : 0.157869 , test loss : 0.183475\n",
      "epoch = 8 train_loss : 0.147587 , test loss : 0.172529\n",
      "epoch = 9 train_loss : 0.143842 , test loss : 0.166856\n",
      "epoch = 10 train_loss : 0.140764 , test loss : 0.165029\n",
      "epoch = 11 train_loss : 0.134777 , test loss : 0.157511\n",
      "epoch = 12 train_loss : 0.134808 , test loss : 0.154121\n",
      "epoch = 13 train_loss : 0.130582 , test loss : 0.151518\n",
      "epoch = 14 train_loss : 0.130530 , test loss : 0.149326\n",
      "epoch = 16 train_loss : 0.129805 , test loss : 0.148871\n",
      "epoch = 18 train_loss : 0.126070 , test loss : 0.145939\n",
      "epoch = 19 train_loss : 0.127184 , test loss : 0.145652\n",
      "epoch = 20 train_loss : 0.124706 , test loss : 0.142487\n",
      "epoch = 23 train_loss : 0.125111 , test loss : 0.140532\n",
      "epoch = 26 train_loss : 0.121332 , test loss : 0.138547\n",
      "epoch = 39 train_loss : 0.120479 , test loss : 0.138512\n",
      "epoch = 53 train_loss : 0.119862 , test loss : 0.137602\n",
      "epoch = 62 train_loss : 0.121311 , test loss : 0.137572\n",
      "epoch = 95 train_loss : 0.118139 , test loss : 0.137494\n",
      "epoch = 111 train_loss : 0.119041 , test loss : 0.137222\n",
      "epoch = 115 train_loss : 0.118884 , test loss : 0.136950\n",
      "epoch = 134 train_loss : 0.117303 , test loss : 0.136551\n",
      "epoch = 141 train_loss : 0.117335 , test loss : 0.136464\n",
      "epoch = 161 train_loss : 0.117286 , test loss : 0.135966\n",
      "epoch = 418 train_loss : 0.116684 , test loss : 0.135949\n",
      "epoch = 597 train_loss : 0.117068 , test loss : 0.135196\n",
      "--------------------------------------------------------------------------\n",
      "fold 2,train loss mean : 0.117068,test loss : 0.135196\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.331993 , test loss : 0.343530\n",
      "epoch = 2 train_loss : 0.250272 , test loss : 0.253589\n",
      "epoch = 3 train_loss : 0.212900 , test loss : 0.227001\n",
      "epoch = 4 train_loss : 0.191754 , test loss : 0.196870\n",
      "epoch = 5 train_loss : 0.176076 , test loss : 0.181679\n",
      "epoch = 6 train_loss : 0.171769 , test loss : 0.170373\n",
      "epoch = 7 train_loss : 0.162425 , test loss : 0.167139\n",
      "epoch = 8 train_loss : 0.151056 , test loss : 0.157358\n",
      "epoch = 9 train_loss : 0.143761 , test loss : 0.145876\n",
      "epoch = 13 train_loss : 0.139809 , test loss : 0.145377\n",
      "epoch = 14 train_loss : 0.129639 , test loss : 0.139430\n",
      "epoch = 16 train_loss : 0.132695 , test loss : 0.137753\n",
      "epoch = 17 train_loss : 0.128562 , test loss : 0.136216\n",
      "epoch = 24 train_loss : 0.123947 , test loss : 0.134510\n",
      "epoch = 32 train_loss : 0.127336 , test loss : 0.133979\n",
      "epoch = 33 train_loss : 0.122494 , test loss : 0.131287\n",
      "epoch = 43 train_loss : 0.124879 , test loss : 0.130741\n",
      "epoch = 49 train_loss : 0.122476 , test loss : 0.130262\n",
      "epoch = 54 train_loss : 0.120557 , test loss : 0.129814\n",
      "epoch = 58 train_loss : 0.120559 , test loss : 0.129284\n",
      "epoch = 112 train_loss : 0.119615 , test loss : 0.129157\n",
      "epoch = 136 train_loss : 0.120201 , test loss : 0.128178\n",
      "epoch = 263 train_loss : 0.119708 , test loss : 0.127175\n",
      "epoch = 540 train_loss : 0.119475 , test loss : 0.127097\n",
      "--------------------------------------------------------------------------\n",
      "fold 3,train loss mean : 0.119475,test loss : 0.127097\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.316263 , test loss : 0.294959\n",
      "epoch = 2 train_loss : 0.253913 , test loss : 0.238100\n",
      "epoch = 3 train_loss : 0.222804 , test loss : 0.211338\n",
      "epoch = 4 train_loss : 0.198237 , test loss : 0.191603\n",
      "epoch = 5 train_loss : 0.183561 , test loss : 0.180352\n",
      "epoch = 6 train_loss : 0.170765 , test loss : 0.167601\n",
      "epoch = 7 train_loss : 0.160289 , test loss : 0.160509\n",
      "epoch = 8 train_loss : 0.159372 , test loss : 0.159746\n",
      "epoch = 9 train_loss : 0.155185 , test loss : 0.156259\n",
      "epoch = 10 train_loss : 0.149997 , test loss : 0.150166\n",
      "epoch = 11 train_loss : 0.146187 , test loss : 0.146900\n",
      "epoch = 12 train_loss : 0.140208 , test loss : 0.140607\n",
      "epoch = 13 train_loss : 0.135788 , test loss : 0.136745\n",
      "epoch = 14 train_loss : 0.134276 , test loss : 0.133503\n",
      "epoch = 15 train_loss : 0.132732 , test loss : 0.132060\n",
      "epoch = 17 train_loss : 0.131053 , test loss : 0.128811\n",
      "epoch = 25 train_loss : 0.126121 , test loss : 0.125706\n",
      "epoch = 36 train_loss : 0.125352 , test loss : 0.125189\n",
      "epoch = 49 train_loss : 0.123183 , test loss : 0.123609\n",
      "epoch = 52 train_loss : 0.123198 , test loss : 0.123203\n",
      "epoch = 74 train_loss : 0.120995 , test loss : 0.123159\n",
      "epoch = 109 train_loss : 0.121129 , test loss : 0.123037\n",
      "epoch = 110 train_loss : 0.121856 , test loss : 0.122946\n",
      "epoch = 127 train_loss : 0.120739 , test loss : 0.122943\n",
      "epoch = 130 train_loss : 0.121957 , test loss : 0.122511\n",
      "epoch = 140 train_loss : 0.121417 , test loss : 0.121551\n",
      "--------------------------------------------------------------------------\n",
      "fold 4,train loss mean : 0.121417,test loss : 0.121551\n",
      "-------------------------------------------------------------------------\n",
      "epoch = 1 train_loss : 0.340335 , test loss : 0.337934\n",
      "epoch = 2 train_loss : 0.252316 , test loss : 0.258013\n",
      "epoch = 3 train_loss : 0.211296 , test loss : 0.220376\n",
      "epoch = 4 train_loss : 0.187701 , test loss : 0.202024\n",
      "epoch = 5 train_loss : 0.171139 , test loss : 0.187142\n",
      "epoch = 6 train_loss : 0.162941 , test loss : 0.180822\n",
      "epoch = 7 train_loss : 0.154672 , test loss : 0.169648\n",
      "epoch = 8 train_loss : 0.148878 , test loss : 0.165164\n",
      "epoch = 9 train_loss : 0.142290 , test loss : 0.158833\n",
      "epoch = 11 train_loss : 0.139080 , test loss : 0.155296\n",
      "epoch = 13 train_loss : 0.134089 , test loss : 0.151122\n",
      "epoch = 15 train_loss : 0.131682 , test loss : 0.149143\n",
      "epoch = 16 train_loss : 0.134637 , test loss : 0.148955\n",
      "epoch = 17 train_loss : 0.129252 , test loss : 0.142624\n",
      "epoch = 25 train_loss : 0.125247 , test loss : 0.142471\n",
      "epoch = 26 train_loss : 0.123146 , test loss : 0.141473\n",
      "epoch = 28 train_loss : 0.122359 , test loss : 0.139217\n",
      "epoch = 30 train_loss : 0.125020 , test loss : 0.139195\n",
      "epoch = 33 train_loss : 0.122635 , test loss : 0.137326\n",
      "epoch = 42 train_loss : 0.121382 , test loss : 0.134944\n",
      "epoch = 43 train_loss : 0.120842 , test loss : 0.134677\n",
      "epoch = 64 train_loss : 0.118680 , test loss : 0.132998\n",
      "epoch = 104 train_loss : 0.119185 , test loss : 0.132448\n",
      "epoch = 106 train_loss : 0.118662 , test loss : 0.132409\n",
      "epoch = 117 train_loss : 0.119337 , test loss : 0.131947\n",
      "epoch = 155 train_loss : 0.119252 , test loss : 0.131748\n",
      "epoch = 608 train_loss : 0.117960 , test loss : 0.131163\n",
      "epoch = 755 train_loss : 0.118187 , test loss : 0.130808\n",
      "--------------------------------------------------------------------------\n",
      "fold 5,train loss mean : 0.118187,test loss : 0.130808\n",
      "-------------------------------------------------------------------------\n",
      "5 fold ,total train loss mean : 0.119327,total test loss mean : 0.127557 \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    return nn.Sequential(nn.Linear(x11.shape[1],128),nn.Linear(128,1))\n",
    "net1=get_net()\n",
    "train_kfold(net1,1000,0.001,5,x11,y11,256,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
